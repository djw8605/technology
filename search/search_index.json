{
    "docs": [
        {
            "location": "/",
            "text": "OSG Technology Area\n\u00b6\n\n\nWelcome to the home page of the OSG Technology Team documentation area!\n\n\nIf you are looking for site administrator documentation, please visit the \nOSG Documentation page\n.\n\n\nThe Team\n\u00b6\n\n\n\n\n\n\n\n\nSoftware and Release\n\n\nTechnology\n\n\n\n\n\n\n\n\n\n\nBrian Lin (software manager)\n\n\nBrian Bockelman (manager) (15%)\n\n\n\n\n\n\nCarl Edquist\n\n\nDerek Weitzel (50%)\n\n\n\n\n\n\nDiego Davila (50%)\n\n\nDiego Davila (50%)\n\n\n\n\n\n\nEdgar Fajardo (50%)\n\n\nEdgar Fajardo (50%)\n\n\n\n\n\n\nMat Selmeci\n\n\nMarian Zvada (20%)\n\n\n\n\n\n\nTim Cartwright (5%)\n\n\n\n\n\n\n\n\nTim Theisen (release manager) (50%)\n\n\n\n\n\n\n\n\n\n\nContact Us\n\u00b6\n\n\n\n\nosg-software@opensciencegrid.org\n - General discussion amongst team members\n   (\nsubscribe\n)\n\n\nSlack channel\n - if you can't create an account, send an e-mail to \nosg-software@opensciencegrid.org\n\n\nosg-commits@cs.wisc.edu\n - Broadcast of all source code repo commits\n\n\n\n\nMeetings\n\u00b6\n\n\nWhen:\n Every Monday, 11:00 a.m. (U.S. Central)\n\nWhere:\n +1 719-284-5267, PIN #57363; \nUber Conference\n\n\nMeeting note archives can be found directly in the\n\nGitHub repository\n.",
            "title": "Home"
        },
        {
            "location": "/#osg-technology-area",
            "text": "Welcome to the home page of the OSG Technology Team documentation area!  If you are looking for site administrator documentation, please visit the  OSG Documentation page .",
            "title": "OSG Technology Area"
        },
        {
            "location": "/#the-team",
            "text": "Software and Release  Technology      Brian Lin (software manager)  Brian Bockelman (manager) (15%)    Carl Edquist  Derek Weitzel (50%)    Diego Davila (50%)  Diego Davila (50%)    Edgar Fajardo (50%)  Edgar Fajardo (50%)    Mat Selmeci  Marian Zvada (20%)    Tim Cartwright (5%)     Tim Theisen (release manager) (50%)",
            "title": "The Team"
        },
        {
            "location": "/#contact-us",
            "text": "osg-software@opensciencegrid.org  - General discussion amongst team members\n   ( subscribe )  Slack channel  - if you can't create an account, send an e-mail to  osg-software@opensciencegrid.org  osg-commits@cs.wisc.edu  - Broadcast of all source code repo commits",
            "title": "Contact Us"
        },
        {
            "location": "/#meetings",
            "text": "When:  Every Monday, 11:00 a.m. (U.S. Central) Where:  +1 719-284-5267, PIN #57363;  Uber Conference  Meeting note archives can be found directly in the GitHub repository .",
            "title": "Meetings"
        },
        {
            "location": "/software/rpm-development-guide/",
            "text": "RPM Development Guide\n\u00b6\n\n\nThis page documents technical guidelines and details about RPM development for the OSG Software Stack. The procedures, conventions, and policies defined within are used by the OSG Software Team, and are recommended to all external developers who wish to contribute to the OSG Software Stack.\n\n\nPrinciples\n\u00b6\n\n\nThe principles below guide the design and implementation of the technical details that follow.\n\n\n\n\nPackages should adhere to community standards (e.g., \nFedora Packaging Guidelines\n) when possible, and significant deviations must be documented\n\n\nEvery released package must be reproducible from data stored in our system\n\n\nSource code for software should be clearly separable from the packaging of that software\n\n\nUpstream source files (which should not be modified) should be clearly separated from files owned by the OSG Software Team\n\n\nBuilding source and binary packages from our system should be easy and efficient\n\n\nExternal developers should have a clear and effective system for developing and contributing packages\n\n\nWe should use standard tools from relevant packaging and development communities when appropriate\n\n\n\n\nContributing Packages\n\u00b6\n\n\nWe encourage all interested parties to contribute to OSG Software, and all the infrastructure described on this page should be friendly to external contributors.\n\n\n\n\nTo participate in the packaging community: You must subscribe to the \nosg-software@opensciencegrid.org\n email list. Subscribing to an OSG email list is \ndescribed here\n.\n\n\nTo create and edit packages: \nObtain access to VDT SVN\n.\n\n\nTo upload new source tarballs: You must have a cs.wisc.edu account with write access to the VDT source tarball directory. Email the osg-software list and request permission.\n\n\nTo build using the OSG's Koji build system: You must have a valid grid certificate and a Koji account. Email the osg-software list with your cert's DN and request permission.\n\n\n\n\nDevelopment Infrastructure\n\u00b6\n\n\nThis section documents most of what a developer needs to know about our RPM infrastructure:\n\n\n\n\nUpstream Source Cache \u2014 a filesystem scheme for caching upstream source files\n\n\nRevision Control System \u2014 where to get and store development files, and how they are organized\n\n\nBuild System \u2014 how to build packages from the revision control system\n\n\nYum Repository \u2014 the location and organization of our Yum repository, and how to promote packages through it\n\n\n\n\nUpstream Source Cache\n\u00b6\n\n\nOne of our principles (every released package must be reproducible from data stored in our system) creates a potential issue: If we keep all historical source data, especially upstream files like source tarballs and source RPMs, in our revision control system, we may face large checkouts and consequently long checkout and update times.\n\n\nOur solution is to cache all upstream source files in a separate filesystem area, retaining historical files indefinitely. To avoid tainting upstream files, our policy is to leave them unmodified after download.\n\n\nLocating Files in the Cache\n\u00b6\n\n\nUpstream source files are stored in the filesystem as follows:\n\n\n\n\n/p/vdt/public/html/upstream/<PACKAGE>/<VERSION>/<FILE>\n\n\n\n\nwhere:\n\n\n\n\n\n\n\n\nSymbol\n\n\nDefinition\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n<PACKAGE>\n\n\nUpstream name of the source package, or some widely accepted form thereof\n\n\nndt\n\n\n\n\n\n\n<VERSION>\n\n\nUpstream version string used to identify the release\n\n\n3.6.4\n\n\n\n\n\n\n<FILE>\n\n\nUpstream filename itself\n\n\nndt-3.6.4.tar.gz\n\n\n\n\n\n\n\n\nThe authoritative cache is the VDT webserver, which is fully backed up. The Koji build system uses this cache.\n\n\nUpstream source files are referenced from within the revision control system; see below for details.\n\n\nYou will need to know the SHA1 checksum of any files you use from the cache.  Do get it, do:\n\n\n$\n sha1sum /p/vdt/public/html/upstream/<PACKAGE>/<VERSION>/<FILE>\n\n\n\n\n\nContributing Upstream Files\n\u00b6\n\n\nYou must make sure that any new upstream source files are cached on the VDT webserver before building the package via Koji. You have two options:\n\n\n\n\nIf you have access to a UW\u2013Madison CSL machine, you can scp the source files directly into the AFS locations using that machine\n\n\nIf you do not have such access, write to the osg-software list to find someone who will post the files for you\n\n\n\n\nGit/GitHub Hosted Upstream Files\n\u00b6\n\n\nIt is also possible to pull sources and spec files from remote Git or GitHub repos instead of our source cache.\nSee the \nupstream dir info\n for more information.\n\n\nRevision Control System\n\u00b6\n\n\nAll packages that the OSG Software Team releases are checked into our Subversion repository.\n\n\nSubversion Access\n\u00b6\n\n\nOur Subversion repository is located at:\n\n\n\n\nhttps://vdt.cs.wisc.edu/svn\n\n\n\n\n\n\n\nProcedure for offsite users obtaining access to Subversion\n\n\nOr, from a UW\u2013Madison Computer Sciences machine:\n\n\n\n\nfile:///p/condor/workspaces/vdt/svn\n\n\n\n\n\n\n\nThe current SVN directory housing our native package work is \n$SVN/native/redhat\n (where \n$SVN\n is one of the ways of accessing our SVN repository above). For example, to check out the current package repository via HTTPS, do:\n\n\n[you@host]$\n svn co https://vdt.cs.wisc.edu/svn/native/redhat\n\n\n\n\n\nOSG-Owned Software\n\u00b6\n\n\nOSG-owned software goes into GitHub under the \nopensciencegrid\n organization. Files are organized as the developer sees fit.\n\n\nIt is strongly recommended that each software package include a top-level Makefile with at least the following targets:\n\n\n\n\n\n\n\n\nSymbol\n\n\nPurpose\n\n\n\n\n\n\n\n\n\n\ninstall\n\n\nInstall the software into final FHS locations rooted at \nDESTDIR\n\n\n\n\n\n\ndist\n\n\nCreate a distribution source tarball (in the current section directory) for a release\n\n\n\n\n\n\nupstream\n\n\nInstall the distribution source tarball into the upstream source cache\n\n\n\n\n\n\n\n\nPackaging Top-Level Directory Organization\n\u00b6\n\n\nThe top levels of our Subversion directory hierarchy for packaging are as follows:\n\n\n\n\nnative/redhat/<SECTION>/<PACKAGE>\n\n\n\n\nwhere:\n\n\n\n\n\n\n\n\nSymbol\n\n\nDefinition\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n<SECTION>\n\n\nDevelopment section\n\n\nStandard Subversion sections like \ntrunk\n and \nbranches/*\n\n\n\n\n\n\n<PACKAGE>\n\n\nOur standardized name for a source package\n\n\nndt\n\n\n\n\n\n\n\n\nPackage Directory Organization\n\u00b6\n\n\nWithin a source package directory, the following files (detailed in separate sections below) may exist:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nREADME\n\n\ntext file\n\n\npackage notes, by and for developers\n\n\n\n\n\n\nupstream/\n\n\ndirectory\n\n\nreferences to the upstream source cache and other kinds of upstream files\n\n\n\n\n\n\nosg/\n\n\ndirectory\n\n\noverrides and patches of upstream files, plus new files, which contribute to the final OSG source package\n\n\n\n\n\n\n\n\nREADME\n\u00b6\n\n\nThis is a free-form text file for developers to leave notes about the package. Please document anything interesting about how you procured the upstream source, the reasons for the modifications you made, or anything else people might need to know in order to maintain the package in the future. Please document the \nwhy\n, not just the \nwhat\n.\n\n\nupstream\n\u00b6\n\n\nWithin the per-package directories of the revision control system, there must be a way to refer to cached files. This is done with small text files that (a) are named consistently, and (b) contain the location of the referenced file as its contents.\n\n\nA reference file is named:\n\n\n\n\n<DESCRIPTION>.<TYPE>.source\n\n\n\n\nwhere:\n\n\n\n\n\n\n\n\nSymbol\n\n\nDefinition\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n<DESCRIPTION>\n\n\nDescriptive label of the source of the referenced file\n\n\ndeveloper\n, \nepel\n, \nemi\n\n\n\n\n\n\n<TYPE>\n\n\nType of referenced file\n\n\ntarball\n, \nsrpm\n\n\n\n\n\n\n\n\nand contain references to cached files, Git repos, and comments.\nwhich start with \n#\n and continue until the end of the line.\nIt is useful to add the source of the upstream file into a comment.\n\n\nCached files\n\u00b6\n\n\nTo reference files in the upstream source cache, use the upstream source cache path defined above,\nwithout the prefix component, followed by the sha1sum of the file:\n\n\n\n\n<PACKAGE>/<VERSION>/<FILE> sha1sum=<SHA1SUM>\n\n\n\n\nObtain the sha1sum by running the \nsha1sum\n command with the source file as an argument, i.e.\n\n\n$\n sha1sum /p/vdt/public/html/upstream/<PACKAGE>/<VERSION>/<FILE>\n\n\n\n\n\n\n\nNote\n\n\nThis feature requires OSG-Build 1.14.0 or later.\n\n\n\n\n\n\nExample\n\n\nThe reference file for \nglobus-common\n's source tarball is named \nepel.srpm.source\n and contains:\n\n\nglobus-common/16.4/globus-common-16.4-1.el6.src.rpm sha1sum=134478c56c2437c335c20636831f794b66290bec\n# Downloaded from 'http://dl.fedoraproject.org/pub/epel/6/SRPMS/globus-common-16.4-1.el6.src.rpm'\n\n\n\n\n\n\n\nGitHub repos\n\u00b6\n\n\n\n\nWarning\n\n\nOSG software policy requires that all Git and GitHub repos used for building software have mirrors at the UW.\nMany software repos under the \nopensciencegrid GitHub organization\n are already mirrored.\nIf you are uncertain, or have a new project that you want mirrored, send email to \nosg-software@opensciencegrid.org\n.\n\n\n\n\n\n\nNote\n\n\nSee also \nadvanced features for Git and GitHub repos\n.\n\n\n\n\nTo reference tags in GitHub repos, use the following syntax (all on one line):\n\n\n\n\ntype=github repo=<OWNER>/<PROJECT> tag=<TAG> hash=<HASH>\n\n\n\n\nwhere:\n\n\n\n\n\n\n\n\nSymbol\n\n\nDefinition\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n<OWNER>\n\n\nOwner of the GitHub repo\n\n\nopensciencegrid\n\n\n\n\n\n\n<PROJECT>\n\n\nName of the project\n\n\nosg-build\n\n\n\n\n\n\n<TAG>\n\n\nGit tag to use\n\n\nv1.12.2\n\n\n\n\n\n\n<HASH>\n\n\nFull 40-char Git hash of the tag\n\n\ncff50ffe812282552cedae81f3809d3cf7087a3e\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe tarball will be called \n<PROJECT>-<VERSION>.tar.gz\n where \n<VERSION>\n is \n<TAG>\n without the \nv\n prefix (if there is one).\n\n\n\n\n\n\nExample\n\n\nYou can refer to the 1.12.2 release of osg-build with this line:\n\n\ntype=github repo=opensciencegrid/osg-build tag=v1.12.2 hash=cff50ffe812282552cedae81f3809d3cf7087a3e\n\n\n\n\n\nThis results in a tarball named \nosg-build-1.12.2.tar.gz\n.\n\n\n\n\nIn addition, if the repository contains a file called \nrpm/<PROJECT>.spec\n, it will be used as the spec file for the build\n(unless overridden in the \nosg\n directory).\n\n\nGit repos\n\u00b6\n\n\n\n\nWarning\n\n\nOSG software policy requires that all Git and GitHub repos used for building software have mirrors at the UW.\nMany software repos under the \nopensciencegrid GitHub organization\n are already mirrored.\nIf you are uncertain, or have a new project that you want mirrored, send email to \nosg-software@opensciencegrid.org\n.\n\n\n\n\n\n\nNote\n\n\nYou can use a shorter syntax for GitHub repos -- see above.\n\n\nSee also \nadvanced features for Git and GitHub repos\n.\n\n\n\n\nTo reference tags in Git repos, use the following syntax (all on one line):\n\n\n\n\ntype=git url=<URL> name=<NAME> tag=<TAG> hash=<HASH>\n\n\n\n\nwhere:\n\n\n\n\n\n\n\n\nSymbol\n\n\nDefinition\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n<URL>\n\n\nLocation of the Git repo\n\n\nhttps://github.com/opensciencegrid/osg-build.git\n\n\n\n\n\n\n<NAME>\n\n\nName of the software (optional)\n\n\nosg-build\n\n\n\n\n\n\n<TAG>\n\n\nGit tag to use\n\n\nv1.11.2\n\n\n\n\n\n\n<HASH>\n\n\nFull 40-char Git hash of the tag\n\n\n5bcf48c442d21b1e8c93a468d884f84122f7cc9e\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n<NAME>\n is optional; if not present, OSG-Build will use the last component of the URL, without the \n.git\n suffix.\n\n\nThe tarball will be called \n<NAME>-<VERSION>.tar.gz\n where \n<VERSION>\n is \n<TAG>\n without the \nv\n prefix (if there is one).\n\n\n\n\n\n\nExample\n\n\nThe reference file for \nosg-build\n's repo is named \nosg.github.source\n and contains:\n\n\ntype=git url=https://github.com/opensciencegrid/osg-build.git name=osg-build tag=v1.11.2 hash=5bcf48c442d21b1e8c93a468d884f84122f7cc9e\n\n\n\n\n\nThis results in a tarball named \nosg-build-1.11.2.tar.gz\n.\n\n\n\n\nIn addition, if the repository contains a file called \nrpm/<NAME>.spec\n, it will be used as the spec file for the build\n(unless overridden in the \nosg\n directory).\n\n\nTypical workflow when building out of GitHub repos\n\u00b6\n\n\n\n\nFork the repository of the package that you would like to build\n\n\nCreate a new branch in your fork\n\n\nMake, commit, and push changes to your new branch\n\n\nIn your fork, tag the commit that you would like to build\n\n\nIn the \nupstream/osg.github.source\n, change the repo to point at your fork and tag\n\n\nAttempt a scratch build\n\n\nIf the build fails, remove the tag and repeat steps 3-6\n\n\nSubmit a PR to merge changes upstream\n\n\nTag the final version on the upstream fork\n\n\nBuild the version that will go through the normal software cycle\n\n\n\n\n\n\nNote\n\n\nPackaging-only changes should be tagged with a release number of the format \nv<version>-<release>\n, e.g. \nv3.4.23-2\n\n\n\n\nAdvanced features for Git and GitHub repos\n\u00b6\n\n\nThe following features make software development in Git and GitHub more convenient:\n\n\n\n\n\n\nSupport for RPM release numbers in Git tags:\n\n\nIf the tag for the software contains a dash, as in \nv1.12.2-1\n,\nit is assumed that the text after the dash is the RPM release instead of the software version.\nThe RPM release is not included in the tarball.\nThat is, the project \nosg-build\n with the tag \nv1.12.2-1\n will result in a tarball named \nosg-build-1.12.1.tar.gz\n,\nnot \nosg-build-1.12.1-1.tar.gz\n.\n\n\n\n\n\n\nCan specify tarball name in the .source file:\n\n\nThe new \ntarball\n attribute allows you to specify the name of the tarball and directory that the repo contents will be put into.\nThe syntax is \ntarball=<NAME>.tar.gz\n.\nThe extension must be \n.tar.gz\n, no other archive formats are supported.\nThe directory inside the tarball will then be \n<NAME>/\n.\n\n\n\n\n\n\nCan ignore hash mismatch (scratch and local builds only):\n\n\nFor local builds (rpmbuild and mock tasks) and Koji scratch builds, a hash mismatch will result in a warning.\nNon-scratch Koji builds will still consider it an error.\n\n\n\n\n\n\nCan use a branch as the tag:\n\n\nThe \ntag\n attribute can refer to a branch instead of a tag, e.g. \ntag=master\n.\n\n\n\n\n\n\nCombining the last two features can really speed up package development.\nFor example, you can use this to make scratch builds of the current master:\n\n\ntype=github repo=<OWNER>/<PROJECT> tarball=<PROJECT>-<VERSION>.tar.gz tag=master hash=0\n\n\n\n\n\nThis might also be useful as part of a continuous integration scheme (e.g. Travis-CI).\n\n\nosg\n\u00b6\n\n\nThe \nosg\n directory contains files that are owned by the OSG Software Team and that are used to create the final, released source package. It may contain a variety of development files:\n\n\n\n\nAn RPM \n.spec\n file, which overrides any spec file from a referenced source\n\n\nPatch (\n.patch\n) or replacement files, which override any same-named file from the top-level directory of a referenced source\n\n\nOther files, which must be explicitly placed into the package by the spec file\n\n\n\n\nGenerated directories\n\u00b6\n\n\nThe following directories may be generated by our build tool, \nOSG-Build\n. They are not under revision control.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n_upstream_srpm_contents/\n\n\nexpanded contents of a cached upstream source package\n\n\n\n\n\n\n_upstream_tarball_contents/\n\n\nexpanded contents of all cached upstream source tarballs\n\n\n\n\n\n\n_final_srpm_contents/\n\n\nthe final contents of the OSG source package\n\n\n\n\n\n\n_build_results/\n\n\nOSG source and binary packages resulting from a build\n\n\n\n\n\n\n_quilt/\n\n\nexpanded, patched contents of the upstream sources, as generated by the \nquilt\n tool\n\n\n\n\n\n\n\n\n_upstream_srpm_contents\n\u00b6\n\n\nThe \n_upstream_srpm_contents\n directory contains the files that are part of the upstream source package. It is a volatile record of the upstream source for developer use.\n\n\n_upstream_tarball_contents\n\u00b6\n\n\nThe \n_upstream_tarball_contents\n directory contains the files that are part of the upstream source tarballs. It is generated by the package build tool if the \n--full-extract\n option is passed. It is not used for anything by the build tool, but meant as a convenience to allow the developer to look inside the upstream sources (for making patches, etc.).\n\n\n_final_srpm_contents\n\u00b6\n\n\nThe \n_final_srpm_contents\n directory contains the final files that are part of the released source package. It is a volatile record of a build for developer use.\n\n\n_build_results\n\u00b6\n\n\nThe \n_build_results\n directory contains the source and binary RPMs that are produced by a local build. It is a volatile record of a build for developer use.\n\n\n_quilt\n\u00b6\n\n\nThe \n_quilt\n directory contains the unpacked sources after they have been patched using the \nquilt\n utility. This allows easier patch development.\n\n\nPackaging Organization Examples\n\u00b6\n\n\nUse Case 1: Packaging an Upstream Source Tarball\n\u00b6\n\n\nWhen the OSG Software Team packages an upstream source tarball, for which there is no existing package, the source tarball is referenced with a .source file and we provide a spec file and, if necessary, patches. For example, RSV is provided as a source tarball only. Its package directory contains:\n\n\n\n\nrsv/\n    osg/\n        rsv.spec\n    upstream/\n        developer.tarball.source\n\n\n\n\n\n\n\nUse Case 2: Passing Through a Source RPM\n\u00b6\n\n\nWhen the OSG Software Team simply provides a copy of an existing source RPM, it is referenced with a .source file and that is it. For example, we do not modify the \nglobus-common\n source RPM from EPEL. Its package directory contains:\n\n\n\n\nglobus-common/\n    upstream/\n        epel.srpm.source\n\n\n\n\n\n\n\nUse Case 3: Modifying a Source RPM\n\u00b6\n\n\nWhen the OSG Software Team modifies an existing source RPM, it is referenced with a .source file and then all changes to the upstream source are contained in the \nosg\n directory. For example, we use this mechanism for the \nglobus-ftp-client\n package, originally obtained from EPEL. Its package directory contains:\n\n\n\n\nglobus-ftp-client/\n    osg/\n        globus-ftp-client.spec\n        1853-ssh-bin.patch\n    upstream/\n        epel.srpm.source\n\n\n\n\n\n\n\nBuild Process\n\u00b6\n\n\n\n\nAll necessary information to create the package will be committed to the VDT source code repository (see below)\n\n\nThe \nOSG build tools\n will take those files, create a source RPM, and submit it to our Koji build system\n\n\n\n\nDevelopers may use \nrpmbuild\n and \nmock\n for faster iterative development before submitting the package to Koji. \nosg-build\n may be used as a wrapper script around \nrpmbuild\n and \nmock\n.\n\n\nOSG Software Repository\n\u00b6\n\n\nOSG Operations maintains the Yum repositories that contain our source and binary RPMs at \nhttps://repo.opensciencegrid.org/osg/\n and are mirrored at other institutions as well.\n\n\nRelease Levels\n\u00b6\n\n\nEvery package is classified into a release level based on the amount of testing it has undergone and our confidence in\nits stability.\nWhen a package is first built, it goes into the lowest level (\nosg-development\n).\nThe members of the OSG Software and Release teams may promote packages through the release levels, as per our\n\nRelease Policy page\n.\n\n\nPackaging Conventions\n\u00b6\n\n\nIn addition to adhering to the \nFedora Packaging Guidelines\n (FPG), we have a few rules and guidelines of our own:\n\n\n\n\nWhen we pass-through an RPM and make any changes to it (so it has an updated package number), we construct the version-release as follows:\n\n\nThe version of the original RPM remains unchanged\n\n\nThe release is composed of three parts: ORIGINALRELEASE.OSGRELEASE\n\n\nWe add a distro tag based on the OSG major version and OS major version, e.g. \"osg33.el6\". (Use \n%{?dist}\n in the Release field)\n\n\n\n\n\n\n\n\nExample: We copy package foobar-3.0.5-1 from somewhere. We need to patch it, so the full name-version-release (NVR) for OSG 3.3 on EL 6 becomes \nfoobar-3.0.5-1.1.osg33.el6\n Note that we added \".1.osg33.el6\" to the release number. If we update our packaging (but still base on foobar-3.0.5-1), we change to \".2.osg33.el6\". In the spec file, this would look like:\n\n\nRelease\n:\n 1.2\n%{?dist}\n\n\n\n\n\n\nPackaging for Multiple Distro Versions\n\u00b6\n\n\nConditionalizing spec files\n\u00b6\n\n\nSome packages may need different build behavior between major versions of the OS; RPM conditional statements will be used to handle this.\n\n\nThe following macros are defined:\n\n\n\n\n\n\n\n\nName\n\n\nValue (EL6)\n\n\nValue (EL7)\n\n\n\n\n\n\n\n\n\n\n%rhel\n\n\n6\n\n\n7\n\n\n\n\n\n\n%el6\n\n\n1\n\n\nundefined\n or \n0\n\n\n\n\n\n\n%el7\n\n\nundefined\n or \n0\n\n\n1\n\n\n\n\n\n\n\n\nHere's how to use them:\n\n\n%if\n 0%{?el6}\n\n# this code will be executed on EL 6 only\n\n\n%endif\n\n\n\n%if\n 0%{?el7}\n\n# this code will be executed on EL 7 only\n\n\n%endif\n\n\n\n%if\n 0%{?rhel} >= 7\n\n# this code will be executed on EL 7 and newer\n\n\n%endif\n\n\n\n\n\n\n(There does not seem to be an \n%elseif\n).\n\n\nThe syntax \n%{?el6}\n expands to the value of the \n%el6\n macro if it is defined, and to the empty string if not; the \n0\n is there to keep the condition from being empty in the \n%if\n statement if the macro is not defined.\n\n\nRenaming or Removing Packages\n\u00b6\n\n\nOccasionally we want to cause a package to be removed on update, or replaced by a package with a different name.\n\n\nFor the most part, the \nFedora Packaging Guidelines page on renames\n shows how to do that.\nThe exception is that we do not have the equivalent of a \nfedora-obsolete-packages\n package, so in order to force the removal of an entire package (not a subpackage), we have to dummy out the package instead -- see below.\n(This should be a rare situation.)\n\n\n\n\nNote\n\n\nAfter doing a rename or a removal, you must update all the packages and subpackages that require the package being removed or renamed, and change or remove the requirements as appropriate.\n\n\n\n\nTo find packages that require the old package at run time, set up a host with the OSG repos and install the \nyum-utils\n RPM.\nThen, run:\n\n\n$\n repoquery --plugins --whatrequires \n$OLDPACKAGE\n\n\n\n\n\n\nTo find packages that require the old package at build time, install \nosg-build\n, and do this from a checkout of the OSG repos:\n\n\n$\n osg-build prebuild *\n\n$\n \nfor\n srpm in */_final_srpm_contents/*.src.rpm\n;\n \ndo\n \n\\\n\n    \necho\n \n\"***** \n$srpm\n *****\"\n;\n \n\\\n\n    rpm -q --requires -p \n$srpm\n \n|\n grep -w \n$OLDPACKAGE\n;\n \n\\\n\n  \ndone\n\n\n\n\n\n\n(examine the output to avoid false matches)\n\n\n\n\nNote\n\n\nCarefully test these changes, including places where the old package may be brought in indirectly.\n\n\n\n\nDummying out a package\n\u00b6\n\n\nIn order to forcibly remove an entire package with no replacement, you have to replace the package with one that does nothing.\nThis is because there is no package that will \"obsolete\" the old package.\n\n\nDo the following for the main package and any subpackages it may have:\n\n\n\n\nChange the Summary to \"Dummy package\"\n\n\n\n\nChange the %description to:\n\n\n\n\nThis is an empty package created for $REASONS\nIt may safely be removed.\n\n\n\n\nWhere \n$REASONS\n is a description of why you need this dummy package\n\n\n\n\n\n\nRemove all Requires and Obsoletes lines\n\n\n\n\nDo not remove Provides lines\n\n\nRemove %pre and %post scriptlets\n\n\nUnless there is a good reason not to, remove %preun and %postun scriptlets\n\n\nEmpty the %files section",
            "title": "RPM Development Guide"
        },
        {
            "location": "/software/rpm-development-guide/#rpm-development-guide",
            "text": "This page documents technical guidelines and details about RPM development for the OSG Software Stack. The procedures, conventions, and policies defined within are used by the OSG Software Team, and are recommended to all external developers who wish to contribute to the OSG Software Stack.",
            "title": "RPM Development Guide"
        },
        {
            "location": "/software/rpm-development-guide/#principles",
            "text": "The principles below guide the design and implementation of the technical details that follow.   Packages should adhere to community standards (e.g.,  Fedora Packaging Guidelines ) when possible, and significant deviations must be documented  Every released package must be reproducible from data stored in our system  Source code for software should be clearly separable from the packaging of that software  Upstream source files (which should not be modified) should be clearly separated from files owned by the OSG Software Team  Building source and binary packages from our system should be easy and efficient  External developers should have a clear and effective system for developing and contributing packages  We should use standard tools from relevant packaging and development communities when appropriate",
            "title": "Principles"
        },
        {
            "location": "/software/rpm-development-guide/#contributing-packages",
            "text": "We encourage all interested parties to contribute to OSG Software, and all the infrastructure described on this page should be friendly to external contributors.   To participate in the packaging community: You must subscribe to the  osg-software@opensciencegrid.org  email list. Subscribing to an OSG email list is  described here .  To create and edit packages:  Obtain access to VDT SVN .  To upload new source tarballs: You must have a cs.wisc.edu account with write access to the VDT source tarball directory. Email the osg-software list and request permission.  To build using the OSG's Koji build system: You must have a valid grid certificate and a Koji account. Email the osg-software list with your cert's DN and request permission.",
            "title": "Contributing Packages"
        },
        {
            "location": "/software/rpm-development-guide/#development-infrastructure",
            "text": "This section documents most of what a developer needs to know about our RPM infrastructure:   Upstream Source Cache \u2014 a filesystem scheme for caching upstream source files  Revision Control System \u2014 where to get and store development files, and how they are organized  Build System \u2014 how to build packages from the revision control system  Yum Repository \u2014 the location and organization of our Yum repository, and how to promote packages through it",
            "title": "Development Infrastructure"
        },
        {
            "location": "/software/rpm-development-guide/#upstream-source-cache",
            "text": "One of our principles (every released package must be reproducible from data stored in our system) creates a potential issue: If we keep all historical source data, especially upstream files like source tarballs and source RPMs, in our revision control system, we may face large checkouts and consequently long checkout and update times.  Our solution is to cache all upstream source files in a separate filesystem area, retaining historical files indefinitely. To avoid tainting upstream files, our policy is to leave them unmodified after download.",
            "title": "Upstream Source Cache"
        },
        {
            "location": "/software/rpm-development-guide/#locating-files-in-the-cache",
            "text": "Upstream source files are stored in the filesystem as follows:   /p/vdt/public/html/upstream/<PACKAGE>/<VERSION>/<FILE>   where:     Symbol  Definition  Example      <PACKAGE>  Upstream name of the source package, or some widely accepted form thereof  ndt    <VERSION>  Upstream version string used to identify the release  3.6.4    <FILE>  Upstream filename itself  ndt-3.6.4.tar.gz     The authoritative cache is the VDT webserver, which is fully backed up. The Koji build system uses this cache.  Upstream source files are referenced from within the revision control system; see below for details.  You will need to know the SHA1 checksum of any files you use from the cache.  Do get it, do:  $  sha1sum /p/vdt/public/html/upstream/<PACKAGE>/<VERSION>/<FILE>",
            "title": "Locating Files in the Cache"
        },
        {
            "location": "/software/rpm-development-guide/#contributing-upstream-files",
            "text": "You must make sure that any new upstream source files are cached on the VDT webserver before building the package via Koji. You have two options:   If you have access to a UW\u2013Madison CSL machine, you can scp the source files directly into the AFS locations using that machine  If you do not have such access, write to the osg-software list to find someone who will post the files for you",
            "title": "Contributing Upstream Files"
        },
        {
            "location": "/software/rpm-development-guide/#gitgithub-hosted-upstream-files",
            "text": "It is also possible to pull sources and spec files from remote Git or GitHub repos instead of our source cache.\nSee the  upstream dir info  for more information.",
            "title": "Git/GitHub Hosted Upstream Files"
        },
        {
            "location": "/software/rpm-development-guide/#revision-control-system",
            "text": "All packages that the OSG Software Team releases are checked into our Subversion repository.",
            "title": "Revision Control System"
        },
        {
            "location": "/software/rpm-development-guide/#subversion-access",
            "text": "Our Subversion repository is located at:   https://vdt.cs.wisc.edu/svn   Procedure for offsite users obtaining access to Subversion  Or, from a UW\u2013Madison Computer Sciences machine:   file:///p/condor/workspaces/vdt/svn   The current SVN directory housing our native package work is  $SVN/native/redhat  (where  $SVN  is one of the ways of accessing our SVN repository above). For example, to check out the current package repository via HTTPS, do:  [you@host]$  svn co https://vdt.cs.wisc.edu/svn/native/redhat",
            "title": "Subversion Access"
        },
        {
            "location": "/software/rpm-development-guide/#osg-owned-software",
            "text": "OSG-owned software goes into GitHub under the  opensciencegrid  organization. Files are organized as the developer sees fit.  It is strongly recommended that each software package include a top-level Makefile with at least the following targets:     Symbol  Purpose      install  Install the software into final FHS locations rooted at  DESTDIR    dist  Create a distribution source tarball (in the current section directory) for a release    upstream  Install the distribution source tarball into the upstream source cache",
            "title": "OSG-Owned Software"
        },
        {
            "location": "/software/rpm-development-guide/#packaging-top-level-directory-organization",
            "text": "The top levels of our Subversion directory hierarchy for packaging are as follows:   native/redhat/<SECTION>/<PACKAGE>   where:     Symbol  Definition  Example      <SECTION>  Development section  Standard Subversion sections like  trunk  and  branches/*    <PACKAGE>  Our standardized name for a source package  ndt",
            "title": "Packaging Top-Level Directory Organization"
        },
        {
            "location": "/software/rpm-development-guide/#package-directory-organization",
            "text": "Within a source package directory, the following files (detailed in separate sections below) may exist:            README  text file  package notes, by and for developers    upstream/  directory  references to the upstream source cache and other kinds of upstream files    osg/  directory  overrides and patches of upstream files, plus new files, which contribute to the final OSG source package",
            "title": "Package Directory Organization"
        },
        {
            "location": "/software/rpm-development-guide/#readme",
            "text": "This is a free-form text file for developers to leave notes about the package. Please document anything interesting about how you procured the upstream source, the reasons for the modifications you made, or anything else people might need to know in order to maintain the package in the future. Please document the  why , not just the  what .",
            "title": "README"
        },
        {
            "location": "/software/rpm-development-guide/#upstream",
            "text": "Within the per-package directories of the revision control system, there must be a way to refer to cached files. This is done with small text files that (a) are named consistently, and (b) contain the location of the referenced file as its contents.  A reference file is named:   <DESCRIPTION>.<TYPE>.source   where:     Symbol  Definition  Example      <DESCRIPTION>  Descriptive label of the source of the referenced file  developer ,  epel ,  emi    <TYPE>  Type of referenced file  tarball ,  srpm     and contain references to cached files, Git repos, and comments.\nwhich start with  #  and continue until the end of the line.\nIt is useful to add the source of the upstream file into a comment.",
            "title": "upstream"
        },
        {
            "location": "/software/rpm-development-guide/#cached-files",
            "text": "To reference files in the upstream source cache, use the upstream source cache path defined above,\nwithout the prefix component, followed by the sha1sum of the file:   <PACKAGE>/<VERSION>/<FILE> sha1sum=<SHA1SUM>   Obtain the sha1sum by running the  sha1sum  command with the source file as an argument, i.e.  $  sha1sum /p/vdt/public/html/upstream/<PACKAGE>/<VERSION>/<FILE>   Note  This feature requires OSG-Build 1.14.0 or later.    Example  The reference file for  globus-common 's source tarball is named  epel.srpm.source  and contains:  globus-common/16.4/globus-common-16.4-1.el6.src.rpm sha1sum=134478c56c2437c335c20636831f794b66290bec\n# Downloaded from 'http://dl.fedoraproject.org/pub/epel/6/SRPMS/globus-common-16.4-1.el6.src.rpm'",
            "title": "Cached files"
        },
        {
            "location": "/software/rpm-development-guide/#github-repos",
            "text": "Warning  OSG software policy requires that all Git and GitHub repos used for building software have mirrors at the UW.\nMany software repos under the  opensciencegrid GitHub organization  are already mirrored.\nIf you are uncertain, or have a new project that you want mirrored, send email to  osg-software@opensciencegrid.org .    Note  See also  advanced features for Git and GitHub repos .   To reference tags in GitHub repos, use the following syntax (all on one line):   type=github repo=<OWNER>/<PROJECT> tag=<TAG> hash=<HASH>   where:     Symbol  Definition  Example      <OWNER>  Owner of the GitHub repo  opensciencegrid    <PROJECT>  Name of the project  osg-build    <TAG>  Git tag to use  v1.12.2    <HASH>  Full 40-char Git hash of the tag  cff50ffe812282552cedae81f3809d3cf7087a3e      Note  The tarball will be called  <PROJECT>-<VERSION>.tar.gz  where  <VERSION>  is  <TAG>  without the  v  prefix (if there is one).    Example  You can refer to the 1.12.2 release of osg-build with this line:  type=github repo=opensciencegrid/osg-build tag=v1.12.2 hash=cff50ffe812282552cedae81f3809d3cf7087a3e  This results in a tarball named  osg-build-1.12.2.tar.gz .   In addition, if the repository contains a file called  rpm/<PROJECT>.spec , it will be used as the spec file for the build\n(unless overridden in the  osg  directory).",
            "title": "GitHub repos"
        },
        {
            "location": "/software/rpm-development-guide/#git-repos",
            "text": "Warning  OSG software policy requires that all Git and GitHub repos used for building software have mirrors at the UW.\nMany software repos under the  opensciencegrid GitHub organization  are already mirrored.\nIf you are uncertain, or have a new project that you want mirrored, send email to  osg-software@opensciencegrid.org .    Note  You can use a shorter syntax for GitHub repos -- see above.  See also  advanced features for Git and GitHub repos .   To reference tags in Git repos, use the following syntax (all on one line):   type=git url=<URL> name=<NAME> tag=<TAG> hash=<HASH>   where:     Symbol  Definition  Example      <URL>  Location of the Git repo  https://github.com/opensciencegrid/osg-build.git    <NAME>  Name of the software (optional)  osg-build    <TAG>  Git tag to use  v1.11.2    <HASH>  Full 40-char Git hash of the tag  5bcf48c442d21b1e8c93a468d884f84122f7cc9e      Note  <NAME>  is optional; if not present, OSG-Build will use the last component of the URL, without the  .git  suffix.  The tarball will be called  <NAME>-<VERSION>.tar.gz  where  <VERSION>  is  <TAG>  without the  v  prefix (if there is one).    Example  The reference file for  osg-build 's repo is named  osg.github.source  and contains:  type=git url=https://github.com/opensciencegrid/osg-build.git name=osg-build tag=v1.11.2 hash=5bcf48c442d21b1e8c93a468d884f84122f7cc9e  This results in a tarball named  osg-build-1.11.2.tar.gz .   In addition, if the repository contains a file called  rpm/<NAME>.spec , it will be used as the spec file for the build\n(unless overridden in the  osg  directory).",
            "title": "Git repos"
        },
        {
            "location": "/software/rpm-development-guide/#typical-workflow-when-building-out-of-github-repos",
            "text": "Fork the repository of the package that you would like to build  Create a new branch in your fork  Make, commit, and push changes to your new branch  In your fork, tag the commit that you would like to build  In the  upstream/osg.github.source , change the repo to point at your fork and tag  Attempt a scratch build  If the build fails, remove the tag and repeat steps 3-6  Submit a PR to merge changes upstream  Tag the final version on the upstream fork  Build the version that will go through the normal software cycle    Note  Packaging-only changes should be tagged with a release number of the format  v<version>-<release> , e.g.  v3.4.23-2",
            "title": "Typical workflow when building out of GitHub repos"
        },
        {
            "location": "/software/rpm-development-guide/#advanced-features-for-git-and-github-repos",
            "text": "The following features make software development in Git and GitHub more convenient:    Support for RPM release numbers in Git tags:  If the tag for the software contains a dash, as in  v1.12.2-1 ,\nit is assumed that the text after the dash is the RPM release instead of the software version.\nThe RPM release is not included in the tarball.\nThat is, the project  osg-build  with the tag  v1.12.2-1  will result in a tarball named  osg-build-1.12.1.tar.gz ,\nnot  osg-build-1.12.1-1.tar.gz .    Can specify tarball name in the .source file:  The new  tarball  attribute allows you to specify the name of the tarball and directory that the repo contents will be put into.\nThe syntax is  tarball=<NAME>.tar.gz .\nThe extension must be  .tar.gz , no other archive formats are supported.\nThe directory inside the tarball will then be  <NAME>/ .    Can ignore hash mismatch (scratch and local builds only):  For local builds (rpmbuild and mock tasks) and Koji scratch builds, a hash mismatch will result in a warning.\nNon-scratch Koji builds will still consider it an error.    Can use a branch as the tag:  The  tag  attribute can refer to a branch instead of a tag, e.g.  tag=master .    Combining the last two features can really speed up package development.\nFor example, you can use this to make scratch builds of the current master:  type=github repo=<OWNER>/<PROJECT> tarball=<PROJECT>-<VERSION>.tar.gz tag=master hash=0  This might also be useful as part of a continuous integration scheme (e.g. Travis-CI).",
            "title": "Advanced features for Git and GitHub repos"
        },
        {
            "location": "/software/rpm-development-guide/#osg",
            "text": "The  osg  directory contains files that are owned by the OSG Software Team and that are used to create the final, released source package. It may contain a variety of development files:   An RPM  .spec  file, which overrides any spec file from a referenced source  Patch ( .patch ) or replacement files, which override any same-named file from the top-level directory of a referenced source  Other files, which must be explicitly placed into the package by the spec file",
            "title": "osg"
        },
        {
            "location": "/software/rpm-development-guide/#generated-directories",
            "text": "The following directories may be generated by our build tool,  OSG-Build . They are not under revision control.           _upstream_srpm_contents/  expanded contents of a cached upstream source package    _upstream_tarball_contents/  expanded contents of all cached upstream source tarballs    _final_srpm_contents/  the final contents of the OSG source package    _build_results/  OSG source and binary packages resulting from a build    _quilt/  expanded, patched contents of the upstream sources, as generated by the  quilt  tool",
            "title": "Generated directories"
        },
        {
            "location": "/software/rpm-development-guide/#95upstream95srpm95contents",
            "text": "The  _upstream_srpm_contents  directory contains the files that are part of the upstream source package. It is a volatile record of the upstream source for developer use.",
            "title": "_upstream_srpm_contents"
        },
        {
            "location": "/software/rpm-development-guide/#95upstream95tarball95contents",
            "text": "The  _upstream_tarball_contents  directory contains the files that are part of the upstream source tarballs. It is generated by the package build tool if the  --full-extract  option is passed. It is not used for anything by the build tool, but meant as a convenience to allow the developer to look inside the upstream sources (for making patches, etc.).",
            "title": "_upstream_tarball_contents"
        },
        {
            "location": "/software/rpm-development-guide/#95final95srpm95contents",
            "text": "The  _final_srpm_contents  directory contains the final files that are part of the released source package. It is a volatile record of a build for developer use.",
            "title": "_final_srpm_contents"
        },
        {
            "location": "/software/rpm-development-guide/#95build95results",
            "text": "The  _build_results  directory contains the source and binary RPMs that are produced by a local build. It is a volatile record of a build for developer use.",
            "title": "_build_results"
        },
        {
            "location": "/software/rpm-development-guide/#95quilt",
            "text": "The  _quilt  directory contains the unpacked sources after they have been patched using the  quilt  utility. This allows easier patch development.",
            "title": "_quilt"
        },
        {
            "location": "/software/rpm-development-guide/#packaging-organization-examples",
            "text": "",
            "title": "Packaging Organization Examples"
        },
        {
            "location": "/software/rpm-development-guide/#use-case-1-packaging-an-upstream-source-tarball",
            "text": "When the OSG Software Team packages an upstream source tarball, for which there is no existing package, the source tarball is referenced with a .source file and we provide a spec file and, if necessary, patches. For example, RSV is provided as a source tarball only. Its package directory contains:   rsv/\n    osg/\n        rsv.spec\n    upstream/\n        developer.tarball.source",
            "title": "Use Case 1: Packaging an Upstream Source Tarball"
        },
        {
            "location": "/software/rpm-development-guide/#use-case-2-passing-through-a-source-rpm",
            "text": "When the OSG Software Team simply provides a copy of an existing source RPM, it is referenced with a .source file and that is it. For example, we do not modify the  globus-common  source RPM from EPEL. Its package directory contains:   globus-common/\n    upstream/\n        epel.srpm.source",
            "title": "Use Case 2: Passing Through a Source RPM"
        },
        {
            "location": "/software/rpm-development-guide/#use-case-3-modifying-a-source-rpm",
            "text": "When the OSG Software Team modifies an existing source RPM, it is referenced with a .source file and then all changes to the upstream source are contained in the  osg  directory. For example, we use this mechanism for the  globus-ftp-client  package, originally obtained from EPEL. Its package directory contains:   globus-ftp-client/\n    osg/\n        globus-ftp-client.spec\n        1853-ssh-bin.patch\n    upstream/\n        epel.srpm.source",
            "title": "Use Case 3: Modifying a Source RPM"
        },
        {
            "location": "/software/rpm-development-guide/#build-process",
            "text": "All necessary information to create the package will be committed to the VDT source code repository (see below)  The  OSG build tools  will take those files, create a source RPM, and submit it to our Koji build system   Developers may use  rpmbuild  and  mock  for faster iterative development before submitting the package to Koji.  osg-build  may be used as a wrapper script around  rpmbuild  and  mock .",
            "title": "Build Process"
        },
        {
            "location": "/software/rpm-development-guide/#osg-software-repository",
            "text": "OSG Operations maintains the Yum repositories that contain our source and binary RPMs at  https://repo.opensciencegrid.org/osg/  and are mirrored at other institutions as well.",
            "title": "OSG Software Repository"
        },
        {
            "location": "/software/rpm-development-guide/#release-levels",
            "text": "Every package is classified into a release level based on the amount of testing it has undergone and our confidence in\nits stability.\nWhen a package is first built, it goes into the lowest level ( osg-development ).\nThe members of the OSG Software and Release teams may promote packages through the release levels, as per our Release Policy page .",
            "title": "Release Levels"
        },
        {
            "location": "/software/rpm-development-guide/#packaging-conventions",
            "text": "In addition to adhering to the  Fedora Packaging Guidelines  (FPG), we have a few rules and guidelines of our own:   When we pass-through an RPM and make any changes to it (so it has an updated package number), we construct the version-release as follows:  The version of the original RPM remains unchanged  The release is composed of three parts: ORIGINALRELEASE.OSGRELEASE  We add a distro tag based on the OSG major version and OS major version, e.g. \"osg33.el6\". (Use  %{?dist}  in the Release field)     Example: We copy package foobar-3.0.5-1 from somewhere. We need to patch it, so the full name-version-release (NVR) for OSG 3.3 on EL 6 becomes  foobar-3.0.5-1.1.osg33.el6  Note that we added \".1.osg33.el6\" to the release number. If we update our packaging (but still base on foobar-3.0.5-1), we change to \".2.osg33.el6\". In the spec file, this would look like:  Release :  1.2 %{?dist}",
            "title": "Packaging Conventions"
        },
        {
            "location": "/software/rpm-development-guide/#packaging-for-multiple-distro-versions",
            "text": "",
            "title": "Packaging for Multiple Distro Versions"
        },
        {
            "location": "/software/rpm-development-guide/#conditionalizing-spec-files",
            "text": "Some packages may need different build behavior between major versions of the OS; RPM conditional statements will be used to handle this.  The following macros are defined:     Name  Value (EL6)  Value (EL7)      %rhel  6  7    %el6  1  undefined  or  0    %el7  undefined  or  0  1     Here's how to use them:  %if  0%{?el6} # this code will be executed on EL 6 only  %endif  %if  0%{?el7} # this code will be executed on EL 7 only  %endif  %if  0%{?rhel} >= 7 # this code will be executed on EL 7 and newer  %endif   (There does not seem to be an  %elseif ).  The syntax  %{?el6}  expands to the value of the  %el6  macro if it is defined, and to the empty string if not; the  0  is there to keep the condition from being empty in the  %if  statement if the macro is not defined.",
            "title": "Conditionalizing spec files"
        },
        {
            "location": "/software/rpm-development-guide/#renaming-or-removing-packages",
            "text": "Occasionally we want to cause a package to be removed on update, or replaced by a package with a different name.  For the most part, the  Fedora Packaging Guidelines page on renames  shows how to do that.\nThe exception is that we do not have the equivalent of a  fedora-obsolete-packages  package, so in order to force the removal of an entire package (not a subpackage), we have to dummy out the package instead -- see below.\n(This should be a rare situation.)   Note  After doing a rename or a removal, you must update all the packages and subpackages that require the package being removed or renamed, and change or remove the requirements as appropriate.   To find packages that require the old package at run time, set up a host with the OSG repos and install the  yum-utils  RPM.\nThen, run:  $  repoquery --plugins --whatrequires  $OLDPACKAGE   To find packages that require the old package at build time, install  osg-build , and do this from a checkout of the OSG repos:  $  osg-build prebuild * $   for  srpm in */_final_srpm_contents/*.src.rpm ;   do   \\ \n     echo   \"*****  $srpm  *****\" ;   \\ \n    rpm -q --requires -p  $srpm   |  grep -w  $OLDPACKAGE ;   \\ \n   done   (examine the output to avoid false matches)   Note  Carefully test these changes, including places where the old package may be brought in indirectly.",
            "title": "Renaming or Removing Packages"
        },
        {
            "location": "/software/rpm-development-guide/#dummying-out-a-package",
            "text": "In order to forcibly remove an entire package with no replacement, you have to replace the package with one that does nothing.\nThis is because there is no package that will \"obsolete\" the old package.  Do the following for the main package and any subpackages it may have:   Change the Summary to \"Dummy package\"   Change the %description to:   This is an empty package created for $REASONS\nIt may safely be removed.   Where  $REASONS  is a description of why you need this dummy package    Remove all Requires and Obsoletes lines   Do not remove Provides lines  Remove %pre and %post scriptlets  Unless there is a good reason not to, remove %preun and %postun scriptlets  Empty the %files section",
            "title": "Dummying out a package"
        },
        {
            "location": "/software/osg-build-tools/",
            "text": "OSG Build Tools\n\u00b6\n\n\nThis page documents the tools used for RPM development for the OSG Software Stack. See \nthe RPM development guide\n for the principles on which these tools are based.\n\n\nThe tools are distributed in the \nosg-build\n RPM in our repositories, but can also be used from a Git clone of \nopensciencegrid/osg-build on GitHub\n.\n\n\nThis page is up-to-date as of \nosg-build\n version 1.14.1.\n\n\nThe tools\n\u00b6\n\n\nosg-build\n\u00b6\n\n\nOverview\n\u00b6\n\n\nThis is the primary tool used in building source and binary RPMs.\n\n\n\n\nosg-build <TASK> [options] <PACKAGE DIRECTORY> [...]\n\n\n\n\npackage_directory\n is a directory containing an \nosg/\n and/or an \nupstream/\n subdirectory. See \nthe RPM development guide\n for how these directories are organized.\n\n\nTasks\n\u00b6\n\n\nkoji\n\u00b6\n\n\nPrebuilds the final source package, then builds it remotely using the Koji instance hosted at UW-Madison. \nhttps://koji.opensciencegrid.org\n By default, the resulting RPMs will end up in the osg-minefield repositories based on the most recent OSG major version (e.g. 3.4). You may specify a different set of repos with \n--repo\n, described later. RPMs from the osg-minefield repositories are regularly pulled to the osg-development repositories hosted by the GOC at \nhttp://repo.opensciencegrid.org\n Unless you specify otherwise (by passing \n--el6\n, \n--el7\n or specifying a different koji tag/target), the package will be built for both el6 and el7. This is the method used to build final versions of packages you expect to ship.\n\n\nlint\n\u00b6\n\n\nPrebuilds the final source package, then runs \nrpmlint\n on it to check for various problems. You will need to have \nrpmlint\n installed. People on UW CSL machines should add \n/p/vdt/workspace/rpmlint\n to their $PATH.\n\n\nmock\n\u00b6\n\n\nPrebuilds the final source package, then builds it locally using \nmock\n, and stores the resulting source and binary RPMs in the package-specific \n_build_results\n directory.\n\n\nprebuild\n\u00b6\n\n\nPrebuilds the final source package from upstream sources (if any) and local files (if any). May create or overwrite the \n_upstream_srpm_contents\n and \n_final_srpm_contents\n directories.\n\n\nprepare\n\u00b6\n\n\nPrebuilds the final source package, then calls \nrpmbuild -bp\n on the result, extracting and patching the source files (and performing any other steps defined in the \n%prep\n section of the spec file. The resulting sources will be under \n_final_srpm_contents\n.\n\n\nrpmbuild\n\u00b6\n\n\nPrebuilds the final source package, then builds it locally using \nrpmbuild\n, and stores the resulting source and binary RPMs in the package-specific \n_build_results\n directory.\n\n\nquilt\n\u00b6\n\n\nCollects the upstream local sources and spec file, then calls \nquilt setup\n on the spec file, extracting the source files and adding the patches to a quilt series file. See \nQuilt documentation (PDF link)\n for more information on quilt; also look at the example in the Usage Patterns section below. Similar to \nprepare\n (in fact, \nquilt\n calls \nrpmbuild -bp\n behind the scenes), but the source tree is in pre-patch state, and various quilt commands can be used to apply and modify patches. Unpacks into \n_quilt\n as of \nosg-build-1.2.2\n or \n_final_srpm_contents\n in previous versions. Requires \nquilt\n. People on UW CSL machines should add \n/p/vdt/workspace/quilt/bin\n to their \n$PATH\n, and \n/p/vdt/workspace/quilt/share/man\n to their \n$MANPATH\n.\n\n\nOptions\n\u00b6\n\n\nThis section lists the command-line options.\n\n\n--help\n\u00b6\n\n\nPrints the built-in usage information and exits without doing anything else.\n\n\n--version\n\u00b6\n\n\nPrints the version of \nosg-build\n and exits without doing anything else.\n\n\nCommon Options\n\u00b6\n\n\n-a, --autoclean, --no-autoclean\n\u00b6\n\n\nBefore each build, clean out the contents of the underscore directories (_build_results, _final_srpm_contents, _upstream_srpm_contents, _upstream_tarball_contents). If the directories are not cleaned up, earlier builds of a package may interfere with later ones. \n--no-autoclean\n will disable this.\n\n\nDefault is \ntrue\n.\n\n\nHas no effect with the \n--vcs\n flag.\n\n\n-c, --cache-prefix \nprefix\n\u00b6\n\n\nSets the \nprefix\n for upstream source cache references. The prefix must be a valid URI starting with either \nhttp\n, \nhttps\n, or \nfile\n, or one of the following special values:\n\n\n\n\nAFS (corresponds to \nfile:///p/vdt/public/html/upstream\n, which is the location of the VDT cache using AFS from a UW CS machine).\n\n\nVDT (corresponds to \nhttp://vdt.cs.wisc.edu/upstream\n, which is the location of the VDT cache from off-site).\n\n\nAUTO (AFS if available, VDT if not)\n\n\n\n\nThe upstream source cache must be organized as described above. All files referenced by \n.source\n files in the affected packages must exist in the cache, or a runtime error will occur.\n\n\nDefault is \nAUTO\n.\n\n\nHas no effect with the \n--vcs\n flag.\n\n\n--el6, --el7, --redhat-release \nversion\n (Config: redhat_release)\n\u00b6\n\n\nSets the distro version to build for. This affects the %dist tag, the mock config, and the default koji tag and target (unless otherwise specified).\n\n\n--el6\n is equivalent to \n--redhat-release 6\n\n\n--el7\n is equivalent to \n--redhat-release 7\n\n\n--loglevel \nloglevel\n\u00b6\n\n\nSets the verbosity of the script. Valid values are: \ndebug\n, \ninfo\n, \nwarning\n, \nerror\n and \ncritical\n.\n\n\nDefault is \ninfo\n.\n\n\n-q, --quiet\n\u00b6\n\n\nDo not display as much information. Equivalent to \n--loglevel warning\n\n\n-v, --verbose\n\u00b6\n\n\nDisplay more information. Equivalent to \n--loglevel debug\n\n\n-w, --working-directory \npath\n\u00b6\n\n\nUse \npath\n as the root directory of the files created by the script. For example, if \npath\n is \n$HOME/working\n, and the package being built is \nndt\n, the following tree will be created:\n\n\n\n\n$HOME/working/ndt/_upstream_srpm_contents\n\n\n$HOME/working/ndt/_upstream_tarball_contents\n\n\n$HOME/working/ndt/_final_srpm_contents\n\n\n$HOME/working/ndt/_build_results\n\n\n\n\nIf \npath\n is \nTEMP\n, a randomly named directory under \n/tmp\n is used as the working directory.\n\n\nThe default setting is to use the package directory as the working directory.\n\n\nHas no effect with the \n--vcs\n flag.\n\n\nOptions specific to prebuild task\n\u00b6\n\n\n--full-extract\n\u00b6\n\n\nIf set, all upstream tarballs will be extracted into \n_upstream_tarball_contents/\n during the prebuild step. This flag is now mostly redundant with the \nprepare\n and \nquilt\n tasks.\n\n\nOptions specific to rpmbuild and mock tasks\n\u00b6\n\n\n--distro-tag \ndist\n\u00b6\n\n\nSets the distribution tag added on to the end of the release in the RPM ( \nrpmbuild\n and \nmock\n tasks only ).\n\n\nDefault is \n.osg.el6\n or \n.osg.el7\n\n\n-t, --target-arch \narch\n\u00b6\n\n\nSpecify an architecture to build packages for ( \nrpmbuild\n and \nmock\n tasks only ).\n\n\nDefault is unspecified, which builds for the current machine architecture.\n\n\nOptions specific to mock task\n\u00b6\n\n\n--mock-clean, --no-mock-clean\n\u00b6\n\n\nEnable/disable deletion of the mock buildroot after a successful build.\n\n\nDefault is \ntrue\n.\n\n\n-m, --mock-config \npath\n\u00b6\n\n\nSpecifies the \nmock\n configuration file to use. This file details how to set up the build environment used by mock for the build, including Yum repositories from which to install dependencies and certain predefined variables (e.g., the distribution tag \n%dist\n).\n\n\nSee also \n--mock-config-from-koji\n.\n\n\n--mock-config-from-koji \nbuild tag\n\u00b6\n\n\nCreates a mock config from a Koji build tag. This is the most accurate way to replicate the build environment that Koji will provide (outside of Koji). The build tag is based on the distro version (el6, el7) and the OSG major version (3.3, 3.4). For 3.4 on el6, it is: \nosg-3.4-el6-build\n Also requires the Koji command-line tools (package \nkoji\n), obtainable from the osg repositories. Since this uses koji, some of the koji-specific options may apply, namely: \n--koji-backend\n, \n--koji-login\n, and \n--koji-wrapper\n.\n\n\nOptions specific to koji task\n\u00b6\n\n\n--dry-run\n\u00b6\n\n\nDo not actually run koji, merely show the command(s) that will be run. For debugging purposes.\n\n\n--getfiles, --get-files\n\u00b6\n\n\nFor scratch builds without \n--vcs\n only. Download the resulting RPMs and logs from the build into the \n_build_results\n directory.\n\n\n-k, --kojilogin, --koji-login \nlogin\n\u00b6\n\n\nSets the login to use for the koji task. This should most likely be your CN. If not specified, will extract it from your client cert (\n~/.osg-koji/client.crt\n or \n~/.koji/client.crt\n).\n\n\n--koji-target \ntarget\n\u00b6\n\n\nThe koji target to use for building.\n\n\nDefault is \nosg-el6\n for el6 and \nosg-el7\n for el7.\n\n\n--koji-tag \ntag\n\u00b6\n\n\nThe koji tag to add packages to. See the \nKoji Workflow guide\n for more information on the terminology. The special value \nTARGET\n uses the destination tag defined in the koji target.\n\n\nDefault is \nosg-el6\n or \nosg-el7\n.\n\n\n--ktt, --koji-tag-and-target \narg\n\u00b6\n\n\nShorthand for setting both --koji-tag and --koji-target to \narg\n.\n\n\n--koji-wrapper, --no-koji-wrapper\n\u00b6\n\n\nEnable/disable use of the \nosg-koji\n wrapper script around koji. See below for a description of \nosg-koji\n.\n\n\nDefault is \ntrue\n.\n\n\n--koji-backend \nbackend\n\u00b6\n\n\nSpecifies the method osg-build will use to interface with Koji. This can be \nshell\n or \nkojilib\n.\n\n\n--wait, --no-wait, --nowait\n\u00b6\n\n\nWait for koji tasks to finish. Bad for running multiple builds in a single command, since you will have to type in your passphrase for the first one, wait for it to complete, then type in your passphrase for the second one, wait for it to complete, etc. If you want to wait for multiple tasks to finish, use the \nkoji watch-task\n command or look at the website \nhttps://koji.opensciencegrid.org\n.\n\n\n--wait\n used to be the default until \nosg-build-1.1.3\n\n\n--regen-repos\n\u00b6\n\n\nStart a \nregen-repo\n koji task on the build tag after each koji build, to update the build repository used for the next build. Not useful unless you are launching multiple builds. This enables you to launch builds that depend on each other. Doesn't work too well with \n--no-wait\n, since the next build may be started before the regen-repo task is complete. Waiting will keep the next build from being queued until the regen-repo is complete.\n\n\n--scratch, --no-scratch\n\u00b6\n\n\nPerform scratch builds. A scratch build does not go into a repository, but the name-version-release (NVR) of the created RPMs are not considered used, so the build may be modified and repeated without needing a release bump. This has the same use case as the mock task: creating packages that you want to test before releasing. If you do not have a machine with mock set up, or want to test exactly the environment that Koji provides, scratch builds might be more convenient.\n\n\n--vcs, --no-vcs, --svn, --no-svn\n\u00b6\n\n\nHave Koji check the package out from a version control system instead of creating an SRPM on the local machine and submitting that to Koji. Currently, SVN and Git are supported. If this flag is specified, you may use SVN URLs or URL@Revision pairs to specify the packages to build. You may continue specify package directories from an SVN checkout, in which case osg-build will use \nsvn info\n to find the right URL@Revision pair to use and warn you about uncommitted changes. osg-build will also warn you about an outdated working directory.\n\n\n--vcs\n defaults to \ntrue\n for non-scratch builds, and \nfalse\n for scratch builds.\n\n\n--repo=\ndestination repository\n, --upcoming\n\u00b6\n\n\nSelects the repositories (osg-3.3, upcoming, etc.) to build packages for. Currently valid repositories are:\n\n\n\n\n\n\n\n\nRepository\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nosg\n\n\nOSG Software development repos for trunk (this is the default)\n\n\n\n\n\n\nosg-3.3 (or just 3.3)\n\n\nOSG Software development repos for 3.3 branch\n\n\n\n\n\n\nupcoming\n\n\nOSG Software development repos for upcoming branch\n\n\n\n\n\n\ninternal\n\n\nOSG Software internal branch\n\n\n\n\n\n\nhcc\n\n\nHolland Computing Center (Nebraska) testing repos\n\n\n\n\n\n\n\n\n--upcoming\n is an alias for \n--repo=upcoming\n\n\nNote that the repo selection affects which VCS paths you are allowed to build from. For example, you are not allowed to build from branches/osg-3.3 (from the OSG SVN) into the 'osg' repo, or from HCC's git repositories into the 'upcoming' repo.\n\n\nkoji-tag-diff\n\u00b6\n\n\nThis script displays the differences between the latest packages in two koji tags.\n\n\nExample invocation: \nkoji-tag-diff osg-3.4-el6-development osg-3.4-el7-testing\n\n\nThis prints the packages that are in osg-3.4-el6-development but not in osg-3.4-el7-testing, or vice versa.\n\n\nosg-build-test\n\u00b6\n\n\nThis script runs automated tests for \nosg-build\n. Only a few tests have been implemented so far.\n\n\nosg-import-srpm\n\u00b6\n\n\nThis is a script to fetch an SRPM from a remote site, copy it into the upstream cache on AFS, and create an SVN package dir (if needed) with an \nupstream/*.source\n file. By default it will put downloaded files into the VDT upstream cache (/p/vdt/public/html/upstream), but you can pass \n--upstream-root=<UPSTREAM DIR>\n to put them somewhere else. If called with the \n--extract-spec\n or \n-e\n argument, it will extract the spec file from the SRPM and place it into the \nosg\n subdir in SVN. If called with the \n--diff-spec\n or \n-d\n argument, it will extract the spec file and compare it to the existing spec file in the \nosg\n subdir. \nThe script hasn't been touched in a while and needs a good deal of cleanup.\n A planned feature is to allow doing a three-way diff between the existing RPM before OSG modifications, the new RPM before OSG modifications and the existing RPM after OSG modifications.\n\n\nosg-koji\n\u00b6\n\n\nThis is a wrapper script around the \nkoji\n command line tool. It automatically specifies parameters to access the OSG's koji instance, and forces SSL authentication. It takes the same parameters as \nkoji\n and passes them on.\n\n\nAn additional command, \nosg-koji setup\n exists, which performs the following tasks:\n\n\n\n\nCreate a koji configuration in \n~/.osg-koji\n\n\nCreate a CA bundle for verifying the server.\n    Use either files in \n/etc/grid-security/certificates\n, or (if those are not found), from files downloaded from the DOEGrids and DigiCert sites.\n\n\nCreate a client cert file. This can be a symlink to your grid proxy, or it can be a file created from your grid public and private key files.\n    The location of those files can be specified by the \n--usercert\n and \n--userkey\n arguments.\n    If unspecified, \nusercert\n defaults to \n~/.globus/usercert.pem\n, and \nuserkey\n defaults to \n~/.globus/userkey.pem\n.\n\n\n\n\nosg-promote\n\u00b6\n\n\nOverview\n\u00b6\n\n\nRun this script to push packages from one set of repos to another (e.g. from development to testing), according to the OSG software promotion guidelines.\n\n\nOnce the packages are promoted, the script will generate code to cut and paste into a JIRA comment.\n\n\nSynopsis\n\u00b6\n\n\n\n\nosg-promote [-r|--route <ROUTE>]... [options] <PACKAGE OR BUILD> [...]\n\n\n\n\nExamples\n\u00b6\n\n\n\n\n\n\nPromote the latest build of \nosg-version\n to testing for the current release series  \n\n\nosg-promote -r testing osg-version\n\n\n\n\n\n\n\n\n\nPromote the latest builds of \nosg-ce\n to testing for the 3.3 and 3.4 release series  \n\n\nosg-promote -r 3.3-testing -r 3.4-testing osg-ce\n\n\n\n\n\n\n\n\n\nPromote \nosg-build-1.5.0-1\n to testing for the current release series  \n\n\nosg-promote -r testing osg-build-1.5.0-1\n\n\n\n\n\n\n\n\n\nArguments\n\u00b6\n\n\n-h\n\u00b6\n\n\nDisplay help and a list of valid routes.\n\n\npackage or build\n\u00b6\n\n\nA package (e.g. \nosg-version\n) or build (e.g. \nosg-version-3.3.0-1.osg33.el6\n) to promote. You may omit the dist tag (the \n.osg33.el6\n part).\n\n\nIf a package is specified, the most recent version of that package will be promoted.\n\n\nIf a build is specified, that build and the build that has the same \nversion\n-\nrelease\n for the other distro version(s) will be promoted. That is, if you specify the route \n3.3-testing\n and the build \nfoo-1-1\n, then \nfoo-1-1.osg33.el6\n and \nfoo-1-1.osg33.el7\n will be promoted.\n\n\nThis may be specified multiple times, to promote multiple packages. The NVRs of each set of builds for a package \nmust\n match.\n\n\n-r \nROUTE\n, --route \nROUTE\n\u00b6\n\n\nThe promotion route to use. Use \nosg-promote -h\n to get a list of valid routes. This may be specified multiple times. For example, to promote for both 3.4 and 3.3, pass \n-r 3.4-testing -r 3.3-testing\n.\n\n\nIf not specified, the \ntesting\n route is used, which corresponds to the testing route for the latest release series.\n\n\n-n, --dry-run\n\u00b6\n\n\nDo not promote, just show what would be done.\n\n\n--el6-only / --el7-only\n\u00b6\n\n\nOnly promote packages for el6 / el7.\n\n\n--no-el6 / --no-el7\n\u00b6\n\n\nDo not promote packages for el6 / el7.\n\n\n--ignore-rejects\n\u00b6\n\n\nIgnore rejections due to version mismatch between dvers or missing package for one dver.\n\n\n--regen\n\u00b6\n\n\nRegenerate the destination repos after promoting.\n\n\n-y, --assume-yes\n\u00b6\n\n\nDo not prompt before promotion.\n\n\nCommon Usage Patterns\n\u00b6\n\n\nVerify that all files necessary to build the package are in the right place\n\u00b6\n\n\nRun \nosg-build prebuild <PACKAGEDIR>\n.\n\n\nFetch and extract all source files for examination\n\u00b6\n\n\nRun \nosg-build prebuild --full-extract <PACKAGEDIR>\n. Look inside the \n_upstream_tarball_contents\n directory.\n\n\nGet a post-patch version of the upstream sources for examination\n\u00b6\n\n\nRun \nosg-build prepare <PACKAGEDIR>\n. Look inside the \n_build_results\n directory.\n\n\nSee which patches work with a new version of a package, update or remove them\n\u00b6\n\n\n\n\nPlace the new source tarball into the upstream cache, edit the version in the spec file and *.sources files as necessary\n\n\nRun \nosg-build quilt <PACKAGEDIR>\n.\n\n\nEnter the extracted sources inside the \n_final_srpm_contents\n directory. You should see a file called \nseries\n and a symlink called \npatches\n.\n\n\nType \nquilt series\n to get a list of patches in order of application.\n\n\nType \nquilt push\n to apply the next patch.\n\n\nIf the patch applies cleanly, continue.\n\n\nIf the patch applies with some fuzz, type \nquilt refresh\n to update the offsets in the patch.\n\n\nIf the patch does not apply and you wish to remove it, type \nquilt delete <PATCH NAME>\n (delete only removes it from the series file, not the disk)\n\n\nIf the patch does not apply and you wish to fix it, either type \nquilt push -f\n to interactively apply the patch, or \nquilt delete <PATCH NAME>\n the patch and use \nquilt new\n / \nquilt edit\n / \nquilt refresh\n to edit files and make a new patch from your changes. Consult the \nquilt(1)\n manpage for more info.\n\n\n\n\n\n\nIf you have a new patch, run \nquilt import <PATCHFILE>\n to add the patch to the series file, and run \nquilt push\n to apply it.\n\n\nIf you have changes to make to the source code that you want to save as a patch, type \nquilt new <PATCHNAME>\n, edit the files, type \nquilt add <FILE>\n on each file you edited, then type \nquilt refresh\n to recreate the patch.\n\n\nOnce you're all done, copy the patches in the \npatches/\n directory to the \nosg/\n dir in SVN, run \nquilt series\n to get the application order and update the spec file accordingly.\n\n\n\n\nSee if a package builds successfully for OSG 3.4\n\u00b6\n\n\n\n\nIf you have all the build dependencies of the package installed, run \nosg-build rpmbuild <PACKAGEDIR>\n. The resulting RPMs will be in the \n_build_results\n directory.\n\n\nIf you do not have all the build dependencies installed, or want to make sure you specified all of the necessary ones and the package builds from a clean environment, run \nosg-build mock --mock-config-from-koji osg-3.4-el6-build <PACKAGEDIR>\n. The resulting RPMs will be in the \n_build_results\n directory.\n\n\nIf you do not have mock installed, or want to exactly replicate the build environment in Koji, run \nosg-build koji --scratch <PACKAGEDIR>\n. You may download the resulting RPMs from kojiweb \nhttps://koji.opensciencegrid.org/koji\n or pass \n--getfiles\n to \nosg-build koji\n and they will get downloaded to the \n_build_results\n directory.\n\n\n\n\nCheck for potential errors in a package\n\u00b6\n\n\nRun \nosg-build lint <PACKAGEDIR>\n.\n\n\nCreate and test a final build of a package for all platforms for upcoming\n\u00b6\n\n\n\n\nsvn commit\n your changes in \nbranches/upcoming\n.\n\n\nType \nosg-build koji --repo=upcoming <PACKAGEDIR>\n\n\nWait for the \nosg-upcoming-minefield\n repos to be regenerated containing the new version of your package. You can run \nosg-koji wait-repo osg-upcoming-el<X>-development --build=<PACKAGENAME-VERSION-RELEASE>\n and wait for that process to finish (substitute \n6\n or \n7\n for \nX\n). Or, you can just check kojiweb \nhttps://koji.opensciencegrid.org/koji/tasks\n.\n\n\nOn your test machine, make sure the \nosg-upcoming-minefield\n repo is enabled (edit \n/etc/yum.repos.d/osg-upcoming-minefield.repo\n or \n/etc/yum.repos.d/osg-el6-upcoming-minefield.repo\n). Clean your cache (\nyum clean all; yum clean expire-cache\n).\n\n\nInstall your software, see if it works.\n\n\n\n\nPromote the latest build of a package to testing for the current OSG release series\n\u00b6\n\n\nRun \nosg-promote -r testing <PACKAGE>\n\n\nPromote the latest build of a package to testing for the 3.3 and 3.4 release series\n\u00b6\n\n\nRun \nosg-promote -r 3.3-testing -r 3.4-testing <PACKAGE>",
            "title": "OSG Build Tools"
        },
        {
            "location": "/software/osg-build-tools/#osg-build-tools",
            "text": "This page documents the tools used for RPM development for the OSG Software Stack. See  the RPM development guide  for the principles on which these tools are based.  The tools are distributed in the  osg-build  RPM in our repositories, but can also be used from a Git clone of  opensciencegrid/osg-build on GitHub .  This page is up-to-date as of  osg-build  version 1.14.1.",
            "title": "OSG Build Tools"
        },
        {
            "location": "/software/osg-build-tools/#the-tools",
            "text": "",
            "title": "The tools"
        },
        {
            "location": "/software/osg-build-tools/#osg-build",
            "text": "",
            "title": "osg-build"
        },
        {
            "location": "/software/osg-build-tools/#overview",
            "text": "This is the primary tool used in building source and binary RPMs.   osg-build <TASK> [options] <PACKAGE DIRECTORY> [...]   package_directory  is a directory containing an  osg/  and/or an  upstream/  subdirectory. See  the RPM development guide  for how these directories are organized.",
            "title": "Overview"
        },
        {
            "location": "/software/osg-build-tools/#tasks",
            "text": "",
            "title": "Tasks"
        },
        {
            "location": "/software/osg-build-tools/#koji",
            "text": "Prebuilds the final source package, then builds it remotely using the Koji instance hosted at UW-Madison.  https://koji.opensciencegrid.org  By default, the resulting RPMs will end up in the osg-minefield repositories based on the most recent OSG major version (e.g. 3.4). You may specify a different set of repos with  --repo , described later. RPMs from the osg-minefield repositories are regularly pulled to the osg-development repositories hosted by the GOC at  http://repo.opensciencegrid.org  Unless you specify otherwise (by passing  --el6 ,  --el7  or specifying a different koji tag/target), the package will be built for both el6 and el7. This is the method used to build final versions of packages you expect to ship.",
            "title": "koji"
        },
        {
            "location": "/software/osg-build-tools/#lint",
            "text": "Prebuilds the final source package, then runs  rpmlint  on it to check for various problems. You will need to have  rpmlint  installed. People on UW CSL machines should add  /p/vdt/workspace/rpmlint  to their $PATH.",
            "title": "lint"
        },
        {
            "location": "/software/osg-build-tools/#mock",
            "text": "Prebuilds the final source package, then builds it locally using  mock , and stores the resulting source and binary RPMs in the package-specific  _build_results  directory.",
            "title": "mock"
        },
        {
            "location": "/software/osg-build-tools/#prebuild",
            "text": "Prebuilds the final source package from upstream sources (if any) and local files (if any). May create or overwrite the  _upstream_srpm_contents  and  _final_srpm_contents  directories.",
            "title": "prebuild"
        },
        {
            "location": "/software/osg-build-tools/#prepare",
            "text": "Prebuilds the final source package, then calls  rpmbuild -bp  on the result, extracting and patching the source files (and performing any other steps defined in the  %prep  section of the spec file. The resulting sources will be under  _final_srpm_contents .",
            "title": "prepare"
        },
        {
            "location": "/software/osg-build-tools/#rpmbuild",
            "text": "Prebuilds the final source package, then builds it locally using  rpmbuild , and stores the resulting source and binary RPMs in the package-specific  _build_results  directory.",
            "title": "rpmbuild"
        },
        {
            "location": "/software/osg-build-tools/#quilt",
            "text": "Collects the upstream local sources and spec file, then calls  quilt setup  on the spec file, extracting the source files and adding the patches to a quilt series file. See  Quilt documentation (PDF link)  for more information on quilt; also look at the example in the Usage Patterns section below. Similar to  prepare  (in fact,  quilt  calls  rpmbuild -bp  behind the scenes), but the source tree is in pre-patch state, and various quilt commands can be used to apply and modify patches. Unpacks into  _quilt  as of  osg-build-1.2.2  or  _final_srpm_contents  in previous versions. Requires  quilt . People on UW CSL machines should add  /p/vdt/workspace/quilt/bin  to their  $PATH , and  /p/vdt/workspace/quilt/share/man  to their  $MANPATH .",
            "title": "quilt"
        },
        {
            "location": "/software/osg-build-tools/#options",
            "text": "This section lists the command-line options.",
            "title": "Options"
        },
        {
            "location": "/software/osg-build-tools/#-help",
            "text": "Prints the built-in usage information and exits without doing anything else.",
            "title": "--help"
        },
        {
            "location": "/software/osg-build-tools/#-version",
            "text": "Prints the version of  osg-build  and exits without doing anything else.",
            "title": "--version"
        },
        {
            "location": "/software/osg-build-tools/#common-options",
            "text": "",
            "title": "Common Options"
        },
        {
            "location": "/software/osg-build-tools/#-a-autoclean-no-autoclean",
            "text": "Before each build, clean out the contents of the underscore directories (_build_results, _final_srpm_contents, _upstream_srpm_contents, _upstream_tarball_contents). If the directories are not cleaned up, earlier builds of a package may interfere with later ones.  --no-autoclean  will disable this.  Default is  true .  Has no effect with the  --vcs  flag.",
            "title": "-a, --autoclean, --no-autoclean"
        },
        {
            "location": "/software/osg-build-tools/#-c-cache-prefix-prefix",
            "text": "Sets the  prefix  for upstream source cache references. The prefix must be a valid URI starting with either  http ,  https , or  file , or one of the following special values:   AFS (corresponds to  file:///p/vdt/public/html/upstream , which is the location of the VDT cache using AFS from a UW CS machine).  VDT (corresponds to  http://vdt.cs.wisc.edu/upstream , which is the location of the VDT cache from off-site).  AUTO (AFS if available, VDT if not)   The upstream source cache must be organized as described above. All files referenced by  .source  files in the affected packages must exist in the cache, or a runtime error will occur.  Default is  AUTO .  Has no effect with the  --vcs  flag.",
            "title": "-c, --cache-prefix prefix"
        },
        {
            "location": "/software/osg-build-tools/#-el6-el7-redhat-release-version-config-redhat95release",
            "text": "Sets the distro version to build for. This affects the %dist tag, the mock config, and the default koji tag and target (unless otherwise specified).  --el6  is equivalent to  --redhat-release 6  --el7  is equivalent to  --redhat-release 7",
            "title": "--el6, --el7, --redhat-release version (Config: redhat_release)"
        },
        {
            "location": "/software/osg-build-tools/#-loglevel-loglevel",
            "text": "Sets the verbosity of the script. Valid values are:  debug ,  info ,  warning ,  error  and  critical .  Default is  info .",
            "title": "--loglevel loglevel"
        },
        {
            "location": "/software/osg-build-tools/#-q-quiet",
            "text": "Do not display as much information. Equivalent to  --loglevel warning",
            "title": "-q, --quiet"
        },
        {
            "location": "/software/osg-build-tools/#-v-verbose",
            "text": "Display more information. Equivalent to  --loglevel debug",
            "title": "-v, --verbose"
        },
        {
            "location": "/software/osg-build-tools/#-w-working-directory-path",
            "text": "Use  path  as the root directory of the files created by the script. For example, if  path  is  $HOME/working , and the package being built is  ndt , the following tree will be created:   $HOME/working/ndt/_upstream_srpm_contents  $HOME/working/ndt/_upstream_tarball_contents  $HOME/working/ndt/_final_srpm_contents  $HOME/working/ndt/_build_results   If  path  is  TEMP , a randomly named directory under  /tmp  is used as the working directory.  The default setting is to use the package directory as the working directory.  Has no effect with the  --vcs  flag.",
            "title": "-w, --working-directory path"
        },
        {
            "location": "/software/osg-build-tools/#options-specific-to-prebuild-task",
            "text": "",
            "title": "Options specific to prebuild task"
        },
        {
            "location": "/software/osg-build-tools/#-full-extract",
            "text": "If set, all upstream tarballs will be extracted into  _upstream_tarball_contents/  during the prebuild step. This flag is now mostly redundant with the  prepare  and  quilt  tasks.",
            "title": "--full-extract"
        },
        {
            "location": "/software/osg-build-tools/#options-specific-to-rpmbuild-and-mock-tasks",
            "text": "",
            "title": "Options specific to rpmbuild and mock tasks"
        },
        {
            "location": "/software/osg-build-tools/#-distro-tag-dist",
            "text": "Sets the distribution tag added on to the end of the release in the RPM (  rpmbuild  and  mock  tasks only ).  Default is  .osg.el6  or  .osg.el7",
            "title": "--distro-tag dist"
        },
        {
            "location": "/software/osg-build-tools/#-t-target-arch-arch",
            "text": "Specify an architecture to build packages for (  rpmbuild  and  mock  tasks only ).  Default is unspecified, which builds for the current machine architecture.",
            "title": "-t, --target-arch arch"
        },
        {
            "location": "/software/osg-build-tools/#options-specific-to-mock-task",
            "text": "",
            "title": "Options specific to mock task"
        },
        {
            "location": "/software/osg-build-tools/#-mock-clean-no-mock-clean",
            "text": "Enable/disable deletion of the mock buildroot after a successful build.  Default is  true .",
            "title": "--mock-clean, --no-mock-clean"
        },
        {
            "location": "/software/osg-build-tools/#-m-mock-config-path",
            "text": "Specifies the  mock  configuration file to use. This file details how to set up the build environment used by mock for the build, including Yum repositories from which to install dependencies and certain predefined variables (e.g., the distribution tag  %dist ).  See also  --mock-config-from-koji .",
            "title": "-m, --mock-config path"
        },
        {
            "location": "/software/osg-build-tools/#-mock-config-from-koji-build-tag",
            "text": "Creates a mock config from a Koji build tag. This is the most accurate way to replicate the build environment that Koji will provide (outside of Koji). The build tag is based on the distro version (el6, el7) and the OSG major version (3.3, 3.4). For 3.4 on el6, it is:  osg-3.4-el6-build  Also requires the Koji command-line tools (package  koji ), obtainable from the osg repositories. Since this uses koji, some of the koji-specific options may apply, namely:  --koji-backend ,  --koji-login , and  --koji-wrapper .",
            "title": "--mock-config-from-koji build tag"
        },
        {
            "location": "/software/osg-build-tools/#options-specific-to-koji-task",
            "text": "",
            "title": "Options specific to koji task"
        },
        {
            "location": "/software/osg-build-tools/#-dry-run",
            "text": "Do not actually run koji, merely show the command(s) that will be run. For debugging purposes.",
            "title": "--dry-run"
        },
        {
            "location": "/software/osg-build-tools/#-getfiles-get-files",
            "text": "For scratch builds without  --vcs  only. Download the resulting RPMs and logs from the build into the  _build_results  directory.",
            "title": "--getfiles, --get-files"
        },
        {
            "location": "/software/osg-build-tools/#-k-kojilogin-koji-login-login",
            "text": "Sets the login to use for the koji task. This should most likely be your CN. If not specified, will extract it from your client cert ( ~/.osg-koji/client.crt  or  ~/.koji/client.crt ).",
            "title": "-k, --kojilogin, --koji-login login"
        },
        {
            "location": "/software/osg-build-tools/#-koji-target-target",
            "text": "The koji target to use for building.  Default is  osg-el6  for el6 and  osg-el7  for el7.",
            "title": "--koji-target target"
        },
        {
            "location": "/software/osg-build-tools/#-koji-tag-tag",
            "text": "The koji tag to add packages to. See the  Koji Workflow guide  for more information on the terminology. The special value  TARGET  uses the destination tag defined in the koji target.  Default is  osg-el6  or  osg-el7 .",
            "title": "--koji-tag tag"
        },
        {
            "location": "/software/osg-build-tools/#-ktt-koji-tag-and-target-arg",
            "text": "Shorthand for setting both --koji-tag and --koji-target to  arg .",
            "title": "--ktt, --koji-tag-and-target arg"
        },
        {
            "location": "/software/osg-build-tools/#-koji-wrapper-no-koji-wrapper",
            "text": "Enable/disable use of the  osg-koji  wrapper script around koji. See below for a description of  osg-koji .  Default is  true .",
            "title": "--koji-wrapper, --no-koji-wrapper"
        },
        {
            "location": "/software/osg-build-tools/#-koji-backend-backend",
            "text": "Specifies the method osg-build will use to interface with Koji. This can be  shell  or  kojilib .",
            "title": "--koji-backend backend"
        },
        {
            "location": "/software/osg-build-tools/#-wait-no-wait-nowait",
            "text": "Wait for koji tasks to finish. Bad for running multiple builds in a single command, since you will have to type in your passphrase for the first one, wait for it to complete, then type in your passphrase for the second one, wait for it to complete, etc. If you want to wait for multiple tasks to finish, use the  koji watch-task  command or look at the website  https://koji.opensciencegrid.org .  --wait  used to be the default until  osg-build-1.1.3",
            "title": "--wait, --no-wait, --nowait"
        },
        {
            "location": "/software/osg-build-tools/#-regen-repos",
            "text": "Start a  regen-repo  koji task on the build tag after each koji build, to update the build repository used for the next build. Not useful unless you are launching multiple builds. This enables you to launch builds that depend on each other. Doesn't work too well with  --no-wait , since the next build may be started before the regen-repo task is complete. Waiting will keep the next build from being queued until the regen-repo is complete.",
            "title": "--regen-repos"
        },
        {
            "location": "/software/osg-build-tools/#-scratch-no-scratch",
            "text": "Perform scratch builds. A scratch build does not go into a repository, but the name-version-release (NVR) of the created RPMs are not considered used, so the build may be modified and repeated without needing a release bump. This has the same use case as the mock task: creating packages that you want to test before releasing. If you do not have a machine with mock set up, or want to test exactly the environment that Koji provides, scratch builds might be more convenient.",
            "title": "--scratch, --no-scratch"
        },
        {
            "location": "/software/osg-build-tools/#-vcs-no-vcs-svn-no-svn",
            "text": "Have Koji check the package out from a version control system instead of creating an SRPM on the local machine and submitting that to Koji. Currently, SVN and Git are supported. If this flag is specified, you may use SVN URLs or URL@Revision pairs to specify the packages to build. You may continue specify package directories from an SVN checkout, in which case osg-build will use  svn info  to find the right URL@Revision pair to use and warn you about uncommitted changes. osg-build will also warn you about an outdated working directory.  --vcs  defaults to  true  for non-scratch builds, and  false  for scratch builds.",
            "title": "--vcs, --no-vcs, --svn, --no-svn"
        },
        {
            "location": "/software/osg-build-tools/#-repodestination-repository-upcoming",
            "text": "Selects the repositories (osg-3.3, upcoming, etc.) to build packages for. Currently valid repositories are:     Repository  Description      osg  OSG Software development repos for trunk (this is the default)    osg-3.3 (or just 3.3)  OSG Software development repos for 3.3 branch    upcoming  OSG Software development repos for upcoming branch    internal  OSG Software internal branch    hcc  Holland Computing Center (Nebraska) testing repos     --upcoming  is an alias for  --repo=upcoming  Note that the repo selection affects which VCS paths you are allowed to build from. For example, you are not allowed to build from branches/osg-3.3 (from the OSG SVN) into the 'osg' repo, or from HCC's git repositories into the 'upcoming' repo.",
            "title": "--repo=destination repository, --upcoming"
        },
        {
            "location": "/software/osg-build-tools/#koji-tag-diff",
            "text": "This script displays the differences between the latest packages in two koji tags.  Example invocation:  koji-tag-diff osg-3.4-el6-development osg-3.4-el7-testing  This prints the packages that are in osg-3.4-el6-development but not in osg-3.4-el7-testing, or vice versa.",
            "title": "koji-tag-diff"
        },
        {
            "location": "/software/osg-build-tools/#osg-build-test",
            "text": "This script runs automated tests for  osg-build . Only a few tests have been implemented so far.",
            "title": "osg-build-test"
        },
        {
            "location": "/software/osg-build-tools/#osg-import-srpm",
            "text": "This is a script to fetch an SRPM from a remote site, copy it into the upstream cache on AFS, and create an SVN package dir (if needed) with an  upstream/*.source  file. By default it will put downloaded files into the VDT upstream cache (/p/vdt/public/html/upstream), but you can pass  --upstream-root=<UPSTREAM DIR>  to put them somewhere else. If called with the  --extract-spec  or  -e  argument, it will extract the spec file from the SRPM and place it into the  osg  subdir in SVN. If called with the  --diff-spec  or  -d  argument, it will extract the spec file and compare it to the existing spec file in the  osg  subdir.  The script hasn't been touched in a while and needs a good deal of cleanup.  A planned feature is to allow doing a three-way diff between the existing RPM before OSG modifications, the new RPM before OSG modifications and the existing RPM after OSG modifications.",
            "title": "osg-import-srpm"
        },
        {
            "location": "/software/osg-build-tools/#osg-koji",
            "text": "This is a wrapper script around the  koji  command line tool. It automatically specifies parameters to access the OSG's koji instance, and forces SSL authentication. It takes the same parameters as  koji  and passes them on.  An additional command,  osg-koji setup  exists, which performs the following tasks:   Create a koji configuration in  ~/.osg-koji  Create a CA bundle for verifying the server.\n    Use either files in  /etc/grid-security/certificates , or (if those are not found), from files downloaded from the DOEGrids and DigiCert sites.  Create a client cert file. This can be a symlink to your grid proxy, or it can be a file created from your grid public and private key files.\n    The location of those files can be specified by the  --usercert  and  --userkey  arguments.\n    If unspecified,  usercert  defaults to  ~/.globus/usercert.pem , and  userkey  defaults to  ~/.globus/userkey.pem .",
            "title": "osg-koji"
        },
        {
            "location": "/software/osg-build-tools/#osg-promote",
            "text": "",
            "title": "osg-promote"
        },
        {
            "location": "/software/osg-build-tools/#overview_1",
            "text": "Run this script to push packages from one set of repos to another (e.g. from development to testing), according to the OSG software promotion guidelines.  Once the packages are promoted, the script will generate code to cut and paste into a JIRA comment.",
            "title": "Overview"
        },
        {
            "location": "/software/osg-build-tools/#synopsis",
            "text": "osg-promote [-r|--route <ROUTE>]... [options] <PACKAGE OR BUILD> [...]",
            "title": "Synopsis"
        },
        {
            "location": "/software/osg-build-tools/#examples",
            "text": "Promote the latest build of  osg-version  to testing for the current release series    osg-promote -r testing osg-version    Promote the latest builds of  osg-ce  to testing for the 3.3 and 3.4 release series    osg-promote -r 3.3-testing -r 3.4-testing osg-ce    Promote  osg-build-1.5.0-1  to testing for the current release series    osg-promote -r testing osg-build-1.5.0-1",
            "title": "Examples"
        },
        {
            "location": "/software/osg-build-tools/#arguments",
            "text": "",
            "title": "Arguments"
        },
        {
            "location": "/software/osg-build-tools/#-h",
            "text": "Display help and a list of valid routes.",
            "title": "-h"
        },
        {
            "location": "/software/osg-build-tools/#package-or-build",
            "text": "A package (e.g.  osg-version ) or build (e.g.  osg-version-3.3.0-1.osg33.el6 ) to promote. You may omit the dist tag (the  .osg33.el6  part).  If a package is specified, the most recent version of that package will be promoted.  If a build is specified, that build and the build that has the same  version - release  for the other distro version(s) will be promoted. That is, if you specify the route  3.3-testing  and the build  foo-1-1 , then  foo-1-1.osg33.el6  and  foo-1-1.osg33.el7  will be promoted.  This may be specified multiple times, to promote multiple packages. The NVRs of each set of builds for a package  must  match.",
            "title": "package or build"
        },
        {
            "location": "/software/osg-build-tools/#-r-route-route-route",
            "text": "The promotion route to use. Use  osg-promote -h  to get a list of valid routes. This may be specified multiple times. For example, to promote for both 3.4 and 3.3, pass  -r 3.4-testing -r 3.3-testing .  If not specified, the  testing  route is used, which corresponds to the testing route for the latest release series.",
            "title": "-r ROUTE, --route ROUTE"
        },
        {
            "location": "/software/osg-build-tools/#-n-dry-run",
            "text": "Do not promote, just show what would be done.",
            "title": "-n, --dry-run"
        },
        {
            "location": "/software/osg-build-tools/#-el6-only-el7-only",
            "text": "Only promote packages for el6 / el7.",
            "title": "--el6-only / --el7-only"
        },
        {
            "location": "/software/osg-build-tools/#-no-el6-no-el7",
            "text": "Do not promote packages for el6 / el7.",
            "title": "--no-el6 / --no-el7"
        },
        {
            "location": "/software/osg-build-tools/#-ignore-rejects",
            "text": "Ignore rejections due to version mismatch between dvers or missing package for one dver.",
            "title": "--ignore-rejects"
        },
        {
            "location": "/software/osg-build-tools/#-regen",
            "text": "Regenerate the destination repos after promoting.",
            "title": "--regen"
        },
        {
            "location": "/software/osg-build-tools/#-y-assume-yes",
            "text": "Do not prompt before promotion.",
            "title": "-y, --assume-yes"
        },
        {
            "location": "/software/osg-build-tools/#common-usage-patterns",
            "text": "",
            "title": "Common Usage Patterns"
        },
        {
            "location": "/software/osg-build-tools/#verify-that-all-files-necessary-to-build-the-package-are-in-the-right-place",
            "text": "Run  osg-build prebuild <PACKAGEDIR> .",
            "title": "Verify that all files necessary to build the package are in the right place"
        },
        {
            "location": "/software/osg-build-tools/#fetch-and-extract-all-source-files-for-examination",
            "text": "Run  osg-build prebuild --full-extract <PACKAGEDIR> . Look inside the  _upstream_tarball_contents  directory.",
            "title": "Fetch and extract all source files for examination"
        },
        {
            "location": "/software/osg-build-tools/#get-a-post-patch-version-of-the-upstream-sources-for-examination",
            "text": "Run  osg-build prepare <PACKAGEDIR> . Look inside the  _build_results  directory.",
            "title": "Get a post-patch version of the upstream sources for examination"
        },
        {
            "location": "/software/osg-build-tools/#see-which-patches-work-with-a-new-version-of-a-package-update-or-remove-them",
            "text": "Place the new source tarball into the upstream cache, edit the version in the spec file and *.sources files as necessary  Run  osg-build quilt <PACKAGEDIR> .  Enter the extracted sources inside the  _final_srpm_contents  directory. You should see a file called  series  and a symlink called  patches .  Type  quilt series  to get a list of patches in order of application.  Type  quilt push  to apply the next patch.  If the patch applies cleanly, continue.  If the patch applies with some fuzz, type  quilt refresh  to update the offsets in the patch.  If the patch does not apply and you wish to remove it, type  quilt delete <PATCH NAME>  (delete only removes it from the series file, not the disk)  If the patch does not apply and you wish to fix it, either type  quilt push -f  to interactively apply the patch, or  quilt delete <PATCH NAME>  the patch and use  quilt new  /  quilt edit  /  quilt refresh  to edit files and make a new patch from your changes. Consult the  quilt(1)  manpage for more info.    If you have a new patch, run  quilt import <PATCHFILE>  to add the patch to the series file, and run  quilt push  to apply it.  If you have changes to make to the source code that you want to save as a patch, type  quilt new <PATCHNAME> , edit the files, type  quilt add <FILE>  on each file you edited, then type  quilt refresh  to recreate the patch.  Once you're all done, copy the patches in the  patches/  directory to the  osg/  dir in SVN, run  quilt series  to get the application order and update the spec file accordingly.",
            "title": "See which patches work with a new version of a package, update or remove them"
        },
        {
            "location": "/software/osg-build-tools/#see-if-a-package-builds-successfully-for-osg-34",
            "text": "If you have all the build dependencies of the package installed, run  osg-build rpmbuild <PACKAGEDIR> . The resulting RPMs will be in the  _build_results  directory.  If you do not have all the build dependencies installed, or want to make sure you specified all of the necessary ones and the package builds from a clean environment, run  osg-build mock --mock-config-from-koji osg-3.4-el6-build <PACKAGEDIR> . The resulting RPMs will be in the  _build_results  directory.  If you do not have mock installed, or want to exactly replicate the build environment in Koji, run  osg-build koji --scratch <PACKAGEDIR> . You may download the resulting RPMs from kojiweb  https://koji.opensciencegrid.org/koji  or pass  --getfiles  to  osg-build koji  and they will get downloaded to the  _build_results  directory.",
            "title": "See if a package builds successfully for OSG 3.4"
        },
        {
            "location": "/software/osg-build-tools/#check-for-potential-errors-in-a-package",
            "text": "Run  osg-build lint <PACKAGEDIR> .",
            "title": "Check for potential errors in a package"
        },
        {
            "location": "/software/osg-build-tools/#create-and-test-a-final-build-of-a-package-for-all-platforms-for-upcoming",
            "text": "svn commit  your changes in  branches/upcoming .  Type  osg-build koji --repo=upcoming <PACKAGEDIR>  Wait for the  osg-upcoming-minefield  repos to be regenerated containing the new version of your package. You can run  osg-koji wait-repo osg-upcoming-el<X>-development --build=<PACKAGENAME-VERSION-RELEASE>  and wait for that process to finish (substitute  6  or  7  for  X ). Or, you can just check kojiweb  https://koji.opensciencegrid.org/koji/tasks .  On your test machine, make sure the  osg-upcoming-minefield  repo is enabled (edit  /etc/yum.repos.d/osg-upcoming-minefield.repo  or  /etc/yum.repos.d/osg-el6-upcoming-minefield.repo ). Clean your cache ( yum clean all; yum clean expire-cache ).  Install your software, see if it works.",
            "title": "Create and test a final build of a package for all platforms for upcoming"
        },
        {
            "location": "/software/osg-build-tools/#promote-the-latest-build-of-a-package-to-testing-for-the-current-osg-release-series",
            "text": "Run  osg-promote -r testing <PACKAGE>",
            "title": "Promote the latest build of a package to testing for the current OSG release series"
        },
        {
            "location": "/software/osg-build-tools/#promote-the-latest-build-of-a-package-to-testing-for-the-33-and-34-release-series",
            "text": "Run  osg-promote -r 3.3-testing -r 3.4-testing <PACKAGE>",
            "title": "Promote the latest build of a package to testing for the 3.3 and 3.4 release series"
        },
        {
            "location": "/software/quilt/",
            "text": "How to Write a Patch\n\u00b6\n\n\nYou create one or more \n.patch\n files with diff and stick them in the osg directory. Then you declare the patch files in the header of the spec file with a line like \nPatch0: py24compat.patch\n and in the \n%prep\n section, just after\n%setup\n, you add a \n%patch\n line to actually apply the patch, like this: \n%patch0 -p1\n (where the \n-p1\n indicates that it should strip off the first leading component of the path in each file mentioned in the .patch file) Look at the mash package for an example.\n\n\nThe easiest way to actually create the patch in the first place is to use a utility called quilt. First you run \nosg-build quilt\n on the package directory and it will create a \n_quilt\n subdirectory that has the expanded sources and patches.\n\n\n\n\ncd into \n_quilt/pegasus-source-2.3.0\n, then run \nquilt push -a\n to apply any patches that already exist (there are none for pegasus but there might be for other packages).\n\n\nrun \nquilt new py24compat.patch\n to name your new patch file.\n\n\nrun \nquilt add <filename>\n for each file you want to make changes to (you \nmust\n run this before making any changes).\n\n\nactually make the changes.\n\n\nrun \nquilt refresh -p1\n to have quilt add those changes into the .patch file. (The -p1 option to quilt refresh must be the same as the -p1 option to %patch0 in your spec file).\n\n\ncopy \npatches/py24compat.patch\n into the \npegasus/osg\n directory and edit the spec file as above.\n\n\n\n\nDon't forget to \ngit add\n your new patch file before committing. Once you've tested your patch successfully, you should make that bug report and send them the patch. A bug report is looked on more favorably if it includes a patch to fix the problem.",
            "title": "Using Quilt"
        },
        {
            "location": "/software/quilt/#how-to-write-a-patch",
            "text": "You create one or more  .patch  files with diff and stick them in the osg directory. Then you declare the patch files in the header of the spec file with a line like  Patch0: py24compat.patch  and in the  %prep  section, just after %setup , you add a  %patch  line to actually apply the patch, like this:  %patch0 -p1  (where the  -p1  indicates that it should strip off the first leading component of the path in each file mentioned in the .patch file) Look at the mash package for an example.  The easiest way to actually create the patch in the first place is to use a utility called quilt. First you run  osg-build quilt  on the package directory and it will create a  _quilt  subdirectory that has the expanded sources and patches.   cd into  _quilt/pegasus-source-2.3.0 , then run  quilt push -a  to apply any patches that already exist (there are none for pegasus but there might be for other packages).  run  quilt new py24compat.patch  to name your new patch file.  run  quilt add <filename>  for each file you want to make changes to (you  must  run this before making any changes).  actually make the changes.  run  quilt refresh -p1  to have quilt add those changes into the .patch file. (The -p1 option to quilt refresh must be the same as the -p1 option to %patch0 in your spec file).  copy  patches/py24compat.patch  into the  pegasus/osg  directory and edit the spec file as above.   Don't forget to  git add  your new patch file before committing. Once you've tested your patch successfully, you should make that bug report and send them the patch. A bug report is looked on more favorably if it includes a patch to fix the problem.",
            "title": "How to Write a Patch"
        },
        {
            "location": "/software/upcoming-to-main/",
            "text": "Promoting Packages from Upcoming to Main\n\u00b6\n\n\nSometimes we move packages from Upcoming to the Main repositories in the middle of a release series. Once the Release Manager has given tentative approval for such a move:\n\n\nIf needed, move the software from upcoming to trunk and release using the usual process:\n\n\n\n\nMerge changes to the package in SVN from branches/upcoming to trunk.\n\n\nBuild the package from trunk.\n\n\nFollow the normal process to prepare a build for release (including development testing, promotion, etc.).\n\n\n\n\nOn release day, when the package has been released in the Main production repository, clean up the package from the upcoming repos:\n\n\n\n\nUntag from \nall upcoming repos\n the version of the package corresponding to the version that was released in main. (Do \nNOT\n untag from the osg-upcoming-elN-release-X.Y.Z tags)\n\n\n\n\nAlso, untag all equal or lesser NVRs (minus the dist tag) from all upcoming repos.\n\n\nIf you do not have the privileges to untag from upcoming-release, someone on the Release Team can help.\n\n\n(These steps are necessary to make sure Koji builds can't mistakenly use an older build from the upcoming repos).\n\n\n\n\nUnless there's a newer build in branches/upcoming than what was released, remove the package directory from branches/upcoming.",
            "title": "Upcoming to Main"
        },
        {
            "location": "/software/upcoming-to-main/#promoting-packages-from-upcoming-to-main",
            "text": "Sometimes we move packages from Upcoming to the Main repositories in the middle of a release series. Once the Release Manager has given tentative approval for such a move:  If needed, move the software from upcoming to trunk and release using the usual process:   Merge changes to the package in SVN from branches/upcoming to trunk.  Build the package from trunk.  Follow the normal process to prepare a build for release (including development testing, promotion, etc.).   On release day, when the package has been released in the Main production repository, clean up the package from the upcoming repos:   Untag from  all upcoming repos  the version of the package corresponding to the version that was released in main. (Do  NOT  untag from the osg-upcoming-elN-release-X.Y.Z tags)   Also, untag all equal or lesser NVRs (minus the dist tag) from all upcoming repos.  If you do not have the privileges to untag from upcoming-release, someone on the Release Team can help.  (These steps are necessary to make sure Koji builds can't mistakenly use an older build from the upcoming repos).   Unless there's a newer build in branches/upcoming than what was released, remove the package directory from branches/upcoming.",
            "title": "Promoting Packages from Upcoming to Main"
        },
        {
            "location": "/software/koji-workflow/",
            "text": "Koji Workflow\n\u00b6\n\n\nThis covers the basics of using and understanding the \nOSG Koji\n instance. It is meant primarily for OSG Software team members who need to interact with the service.\n\n\nTerminology\n\u00b6\n\n\nUsing and understanding the following terminology correctly will help in the reading of this document:\n\n\nPackage\n\nThis refers to a named piece of software in the Koji database. An example would be \"lcmaps\".\n\n\nBuild\n\nA specific version and release of a package, and an associated state. A build state may be successful (and contain RPMs), failed, or in-progress. A given build may be in one or more tags. The build is associated with the output of the latest build task with the same version and release of the package.\n\n\nTag\n\nA named set of packages and builds, parent tags, and reference to external repositories. An example would be the \"osg-3.3-el6-development\" tag, which contains (among others) the \"lcmaps\" package and the \"lcmaps-1.6.6-1.1.osg33.el6\" build. There is an inheritance structure to tags: by default, all packages/builds in a parent tag are added to the tag. A tag may contain a reference to (possibly inherited) external repositories; the RPMs in these repositories are added to repositories created from this tag. Examples of referenced external repositories include CentOS base, EPEL, or JPackage.\n\n\n\n\nNote\n\n\nA tag is NOT a yum repository.\n\n\n\n\nTarget\n\nA target consists of a build tag and a destination tag. An example is \"osg-3.3-el6\", where the build tag is \"osg-3.3-el6-build\" and the destination tag is \"osg-3.3-el6\". A target is used by the build task to know what repository to build from and tag to build into.\n\n\nTask\n\nA unit of work for Koji. Several common tasks are:\n\n\n\n\n\n\nbuild\n\n    This task takes a SRPM and a target, and attempts to create a complete Build in the target's destination tag from the target's build repository. This task will launch one buildArch task for each architecture in the destination tag; if each subtask is successful, then it will launch a tagBuild subtask.\n\n\n\n\nNote\n\n\nIf the build task is marked as \"scratch\", then it won't result in a saved Build.\n\n\n\n\n\n\n\n\nbuildArch\n\n    This task takes a SRPM, architecture name, and a Koji repository as an input, and runs \nmock\n to create output RPMs for that arch. The build artifacts are added to the Build if all buildArch tasks are successful.\n\n\n\n\n\n\ntagBuild\n\n    This adds a successful build to a given tag.\n\n\n\n\n\n\nnewRepo\n\n    This creates a new repository from a given tag.\n\n\n\n\n\n\nBuild artifacts\n\nThe results of a buildArch task. Their metadata are recorded in the Koji database, and files are saved to disk. Metadata may include checksums, timestamps, and who initiated the task. Artifacts may include RPMs, SRPMs, and build logs.\n\n\nRepository\n\nA yum repository created from the contents of a tag at a specific point in time. By default, the yum repository will contain all successful, non-blocked builds in the tag, plus all RPMs in the external repositories for the tag.\n\n\nUsing Koji\n\u00b6\n\n\nRequired Software\n\u00b6\n\n\nUsing Koji requires:\n\n\n\n\nosg-build\n version 1.6.3 or later.\n\n\nkoji\n 1.6.0-2.osg or later. \nNote\n that you want a koji build from osg; the output of \nrpm -q koji\n should end in \".osg\".\n\n\n\n\nBoth pieces of software are available from the osg repositories. \nosg-build\n may also be obtained from GitHub by cloning out \nhttps://github.com/opensciencegrid/osg-build\n\n\nSpecial instructions for UW-Madison CSL machines:\n\u00b6\n\n\n\n\n\n\nClone the osg-build GitHub repo:\n\n\n[you@host]$\n git clone https://github.com/opensciencegrid/osg-build\n\n\n\n\n\n\n\n\n\nAdd this directory to your \n$PATH\n\n\n\n\n\n\nRun\n\n\n[you@host]$\n osg-koji setup\n\n\n\n\n\nto set up the koji configuration and certificates in \n~/.osg-koji\n\n\n\n\n\n\nObtaining a login\n\u00b6\n\n\nYou will be using your grid certificate to log in. Email a Koji admin the DN of your certificate, and we will set up a Koji account with the appropriate permissions.\n\n\nIf you are switching certificate providers, you will need to email a Koji admin with your new DN. You will also need to clear your browser cookies and cache for \nhttps://koji.opensciencegrid.org\n before trying to use the Koji web interface again. If your CN has changed, you will not be able to use your old certificate.\n\n\nCurrent Koji admins are Mat Selmeci and Carl Edquist.\n\n\nConfiguring certificate authentication\n\u00b6\n\n\nYou must also configure certificate authentication for the command-line tools on your build host:\n\n\n\n\n\n\nRun\n\n\n[you@host]$\n osg-koji setup\n\n\n\n\n\nto set up the appropriate configuration and certificates in \n~/.osg-koji\n\n\n\n\n\n\nAfter this, you will also be able to run koji commands manually by using the \nosg-koji\n wrapper script. You might need to rerun \nosg-koji setup\n if you renew or change your cert.\n\n\nCreating a new build\n\u00b6\n\n\nWe create a new build in Koji from the package's directory in OSG Software subversion.\n\n\nIf a successful build already exists in Koji (regardless of whether it is in the tag you use), you cannot replace the build. Two builds are the same if they have the same NVR (Name-Version-Release). You \ncan\n do a \"scratch\" build, which recompiles, but the results are not added to the tag. This is useful for experimenting with koji.\n\n\nTo do a build, execute the following command from within the OSG Software subversion checkout:\n\n\n[you@host]$\n osg-build koji <PACKAGE NAME>\n\n\n\n\n\nTo do a scratch build, simply add the \n--scratch\n command line flag.\n\n\nEach invocation of osg-build will ask for the password once or twice; if you get asked more like 20 times, then you may not be running the OSG-patched version of Koji; try switching to the one from the osg-development repository.\n\n\nWhen you do a non-scratch build, it will build with the \nosg-el6\n and \nosg-el7\n targets. This will assign your build the \nosg-3.4-el6-development\n and \nosg-3.4-el7-development\n tags (and your package will be assigned the \nosg-el6\n and \nosg-el7\n tags). If successful, your build will end up in the Koji \nosg-minefield\n yum repos and will eventually show up in the \nosg-development\n yum repos. This is a high latency process.\n\n\nBuild task Results\n\u00b6\n\n\nHow to find build results\n\u00b6\n\n\nThe most recent build results are always shown on the home page of Koji:\n\n\nhttps://koji.opensciencegrid.org/koji/index\n\n\nClicking on a build result brings you to the build information page. A successful build will result in the build page having build logs, RPMs, and a SRPM.\n\n\nIf your build isn't in the recent list, you can use the search box in the upper-right-hand corner. Type the exact package name (or use a wildcard), and it will bring up a list of all builds for that package. You can find your build from there. For example, the \"lcmaps\" package page is here:\n\n\nhttps://koji.opensciencegrid.org/koji/packageinfo?packageID=56\n\n\nAnd the lcmaps-1.6.6-1.1.osg33.el6 build is here:\n\n\nhttps://koji.opensciencegrid.org/koji/buildinfo?buildID=7427\n\n\nTrying our your build\n\u00b6\n\n\nBecause it takes a while for your build to get into one of the regular repositories, it's simplest to download your RPM directly (see the previous section on How to find build results), and install it with:\n\n\n[root@host]#\n yum localinstall <RPM>\n\n\n\n\n\nHow to get the resulting RPM into a repository\n\u00b6\n\n\nOnce a package has been built, it is added to a tag. We then must turn the tag into a yum repository. This is normally done automatically and you do not need to deal with it yourself. Three notes:\n\n\n\n\nThe kojira daemon creates a repository automatically post-build on the koji-hub host. Eventually, the development repository will be the one hosted by koji-hub.\n\n\n\n\nThe koji-hub repository can be created manually by running\n\n\n[you@host]$\n osg-koji regen-repo <TAG NAME>\n\n\n\n\n\nFor example, the tag name for osg-development in 3.4 on el6 is \"osg-3.4-el6-development\". Likely, you won't need to do this when kojira is working.\n-   Repositories are created on external hosts with the \nmash\n tool. These are usually triggered by cron jobs, but may be run by hand too. Documentation for running mash is on the TODO list.\n-   You can create your own personal repository using \nmash\n.\n\n\n\n\n\n\nDebugging build issues\n\u00b6\n\n\n\n\n\n\nFailed build tasks can be seen from the Koji homepage. The logs from the tasks are included. Relevant logs include:\n\n\n\n\n\n\nroot.log\n\n    This is the log of mock trying to create an appropriate build root for your RPM. This will invoke yum twice: once to create a generic build root, once for all the dependencies in your BuildRequires. All RPMs in your build root will be logged here. If mock is unable to create the build root, the reason will show up here.\n\n\n\n\n\n\n404 Errors\n\n\nIf you see \nError downloading packages\n and \nHTTP Error 404 - Not Found\n errors in your \nroot.log\n,\nthis commonly indicates that an rpm repo mirror was updated and our build repo is out-of-date.\nThis can be fixed by regenerating the relevant build repos for your builds.\n\n\nThis is usually something like \nosg-3.4-el7-build\n or \nosg-upcoming-el7-build\n;\nbut you can find the exact build tag by clicking the Build Target link for the koji task,\nand whatever is listed for the Build Tag is the name of the repo to regen.\n\n\nRegenerate each repo that failed with 404 errors:\n\n\n$\n osg-koji regen-repo <BUILD TAG>\n\n\n\n\n\n\n\n\n\n\n\n\n\nbuild.log\n\n    The output of the rpmbuild executable. If your package fails to compile, the reason will show up here.\n\n\n\n\n\n\n\n\n\n\nOne input to the buildArch task is a repository, which is based on a Koji tag. If the repository hasn't been recreated for a dependency you need (for example, when kojira isn't working), you may not have the right RPMs available in your build root.\n\n\n\n\n\n\nOne common issue is building a chain of dependencies. For example, suppose build B depends on the results of build A. If you build A then build B immediately, B will likely fail. This is because A is not in the repository that B uses. The proper string of events building A, starting the regeneration of the destination and build repo (which should happen in a few minutes of the build A task completing), then submitting build task B.\n\n\n\n\nNote\n\n\nif you submit build task B while the build repository task is open, it will not start until the build task has finished.\n\n\n\n\n\n\n\n\n\n\n\n\nOther errors\n\n\n\n\npackage <PACKAGE NAME> not in list for tag <TAG>\n\n    This happens when the name of the directory your package is in does not match the name of the package.\n    You must rename one or the other and commit your changes before trying again.\n\n\n\n\n\n\n\n\nPromoting Builds from Development -> Testing\n\u00b6\n\n\nSoftware contributors can promote any package to testing. Members of the security team can promote ca-cert packages to testing.\n\n\nTo promote from development to testing:\n\n\nUsing \nosg-promote\n\u00b6\n\n\nIf you want to promote the latest version:\n\n\n[you@host]$\n osg-promote -r <OSGVER>-testing <PACKAGE NAME>\n\n\n\n\n\n<PACKAGE NAME> is the bare package name without version, e.g. \ngratia-probe\n.\n\n\nIf you want to promote a specific version:\n\n\n[you@host]$\n osg-promote -r <OSGVER>-testing <BUILD NAME>\n\n\n\n\n\n<BUILD NAME> is a full \nname-version-revision.disttag\n such as \ngratia-probe-1.17.0-2.osg33.el6\n.\n\n\n<OSGVER> is the OSG major version that you are promoting for (e.g. \n3.4\n).\n\n\nosg-promote\n will promote both the el6 and el7 builds of a package. After promoting, copy and paste the JIRA code \nosg-promote\n produces into the JIRA ticket that you are working on.\n\n\nFor \nosg-promote\n, you may omit the \n.osg34.el6\n or \n.osg34.el7\n; the script will add the appropriate disttag on.\n\n\nSee \nOSG Building Tools\n for full details on \nosg-promote\n.\n\n\nCreating custom koji areas\n\u00b6\n\n\nOccasionally you may want to make builds of a package (or packages) which you\ndo not yet want to go into the main development repos.  In this case, you can\ncreate a set of custom koji tags and build targets for these builds.  We have\na script in our\n\nosg-next-tools\n repo\ncalled\n\nnew-koji-area\n\nthat facilitates this set up.\n\n\nFurther reading\n\u00b6\n\n\n\n\nOfficial Koji documentation: \nhttps://docs.pagure.org/koji/\n\n\nFedora's koji documentation: \nhttps://fedoraproject.org/wiki/Koji\n\n\nFedora's \"Using Koji\" page: \nhttps://fedoraproject.org/wiki/Using_the_Koji_build_system\n Note that some instructions there may not apply to OSG's Koji. For the most part though, they are useful.",
            "title": "Koji Workflow"
        },
        {
            "location": "/software/koji-workflow/#koji-workflow",
            "text": "This covers the basics of using and understanding the  OSG Koji  instance. It is meant primarily for OSG Software team members who need to interact with the service.",
            "title": "Koji Workflow"
        },
        {
            "location": "/software/koji-workflow/#terminology",
            "text": "Using and understanding the following terminology correctly will help in the reading of this document:  Package \nThis refers to a named piece of software in the Koji database. An example would be \"lcmaps\".  Build \nA specific version and release of a package, and an associated state. A build state may be successful (and contain RPMs), failed, or in-progress. A given build may be in one or more tags. The build is associated with the output of the latest build task with the same version and release of the package.  Tag \nA named set of packages and builds, parent tags, and reference to external repositories. An example would be the \"osg-3.3-el6-development\" tag, which contains (among others) the \"lcmaps\" package and the \"lcmaps-1.6.6-1.1.osg33.el6\" build. There is an inheritance structure to tags: by default, all packages/builds in a parent tag are added to the tag. A tag may contain a reference to (possibly inherited) external repositories; the RPMs in these repositories are added to repositories created from this tag. Examples of referenced external repositories include CentOS base, EPEL, or JPackage.   Note  A tag is NOT a yum repository.   Target \nA target consists of a build tag and a destination tag. An example is \"osg-3.3-el6\", where the build tag is \"osg-3.3-el6-build\" and the destination tag is \"osg-3.3-el6\". A target is used by the build task to know what repository to build from and tag to build into.  Task \nA unit of work for Koji. Several common tasks are:    build \n    This task takes a SRPM and a target, and attempts to create a complete Build in the target's destination tag from the target's build repository. This task will launch one buildArch task for each architecture in the destination tag; if each subtask is successful, then it will launch a tagBuild subtask.   Note  If the build task is marked as \"scratch\", then it won't result in a saved Build.     buildArch \n    This task takes a SRPM, architecture name, and a Koji repository as an input, and runs  mock  to create output RPMs for that arch. The build artifacts are added to the Build if all buildArch tasks are successful.    tagBuild \n    This adds a successful build to a given tag.    newRepo \n    This creates a new repository from a given tag.    Build artifacts \nThe results of a buildArch task. Their metadata are recorded in the Koji database, and files are saved to disk. Metadata may include checksums, timestamps, and who initiated the task. Artifacts may include RPMs, SRPMs, and build logs.  Repository \nA yum repository created from the contents of a tag at a specific point in time. By default, the yum repository will contain all successful, non-blocked builds in the tag, plus all RPMs in the external repositories for the tag.",
            "title": "Terminology"
        },
        {
            "location": "/software/koji-workflow/#using-koji",
            "text": "",
            "title": "Using Koji"
        },
        {
            "location": "/software/koji-workflow/#required-software",
            "text": "Using Koji requires:   osg-build  version 1.6.3 or later.  koji  1.6.0-2.osg or later.  Note  that you want a koji build from osg; the output of  rpm -q koji  should end in \".osg\".   Both pieces of software are available from the osg repositories.  osg-build  may also be obtained from GitHub by cloning out  https://github.com/opensciencegrid/osg-build",
            "title": "Required Software"
        },
        {
            "location": "/software/koji-workflow/#special-instructions-for-uw-madison-csl-machines",
            "text": "Clone the osg-build GitHub repo:  [you@host]$  git clone https://github.com/opensciencegrid/osg-build    Add this directory to your  $PATH    Run  [you@host]$  osg-koji setup  to set up the koji configuration and certificates in  ~/.osg-koji",
            "title": "Special instructions for UW-Madison CSL machines:"
        },
        {
            "location": "/software/koji-workflow/#obtaining-a-login",
            "text": "You will be using your grid certificate to log in. Email a Koji admin the DN of your certificate, and we will set up a Koji account with the appropriate permissions.  If you are switching certificate providers, you will need to email a Koji admin with your new DN. You will also need to clear your browser cookies and cache for  https://koji.opensciencegrid.org  before trying to use the Koji web interface again. If your CN has changed, you will not be able to use your old certificate.  Current Koji admins are Mat Selmeci and Carl Edquist.",
            "title": "Obtaining a login"
        },
        {
            "location": "/software/koji-workflow/#configuring-certificate-authentication",
            "text": "You must also configure certificate authentication for the command-line tools on your build host:    Run  [you@host]$  osg-koji setup  to set up the appropriate configuration and certificates in  ~/.osg-koji    After this, you will also be able to run koji commands manually by using the  osg-koji  wrapper script. You might need to rerun  osg-koji setup  if you renew or change your cert.",
            "title": "Configuring certificate authentication"
        },
        {
            "location": "/software/koji-workflow/#creating-a-new-build",
            "text": "We create a new build in Koji from the package's directory in OSG Software subversion.  If a successful build already exists in Koji (regardless of whether it is in the tag you use), you cannot replace the build. Two builds are the same if they have the same NVR (Name-Version-Release). You  can  do a \"scratch\" build, which recompiles, but the results are not added to the tag. This is useful for experimenting with koji.  To do a build, execute the following command from within the OSG Software subversion checkout:  [you@host]$  osg-build koji <PACKAGE NAME>  To do a scratch build, simply add the  --scratch  command line flag.  Each invocation of osg-build will ask for the password once or twice; if you get asked more like 20 times, then you may not be running the OSG-patched version of Koji; try switching to the one from the osg-development repository.  When you do a non-scratch build, it will build with the  osg-el6  and  osg-el7  targets. This will assign your build the  osg-3.4-el6-development  and  osg-3.4-el7-development  tags (and your package will be assigned the  osg-el6  and  osg-el7  tags). If successful, your build will end up in the Koji  osg-minefield  yum repos and will eventually show up in the  osg-development  yum repos. This is a high latency process.",
            "title": "Creating a new build"
        },
        {
            "location": "/software/koji-workflow/#build-task-results",
            "text": "",
            "title": "Build task Results"
        },
        {
            "location": "/software/koji-workflow/#how-to-find-build-results",
            "text": "The most recent build results are always shown on the home page of Koji:  https://koji.opensciencegrid.org/koji/index  Clicking on a build result brings you to the build information page. A successful build will result in the build page having build logs, RPMs, and a SRPM.  If your build isn't in the recent list, you can use the search box in the upper-right-hand corner. Type the exact package name (or use a wildcard), and it will bring up a list of all builds for that package. You can find your build from there. For example, the \"lcmaps\" package page is here:  https://koji.opensciencegrid.org/koji/packageinfo?packageID=56  And the lcmaps-1.6.6-1.1.osg33.el6 build is here:  https://koji.opensciencegrid.org/koji/buildinfo?buildID=7427",
            "title": "How to find build results"
        },
        {
            "location": "/software/koji-workflow/#trying-our-your-build",
            "text": "Because it takes a while for your build to get into one of the regular repositories, it's simplest to download your RPM directly (see the previous section on How to find build results), and install it with:  [root@host]#  yum localinstall <RPM>",
            "title": "Trying our your build"
        },
        {
            "location": "/software/koji-workflow/#how-to-get-the-resulting-rpm-into-a-repository",
            "text": "Once a package has been built, it is added to a tag. We then must turn the tag into a yum repository. This is normally done automatically and you do not need to deal with it yourself. Three notes:   The kojira daemon creates a repository automatically post-build on the koji-hub host. Eventually, the development repository will be the one hosted by koji-hub.   The koji-hub repository can be created manually by running  [you@host]$  osg-koji regen-repo <TAG NAME>  For example, the tag name for osg-development in 3.4 on el6 is \"osg-3.4-el6-development\". Likely, you won't need to do this when kojira is working.\n-   Repositories are created on external hosts with the  mash  tool. These are usually triggered by cron jobs, but may be run by hand too. Documentation for running mash is on the TODO list.\n-   You can create your own personal repository using  mash .",
            "title": "How to get the resulting RPM into a repository"
        },
        {
            "location": "/software/koji-workflow/#debugging-build-issues",
            "text": "Failed build tasks can be seen from the Koji homepage. The logs from the tasks are included. Relevant logs include:    root.log \n    This is the log of mock trying to create an appropriate build root for your RPM. This will invoke yum twice: once to create a generic build root, once for all the dependencies in your BuildRequires. All RPMs in your build root will be logged here. If mock is unable to create the build root, the reason will show up here.    404 Errors  If you see  Error downloading packages  and  HTTP Error 404 - Not Found  errors in your  root.log ,\nthis commonly indicates that an rpm repo mirror was updated and our build repo is out-of-date.\nThis can be fixed by regenerating the relevant build repos for your builds.  This is usually something like  osg-3.4-el7-build  or  osg-upcoming-el7-build ;\nbut you can find the exact build tag by clicking the Build Target link for the koji task,\nand whatever is listed for the Build Tag is the name of the repo to regen.  Regenerate each repo that failed with 404 errors:  $  osg-koji regen-repo <BUILD TAG>      build.log \n    The output of the rpmbuild executable. If your package fails to compile, the reason will show up here.      One input to the buildArch task is a repository, which is based on a Koji tag. If the repository hasn't been recreated for a dependency you need (for example, when kojira isn't working), you may not have the right RPMs available in your build root.    One common issue is building a chain of dependencies. For example, suppose build B depends on the results of build A. If you build A then build B immediately, B will likely fail. This is because A is not in the repository that B uses. The proper string of events building A, starting the regeneration of the destination and build repo (which should happen in a few minutes of the build A task completing), then submitting build task B.   Note  if you submit build task B while the build repository task is open, it will not start until the build task has finished.       Other errors   package <PACKAGE NAME> not in list for tag <TAG> \n    This happens when the name of the directory your package is in does not match the name of the package.\n    You must rename one or the other and commit your changes before trying again.",
            "title": "Debugging build issues"
        },
        {
            "location": "/software/koji-workflow/#promoting-builds-from-development-testing",
            "text": "Software contributors can promote any package to testing. Members of the security team can promote ca-cert packages to testing.  To promote from development to testing:",
            "title": "Promoting Builds from Development -&gt; Testing"
        },
        {
            "location": "/software/koji-workflow/#using-osg-promote",
            "text": "If you want to promote the latest version:  [you@host]$  osg-promote -r <OSGVER>-testing <PACKAGE NAME>  <PACKAGE NAME> is the bare package name without version, e.g.  gratia-probe .  If you want to promote a specific version:  [you@host]$  osg-promote -r <OSGVER>-testing <BUILD NAME>  <BUILD NAME> is a full  name-version-revision.disttag  such as  gratia-probe-1.17.0-2.osg33.el6 .  <OSGVER> is the OSG major version that you are promoting for (e.g.  3.4 ).  osg-promote  will promote both the el6 and el7 builds of a package. After promoting, copy and paste the JIRA code  osg-promote  produces into the JIRA ticket that you are working on.  For  osg-promote , you may omit the  .osg34.el6  or  .osg34.el7 ; the script will add the appropriate disttag on.  See  OSG Building Tools  for full details on  osg-promote .",
            "title": "Using osg-promote"
        },
        {
            "location": "/software/koji-workflow/#creating-custom-koji-areas",
            "text": "Occasionally you may want to make builds of a package (or packages) which you\ndo not yet want to go into the main development repos.  In this case, you can\ncreate a set of custom koji tags and build targets for these builds.  We have\na script in our osg-next-tools  repo\ncalled new-koji-area \nthat facilitates this set up.",
            "title": "Creating custom koji areas"
        },
        {
            "location": "/software/koji-workflow/#further-reading",
            "text": "Official Koji documentation:  https://docs.pagure.org/koji/  Fedora's koji documentation:  https://fedoraproject.org/wiki/Koji  Fedora's \"Using Koji\" page:  https://fedoraproject.org/wiki/Using_the_Koji_build_system  Note that some instructions there may not apply to OSG's Koji. For the most part though, they are useful.",
            "title": "Further reading"
        },
        {
            "location": "/software/create-vo-client/",
            "text": "Creating the VO Client Package\n\u00b6\n\n\nOverview\n\u00b6\n\n\nThis document will explain the step-by-step procedures for creating and releasing the VO Client Package.\n\n\nThe VO Client Package sources can be found here:\n\nhttps://github.com/opensciencegrid/osg-vo-config\n\n\nWhen upstream changes have been made and are ready for a new VO Client Package release, these sources will be used to\nprepare a release tarball, which will in turn be used for the RPMs.\n\n\nIn order to build the RPM, one needs:\n\n\n\n\nThe tarball containing the:\n\n\nedg-mkgridmap.conf\n file\n\n\ngums.config.template\n file\n\n\ngrid-vorolemap\n file (generated)\n\n\nvoms-mapfile-default\n file (generated)\n\n\nvomses\n file\n\n\nvomsdir\n directory tree, containing the .lsc files.\n\n\n\n\n\n\nThe RPM spec file, \nmaintained\n in the OSG packaging area.\n\n\n\n\nJIRA Ticket for the Release\n\u00b6\n\n\nThere should be an associated JIRA ticket with a summary line of the form \"Release VO Package 85\".\n(Throughout this document, this release number will be referred to as \n<NN>\n.)\n\n\nThe JIRA ticket should contain the details of the changes expected in the new VO Client Package release, which you\nshould verify before proceeding.\nYou can verify this with your favorite git tool (eg, \ngit diff\n or \ngitk\n), or just view the changes directly on GitHub:\n\n\n\n\nhttps://github.com/opensciencegrid/osg-vo-config/compare/release-84...master\n\n\n\n\nHere, \nrelease-84\n is the \nprevious\n release tag, which you are comparing to the latest changes in \nmaster\n.\nTo use GitHub to view the comparison, you need to specify whatever is the most recent \nprevious\n release tag.\n\n\nAlternatively, you can proceed to \nmake the tarball\n, and compare the result to the previous\n\nvo-client\n tarball (from the upstream source cache) before \npublishing the new release\n.\n\n\nHowever you choose to do it, the point is to verify that the changes going into the release match what is expected in\nthe JIRA ticket before publishing a new release.\n\n\nUpdates to the GUMS Template\n\u00b6\n\n\nMost commonly, VO Client Package releases do not involve changes to the \ngums.config.template\n file, though on occasion\nit needs to be updated.\nBefore proceeding, any changes to \ngums.config.template\n related to this release should be committed to git and pushed\nto the upstream repo on GitHub.\n\n\nThe procedure for updating \ngums.config.template\n is outside the scope of this document, but the main important point is\nthat any updates to this file should be done with the GUMS web interface rather than editing its xml contents by hand.\n\n\nMaking the Tarball\n\u00b6\n\n\nThe process to make a new tarball has been mostly scripted.\n\n\nTo make the tarball:\n\n\n\n\n\n\nStart with a clean checkout of the latest \nmaster\n branch of the \nosg-vo-config\n\n    \nsource repo\n.\n\n\nThis checked out commit should be the one intended to be tagged for the new release.\n-   Run the \nmk-vo-client-tarball\n script with the new release number \n<NN>\n:\n\n\n$ ./bin/mk-vo-client-tarball <NN>\n\n\n\n\n\nFor example:\n\n\n$ ./bin/mk-vo-client-tarball 85\n\n\n\n\n\nThis will create a file \nvo-client-<NN>-osg.tar.gz\n in the current directory.\n\n\n\n\n\n\nOnce the tarball is created:\n\n\n\n\n\n\nIf you have not already verified the changes expected in the JIRA ticket, compare the contents of the new tarball\n    with the previous version in the \nupstream source cache\n.\n\n\n\n\n\n\nUpload the tarball into the \nupstream source cache\n, under\n    the \nvo-client/<NN>/\n directory.\n\n\n\n\n\n\nRPM Spec File Maintenance\n\u00b6\n\n\nThe OSG RPM spec file is \nmaintained in Subversion\n.\n\n\nThe VO Client package is located in \nnative/redhat/trunk/vo-client\n; that is,\n\nhere\n.\n\n\nThere are two files that need to be maintained:\n\n\n\n\n\n\nosg/vo-client.spec\n\n\n\n\nThe \nVersion:\n field should be updated to match the \n<NN>\n number for the release\n\n\nA \n%changelog\n entry should be added for the new release, mentioning any changes and their associated tickets\n\n\n\n\n\n\n\n\nupstream/release_tarball.source\n\n\n\n\nUpdate the relative path for the new tarball within the\n    \nupstream source cache\n.\n    Typically this will be \nvo-client/<NN>/vo-client-<NN>-osg.tar.gz\n.\n\n\n\n\n\n\n\n\nRPM Building\n\u00b6\n\n\nAfter installing the \nosg-build tools\n, check out a clean copy of the \nvo-client\n packaging\ndirectory from svn, then:\n\n\n\n\nosg-build prebuild .\n\n\nOnce there are no errors, run \nosg-build koji . --scratch\n.\n    (This can be done without making any permanent change.)\n\n\nOnce that builds successfully, run \nosg-build koji .\n\n    (This is permanent, unlike when you ran with \n--scratch\n.)\n    You cannot rebuild this version of the RPM again; to rebuild with changes, you must bump the release number and edit\n    the changelog.\n\n\n\n\nThis will push the RPMs into the OSG development repository.\n\n\n\n\nNote\n\n\nKoji requires additional setup compared to rpmbuild; \nsee the documentation here\n.\n\n\n\n\nPublishing the New Release\n\u00b6\n\n\nThe final version of the sources in the \nosg-vo-config\n, which was used to create the tarball that was used in the koji\nbuild, needs be tagged in git with a \nrelease-<NN>\n tag (eg, \nrelease-85\n) and published as a release on GitHub.\n\n\nYou can create and push the \nrelease-<NN>\n from your git checkout of \nosg-vo-config\n, OR create the tag while publishing\nthe release on GitHub (recommended).\n\n\nTo publish the new release on GitHub:\n\n\n\n\nGo to \nhttps://github.com/opensciencegrid/osg-vo-config/releases/new\n\n\nIn the \"Tag version\" field, enter \nrelease-<NN>\n (eg, \nrelease-85\n)\n\n\nIf you are creating this tag on GitHub, click the \"Target\" dropdown button, and under the \"Recent Commits\" tab, make\n    sure to select the commit you used when creating the tarball\n    (It should be the first one)\n\n\nIn the \"Release title\" field, enter \n<MONTH> <YEAR> VO Package Release <NN>\n\n    (eg, \nDecember 2018 VO Package Release 85\n)\n\n\n\n\nIn the release description, list the changes in this release and their associated ticket numbers, similar to the new\n    \n%changelog\n entry added in the rpm spec file\n\n\n(You can view the \nreleases\n page for examples)\n-   Click the \"Publish release\" button\n\n\n\n\n\n\nPromotion to Testing and Release:\n\u00b6\n\n\nRead \nRelease Policy\n.\n\n\nNote that the \nvo-client\n package frequently is part of a separate \n-data\n release; it does not necessarily have to\nwait for the main release cycle.",
            "title": "Creating the VO Client Package"
        },
        {
            "location": "/software/create-vo-client/#creating-the-vo-client-package",
            "text": "",
            "title": "Creating the VO Client Package"
        },
        {
            "location": "/software/create-vo-client/#overview",
            "text": "This document will explain the step-by-step procedures for creating and releasing the VO Client Package.  The VO Client Package sources can be found here: https://github.com/opensciencegrid/osg-vo-config  When upstream changes have been made and are ready for a new VO Client Package release, these sources will be used to\nprepare a release tarball, which will in turn be used for the RPMs.  In order to build the RPM, one needs:   The tarball containing the:  edg-mkgridmap.conf  file  gums.config.template  file  grid-vorolemap  file (generated)  voms-mapfile-default  file (generated)  vomses  file  vomsdir  directory tree, containing the .lsc files.    The RPM spec file,  maintained  in the OSG packaging area.",
            "title": "Overview"
        },
        {
            "location": "/software/create-vo-client/#jira-ticket-for-the-release",
            "text": "There should be an associated JIRA ticket with a summary line of the form \"Release VO Package 85\".\n(Throughout this document, this release number will be referred to as  <NN> .)  The JIRA ticket should contain the details of the changes expected in the new VO Client Package release, which you\nshould verify before proceeding.\nYou can verify this with your favorite git tool (eg,  git diff  or  gitk ), or just view the changes directly on GitHub:   https://github.com/opensciencegrid/osg-vo-config/compare/release-84...master   Here,  release-84  is the  previous  release tag, which you are comparing to the latest changes in  master .\nTo use GitHub to view the comparison, you need to specify whatever is the most recent  previous  release tag.  Alternatively, you can proceed to  make the tarball , and compare the result to the previous vo-client  tarball (from the upstream source cache) before  publishing the new release .  However you choose to do it, the point is to verify that the changes going into the release match what is expected in\nthe JIRA ticket before publishing a new release.",
            "title": "JIRA Ticket for the Release"
        },
        {
            "location": "/software/create-vo-client/#updates-to-the-gums-template",
            "text": "Most commonly, VO Client Package releases do not involve changes to the  gums.config.template  file, though on occasion\nit needs to be updated.\nBefore proceeding, any changes to  gums.config.template  related to this release should be committed to git and pushed\nto the upstream repo on GitHub.  The procedure for updating  gums.config.template  is outside the scope of this document, but the main important point is\nthat any updates to this file should be done with the GUMS web interface rather than editing its xml contents by hand.",
            "title": "Updates to the GUMS Template"
        },
        {
            "location": "/software/create-vo-client/#making-the-tarball",
            "text": "The process to make a new tarball has been mostly scripted.  To make the tarball:    Start with a clean checkout of the latest  master  branch of the  osg-vo-config \n     source repo .  This checked out commit should be the one intended to be tagged for the new release.\n-   Run the  mk-vo-client-tarball  script with the new release number  <NN> :  $ ./bin/mk-vo-client-tarball <NN>  For example:  $ ./bin/mk-vo-client-tarball 85  This will create a file  vo-client-<NN>-osg.tar.gz  in the current directory.    Once the tarball is created:    If you have not already verified the changes expected in the JIRA ticket, compare the contents of the new tarball\n    with the previous version in the  upstream source cache .    Upload the tarball into the  upstream source cache , under\n    the  vo-client/<NN>/  directory.",
            "title": "Making the Tarball"
        },
        {
            "location": "/software/create-vo-client/#rpm-spec-file-maintenance",
            "text": "The OSG RPM spec file is  maintained in Subversion .  The VO Client package is located in  native/redhat/trunk/vo-client ; that is, here .  There are two files that need to be maintained:    osg/vo-client.spec   The  Version:  field should be updated to match the  <NN>  number for the release  A  %changelog  entry should be added for the new release, mentioning any changes and their associated tickets     upstream/release_tarball.source   Update the relative path for the new tarball within the\n     upstream source cache .\n    Typically this will be  vo-client/<NN>/vo-client-<NN>-osg.tar.gz .",
            "title": "RPM Spec File Maintenance"
        },
        {
            "location": "/software/create-vo-client/#rpm-building",
            "text": "After installing the  osg-build tools , check out a clean copy of the  vo-client  packaging\ndirectory from svn, then:   osg-build prebuild .  Once there are no errors, run  osg-build koji . --scratch .\n    (This can be done without making any permanent change.)  Once that builds successfully, run  osg-build koji . \n    (This is permanent, unlike when you ran with  --scratch .)\n    You cannot rebuild this version of the RPM again; to rebuild with changes, you must bump the release number and edit\n    the changelog.   This will push the RPMs into the OSG development repository.   Note  Koji requires additional setup compared to rpmbuild;  see the documentation here .",
            "title": "RPM Building"
        },
        {
            "location": "/software/create-vo-client/#publishing-the-new-release",
            "text": "The final version of the sources in the  osg-vo-config , which was used to create the tarball that was used in the koji\nbuild, needs be tagged in git with a  release-<NN>  tag (eg,  release-85 ) and published as a release on GitHub.  You can create and push the  release-<NN>  from your git checkout of  osg-vo-config , OR create the tag while publishing\nthe release on GitHub (recommended).  To publish the new release on GitHub:   Go to  https://github.com/opensciencegrid/osg-vo-config/releases/new  In the \"Tag version\" field, enter  release-<NN>  (eg,  release-85 )  If you are creating this tag on GitHub, click the \"Target\" dropdown button, and under the \"Recent Commits\" tab, make\n    sure to select the commit you used when creating the tarball\n    (It should be the first one)  In the \"Release title\" field, enter  <MONTH> <YEAR> VO Package Release <NN> \n    (eg,  December 2018 VO Package Release 85 )   In the release description, list the changes in this release and their associated ticket numbers, similar to the new\n     %changelog  entry added in the rpm spec file  (You can view the  releases  page for examples)\n-   Click the \"Publish release\" button",
            "title": "Publishing the New Release"
        },
        {
            "location": "/software/create-vo-client/#promotion-to-testing-and-release",
            "text": "Read  Release Policy .  Note that the  vo-client  package frequently is part of a separate  -data  release; it does not necessarily have to\nwait for the main release cycle.",
            "title": "Promotion to Testing and Release:"
        },
        {
            "location": "/software/repository-management/",
            "text": "Repository Management\n\u00b6\n\n\nThis document attempts to record everything there is to know about repository management for the OSG.\n\n\nPublic repositories\n\u00b6\n\n\nWe host four public-facing repositories at \nrepo.opensciencegrid.org\n:\n\n\n\n\n\n\ndevelopment\n: This repository is the bleeding edge. Installing from this repository may cause the host to stop functioning, and we will not assist in undoing any damage.\n\n\n\n\n\n\ntesting\n: This repository contains software ready for testing. If you install packages from here, they may be buggy, but we will provide limited assistance in providing a migration path to a fixed verison.\n\n\n\n\n\n\nrelease\n: This repository contains software that we are willing to support and can be used by the general community.\n\n\n\n\n\n\ncontrib\n: RPMs contributed from outside the OSG.\n\n\n\n\n\n\nThese repos are updated by the \nmash\n script running on \nrepo.opensciencegrid.org\n.\n\n\nInternal repositories\n\u00b6\n\n\nIn addition to the public repositories above, we host two repositories on \nkoji.opensciencegrid.org\n. These are updated shortly after jobs are built into them or tagged into them. They are technically publicly accessible, but we discourage the public from using them.\n\n\n\n\n\n\nminefield\n: This repository is a copy of development above.\n\n\n\n\n\n\nprerelease\n: This repository is a staging area for software that is slated to be in the next release.\n\n\n\n\n\n\nThese repos are updated by the \nkojira\n daemon running on \nkoji.opensciencegrid.org\n.\n\n\nBuild repositories\n\u00b6\n\n\nThe \nkoji\n task in \nosg-build\n uses the \nosg-3.4-el6-build\n/\nosg-3.4-el7-build\n repo, which is the union of the following repositories:\n\n\n\n\nMinefield a.k.a. \nosg-3.4-el6-development\n / \nosg-3.4-el7-development\n\n\nThe \nosg-el6-internal\n / \nosg-el7-internal\n tag (containing build dependencies we do not want to make public)\n\n\nThe \ndist-el6-build\n / \ndist-el7-build\n tag (consisting of the appropriate macros for %dist)\n\n\nCentOS and EPEL\n\n\n\n\nKoji will work from its internal cache of the above repositories (downloading the packages from the source), and will not update until the build repository is regenerated. By default, Koji does a groupinstall of the build group, then resolves the BuildRequires dependencies.\n\n\nThe tarball creation scripts use the \nosg-3.4-el6-release-build\n / \nosg-3.4-el7-release-build\n repo, which is the union of the following repositories:\n\n\n\n\nRelease a.k.a. \nosg-3.4-el6-release\n / \nosg-3.4-el7-release\n\n\nThe \ndist-el6-build\n / \ndist-el7-build\n tag (consisting of the appropriate macros for \n%dist\n)\n\n\nCentOS and EPEL",
            "title": "Repository Management"
        },
        {
            "location": "/software/repository-management/#repository-management",
            "text": "This document attempts to record everything there is to know about repository management for the OSG.",
            "title": "Repository Management"
        },
        {
            "location": "/software/repository-management/#public-repositories",
            "text": "We host four public-facing repositories at  repo.opensciencegrid.org :    development : This repository is the bleeding edge. Installing from this repository may cause the host to stop functioning, and we will not assist in undoing any damage.    testing : This repository contains software ready for testing. If you install packages from here, they may be buggy, but we will provide limited assistance in providing a migration path to a fixed verison.    release : This repository contains software that we are willing to support and can be used by the general community.    contrib : RPMs contributed from outside the OSG.    These repos are updated by the  mash  script running on  repo.opensciencegrid.org .",
            "title": "Public repositories"
        },
        {
            "location": "/software/repository-management/#internal-repositories",
            "text": "In addition to the public repositories above, we host two repositories on  koji.opensciencegrid.org . These are updated shortly after jobs are built into them or tagged into them. They are technically publicly accessible, but we discourage the public from using them.    minefield : This repository is a copy of development above.    prerelease : This repository is a staging area for software that is slated to be in the next release.    These repos are updated by the  kojira  daemon running on  koji.opensciencegrid.org .",
            "title": "Internal repositories"
        },
        {
            "location": "/software/repository-management/#build-repositories",
            "text": "The  koji  task in  osg-build  uses the  osg-3.4-el6-build / osg-3.4-el7-build  repo, which is the union of the following repositories:   Minefield a.k.a.  osg-3.4-el6-development  /  osg-3.4-el7-development  The  osg-el6-internal  /  osg-el7-internal  tag (containing build dependencies we do not want to make public)  The  dist-el6-build  /  dist-el7-build  tag (consisting of the appropriate macros for %dist)  CentOS and EPEL   Koji will work from its internal cache of the above repositories (downloading the packages from the source), and will not update until the build repository is regenerated. By default, Koji does a groupinstall of the build group, then resolves the BuildRequires dependencies.  The tarball creation scripts use the  osg-3.4-el6-release-build  /  osg-3.4-el7-release-build  repo, which is the union of the following repositories:   Release a.k.a.  osg-3.4-el6-release  /  osg-3.4-el7-release  The  dist-el6-build  /  dist-el7-build  tag (consisting of the appropriate macros for  %dist )  CentOS and EPEL",
            "title": "Build repositories"
        },
        {
            "location": "/software/globus-mass-update-procedure/",
            "text": "Globus mass update procedure\n\u00b6\n\n\nGlobus consists of many packages, which we tend to update at the same time. This requires extra work, primarily to prevent dependency issues.\n\n\nPrep work\n\u00b6\n\n\nDocs\n\u00b6\n\n\nCreate a spreadsheet or table of the builds. Table should have NVR, perhaps URL, status (not started, imported, built, tested), and comments (mostly to record if it was a simple pass-through or not).\n\n\nGet packages to update, using \nosg-outdated-epel-pkgs\n from \nopensciencegrid/tools\n.\n\n\nTo get in N-V-R format:\n\n\n[you@host]$\n ./osg-outdated-epel-pkgs \n|\n \n\\\n\n    egrep \n'^(globus|myproxy|gsi)'\n \n|\n \n\\\n\n    awk \n'BEGIN {OFS=\"\"} {print $1, \"-\", $3}'\n\n\n\n\n\n\nor to split up N and V-R in a comma-separated way (which you can feed into a Google Sheet to turn it into two columns):\n\n\n[you@host]$\n ./osg-outdated-epel-pkgs \n|\n \n\\\n\n    egrep \n'^(globus|myproxy|gsi)'\n \n|\n \n\\\n\n    awk \n'BEGIN {OFS=\"\"} {print $1, \",\", $3}'\n\n\n\n\n\n\nSVN\n\u00b6\n\n\nCreate a separate SVN branch and populate it with all the packages you will update. (Get the list from the doc created above).\n\n\n[you@uw]$\n svn mkdir file:///p/vdt/workspace/svn/native/redhat/branches/globus\n\n#\n## From a checkout, in native/redhat\n\n\n[you@uw]$\n \nfor\n x in <PACKAGES>\n;\n \ndo\n \n\\\n\n\n     svn copy \n$x\n branches/globus/\n${\nx\n#trunk/\n}\n;\n \n\\\n\n   \ndone\n\n\n\n\n\n\nChange \n<PACKAGES>\n for the list of package names from generated in the above section (\nDocs\n))\n\n\nKoji (Mat/Carl)\n\u00b6\n\n\nThis requires a Koji administrator. Koji admins as of August 2017 are Mat Selmeci and Carl Edquist.\n\n\nEnsure Koji tags exist: a destination tag, and a build tag, one for each dver, e.g.:\n\n\n\n\nel6-globus\n\n\nel6-globus-build\n\n\nel7-globus\n\n\nel7-globus-build\n\n\n\n\nSet up tag inheritence: base the build tags off of the corresponding \ndist-el?-build\n tag. This is because we don't want old osg packages interfering with the new versions we're building. These may already exist -- check the \nel?-globus-build\n tags in the web interface.\n\n\n[you@host]$\n \nfor\n el in el6 el7\n;\n \ndo\n \n\\\n\n        osg-koji add-tag --parent\n=\ndist-\n$el\n-build \n\\\n\n            --arches\n=\nx86_64 \n$el\n-globus-build\n;\n \n\\\n\n    \ndone\n\n\n\n\n\n\nTag \nbuildsys-macros\n for the OSG release into the build tags:\n\n\n[you@host]$\n \nfor\n el in el6 el7\n;\n \ndo\n \n\\\n\n       \nbuildsys_macros_nvr\n=\n$(\nosg-koji -q list-tagged osg-3.4-\n$el\n-development \n\\\n\n         buildsys-macros --latest \n|\n awk \n'{print $1}'\n)\n;\n \n\\\n\n       osg-koji tag-pkg \n$el\n-globus-build \n$buildsys_macros_nvr\n;\n \n\\\n\n   \ndone\n\n\n\n\n\n\nEnsure Koji targets exist, one for each dver, e.g.:\n\n\n\n\nel6-globus (el6-globus-build \u2192 el6-globus)\n\n\nel7-globus (el7-globus-build \u2192 el7-globus)\n\n\nkojira-fake-el6-globus (el6-globus \u2192 kojira-fake)\n\n\nkojira-fake-el7-globus (el7-globus \u2192 kojira-fake)\n\n\n\n\n[you@host]$\n \nfor\n el in el6 el7\n;\n \ndo\n \n\\\n\n       osg-koji add-target \n$el\n-globus \n$el\n-globus-build \n$el\n-globus\n;\n \n\\\n\n       osg-koji add-target kojira-fake-\n$el\n-globus \n$el\n-globus kojira-fake\n;\n \n\\\n\n   \ndone\n\n\n\n\n\n\nIf basing the packages off of the Globus repos, add the Globus repos as external repos, and add them to the build tags (but not the dest tags).\n\n\nEdit \n/etc/koji-hub/plugins/sign.conf\n and set up the GPG signing for the RPMs. Run \n/etc/koji-hub/plugins/fix-permissions\n after editing the file.\n\n\nPer-package work\n\u00b6\n\n\n\n\ncd into branches/globus\n\n\nDownload packages from \nhttp://dl.fedoraproject.org/pub/epel/6/SRPMS/\n\n\n\n\nA useful alias:\n\n\n[you@host]$\n \nalias\n osg-build-globus\n=\n\"osg-build koji --ktt el6-globus --ktt el7-globus\"\n\n\n\n\n\n\nStrict pass-through (no osg/ directory)\n\u00b6\n\n\n\n\n\n\nRun:\n\n\n[you@uw]$\n osg-import-srpm <URL>\n\n[you@uw]$\n osg-build-globus --scratch <PKG>\n\n\n\n\n\nChange \n<URL>\n for the URL from where the package will be donwloaded e.g. https://dl.fedoraproject.org/pub/epel/6/SRPMS/Packages/g/globus-authz-4.2-1.el6.src.rpm\nand \n<PKG>\n> for the name of the package e.g. \nglobus-authz\n\n\n\n\n\n\nCommit - use a message like \"Update to 3.12-1 from EPEL (SOFTWARE-2197)\"\n\n\n\n\n\n\nDo a non-scratch build.\n\n\n\n\n\n\nNon-strict pass-through\n\u00b6\n\n\n\n\n\n\nRun:\n\n\n[you@uw]$\n osg-import-srpm --diff3 <URL>\n\n\n\n\n\nChange \n<URL>\n for the URL from where the package will be donwloaded e.g. https://dl.fedoraproject.org/pub/epel/6/SRPMS/Packages/g/globus-authz-4.2-1.el6.src.rpm\n\n\n\n\n\n\nFix merge conflicts in the spec file. If not already there, put a .1 after the Release number to mark the changes as ours.\n\n\n\n\n\n\nRun:\n\n\n[you@uw]$\n osg-build quilt <PKG>\n\n\n\n\n\nChange \n<PKG>\n> for the name of the package e.g. \nglobus-authz\n\n\n\n\n\n\nFix patches if necessary.\n\n\n\n\n\n\nRun:\n\n\n[you@uw>]$\n osg-build-globus --scratch <PKG>\n\n\n\n\n\nChange \n<PKG>\n> for the name of the package e.g. \nglobus-authz\n\n\n\n\n\n\nCommit - use a message like \"Update to 8.29-1 from EPEL and merge OSG changes (SOFTWARE-2197)\"\n\n\n\n\n\n\nDo a non-scratch build.\n\n\n\n\n\n\nTesting\n\u00b6\n\n\nCreate a yum \n.repo\n file similar to \nosg-minefield\n that installs from the \nel?-globus\n repos. Enable this and \nosg-minefield\n.\n\n\nEL7 example:\n\n\n[globus]\n\n\nname\n=\nglobus\n\n\nbaseurl\n=\nhttp://koji.chtc.wisc.edu/mnt/koji/repos/el7-globus/latest/$basearch/\n\n\nfailovermethod\n=\npriority\n\n\npriority\n=\n98\n\n\nenabled\n=\n1\n\n\ngpgcheck\n=\n0\n\n\ngpgkey\n=\nfile:///etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\n\n\nconsider_as_osg\n=\nyes\n\n\n\n\n\n\nMerge\n\u00b6\n\n\nKoji (Mat/Carl)\n\u00b6\n\n\nThis requires a Koji administrator. Koji admins as of August 2017 are Mat Selmeci and Carl Edquist.\n\n\n\n\nUntag broken versions that we don't want to ship.\n\n\nUse \nmove-pkg\n:\n[you@host>]$\n \nfor\n el in el6 el7\n;\n \ndo\n \n\\\n\n        osg-koji -q list-tagged \n${\nel\n}\n-globus \n|\n \n\\\n\n            awk \n'{print $1}'\n > \n${\nel\n}\n-tagged.txt\n;\n \n\\\n\n    \ndone\n\n\n#\n## Check the txts if they look sane\n\n\n[you@host>]$\n \nfor\n el in el6 el7\n;\n \ndo\n \n\\\n\n        xargs -a \n${\nel\n}\n-tagged.txt \n\\\n\n            osg-koji move-pkg \n${\nel\n}\n-globus \n\\\n\n                osg-3.3-\n${\nel\n}\n-development\n;\n \n\\\n\n    \ndone\n\n\n\n\n\n\n\n\n\n\nSVN\n\u00b6\n\n\n\n\nMerge from \ntrunk\n to \nbranches/globus\n first, to pick up any globus changes that may have happened in trunk.\n\n\nMerge from \nbranches/globus\n to \ntrunk\n.\n\n\n\n\nMove \nbranches/globus\n to \ntags/globus-<DATE>\n.\n\n\nWhere \n<DATE>\n is the current date in the following format: YYYY-MM-DD, e.g. 2016-08-29",
            "title": "Globus Mass Update Procedure"
        },
        {
            "location": "/software/globus-mass-update-procedure/#globus-mass-update-procedure",
            "text": "Globus consists of many packages, which we tend to update at the same time. This requires extra work, primarily to prevent dependency issues.",
            "title": "Globus mass update procedure"
        },
        {
            "location": "/software/globus-mass-update-procedure/#prep-work",
            "text": "",
            "title": "Prep work"
        },
        {
            "location": "/software/globus-mass-update-procedure/#docs",
            "text": "Create a spreadsheet or table of the builds. Table should have NVR, perhaps URL, status (not started, imported, built, tested), and comments (mostly to record if it was a simple pass-through or not).  Get packages to update, using  osg-outdated-epel-pkgs  from  opensciencegrid/tools .  To get in N-V-R format:  [you@host]$  ./osg-outdated-epel-pkgs  |   \\ \n    egrep  '^(globus|myproxy|gsi)'   |   \\ \n    awk  'BEGIN {OFS=\"\"} {print $1, \"-\", $3}'   or to split up N and V-R in a comma-separated way (which you can feed into a Google Sheet to turn it into two columns):  [you@host]$  ./osg-outdated-epel-pkgs  |   \\ \n    egrep  '^(globus|myproxy|gsi)'   |   \\ \n    awk  'BEGIN {OFS=\"\"} {print $1, \",\", $3}'",
            "title": "Docs"
        },
        {
            "location": "/software/globus-mass-update-procedure/#svn",
            "text": "Create a separate SVN branch and populate it with all the packages you will update. (Get the list from the doc created above).  [you@uw]$  svn mkdir file:///p/vdt/workspace/svn/native/redhat/branches/globus # ## From a checkout, in native/redhat  [you@uw]$   for  x in <PACKAGES> ;   do   \\       svn copy  $x  branches/globus/ ${ x #trunk/ } ;   \\ \n    done   Change  <PACKAGES>  for the list of package names from generated in the above section ( Docs ))",
            "title": "SVN"
        },
        {
            "location": "/software/globus-mass-update-procedure/#koji-matcarl",
            "text": "This requires a Koji administrator. Koji admins as of August 2017 are Mat Selmeci and Carl Edquist.  Ensure Koji tags exist: a destination tag, and a build tag, one for each dver, e.g.:   el6-globus  el6-globus-build  el7-globus  el7-globus-build   Set up tag inheritence: base the build tags off of the corresponding  dist-el?-build  tag. This is because we don't want old osg packages interfering with the new versions we're building. These may already exist -- check the  el?-globus-build  tags in the web interface.  [you@host]$   for  el in el6 el7 ;   do   \\ \n        osg-koji add-tag --parent = dist- $el -build  \\ \n            --arches = x86_64  $el -globus-build ;   \\ \n     done   Tag  buildsys-macros  for the OSG release into the build tags:  [you@host]$   for  el in el6 el7 ;   do   \\ \n        buildsys_macros_nvr = $( osg-koji -q list-tagged osg-3.4- $el -development  \\ \n         buildsys-macros --latest  |  awk  '{print $1}' ) ;   \\ \n       osg-koji tag-pkg  $el -globus-build  $buildsys_macros_nvr ;   \\ \n    done   Ensure Koji targets exist, one for each dver, e.g.:   el6-globus (el6-globus-build \u2192 el6-globus)  el7-globus (el7-globus-build \u2192 el7-globus)  kojira-fake-el6-globus (el6-globus \u2192 kojira-fake)  kojira-fake-el7-globus (el7-globus \u2192 kojira-fake)   [you@host]$   for  el in el6 el7 ;   do   \\ \n       osg-koji add-target  $el -globus  $el -globus-build  $el -globus ;   \\ \n       osg-koji add-target kojira-fake- $el -globus  $el -globus kojira-fake ;   \\ \n    done   If basing the packages off of the Globus repos, add the Globus repos as external repos, and add them to the build tags (but not the dest tags).  Edit  /etc/koji-hub/plugins/sign.conf  and set up the GPG signing for the RPMs. Run  /etc/koji-hub/plugins/fix-permissions  after editing the file.",
            "title": "Koji (Mat/Carl)"
        },
        {
            "location": "/software/globus-mass-update-procedure/#per-package-work",
            "text": "cd into branches/globus  Download packages from  http://dl.fedoraproject.org/pub/epel/6/SRPMS/   A useful alias:  [you@host]$   alias  osg-build-globus = \"osg-build koji --ktt el6-globus --ktt el7-globus\"",
            "title": "Per-package work"
        },
        {
            "location": "/software/globus-mass-update-procedure/#strict-pass-through-no-osg-directory",
            "text": "Run:  [you@uw]$  osg-import-srpm <URL> [you@uw]$  osg-build-globus --scratch <PKG>  Change  <URL>  for the URL from where the package will be donwloaded e.g. https://dl.fedoraproject.org/pub/epel/6/SRPMS/Packages/g/globus-authz-4.2-1.el6.src.rpm\nand  <PKG> > for the name of the package e.g.  globus-authz    Commit - use a message like \"Update to 3.12-1 from EPEL (SOFTWARE-2197)\"    Do a non-scratch build.",
            "title": "Strict pass-through (no osg/ directory)"
        },
        {
            "location": "/software/globus-mass-update-procedure/#non-strict-pass-through",
            "text": "Run:  [you@uw]$  osg-import-srpm --diff3 <URL>  Change  <URL>  for the URL from where the package will be donwloaded e.g. https://dl.fedoraproject.org/pub/epel/6/SRPMS/Packages/g/globus-authz-4.2-1.el6.src.rpm    Fix merge conflicts in the spec file. If not already there, put a .1 after the Release number to mark the changes as ours.    Run:  [you@uw]$  osg-build quilt <PKG>  Change  <PKG> > for the name of the package e.g.  globus-authz    Fix patches if necessary.    Run:  [you@uw>]$  osg-build-globus --scratch <PKG>  Change  <PKG> > for the name of the package e.g.  globus-authz    Commit - use a message like \"Update to 8.29-1 from EPEL and merge OSG changes (SOFTWARE-2197)\"    Do a non-scratch build.",
            "title": "Non-strict pass-through"
        },
        {
            "location": "/software/globus-mass-update-procedure/#testing",
            "text": "Create a yum  .repo  file similar to  osg-minefield  that installs from the  el?-globus  repos. Enable this and  osg-minefield .  EL7 example:  [globus]  name = globus  baseurl = http://koji.chtc.wisc.edu/mnt/koji/repos/el7-globus/latest/$basearch/  failovermethod = priority  priority = 98  enabled = 1  gpgcheck = 0  gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-OSG  consider_as_osg = yes",
            "title": "Testing"
        },
        {
            "location": "/software/globus-mass-update-procedure/#merge",
            "text": "",
            "title": "Merge"
        },
        {
            "location": "/software/globus-mass-update-procedure/#koji-matcarl_1",
            "text": "This requires a Koji administrator. Koji admins as of August 2017 are Mat Selmeci and Carl Edquist.   Untag broken versions that we don't want to ship.  Use  move-pkg : [you@host>]$   for  el in el6 el7 ;   do   \\ \n        osg-koji -q list-tagged  ${ el } -globus  |   \\ \n            awk  '{print $1}'  >  ${ el } -tagged.txt ;   \\ \n     done  # ## Check the txts if they look sane  [you@host>]$   for  el in el6 el7 ;   do   \\ \n        xargs -a  ${ el } -tagged.txt  \\ \n            osg-koji move-pkg  ${ el } -globus  \\ \n                osg-3.3- ${ el } -development ;   \\ \n     done",
            "title": "Koji (Mat/Carl)"
        },
        {
            "location": "/software/globus-mass-update-procedure/#svn_1",
            "text": "Merge from  trunk  to  branches/globus  first, to pick up any globus changes that may have happened in trunk.  Merge from  branches/globus  to  trunk .   Move  branches/globus  to  tags/globus-<DATE> .  Where  <DATE>  is the current date in the following format: YYYY-MM-DD, e.g. 2016-08-29",
            "title": "SVN"
        },
        {
            "location": "/software/resurrecting-epel-packages/",
            "text": "Resurrecting EPEL RPMs\n\u00b6\n\n\nYou will need to be a Koji admin to do these steps. \n\n\n[user@client ~] $\n osg-koji --list-permissions --mine\n\n\n\n\n\nWill tell you if you're an admin or not. Current Koji admins are the Madison team and Brian Bockelman.\n\n\n\n\n\n\n\n\nEPEL version\n\n\nEPEL Koji tag\n\n\nOur Koji tag\n\n\n\n\n\n\n\n\n\n\n5\n\n\ndist-5E-epel\n\n\nepelrescue-el5\n\n\n\n\n\n\n6\n\n\ndist-6E-epel\n\n\nepelrescue-el6\n\n\n\n\n\n\n7\n\n\nepel7\n\n\nepelrescue-el7\n\n\n\n\n\n\n\n\n\n\n\n\nDetermine the NVR of the build containing the RPM of the package you want.\n\n\nUse the Fedora/EPEL Koji web interface (\nhttps://koji.fedoraproject.org\n) to search for it.\n\n\nYou can use the search box in the upper right to look for packages, builds, or RPMs; it accepts shell wildcards.\n\n\nEPEL builds have .el5, .el6, or .el7 in the dist tag.\n\n\n\n\n\n\nDownload \nall\n RPMs for \nall\n architectures we care about (i386, i486, i586, i686, x86_64, noarch), including the .src.rpm and the debuginfo rpms.\n\n\nYou have three options for the downloads:\n\n\n\n\nUse the links in the web interface\n\n\n\n\nUse the koji command-line interface against the Fedora koji:\n\n\n\n\nDownload \nfedora-koji.conf\n, attached to this page\n\n\nRun \nkoji --noauth -c fedora-koji.conf download-build --debuginfo <PACKAGE_NVR>\n\n\nDelete RPMs for architectures we do not care about (see list above)\n\n\n\n\n<PACKAGE_NVR>\n is the Name-Version-Release information about the build, which was determined in the step 1 above\n\n\n\n\n\n\nDig around in \nhttps://kojipkgs.fedoraproject.org/packages/\n\n\n\n\n\n\n\n\n\n\nOn your development machine:\n\n\n\n\n\n\nImportant:\n Verify that all of the RPMs are signed:\n\n\n[root@client ~] #\n rpm -K *.rpm \n|\n grep -iv gpg\n\n\n\n\n\nshould be empty\n\n\nIf not, \nSTOP\n and sign them using the OSG RPM key -- talk to Mat\n\n\n\n\n\n\nImport the RPMs themselves into the Koji system\n\n\n[user@client ~] $\n osg-koji import <RPM_DIRECTORY>/*.rpm\n\n\n\n\n\nWhere \n<RPM_DIRECTORY>\n is the directory where you have downloaded the rpms.\nThey will not be in any tags at this point\n\n\n\n\n\n\nAdd the package to the whitelist for our koji tag:\n\n\n[user@client ~] $\n osg-koji add-pkg <OUR_KOJI_TAG> <PACKAGE> --owner\n=\n\"<YOUR_KOJI_USERNAME>\"\n\n\n\n\n\n\nWhere \n<OUR_KOJI_TAG>\n is one of those listed in the table at the top of this page, an example of \n<PACKAGE>\n is:\n\ncvmfs-config-osg-2.4-1.osg34.el6\n and \n<YOUR_KOJI_USERNAME>\n is the username you use to interact with the Koji\nsystem\n\n\n\n\n\n\nActually tag the builds:\n\n\n[user@client ~] $\n osg-koji tag-pkg <OUR_KOJI_TAG> <PACKAGE>\n\n\n\n\n\n\n\n\n\nCheck the Tasks tab in Koji to see if kojira has started regening the repos -- it might take a few minutes to kick in.\n\n\nIf it doesn't, do it manually (if you're doing multiple packages, save this step until you're done with all of them):\n\n\nfor repo in osg-{3.1,3.2,3.3,upcoming}-el5-{build,development,testing,release,prerelease,release-build}; do\n   osg-koji regen-repo --nowait $repo\ndone\n\n\n\n\n\n\n\n\n\nMake a test VM and install the package from minefield to test that it is actually present.\n\n\n\n\nUpdate the epelrescue RPMs table below\n\n\n\n\nRemoving resurrected RPMs\n\u00b6\n\n\nIn case the RPM appeared back in EPEL, or we no longer need it, here's how to remove it from the epelrescue tags so we're not overriding the EPEL version:\n\n\n\n\n\n\nFind out the NVR of the build:\n\n\n[user@client ~] $\n osg-koji list-tagged <OUR_KOJI_TAG> <PACKAGE>\n\n\n\n\n\nWhere \n<OUR_KOJI_TAG>\n is one of those listed in the table at the top of this page and an example of \n<PACKAGE>\n is:\n\ncvmfs-config-osg-2.4-1.osg34.el6\n\n\n\n\n\n\nUntag the packages:\n\n\n[user@client ~] $\n osg-koji untag-pkg <OUR_KOJI_TAG> <PACKAGE>\n\n\n\n\n\n\n\n\n\nWhy you should not use block-pkg\n\u00b6\n\n\nEPEL removes their packages by using 'koji block-pkg', which leaves the package and the builds in the tag, but prevents it from appearing in the repos. We cannot do that, because blocks are inherited and this will mess up our build repos. This is what happened in one case:\n\n\n\n\nEPEL removed rpmdevtools, which is a necessary package for all builds. I resurrected it into epelrescue-el5.\n\n\nLater, EPEL put rpmdevtools back into their repos, so it no longer needed to be in epelrescue-el5.\n\n\nI used block-pkg on rpmdevtools in epelrescue-el5, thinking that the package could remain tagged, but will stay out of our repos, and the EPEL package would be used instead.\n\n\nThe block not only hid our rpmdevtools, it hid EPEL's rpmdevtools as well, preventing us from being able to build.\n\n\nI unblocked the rpmdevtools, and just untagged the build instead, regenerated our build repos, and we could build again.\n\n\n\n\nPolicy for epelrescue tags\n\u00b6\n\n\nhttps://jira.opensciencegrid.org/browse/SOFTWARE-2046\n\n\nTable of epelrescue RPMs\n\u00b6\n\n\n\n\n\n\n\n\nPackage\n\n\nDistro version\n\n\nDate added\n\n\nReason added\n\n\nDate removed\n\n\n\n\n\n\n\n\n\n\npython-six-1.7.3-1.el6\n\n\n6\n\n\n2015-08-12\n\n\nDep of osg-build (via mock)\n\n\n2015-10-14\n\n\n\n\n\n\npython-argparse-1.2.1-2.el6\n\n\n6\n\n\n2015-09-23\n\n\nDep of osg-wn-client (via gfal2)\n\n\n2015-10-14\n\n\n\n\n\n\npython-backports-ssl_match_hostname-3.4.0.2-4.el6\n\n\n6\n\n\n2015-09-23\n\n\nDep of osg-build (via mock)\n\n\n2015-10-14\n\n\n\n\n\n\npython-requests-1.1.0-4.el6\n\n\n6\n\n\n2015-09-23\n\n\nDep of osg-build (via mock)\n\n\n2015-10-14\n\n\n\n\n\n\npython-urllib3-1.5-7.el6\n\n\n6\n\n\n2015-09-23\n\n\nDep of osg-build (via mock)\n\n\n2015-10-14\n\n\n\n\n\n\n\n\nFinding out if a package is still needed in epelrescue\n\u00b6\n\n\nSet \n$pkg\n to the name of a package to test (e.g. \npython-six\n), and \n$rhel\n set to the RHEL version you're testing for (e.g. \n5\n, \n6\n, or \n7\n).\n\n\nUsing Carl's \ncentos-srpms\n, \nscientific-srpms\n, \nslf-srpms\n scripts:\n\n\nfor script in centos-srpms scientific-srpms slf-srpms; do\n       echo -n $script \": \"\n       $script -$rhel $pkg | grep . || echo none\ndone\n\n\n\n\n\nA dry run of removing the package:\n\n\nosg-koji untag-pkg -n --all epelrescue-el$rhel $pkg\n\n\n\n\n\nRemove the \n-n\n when the output of that looks fine.",
            "title": "Resurrecting Epel Packages"
        },
        {
            "location": "/software/resurrecting-epel-packages/#resurrecting-epel-rpms",
            "text": "You will need to be a Koji admin to do these steps.   [user@client ~] $  osg-koji --list-permissions --mine  Will tell you if you're an admin or not. Current Koji admins are the Madison team and Brian Bockelman.     EPEL version  EPEL Koji tag  Our Koji tag      5  dist-5E-epel  epelrescue-el5    6  dist-6E-epel  epelrescue-el6    7  epel7  epelrescue-el7       Determine the NVR of the build containing the RPM of the package you want.  Use the Fedora/EPEL Koji web interface ( https://koji.fedoraproject.org ) to search for it.  You can use the search box in the upper right to look for packages, builds, or RPMs; it accepts shell wildcards.  EPEL builds have .el5, .el6, or .el7 in the dist tag.    Download  all  RPMs for  all  architectures we care about (i386, i486, i586, i686, x86_64, noarch), including the .src.rpm and the debuginfo rpms.  You have three options for the downloads:   Use the links in the web interface   Use the koji command-line interface against the Fedora koji:   Download  fedora-koji.conf , attached to this page  Run  koji --noauth -c fedora-koji.conf download-build --debuginfo <PACKAGE_NVR>  Delete RPMs for architectures we do not care about (see list above)   <PACKAGE_NVR>  is the Name-Version-Release information about the build, which was determined in the step 1 above    Dig around in  https://kojipkgs.fedoraproject.org/packages/      On your development machine:    Important:  Verify that all of the RPMs are signed:  [root@client ~] #  rpm -K *.rpm  |  grep -iv gpg  should be empty  If not,  STOP  and sign them using the OSG RPM key -- talk to Mat    Import the RPMs themselves into the Koji system  [user@client ~] $  osg-koji import <RPM_DIRECTORY>/*.rpm  Where  <RPM_DIRECTORY>  is the directory where you have downloaded the rpms.\nThey will not be in any tags at this point    Add the package to the whitelist for our koji tag:  [user@client ~] $  osg-koji add-pkg <OUR_KOJI_TAG> <PACKAGE> --owner = \"<YOUR_KOJI_USERNAME>\"   Where  <OUR_KOJI_TAG>  is one of those listed in the table at the top of this page, an example of  <PACKAGE>  is: cvmfs-config-osg-2.4-1.osg34.el6  and  <YOUR_KOJI_USERNAME>  is the username you use to interact with the Koji\nsystem    Actually tag the builds:  [user@client ~] $  osg-koji tag-pkg <OUR_KOJI_TAG> <PACKAGE>    Check the Tasks tab in Koji to see if kojira has started regening the repos -- it might take a few minutes to kick in.  If it doesn't, do it manually (if you're doing multiple packages, save this step until you're done with all of them):  for repo in osg-{3.1,3.2,3.3,upcoming}-el5-{build,development,testing,release,prerelease,release-build}; do\n   osg-koji regen-repo --nowait $repo\ndone    Make a test VM and install the package from minefield to test that it is actually present.   Update the epelrescue RPMs table below",
            "title": "Resurrecting EPEL RPMs"
        },
        {
            "location": "/software/resurrecting-epel-packages/#removing-resurrected-rpms",
            "text": "In case the RPM appeared back in EPEL, or we no longer need it, here's how to remove it from the epelrescue tags so we're not overriding the EPEL version:    Find out the NVR of the build:  [user@client ~] $  osg-koji list-tagged <OUR_KOJI_TAG> <PACKAGE>  Where  <OUR_KOJI_TAG>  is one of those listed in the table at the top of this page and an example of  <PACKAGE>  is: cvmfs-config-osg-2.4-1.osg34.el6    Untag the packages:  [user@client ~] $  osg-koji untag-pkg <OUR_KOJI_TAG> <PACKAGE>",
            "title": "Removing resurrected RPMs"
        },
        {
            "location": "/software/resurrecting-epel-packages/#why-you-should-not-use-block-pkg",
            "text": "EPEL removes their packages by using 'koji block-pkg', which leaves the package and the builds in the tag, but prevents it from appearing in the repos. We cannot do that, because blocks are inherited and this will mess up our build repos. This is what happened in one case:   EPEL removed rpmdevtools, which is a necessary package for all builds. I resurrected it into epelrescue-el5.  Later, EPEL put rpmdevtools back into their repos, so it no longer needed to be in epelrescue-el5.  I used block-pkg on rpmdevtools in epelrescue-el5, thinking that the package could remain tagged, but will stay out of our repos, and the EPEL package would be used instead.  The block not only hid our rpmdevtools, it hid EPEL's rpmdevtools as well, preventing us from being able to build.  I unblocked the rpmdevtools, and just untagged the build instead, regenerated our build repos, and we could build again.",
            "title": "Why you should not use block-pkg"
        },
        {
            "location": "/software/resurrecting-epel-packages/#policy-for-epelrescue-tags",
            "text": "https://jira.opensciencegrid.org/browse/SOFTWARE-2046",
            "title": "Policy for epelrescue tags"
        },
        {
            "location": "/software/resurrecting-epel-packages/#table-of-epelrescue-rpms",
            "text": "Package  Distro version  Date added  Reason added  Date removed      python-six-1.7.3-1.el6  6  2015-08-12  Dep of osg-build (via mock)  2015-10-14    python-argparse-1.2.1-2.el6  6  2015-09-23  Dep of osg-wn-client (via gfal2)  2015-10-14    python-backports-ssl_match_hostname-3.4.0.2-4.el6  6  2015-09-23  Dep of osg-build (via mock)  2015-10-14    python-requests-1.1.0-4.el6  6  2015-09-23  Dep of osg-build (via mock)  2015-10-14    python-urllib3-1.5-7.el6  6  2015-09-23  Dep of osg-build (via mock)  2015-10-14",
            "title": "Table of epelrescue RPMs"
        },
        {
            "location": "/software/resurrecting-epel-packages/#finding-out-if-a-package-is-still-needed-in-epelrescue",
            "text": "Set  $pkg  to the name of a package to test (e.g.  python-six ), and  $rhel  set to the RHEL version you're testing for (e.g.  5 ,  6 , or  7 ).  Using Carl's  centos-srpms ,  scientific-srpms ,  slf-srpms  scripts:  for script in centos-srpms scientific-srpms slf-srpms; do\n       echo -n $script \": \"\n       $script -$rhel $pkg | grep . || echo none\ndone  A dry run of removing the package:  osg-koji untag-pkg -n --all epelrescue-el$rhel $pkg  Remove the  -n  when the output of that looks fine.",
            "title": "Finding out if a package is still needed in epelrescue"
        },
        {
            "location": "/software/koji-mass-rebuilds/",
            "text": "Mass RPM Rebuilds for a new Build Target in Koji\n\u00b6\n\n\nWhenever we move to a new OSG series (OSG 3.3) and/or a new RHEL version (EL7), we want to make new builds for all of our packages in the new koji build target (osg-3.3-el7). Due to tricky build dependencies and unexpected build failures, this can be a messy task; and in the past we have gone about it in an ad-hoc manner.\n\n\nThis document will discuss some of the aspects of the task and issues involved, some possible approaches, and ultimately a proposal for a general tool or procedure for doing our mass rebuilds.\n\n\nNew RHEL version vs new OSG series\n\u00b6\n\n\nNew RHEL version\n\u00b6\n\n\nFor a new RHEL version, we start with no osg packages to build against, so we are forced to build things in dependency order. Figuring out the dependency order is possibly the most difficult (or interesting) part of doing mass rebuilds -- more on that later.\n\n\nNew OSG series\n\u00b6\n\n\nFor a new OSG series within an existing RHEL version, we have more options. While it's possible to \"start from scratch\" the same way we would with a new RHEL version and build everything in dependency order, this is not really necessary if we take advantage of existing builds from the previous series.\n\n\nA prior step is to determine the package list for the new series -- this will be some combination of Upcoming and the current release series, minus any packages pruned for the new series. This should also be reflected in the new trunk packaging area. All the current builds for packages in that list (from upcoming + current series) can be tagged into the new *-development (or *-build) repos. This should make all of the build dependencies available for mass rebuilding the new series all at once (osg-build koji *).\n\n\nAfter some consideration, I wholeheartedly endorse this approach for new OSG series -- for all but academic exercises. Rebuilding in dependency order when all the dependencies are already built just seems like wasted effort.\n\n\nDoing scratch builds of everything first\n\u00b6\n\n\nBefore doing the mass rebuilds in a new build target, it seems to be a good idea to do scratch builds of all the packages in the current series first. (Or, at least the ones we intend to bring into the new build target.) This will give us a chance to see any build failures that have crept in (possibly due to upstream changes in the OS or EPEL), and fix them first if desired, but in any case avoid the confusion of seeing the failures for the first time in the new build target.\n\n\nDoing mass scratch rebuilds for an existing series is easy, as they can all be done at once.\n\n\nRelatedly, doing a round of scratch builds \nafter\n successfully building all packages into a new build target can also be useful, because it can reveal dependency issues only present in the new set of builds. Doing developer test installs or a round of VMU tests may also uncover any runtime dependency issues.\n\n\nOptions for calculating build dependencies\n\u00b6\n\n\nWe can get dependency information from a number of places:\n\n\n\n\nscraping .spec files for Requires/BuildRequires/Provides and \n%package\n names\n\n\nquerying existing rpms directly on koji-hub and our OS/EPEL mirrors (\nrpm -q\n)\n\n\nquerying srpms from \nosg-build prebuild\n directly for build requirements\n\n\ninspecting previous buildroots to determine resolved build dependencies\n\n\nuse \nrepoquery\n to determine whatrequires/whatprovides for packages\n\n\nuse \nyum-builddep\n to find packages with all build requirements available\n\n\nusing the repodata (primary+filelists) from rpm repositories, including:\n\n\nupcoming + 3.X development + external repos (Centos/EPEL/JPackage), OR\n\n\nosg-upcoming-elX-build, which includes them all\n\n\n\n\nOne important aspect is that the runtime requirements are also relevant for determining build requirements, since a build will require installing all of the runtime requirements of the packages required for the build.\n\n\nThat is, \n(A BuildRequires B) and (B Requires C)\n implies \nA BuildRequires C\n.\n\n\nCombined with the fact that runtime requirements are transitive, that is, \n(A Requires B) and (B Requires C)\n implies \nA Requires C\n, computing build requirements is a recursive operation, which can be many levels deep.\n\n\nAnother question to keep in mind is whether to use versioned requires/provides (i.e., BuildRequires xyz >= 1.2-3) or to only pay attention to the package/capability names. Similarly, whether to pay any attention to conflicts/obsoletes. These would add complexity to anything except the standard tools (repoquery, yum-builddep) which already take these things into account. (And we may get pretty far even without paying attention to versions.)\n\n\nNote also that the dependencies/capabilities for a given package often varies between different rhel versions.\n\n\nPre-computing (predictive) vs just-in-time\n\u00b6\n\n\nTwo different approaches to determining dependency order for building are:\n\n\n\n\npre compute all dependencies based on an existing series/rhel version, OR\n\n\ncompute which remaining packages have all build reqs satisfied now\n\n\n\n\nThe first approach has the benefit of being able to determine the packages that need to be built in order to accomplish a smaller subset goal first -- for example, to be able to install osg-wn-client. (And, if there are problems with resolving certain dependencies (say with osg-wn-client again), it will become apparent earlier, as opposed to not until all possible-to-build packages have been built.) The limitation of this approach is that the predicted set of files/capabilities that a binary package will provide may differ between osg series/rhel versions, and as a result may be inaccurate for the new build target.\n\n\nThe second approach provides somewhat more confidence about being able to correctly determine which packages should be buildable at any point in time, but (as mentioned above) it is a bit more in the dark about seeing the bigger picture of the dependency graph or being able to build subsets of targets.\n\n\nIt may be useful to have both options available -- building from the list in the second approach, but using the first mechanism to have a better picture of where things are at, or perhaps to steer toward finishing a certain subset of packages first.\n\n\nPackage list closure, pruning\n\u00b6\n\n\nAt some point (either in the planning stage or after building packages into the new build target), we need to ensure that the new osg series/rhel version contains all of its install requirements for all of its packages. It would probably suffice to do a VMU run that installs each package (perhaps individually, to avoid conflicts).\n\n\nBut if we go about it more analytically, we may also get, as a result, a list of packages which we previously only maintained for the purpose of building our other packages (ie, that were never required at runtime for any use cases that we cared about), which now, in the new target, are no longer build requirements (directly or indirectly) for any packages that we care about installing. Packages in this category could be reviewed to also be dropped from the new build target.\n\n\nProposal / Recommendations\n\u00b6\n\n\nAs mentioned earlier, my recommendation is that we treat a new OSG series differently than a new RHEL version.\n\n\nFor a new OSG series:\n\u00b6\n\n\n\n\n\n\nupdate native/redhat packaging area to reflect packages for new series, including upcoming + trunk - removed packages\n\n\n\n\n\n\ntag existing builds of packages in new list into the new development tag (eg, for osg-3.3-el6, tag the .osgup.el6 and .osg32.el6 builds into osg-3.3-el6-development)\n\n\n\n\n\n\nbuild all packages in new packaging area into new build target at once\n\n\n\n\n\n\nfor all successful builds, remove corresponding old builds (eg, .osgup/.osg32) from the new tag (osg-3.3-el6-development)\n\n\n\n\n\n\nFor a new RHEL version:\n\u00b6\n\n\n\n\npull the repodata from the relevant \n*-build\n repo from koji:\n\n\n\n\nfor pre-computing, use a build repo from an existing rhel version:\n\n\nhttps://koji.chtc.wisc.edu/mnt/koji/repos/osg-3.2-el6-build/latest/x86_64/repodata/\n\n\nfor just-in-time, use the new build repo:\n\n\nhttps://koji.chtc.wisc.edu/mnt/koji/repos/osg-3.2-el8-build/latest/x86_64/repodata/\n\n\nthe primary and filelists (sqlite) files can be used to get runtime requires and provides. (Note that this includes packages from the relevant external repos, also.)\n\n\n\n\ngenerate srpms repodata for the current set of packages to build, with osg-build prebuild and createrepo.\n\n\n\n\nthe primary (sqlite) file can be used to get build-requires.\n\n\n\n\nuse sql to resolve direct dependencies at the package name level:\n\n\nsrc-pkg: bin-pkg (BuildRequires)\n\n\nbin-pkg: bin-pkg (Requires)\n\n\nbin-pkg: src-pkg (bin-pkg comes from which src-pkg? only needed for pre-computing dependencies)\n\n\n\n\n\n\nresolve this list into a full list of recursive build dependencies.\n\n\n\n\nSince this is recursive, there is no way to do it in a fixed number of sql queries. However the above input list is already directly consumable by Make, which is designed to handle recursive dependencies just like this. Or we can write a new tool to do it in python.\n\n\n\n\nbuild ready-to-be-built packages\n\n\nupdate our copy of the repodata from the regen'ed \n*-build\n repo, as often as new versions become available\n\n\nupdate our dependency lists\n\n\nrepeat until all packages are built",
            "title": "Koji Mass Rebuilds"
        },
        {
            "location": "/software/koji-mass-rebuilds/#mass-rpm-rebuilds-for-a-new-build-target-in-koji",
            "text": "Whenever we move to a new OSG series (OSG 3.3) and/or a new RHEL version (EL7), we want to make new builds for all of our packages in the new koji build target (osg-3.3-el7). Due to tricky build dependencies and unexpected build failures, this can be a messy task; and in the past we have gone about it in an ad-hoc manner.  This document will discuss some of the aspects of the task and issues involved, some possible approaches, and ultimately a proposal for a general tool or procedure for doing our mass rebuilds.",
            "title": "Mass RPM Rebuilds for a new Build Target in Koji"
        },
        {
            "location": "/software/koji-mass-rebuilds/#new-rhel-version-vs-new-osg-series",
            "text": "",
            "title": "New RHEL version vs new OSG series"
        },
        {
            "location": "/software/koji-mass-rebuilds/#new-rhel-version",
            "text": "For a new RHEL version, we start with no osg packages to build against, so we are forced to build things in dependency order. Figuring out the dependency order is possibly the most difficult (or interesting) part of doing mass rebuilds -- more on that later.",
            "title": "New RHEL version"
        },
        {
            "location": "/software/koji-mass-rebuilds/#new-osg-series",
            "text": "For a new OSG series within an existing RHEL version, we have more options. While it's possible to \"start from scratch\" the same way we would with a new RHEL version and build everything in dependency order, this is not really necessary if we take advantage of existing builds from the previous series.  A prior step is to determine the package list for the new series -- this will be some combination of Upcoming and the current release series, minus any packages pruned for the new series. This should also be reflected in the new trunk packaging area. All the current builds for packages in that list (from upcoming + current series) can be tagged into the new *-development (or *-build) repos. This should make all of the build dependencies available for mass rebuilding the new series all at once (osg-build koji *).  After some consideration, I wholeheartedly endorse this approach for new OSG series -- for all but academic exercises. Rebuilding in dependency order when all the dependencies are already built just seems like wasted effort.",
            "title": "New OSG series"
        },
        {
            "location": "/software/koji-mass-rebuilds/#doing-scratch-builds-of-everything-first",
            "text": "Before doing the mass rebuilds in a new build target, it seems to be a good idea to do scratch builds of all the packages in the current series first. (Or, at least the ones we intend to bring into the new build target.) This will give us a chance to see any build failures that have crept in (possibly due to upstream changes in the OS or EPEL), and fix them first if desired, but in any case avoid the confusion of seeing the failures for the first time in the new build target.  Doing mass scratch rebuilds for an existing series is easy, as they can all be done at once.  Relatedly, doing a round of scratch builds  after  successfully building all packages into a new build target can also be useful, because it can reveal dependency issues only present in the new set of builds. Doing developer test installs or a round of VMU tests may also uncover any runtime dependency issues.",
            "title": "Doing scratch builds of everything first"
        },
        {
            "location": "/software/koji-mass-rebuilds/#options-for-calculating-build-dependencies",
            "text": "We can get dependency information from a number of places:   scraping .spec files for Requires/BuildRequires/Provides and  %package  names  querying existing rpms directly on koji-hub and our OS/EPEL mirrors ( rpm -q )  querying srpms from  osg-build prebuild  directly for build requirements  inspecting previous buildroots to determine resolved build dependencies  use  repoquery  to determine whatrequires/whatprovides for packages  use  yum-builddep  to find packages with all build requirements available  using the repodata (primary+filelists) from rpm repositories, including:  upcoming + 3.X development + external repos (Centos/EPEL/JPackage), OR  osg-upcoming-elX-build, which includes them all   One important aspect is that the runtime requirements are also relevant for determining build requirements, since a build will require installing all of the runtime requirements of the packages required for the build.  That is,  (A BuildRequires B) and (B Requires C)  implies  A BuildRequires C .  Combined with the fact that runtime requirements are transitive, that is,  (A Requires B) and (B Requires C)  implies  A Requires C , computing build requirements is a recursive operation, which can be many levels deep.  Another question to keep in mind is whether to use versioned requires/provides (i.e., BuildRequires xyz >= 1.2-3) or to only pay attention to the package/capability names. Similarly, whether to pay any attention to conflicts/obsoletes. These would add complexity to anything except the standard tools (repoquery, yum-builddep) which already take these things into account. (And we may get pretty far even without paying attention to versions.)  Note also that the dependencies/capabilities for a given package often varies between different rhel versions.",
            "title": "Options for calculating build dependencies"
        },
        {
            "location": "/software/koji-mass-rebuilds/#pre-computing-predictive-vs-just-in-time",
            "text": "Two different approaches to determining dependency order for building are:   pre compute all dependencies based on an existing series/rhel version, OR  compute which remaining packages have all build reqs satisfied now   The first approach has the benefit of being able to determine the packages that need to be built in order to accomplish a smaller subset goal first -- for example, to be able to install osg-wn-client. (And, if there are problems with resolving certain dependencies (say with osg-wn-client again), it will become apparent earlier, as opposed to not until all possible-to-build packages have been built.) The limitation of this approach is that the predicted set of files/capabilities that a binary package will provide may differ between osg series/rhel versions, and as a result may be inaccurate for the new build target.  The second approach provides somewhat more confidence about being able to correctly determine which packages should be buildable at any point in time, but (as mentioned above) it is a bit more in the dark about seeing the bigger picture of the dependency graph or being able to build subsets of targets.  It may be useful to have both options available -- building from the list in the second approach, but using the first mechanism to have a better picture of where things are at, or perhaps to steer toward finishing a certain subset of packages first.",
            "title": "Pre-computing (predictive) vs just-in-time"
        },
        {
            "location": "/software/koji-mass-rebuilds/#package-list-closure-pruning",
            "text": "At some point (either in the planning stage or after building packages into the new build target), we need to ensure that the new osg series/rhel version contains all of its install requirements for all of its packages. It would probably suffice to do a VMU run that installs each package (perhaps individually, to avoid conflicts).  But if we go about it more analytically, we may also get, as a result, a list of packages which we previously only maintained for the purpose of building our other packages (ie, that were never required at runtime for any use cases that we cared about), which now, in the new target, are no longer build requirements (directly or indirectly) for any packages that we care about installing. Packages in this category could be reviewed to also be dropped from the new build target.",
            "title": "Package list closure, pruning"
        },
        {
            "location": "/software/koji-mass-rebuilds/#proposal-recommendations",
            "text": "As mentioned earlier, my recommendation is that we treat a new OSG series differently than a new RHEL version.",
            "title": "Proposal / Recommendations"
        },
        {
            "location": "/software/koji-mass-rebuilds/#for-a-new-osg-series",
            "text": "update native/redhat packaging area to reflect packages for new series, including upcoming + trunk - removed packages    tag existing builds of packages in new list into the new development tag (eg, for osg-3.3-el6, tag the .osgup.el6 and .osg32.el6 builds into osg-3.3-el6-development)    build all packages in new packaging area into new build target at once    for all successful builds, remove corresponding old builds (eg, .osgup/.osg32) from the new tag (osg-3.3-el6-development)",
            "title": "For a new OSG series:"
        },
        {
            "location": "/software/koji-mass-rebuilds/#for-a-new-rhel-version",
            "text": "pull the repodata from the relevant  *-build  repo from koji:   for pre-computing, use a build repo from an existing rhel version:  https://koji.chtc.wisc.edu/mnt/koji/repos/osg-3.2-el6-build/latest/x86_64/repodata/  for just-in-time, use the new build repo:  https://koji.chtc.wisc.edu/mnt/koji/repos/osg-3.2-el8-build/latest/x86_64/repodata/  the primary and filelists (sqlite) files can be used to get runtime requires and provides. (Note that this includes packages from the relevant external repos, also.)   generate srpms repodata for the current set of packages to build, with osg-build prebuild and createrepo.   the primary (sqlite) file can be used to get build-requires.   use sql to resolve direct dependencies at the package name level:  src-pkg: bin-pkg (BuildRequires)  bin-pkg: bin-pkg (Requires)  bin-pkg: src-pkg (bin-pkg comes from which src-pkg? only needed for pre-computing dependencies)    resolve this list into a full list of recursive build dependencies.   Since this is recursive, there is no way to do it in a fixed number of sql queries. However the above input list is already directly consumable by Make, which is designed to handle recursive dependencies just like this. Or we can write a new tool to do it in python.   build ready-to-be-built packages  update our copy of the repodata from the regen'ed  *-build  repo, as often as new versions become available  update our dependency lists  repeat until all packages are built",
            "title": "For a new RHEL version:"
        },
        {
            "location": "/software/development-process/",
            "text": "Software Development Process\n\u00b6\n\n\nThis page is for the OSG Software team and other contributors to the OSG software stack.\nIt is meant to be the central source for all development processes for the Software team.\n(But right now, it is just a starting point.)\n\n\nOverall Development Cycle\n\u00b6\n\n\nFor a typical update to an existing package, the overall development cycle is roughly as follows:\n\n\n\n\nDownload the new upstream source (tarball, source RPM, checkout) into\n    \nthe UW AFS upstream area\n\n\nIn \na checkout of our packaging code\n,\n    update \nthe reference to the upstream file\n and,\n    as needed, \nthe RPM spec file\n\n\nUse \nosg-build\n to perform a scratch build of the updated package\n\n\nVerify that the build succeeded; if not, redo previous steps until success\n\n\nOptionally, lightly test the new RPM(s); if there are problems, redo previous steps until success\n\n\nUse \nosg-build\n to perform an official build of the updated package\n    (which will go into the development repos)\n\n\nPerform standard developer testing of the new RPM(s) \u2014 see below for details\n\n\nObtain permission from the Software Manager to promote the package\n\n\nPromote the package to testing \u2014 see below for details\n\n\n\n\nVersioning Guidelines\n\u00b6\n\n\nOSG-owned software should contain three digits, X.Y.Z, where X represents the major version, Y the minor version,\nand Z the maintenance version.\nNew releases of software should increment one of the major, minor, or maintenance according to the following guidelines:\n\n\n\n\nMajor:\n Major new software, typically (but not limited to) full rewrites, new architectures, major new features;\n    can certainly break backward compatibility (but should provide a smooth upgrade path). Worthy of introduction into Upcoming.\n\n\nMinor:\n Notable changes to the software, including significant feature changes, API changes, etc.;\n    may break compatibility, but must provide an upgrade path from other versions within the same Major series.\n\n\nMaintenance:\n Bug fixes, minor feature tweaks, etc.;\n    must not break compatibility with other versions within the same Major.Minor series.\n\n\n\n\nIf you are unsure about which version number to increment in a software update, consult the Software Manager.\n\n\nBuild Procedures\n\u00b6\n\n\nVerifying builds through Travis-CI\n\u00b6\n\n\nAutomatic build verification can be performed for each commit pushed to a GitHub repository with Travis CI.\nTo enable this feature, the GitHub repository must meet the following criteria:\n\n\n\n\nContains an \nrpm/<REPO NAME>.spec\n file that describes the RPM\n\n\nEnabled in \nTravis CI\n.\n   Repositories that are part of the \nopensciencegrid\n GitHub organization require special permission to enable.\n   Consult Brian or Mat.\n\n\nContains \n.travis.yml\n file with the following contents:\nsudo\n:\n \nrequired\n\n\nenv\n:\n\n  \n-\n \nREPO_NAME=${TRAVIS_REPO_SLUG#*/}\n\n\n\ngit\n:\n\n  \ndepth\n:\n \nfalse\n\n  \nquiet\n:\n \ntrue\n\n\n\nservices\n:\n\n  \n-\n \ndocker\n\n\n\nbefore_install\n:\n\n  \n-\n \nsudo apt-get update\n\n  \n-\n \necho 'DOCKER_OPTS=\"-H tcp://127.0.0.1:2375 -H unix:///var/run/docker.sock -s devicemapper\"' | sudo tee /etc/default/docker > /dev/null\n\n  \n-\n \nsudo service docker restart\n\n  \n-\n \nsleep 5\n\n  \n-\n \nsudo docker pull opensciencegrid/osg-build\n\n\n\nscript\n:\n\n  \n-\n \ndocker run -v $(pwd):/$REPO_NAME -e REPO_NAME=$REPO_NAME --cap-add=SYS_ADMIN opensciencegrid/osg-build build-from-github\n\n\n\n\n\n\n\n\n\n\nBuilding packages for multiple OSG release series\n\u00b6\n\n\nThe OSG Software team supports multiple release series, independent but in parallel to a large degree.\nIn many cases, a single package is the same across release series, and therefore we want to build the package once\nand share it among the series.\nThe procedure below suggests a way to accomplish this task.\n\n\nCurrent definitions:\n\n\n\n\nmaintenance: OSG 3.4 ( \ntrunk\n )\n\n\ncurrent: OSG 3.5 ( \nbranches/osg-3.5\n )\n\n\n\n\n\n\n\nProcedure:\n\n\n\n\nMake changes to \ntrunk\n\n\nOptionally, make and test a scratch build from \ntrunk\n\n\nCommit the changes\n\n\nMake an official build from \ntrunk\n (e.g.: \nosg-build koji <PACKAGE>\n)\n\n\nPerform the standard 4 tests for the \ncurrent\n series (see below)\n\n\nMerge the relevant commits from \ntrunk\n into the \nmaintenance\n branch (see below for tips)\n\n\nOptionally, make and test a scratch build from the \nmaintenance\n branch\n\n\nCommit the merge\n\n\nMake an official build from the \nmaintenance\n branch (e.g.: \nosg-build koji --repo=3.4 <PACKAGE>\n)\n\n\nPerform the standard 4 tests for the \nmaintenance\n series (see below)\n\n\nAs needed (or directed by the Software manager), perform the cross-series tests (see below)\n\n\n\n\n\n\nNote\n\n\nDo not change the RPM Release number in the \nmaintenance\n branch before rebuilding;\nthe \n%dist\n tag will differ automatically, and hence the \nmaintenance\n and \ncurrent\n NVRs will not conflict.\n\n\n\n\n\n\n\nMerging changes from one release series to another\n\u00b6\n\n\nThese instructions assume that you are merging from \ntrunk\n to \nbranches/osg-3.5\n.\nThey also assume that the current directory you are in is a checkout of \nbranches/osg-3.5\n.\nI will use \n$pkg\n to refer to the name of your package.\n\n\nFirst, you will need the commit numbers for your changes:\n\n\nsvn log \\^/native/redhat/trunk/$pkg | less\n\n\n\n\n\nWrite down the commits you want to merge.\n\n\nIf you only have one commit, merge that commit with -c as follows:\n\n\nsvn merge -c $commit_num \\^/native/redhat/trunk/$pkg $pkg\n\n\n\n\n\nWhere \n$commit_num\n is the SVN revision number of that commit (e.g. 17000).\nMerging an individual change like this is referred to as \"cherry-picking\".\n\n\nIf you have a range of commits and you wish to merge all commits within that range, then do the following:\n\n\nsvn merge -r $start_num:$end_num \\^/native/redhat/trunk/$pkg $pkg\n\n\n\n\n\nWhere \n$start_num\n is the SVN revision of the commit \nBEFORE\n your first commit,\nand \n$end_num\n is the SVN revision of your last commit in that range.\n\nNote:\n Be very careful when merging a range from trunk into the maintenance branch\nso that you do not introduce more changes to the maintenance branch than are necessary.\n\n\nIf you have multiple commits but they are not contiguous (i.e. there are commits made by you or someone else in that range\nthat you do not want to merge), you will need to cherry-pick each individual commit.\n\n\nsvn merge -c $commit1 \\^/native/redhat/trunk/$pkg $pkg\nsvn merge -c $commit2 \\^/native/redhat/trunk/$pkg $pkg\n...\n\n\n\n\n\nWhere \n$commit1\n, \n$commit2\n are the commit numbers of the individual changes.\n\n\nNote that merge tracking in recent versions of SVN (1.5 or newer) should prevent commits from accidentally being merged multiple times.\nYou should still look out for conflicts and examine the changes via \nsvn diff\n before committing the merge.\n\n\nTesting Procedures\n\u00b6\n\n\nBefore promoting a package to a testing repository, each build must be tested lightly from the development repos\nto make sure that it is not completely broken, thereby wasting time during acceptance testing.\nNormally, the person who builds a package performs the development testing.\n\n\nIf you are not doing your own development testing for a package\n, contact the Software Manager\nand/or leave a comment in the associated ticket; otherwise, your package may never be promoted to testing and hence never released.\n\n\nThe \"Standard 4\" tests, defined\n\u00b6\n\n\nIn most cases, the Software manager will ask a developer to perform the \u201cstandard 4\u201d tests\non an updated package in a release series before promotion.\nThis is a shorthand description for a standard set of 4 test runs:\n\n\n\n\nFresh install on el6\n\n\nFresh install on el7\n\n\nUpdate install on el6\n\n\nUpdate install on el7\n\n\n\n\nAn \u201cupdate install\u201d is a fresh install of the relevant package (or better yet, metapackage that includes it)\n\nfrom the production repository\n, followed by an update to the new build \nfrom the development repository\n.\n\n\nFor each test run, the amount of functional testing required will vary.\n\n\n\n\nFor very simple changes, it may be sufficient to verify that each installation succeeds and that the expected files are in place\n\n\nFor some changes, it may be sufficient to run osg-test on the resulting installation\n\n\nFor some changes, it will be necessary to perform careful functional tests of the affected component(s)\n\n\n\n\nIf you have questions, check with the Software Manager to determine the amount of testing that is required per test run.\n\n\nThe \"Cross-Series\" test, defined\n\u00b6\n\n\nThe cross-series test may need to be run for packages that have been built for multiple release series of the OSG software stack (i.e. 3.4 and 3.5):\n\n\n\n\nOn el7, install from the 3.4 repositories, then update from the 3.5 repositories\n\n\n\n\nViewed another way, this test is similar to the update installs, above, except from 3.4-release to 3.5-development.\n\n\nThe \"Long Tail\" tests, defined\n\u00b6\n\n\nThese tests may need to be run when updating a package that's also in the old, unsupported (3.3) branch. They will consist of:\n\n\n\n\nInstall from 3.3-release and update to 3.5-development (on el7 only)\n\n\n\n\nThe \"full set of tests\", defined\n\u00b6\n\n\nAll of the tests mentioned above.\n\n\nRunning the tests in VM Universe\n\u00b6\n\n\nIn the case that the package you're testing is covered by osg-tested-internal,\nyou can run the full set of tests in a manual VM universe test run.\nMake sure you meet the \npre-requisites\n required\nto submit VM Universe jobs on \nosghost.chtc.wisc.edu\n.\nAfter that's done, prepare the test suite with a comment describing the test run.\nFor example, if you were testing a new \nhtcondor-ce\n package:\n\n\nosg-run-tests 'Testing htcondor-ce-3.2.1-1'\n\n\n\n\n\n\nAfter you \ncd\n into the directory specified in the output of the previous command,\nyou will need to edit the \n*.yaml\n files in \nparameters.d\n to reflect the tests that you will want to run,\ni.e. clean installs, upgrade installs and upgrade installs between OSG versions.\n\n\nOnce you're satisfied with your list of parameters, submit the dag:\n\n\ncondor_submit_dag master-run.dag\n\n\n\n\n\n\nPromoting a Package to Testing\n\u00b6\n\n\nOnce development and development testing is complete, the final OSG Software step is to promote the package(s)\nto our testing repositories.\nAfter that, the Release team takes over with acceptance testing and ultimately release.\nOf course if they discover problems, the ticket(s) will be returned to OSG Software for further development,\nessentially restarting the development cycle.\n\n\nPreparing a Good Promotion Request\n\u00b6\n\n\nDevelopers must obtain permission from the OSG Software manager to promote a package from development to testing.\nA promotion request goes into at least one affected JIRA ticket and will be answered there as well.\nBelow are some tips for writing a good promotion request:\n\n\n\n\nMake sure that relevant information about goals, history, and resolution is in the associated ticket(s)\n\n\nInclude globs for the NVRs to be promoted (or a detailed list, if it is that complicated, which it almost never is)\n\n\nIf you ran automated tests:\n\n\nLink to the results page(s)\n\n\nVerify that relevant tests ran successfully (as opposed to being skipped or failing) \u2013\u00a0briefly summarize your findings\n\n\nNote whether the automated tests are just regression tests or actually test the current change(s)\n\n\nIf there are \nany\n failures, explain why they are not important to the promotion request\n\n\n\n\n\n\nIf you ran manual tests:\n\n\nSummarize your tests and findings\n\n\nIf there were failures, explain why they are not important to the promotion request\n\n\n\n\n\n\nIf there are critical build dependencies that we typically check, include reports from the \nbuilt-against-pkgs\n tool\n\n\nNote: This step is really just for known, specific cases, like the {HTCondor, HTCondor-CE, BLAHP} set and the {BeStMan, GUMS, VOMS Admin, etc.} Java set\n\n\nOccasionally, the OSG Software manager will request the tool to be run for other cases\n\n\n\n\n\n\nIf other packages depend on the to-be-promoted package, explain whether the dependent packages must be rebuilt or, if not, why not\n\n\n\n\nFor example (hypothetical promotion request for HTCondor-CE):\n\n\n\n\nMay I promote \nhtcondor-ce-2.3.4-2.osg3*.el*\n? I ran a complete set of automated tests <LINK THE PRECEDING TEXT OR SEPARATELY HERE>;\nthe HTCondor-CE tests ran and passed in all cases. There were some spurious failures of RSV in the All condition for RHEL 6,\nbut this is a known failure case that is independent of HTCondor-CE. I also did a few spot checks manually\n(one VM each for SL 6 and SL 7), and in each case setting \nuse_frobnosticator = true\n in the configuration resulted in\nthe expected behavior as defined in the description field above.\nThe \nbuilt-against-pkgs\n tool shows that I built against all the latest HTCondor and BLAHP builds, see below.\n<JIRA-formatted table comes after>\n\n\n\n\nPromoting\n\u00b6\n\n\nFollow these steps to request promotion, promote a package, and note the promotion in JIRA:\n\n\n\n\nMake sure the package update has at least one associated JIRA ticket;\n    if there is no ticket, at least create one for releasing the package(s)\n\n\nObtain permission to promote the package(s) from the Software Manager (see above)\n\n\nUse \nosg-promote\n to promote the package(s) from development to testing\n\n\nComment on the associated JIRA ticket(s) with osg-promote's JIRA-formatted output (or at least the build NVRs) and,\n    if you know, suggestions for acceptance testing\n\n\nMark each associated JIRA ticket as \u201cReady For Testing\u201d",
            "title": "Development Process"
        },
        {
            "location": "/software/development-process/#software-development-process",
            "text": "This page is for the OSG Software team and other contributors to the OSG software stack.\nIt is meant to be the central source for all development processes for the Software team.\n(But right now, it is just a starting point.)",
            "title": "Software Development Process"
        },
        {
            "location": "/software/development-process/#overall-development-cycle",
            "text": "For a typical update to an existing package, the overall development cycle is roughly as follows:   Download the new upstream source (tarball, source RPM, checkout) into\n     the UW AFS upstream area  In  a checkout of our packaging code ,\n    update  the reference to the upstream file  and,\n    as needed,  the RPM spec file  Use  osg-build  to perform a scratch build of the updated package  Verify that the build succeeded; if not, redo previous steps until success  Optionally, lightly test the new RPM(s); if there are problems, redo previous steps until success  Use  osg-build  to perform an official build of the updated package\n    (which will go into the development repos)  Perform standard developer testing of the new RPM(s) \u2014 see below for details  Obtain permission from the Software Manager to promote the package  Promote the package to testing \u2014 see below for details",
            "title": "Overall Development Cycle"
        },
        {
            "location": "/software/development-process/#versioning-guidelines",
            "text": "OSG-owned software should contain three digits, X.Y.Z, where X represents the major version, Y the minor version,\nand Z the maintenance version.\nNew releases of software should increment one of the major, minor, or maintenance according to the following guidelines:   Major:  Major new software, typically (but not limited to) full rewrites, new architectures, major new features;\n    can certainly break backward compatibility (but should provide a smooth upgrade path). Worthy of introduction into Upcoming.  Minor:  Notable changes to the software, including significant feature changes, API changes, etc.;\n    may break compatibility, but must provide an upgrade path from other versions within the same Major series.  Maintenance:  Bug fixes, minor feature tweaks, etc.;\n    must not break compatibility with other versions within the same Major.Minor series.   If you are unsure about which version number to increment in a software update, consult the Software Manager.",
            "title": "Versioning Guidelines"
        },
        {
            "location": "/software/development-process/#build-procedures",
            "text": "",
            "title": "Build Procedures"
        },
        {
            "location": "/software/development-process/#verifying-builds-through-travis-ci",
            "text": "Automatic build verification can be performed for each commit pushed to a GitHub repository with Travis CI.\nTo enable this feature, the GitHub repository must meet the following criteria:   Contains an  rpm/<REPO NAME>.spec  file that describes the RPM  Enabled in  Travis CI .\n   Repositories that are part of the  opensciencegrid  GitHub organization require special permission to enable.\n   Consult Brian or Mat.  Contains  .travis.yml  file with the following contents: sudo :   required  env : \n   -   REPO_NAME=${TRAVIS_REPO_SLUG#*/}  git : \n   depth :   false \n   quiet :   true  services : \n   -   docker  before_install : \n   -   sudo apt-get update \n   -   echo 'DOCKER_OPTS=\"-H tcp://127.0.0.1:2375 -H unix:///var/run/docker.sock -s devicemapper\"' | sudo tee /etc/default/docker > /dev/null \n   -   sudo service docker restart \n   -   sleep 5 \n   -   sudo docker pull opensciencegrid/osg-build  script : \n   -   docker run -v $(pwd):/$REPO_NAME -e REPO_NAME=$REPO_NAME --cap-add=SYS_ADMIN opensciencegrid/osg-build build-from-github",
            "title": "Verifying builds through Travis-CI"
        },
        {
            "location": "/software/development-process/#building-packages-for-multiple-osg-release-series",
            "text": "The OSG Software team supports multiple release series, independent but in parallel to a large degree.\nIn many cases, a single package is the same across release series, and therefore we want to build the package once\nand share it among the series.\nThe procedure below suggests a way to accomplish this task.  Current definitions:   maintenance: OSG 3.4 (  trunk  )  current: OSG 3.5 (  branches/osg-3.5  )    Procedure:   Make changes to  trunk  Optionally, make and test a scratch build from  trunk  Commit the changes  Make an official build from  trunk  (e.g.:  osg-build koji <PACKAGE> )  Perform the standard 4 tests for the  current  series (see below)  Merge the relevant commits from  trunk  into the  maintenance  branch (see below for tips)  Optionally, make and test a scratch build from the  maintenance  branch  Commit the merge  Make an official build from the  maintenance  branch (e.g.:  osg-build koji --repo=3.4 <PACKAGE> )  Perform the standard 4 tests for the  maintenance  series (see below)  As needed (or directed by the Software manager), perform the cross-series tests (see below)    Note  Do not change the RPM Release number in the  maintenance  branch before rebuilding;\nthe  %dist  tag will differ automatically, and hence the  maintenance  and  current  NVRs will not conflict.",
            "title": "Building packages for multiple OSG release series"
        },
        {
            "location": "/software/development-process/#merging-changes-from-one-release-series-to-another",
            "text": "These instructions assume that you are merging from  trunk  to  branches/osg-3.5 .\nThey also assume that the current directory you are in is a checkout of  branches/osg-3.5 .\nI will use  $pkg  to refer to the name of your package.  First, you will need the commit numbers for your changes:  svn log \\^/native/redhat/trunk/$pkg | less  Write down the commits you want to merge.  If you only have one commit, merge that commit with -c as follows:  svn merge -c $commit_num \\^/native/redhat/trunk/$pkg $pkg  Where  $commit_num  is the SVN revision number of that commit (e.g. 17000).\nMerging an individual change like this is referred to as \"cherry-picking\".  If you have a range of commits and you wish to merge all commits within that range, then do the following:  svn merge -r $start_num:$end_num \\^/native/redhat/trunk/$pkg $pkg  Where  $start_num  is the SVN revision of the commit  BEFORE  your first commit,\nand  $end_num  is the SVN revision of your last commit in that range. Note:  Be very careful when merging a range from trunk into the maintenance branch\nso that you do not introduce more changes to the maintenance branch than are necessary.  If you have multiple commits but they are not contiguous (i.e. there are commits made by you or someone else in that range\nthat you do not want to merge), you will need to cherry-pick each individual commit.  svn merge -c $commit1 \\^/native/redhat/trunk/$pkg $pkg\nsvn merge -c $commit2 \\^/native/redhat/trunk/$pkg $pkg\n...  Where  $commit1 ,  $commit2  are the commit numbers of the individual changes.  Note that merge tracking in recent versions of SVN (1.5 or newer) should prevent commits from accidentally being merged multiple times.\nYou should still look out for conflicts and examine the changes via  svn diff  before committing the merge.",
            "title": "Merging changes from one release series to another"
        },
        {
            "location": "/software/development-process/#testing-procedures",
            "text": "Before promoting a package to a testing repository, each build must be tested lightly from the development repos\nto make sure that it is not completely broken, thereby wasting time during acceptance testing.\nNormally, the person who builds a package performs the development testing.  If you are not doing your own development testing for a package , contact the Software Manager\nand/or leave a comment in the associated ticket; otherwise, your package may never be promoted to testing and hence never released.",
            "title": "Testing Procedures"
        },
        {
            "location": "/software/development-process/#the-standard-4-tests-defined",
            "text": "In most cases, the Software manager will ask a developer to perform the \u201cstandard 4\u201d tests\non an updated package in a release series before promotion.\nThis is a shorthand description for a standard set of 4 test runs:   Fresh install on el6  Fresh install on el7  Update install on el6  Update install on el7   An \u201cupdate install\u201d is a fresh install of the relevant package (or better yet, metapackage that includes it) from the production repository , followed by an update to the new build  from the development repository .  For each test run, the amount of functional testing required will vary.   For very simple changes, it may be sufficient to verify that each installation succeeds and that the expected files are in place  For some changes, it may be sufficient to run osg-test on the resulting installation  For some changes, it will be necessary to perform careful functional tests of the affected component(s)   If you have questions, check with the Software Manager to determine the amount of testing that is required per test run.",
            "title": "The \"Standard 4\" tests, defined"
        },
        {
            "location": "/software/development-process/#the-cross-series-test-defined",
            "text": "The cross-series test may need to be run for packages that have been built for multiple release series of the OSG software stack (i.e. 3.4 and 3.5):   On el7, install from the 3.4 repositories, then update from the 3.5 repositories   Viewed another way, this test is similar to the update installs, above, except from 3.4-release to 3.5-development.",
            "title": "The \"Cross-Series\" test, defined"
        },
        {
            "location": "/software/development-process/#the-long-tail-tests-defined",
            "text": "These tests may need to be run when updating a package that's also in the old, unsupported (3.3) branch. They will consist of:   Install from 3.3-release and update to 3.5-development (on el7 only)",
            "title": "The \"Long Tail\" tests, defined"
        },
        {
            "location": "/software/development-process/#the-full-set-of-tests-defined",
            "text": "All of the tests mentioned above.",
            "title": "The \"full set of tests\", defined"
        },
        {
            "location": "/software/development-process/#running-the-tests-in-vm-universe",
            "text": "In the case that the package you're testing is covered by osg-tested-internal,\nyou can run the full set of tests in a manual VM universe test run.\nMake sure you meet the  pre-requisites  required\nto submit VM Universe jobs on  osghost.chtc.wisc.edu .\nAfter that's done, prepare the test suite with a comment describing the test run.\nFor example, if you were testing a new  htcondor-ce  package:  osg-run-tests 'Testing htcondor-ce-3.2.1-1'   After you  cd  into the directory specified in the output of the previous command,\nyou will need to edit the  *.yaml  files in  parameters.d  to reflect the tests that you will want to run,\ni.e. clean installs, upgrade installs and upgrade installs between OSG versions.  Once you're satisfied with your list of parameters, submit the dag:  condor_submit_dag master-run.dag",
            "title": "Running the tests in VM Universe"
        },
        {
            "location": "/software/development-process/#promoting-a-package-to-testing",
            "text": "Once development and development testing is complete, the final OSG Software step is to promote the package(s)\nto our testing repositories.\nAfter that, the Release team takes over with acceptance testing and ultimately release.\nOf course if they discover problems, the ticket(s) will be returned to OSG Software for further development,\nessentially restarting the development cycle.",
            "title": "Promoting a Package to Testing"
        },
        {
            "location": "/software/development-process/#preparing-a-good-promotion-request",
            "text": "Developers must obtain permission from the OSG Software manager to promote a package from development to testing.\nA promotion request goes into at least one affected JIRA ticket and will be answered there as well.\nBelow are some tips for writing a good promotion request:   Make sure that relevant information about goals, history, and resolution is in the associated ticket(s)  Include globs for the NVRs to be promoted (or a detailed list, if it is that complicated, which it almost never is)  If you ran automated tests:  Link to the results page(s)  Verify that relevant tests ran successfully (as opposed to being skipped or failing) \u2013\u00a0briefly summarize your findings  Note whether the automated tests are just regression tests or actually test the current change(s)  If there are  any  failures, explain why they are not important to the promotion request    If you ran manual tests:  Summarize your tests and findings  If there were failures, explain why they are not important to the promotion request    If there are critical build dependencies that we typically check, include reports from the  built-against-pkgs  tool  Note: This step is really just for known, specific cases, like the {HTCondor, HTCondor-CE, BLAHP} set and the {BeStMan, GUMS, VOMS Admin, etc.} Java set  Occasionally, the OSG Software manager will request the tool to be run for other cases    If other packages depend on the to-be-promoted package, explain whether the dependent packages must be rebuilt or, if not, why not   For example (hypothetical promotion request for HTCondor-CE):   May I promote  htcondor-ce-2.3.4-2.osg3*.el* ? I ran a complete set of automated tests <LINK THE PRECEDING TEXT OR SEPARATELY HERE>;\nthe HTCondor-CE tests ran and passed in all cases. There were some spurious failures of RSV in the All condition for RHEL 6,\nbut this is a known failure case that is independent of HTCondor-CE. I also did a few spot checks manually\n(one VM each for SL 6 and SL 7), and in each case setting  use_frobnosticator = true  in the configuration resulted in\nthe expected behavior as defined in the description field above.\nThe  built-against-pkgs  tool shows that I built against all the latest HTCondor and BLAHP builds, see below.\n<JIRA-formatted table comes after>",
            "title": "Preparing a Good Promotion Request"
        },
        {
            "location": "/software/development-process/#promoting",
            "text": "Follow these steps to request promotion, promote a package, and note the promotion in JIRA:   Make sure the package update has at least one associated JIRA ticket;\n    if there is no ticket, at least create one for releasing the package(s)  Obtain permission to promote the package(s) from the Software Manager (see above)  Use  osg-promote  to promote the package(s) from development to testing  Comment on the associated JIRA ticket(s) with osg-promote's JIRA-formatted output (or at least the build NVRs) and,\n    if you know, suggestions for acceptance testing  Mark each associated JIRA ticket as \u201cReady For Testing\u201d",
            "title": "Promoting"
        },
        {
            "location": "/software/git-software-development/",
            "text": "Git software development workflow\n\u00b6\n\n\nThis document describes the development workflow for OSG software packages kept in GitHub. It is intended for people who wish to contribute to OSG software.\n\n\nGit and GitHub basics\n\u00b6\n\n\nIf you are unfamiliar with Git and GitHub, the GitHub website has a good series of tutorials at \nhttps://help.github.com/categories/bootcamp/\n\n\nGetting shell access to GitHub\n\u00b6\n\n\nThere are multiple ways of authenticating to GitHub from the shell. This section will cover using SSH keys. This is no longer the method recommended by GitHub, but is easier to set up for someone with existing SSH experience.\n\n\nThe instructions here are derived from \nGitHub's own instructions on using SSH keys\n.\n\n\nCreating a new SSH key (optional but recommended)\n\u00b6\n\n\nIf you already have an SSH keypair in your \n~/.ssh\n directory that you want to use for GitHub, you may skip this step. It is more secure, however, to create a new keypair specifically for use with GitHub.\n\n\nThe instructions below will create an SSH public/private key pair with the private key stored in \n~/.ssh/id_github\n and public key stored in \n~/.ssh/id_github.pub\n.\n\n\nGenerating the key\n\u00b6\n\n\nUse \nssh-keygen\n to generate the SSH keypair. For \n<EMAIL_ADDRESS>\n, use the email address associated with your GitHub account.\n\n\n[user@client ~ ] $\n ssh-keygen -t rsa -b \n4096\n -f ~/.ssh/id_github -C <EMAIL_ADDRESS>\n\n\n\n\n\nConfiguring SSH to use the key for GitHub\n\u00b6\n\n\nMake sure SSH uses the new key by default to access GitHub. Create or edit \n~/.ssh/config\n and append the following lines:\n\n\nHost github.com\n\nIdentityFile <YOUR_HOME_DIR>/.ssh/id_github\n\n\n\n\n\nWhere \n is the output of the command:\n\necho $HOME\n\n\nAdding the SSH public key to GitHub\n\u00b6\n\n\nUsing the GitHub web interface:\n\n\n\n\nOn the upper right of the screen, click on your profile picture\n\n\nIn the menu that pops up, click \"Settings\"\n\n\nOn the left-hand sidebar, click \"SSH and GPG keys\"\n\n\nIn the top right of the \"SSH keys\" box, click \"New SSH key\"\n\n\nIn the \"Title\" field of the dialog that pops up, enter a descriptive name for the key\n\n\nOpen the public key file (e.g. \n~/.ssh/id_github.pub\n (don't forget the \n.pub\n)) in a text editor and copy its full contents to the clipboard\n\n\nIn the \"Key\" field, paste the public key\n\n\nBelow the \"Key\" field, click \"Add SSH key\"\n\n\n\n\nYou should see your new key in the \"SSH keys\" list.\n\n\nTesting that shell access works\n\u00b6\n\n\nTo verify you can authenticate to GitHub using SSH, SSH to \ngit@github.com\n. You should see a message that 'you've successfully authenticated, but GitHub does not provide shell access.'\n\n\nContribution workflow\n\u00b6\n\n\nWe use the standard GitHub \npull request\n workflow for making contributions to OSG software.\n\n\nIf you've never contributed to this project on GitHub before, do the following steps first:\n\n\n\n\nUsing the GitHub web interface, fork the repo you wish to contribute to.\n\n\n\n\nMake a clone of your forked repo on your local machine.\n\n\n[user@client ~ ] $\n git clone git@github.com:<USERNAME/PROJECT>\n\n\n\n\n\nWhere \n<USERNAME>\n is your github username and \n<PROJECT>\n is the name of the project you want to contribute to,\ne.g. in order to clone my local fork of the \nopenscience/technology\n repository: \n\n\n[user@client ~ ] $\n git clone https://github.com/ddavila0/technology.git\n\n\n\n\n\n\n\nNote\n\n\nIf you get a \"Permission denied\" error, your public key may not be set up with GitHub -- please see the \"Getting shell access to GitHub\" section above.\n\n\nIf you get some other error, \nthe GitHub page on SSH\n may contain useful information on troubleshooting.\n\n\n\n\n\n\n\n\nOnce you have your local repo, do the following:\n\n\n\n\n\n\nCreate a branch to hold changes that are related to the issue you are working on. Give the \n<BRANCH>\n a name that will remind you of its purpose, such as \nsw2345-pathchange\n\n\n[user@client ~ ] $\n git checkout -b <BRANCH>\n\n\n\n\n\n\n\n\n\nMake your commits to this branch, then push the branch to your repo on GitHub.\n\n\n[user@client ~ ] $\n git push origin <BRANCH>\n\n\n\n\n\n\n\n\n\nSelect your branch in the GitHub web interface, then create a \"pull request\" against the original repo. Add a good description of your change into the message for the pull request. Enter a JIRA ticket number in the message to automatically link the pull request to the JIRA ticket.\n\n\n\n\n\n\nRequest a review from the drop down menu on the right and wait for your pull request to be reviewed by a software team member.\n\n\n\n\nIf the team member accepts your changes, they will merge your pull request, and your changes will be incorporated upstream. You may then delete the branch you created your pull request from.\n\n\nIf your changes are rejected, then you may make additional changes to the branch that your pull request is for. Once you push the changes from your local repo to your GitHub repo, they will automatically be added to the pull request.\n\n\n\n\n\n\n\n\nRelease workflow\n\u00b6\n\n\nThis section is intended for OSG Software team members or the primary developers of a software project (i.e. those that make releases). Some of the steps require direct write access the GitHub repo for the project owned by \nopensciencegrid\n. (If you can approve pull requests, you have write access).\n\n\nA release of a software is created from your local clone of a software project. Before you release, you need to make sure your local clone is in sync with the GitHub repo owned by \nopensciencegrid\n (the OSG repo):\n\n\n\n\n\n\nIf you haven't already, add the OSG repo as a \"remote\" to your repo:\n\n\n[user@client ~ ] $\n git remote add upstream git@github.com:opensciencegrid/<PROJECT>\n\n\n\n\n\nWhere \n<PROJECT>\n is the name of the project you are going to release, e.g. \n for \nopenscience/technology\n repository it would be \ntechnology.git\n\n\n\n\n\n\nFetch changes from the OSG repo:\n\n\n[user@client ~ ] $\n git fetch upstream\n\n\n\n\n\n\n\n\n\nCompare your branch you are releasing from (probably \nmaster\n) to its copy in the OSG repo:\n\n\n[user@client ~ ] $\n git checkout master\n;\n git diff upstream/master\n\n\n\n\n\nThere should be no differences.\n\n\n\n\n\n\nOnce this is done, release the software as you usually do. This process varies from one project to another, but often it involves running \nmake upstream\n or similar. Check your project's \nREADME\n file for instructions.\n\n\n\n\nTest your software.\n\n\n\n\nTag the commit that you made the release from. Git release tags are conventionally called \nVERSION\n, where \nVERSION\n is the version of the software you are releasing. So if you're releasing version 1.3.0, you would create the \n<TAG>\n \nv1.3.0\n.\n\n\n\n\nNote\n\n\nOnce a tag has been pushed to the OSG repo, it should not be changed. Be sure the commit you want to tag is the final one you made the release from.\n\n\n\n\n\n\n\n\nCreate the tag in your local repo:\n\n\n[user@client ~ ] $\n git tag <TAG>\n\n\n\n\n\n\n\n\n\nPush the tag to your own GitHub repo:\n\n\n[user@client ~ ] $\n git push origin <TAG>\n\n\n\n\n\n\n\n\n\nPush the tag to the OSG repo:\n\n\n[user@client ~ ] $\n git push upstream <TAG>",
            "title": "Git Software Development Process"
        },
        {
            "location": "/software/git-software-development/#git-software-development-workflow",
            "text": "This document describes the development workflow for OSG software packages kept in GitHub. It is intended for people who wish to contribute to OSG software.",
            "title": "Git software development workflow"
        },
        {
            "location": "/software/git-software-development/#git-and-github-basics",
            "text": "If you are unfamiliar with Git and GitHub, the GitHub website has a good series of tutorials at  https://help.github.com/categories/bootcamp/",
            "title": "Git and GitHub basics"
        },
        {
            "location": "/software/git-software-development/#getting-shell-access-to-github",
            "text": "There are multiple ways of authenticating to GitHub from the shell. This section will cover using SSH keys. This is no longer the method recommended by GitHub, but is easier to set up for someone with existing SSH experience.  The instructions here are derived from  GitHub's own instructions on using SSH keys .",
            "title": "Getting shell access to GitHub"
        },
        {
            "location": "/software/git-software-development/#creating-a-new-ssh-key-optional-but-recommended",
            "text": "If you already have an SSH keypair in your  ~/.ssh  directory that you want to use for GitHub, you may skip this step. It is more secure, however, to create a new keypair specifically for use with GitHub.  The instructions below will create an SSH public/private key pair with the private key stored in  ~/.ssh/id_github  and public key stored in  ~/.ssh/id_github.pub .",
            "title": "Creating a new SSH key (optional but recommended)"
        },
        {
            "location": "/software/git-software-development/#generating-the-key",
            "text": "Use  ssh-keygen  to generate the SSH keypair. For  <EMAIL_ADDRESS> , use the email address associated with your GitHub account.  [user@client ~ ] $  ssh-keygen -t rsa -b  4096  -f ~/.ssh/id_github -C <EMAIL_ADDRESS>",
            "title": "Generating the key"
        },
        {
            "location": "/software/git-software-development/#configuring-ssh-to-use-the-key-for-github",
            "text": "Make sure SSH uses the new key by default to access GitHub. Create or edit  ~/.ssh/config  and append the following lines:  Host github.com IdentityFile <YOUR_HOME_DIR>/.ssh/id_github  Where   is the output of the command: echo $HOME",
            "title": "Configuring SSH to use the key for GitHub"
        },
        {
            "location": "/software/git-software-development/#adding-the-ssh-public-key-to-github",
            "text": "Using the GitHub web interface:   On the upper right of the screen, click on your profile picture  In the menu that pops up, click \"Settings\"  On the left-hand sidebar, click \"SSH and GPG keys\"  In the top right of the \"SSH keys\" box, click \"New SSH key\"  In the \"Title\" field of the dialog that pops up, enter a descriptive name for the key  Open the public key file (e.g.  ~/.ssh/id_github.pub  (don't forget the  .pub )) in a text editor and copy its full contents to the clipboard  In the \"Key\" field, paste the public key  Below the \"Key\" field, click \"Add SSH key\"   You should see your new key in the \"SSH keys\" list.",
            "title": "Adding the SSH public key to GitHub"
        },
        {
            "location": "/software/git-software-development/#testing-that-shell-access-works",
            "text": "To verify you can authenticate to GitHub using SSH, SSH to  git@github.com . You should see a message that 'you've successfully authenticated, but GitHub does not provide shell access.'",
            "title": "Testing that shell access works"
        },
        {
            "location": "/software/git-software-development/#contribution-workflow",
            "text": "We use the standard GitHub  pull request  workflow for making contributions to OSG software.  If you've never contributed to this project on GitHub before, do the following steps first:   Using the GitHub web interface, fork the repo you wish to contribute to.   Make a clone of your forked repo on your local machine.  [user@client ~ ] $  git clone git@github.com:<USERNAME/PROJECT>  Where  <USERNAME>  is your github username and  <PROJECT>  is the name of the project you want to contribute to,\ne.g. in order to clone my local fork of the  openscience/technology  repository:   [user@client ~ ] $  git clone https://github.com/ddavila0/technology.git   Note  If you get a \"Permission denied\" error, your public key may not be set up with GitHub -- please see the \"Getting shell access to GitHub\" section above.  If you get some other error,  the GitHub page on SSH  may contain useful information on troubleshooting.     Once you have your local repo, do the following:    Create a branch to hold changes that are related to the issue you are working on. Give the  <BRANCH>  a name that will remind you of its purpose, such as  sw2345-pathchange  [user@client ~ ] $  git checkout -b <BRANCH>    Make your commits to this branch, then push the branch to your repo on GitHub.  [user@client ~ ] $  git push origin <BRANCH>    Select your branch in the GitHub web interface, then create a \"pull request\" against the original repo. Add a good description of your change into the message for the pull request. Enter a JIRA ticket number in the message to automatically link the pull request to the JIRA ticket.    Request a review from the drop down menu on the right and wait for your pull request to be reviewed by a software team member.   If the team member accepts your changes, they will merge your pull request, and your changes will be incorporated upstream. You may then delete the branch you created your pull request from.  If your changes are rejected, then you may make additional changes to the branch that your pull request is for. Once you push the changes from your local repo to your GitHub repo, they will automatically be added to the pull request.",
            "title": "Contribution workflow"
        },
        {
            "location": "/software/git-software-development/#release-workflow",
            "text": "This section is intended for OSG Software team members or the primary developers of a software project (i.e. those that make releases). Some of the steps require direct write access the GitHub repo for the project owned by  opensciencegrid . (If you can approve pull requests, you have write access).  A release of a software is created from your local clone of a software project. Before you release, you need to make sure your local clone is in sync with the GitHub repo owned by  opensciencegrid  (the OSG repo):    If you haven't already, add the OSG repo as a \"remote\" to your repo:  [user@client ~ ] $  git remote add upstream git@github.com:opensciencegrid/<PROJECT>  Where  <PROJECT>  is the name of the project you are going to release, e.g.   for  openscience/technology  repository it would be  technology.git    Fetch changes from the OSG repo:  [user@client ~ ] $  git fetch upstream    Compare your branch you are releasing from (probably  master ) to its copy in the OSG repo:  [user@client ~ ] $  git checkout master ;  git diff upstream/master  There should be no differences.    Once this is done, release the software as you usually do. This process varies from one project to another, but often it involves running  make upstream  or similar. Check your project's  README  file for instructions.   Test your software.   Tag the commit that you made the release from. Git release tags are conventionally called  VERSION , where  VERSION  is the version of the software you are releasing. So if you're releasing version 1.3.0, you would create the  <TAG>   v1.3.0 .   Note  Once a tag has been pushed to the OSG repo, it should not be changed. Be sure the commit you want to tag is the final one you made the release from.     Create the tag in your local repo:  [user@client ~ ] $  git tag <TAG>    Push the tag to your own GitHub repo:  [user@client ~ ] $  git push origin <TAG>    Push the tag to the OSG repo:  [user@client ~ ] $  git push upstream <TAG>",
            "title": "Release workflow"
        },
        {
            "location": "/software/ce-test-scaling/",
            "text": "How to Run Scalability Tests on a CE\n\u00b6\n\n\nIntroduction\n\u00b6\n\n\nThis document is intended as a general overview of the process for scalability testing of an OSG CE (Compute Element). All examples are for testing an \nHTCondor-CE\n, but they should be applicable for other CE software.\n\n\nThe focus of testing a CE is on the number of concurrent running jobs the CE can sustain as well as the ramp-up rate when many jobs are queued.\n\n\nSleeper Pool\n\u00b6\n\n\nWith the focus on the CE, actual job payloads can be minimal \u2013 simple long sleep jobs are fine. Thus, then can run on nearly any resources, and it is even possible to allow far more of these jobs to run on a single resource than would be sensible for real jobs.\n\n\nWhen large-scale testing a CE, one of the objectives is to see if the CE can fully utilize all resources (cores) available to it or if there are bottlenecks preventing that outcome. However to do this would normally require using up production slots, and it is hard to find a site willing to give up so many production slots for so long. Thus, running resourceless jobs in parallel with production jobs allows the testing to proceed without interfering with real work.\n\n\nSetting Up a Sleeper Pool\n\u00b6\n\n\nA sleeper pool is created by \u201ctricking\u201d a worker node into thinking it has more cores than physically available. Then, the host is configured so that jobs marked for the sleeper pool are routed to the extra slots. In HTCondor, this is done by changing the START expression on each startd. For example, on a 32-core machine:\n\n\nSTART = ( \\\n          (SlotID >= 1) && \\\n          (SlotID < 33) && \\\n          (RequiresWholeMachine =!= TRUE ) && \\\n          (SleepSlot =!= TRUE) && \\\n          (distro =?= \"RHEL6\" ) && \\\n          (CPU_Only == TRUE ) \\\n          ) || \\\n          ( (SlotID >= 33) && (distro =?= \"RHEL6\" ) && (SleepSlot == TRUE) )\n\n\n\n\n\nUsual Topology of the Tests\n\u00b6\n\n\nA brief introduction to the topology involved in the tests.\n\n\nBatch System and Sleeper Pool\n\u00b6\n\n\nThis is normally the batch system of the resources which will be behind the CE to be tested. It is normally set up by a site administrator.\n\n\nCE\n\u00b6\n\n\nThis is the physical hardware where the CE software runs, hopefully mimicking real production hardware specifications.\n\n\nSubmitter\n\u00b6\n\n\nAn HTCondor submit host. It can be a virtual machine for most test submissions.\n\n\nMonitoring tools\n\u00b6\n\n\nTo monitor tests, two software components are needed (which can be installed on the same node): ganglia-gmond and ganglia-gmetad. Once they are installed, then some ad-hoc metrics can be created to monitor the CE; for example:\n\n\ncondor_q -pool red.unl.edu:9619 -name sleeper@red.unl.edu -const 'JobStatus=?=2' | wc -l\n\n\ngmetric --name RunningJobsCE \n\n\n\n\n\n\nGenerating Load\n\u00b6\n\n\nLocation\n\u00b6\n\n\nThe load_generators are found in the  \nOSgscal github repo\n. The binary of interest here is \nloadtest_condor\n\n\nUse\n\u00b6\n\n\nJust untar it or check it out from mas on the HTCondor submit node (see above):\n\n\ngit checkout https://github.com/efajardo/osgscal\n\n\ncd load_generators/loadtest_condor/trunk/bin\n\n\n\n\n\n\nKeep in mind that you also need a valid proxy for grid submissions.\n\n\nFor example, if the goal is to keep 1,000 jobs in the queue and run 6-hour sleep jobs (on average), you can run this command:\n\n\n./loadtest_condor.sh -type grid condor sleeper@red.unl.edu red.unl.edu:9619 -jobs 40000 -cluster 10 -proxy /home/submituser/.globus/cmspilot01.proxy -end random 21600 -maxidle 1000 -in sandbox 50",
            "title": "CE Scale Testing"
        },
        {
            "location": "/software/ce-test-scaling/#how-to-run-scalability-tests-on-a-ce",
            "text": "",
            "title": "How to Run Scalability Tests on a CE"
        },
        {
            "location": "/software/ce-test-scaling/#introduction",
            "text": "This document is intended as a general overview of the process for scalability testing of an OSG CE (Compute Element). All examples are for testing an  HTCondor-CE , but they should be applicable for other CE software.  The focus of testing a CE is on the number of concurrent running jobs the CE can sustain as well as the ramp-up rate when many jobs are queued.",
            "title": "Introduction"
        },
        {
            "location": "/software/ce-test-scaling/#sleeper-pool",
            "text": "With the focus on the CE, actual job payloads can be minimal \u2013 simple long sleep jobs are fine. Thus, then can run on nearly any resources, and it is even possible to allow far more of these jobs to run on a single resource than would be sensible for real jobs.  When large-scale testing a CE, one of the objectives is to see if the CE can fully utilize all resources (cores) available to it or if there are bottlenecks preventing that outcome. However to do this would normally require using up production slots, and it is hard to find a site willing to give up so many production slots for so long. Thus, running resourceless jobs in parallel with production jobs allows the testing to proceed without interfering with real work.",
            "title": "Sleeper Pool"
        },
        {
            "location": "/software/ce-test-scaling/#setting-up-a-sleeper-pool",
            "text": "A sleeper pool is created by \u201ctricking\u201d a worker node into thinking it has more cores than physically available. Then, the host is configured so that jobs marked for the sleeper pool are routed to the extra slots. In HTCondor, this is done by changing the START expression on each startd. For example, on a 32-core machine:  START = ( \\\n          (SlotID >= 1) && \\\n          (SlotID < 33) && \\\n          (RequiresWholeMachine =!= TRUE ) && \\\n          (SleepSlot =!= TRUE) && \\\n          (distro =?= \"RHEL6\" ) && \\\n          (CPU_Only == TRUE ) \\\n          ) || \\\n          ( (SlotID >= 33) && (distro =?= \"RHEL6\" ) && (SleepSlot == TRUE) )",
            "title": "Setting Up a Sleeper Pool"
        },
        {
            "location": "/software/ce-test-scaling/#usual-topology-of-the-tests",
            "text": "A brief introduction to the topology involved in the tests.",
            "title": "Usual Topology of the Tests"
        },
        {
            "location": "/software/ce-test-scaling/#batch-system-and-sleeper-pool",
            "text": "This is normally the batch system of the resources which will be behind the CE to be tested. It is normally set up by a site administrator.",
            "title": "Batch System and Sleeper Pool"
        },
        {
            "location": "/software/ce-test-scaling/#ce",
            "text": "This is the physical hardware where the CE software runs, hopefully mimicking real production hardware specifications.",
            "title": "CE"
        },
        {
            "location": "/software/ce-test-scaling/#submitter",
            "text": "An HTCondor submit host. It can be a virtual machine for most test submissions.",
            "title": "Submitter"
        },
        {
            "location": "/software/ce-test-scaling/#monitoring-tools",
            "text": "To monitor tests, two software components are needed (which can be installed on the same node): ganglia-gmond and ganglia-gmetad. Once they are installed, then some ad-hoc metrics can be created to monitor the CE; for example:  condor_q -pool red.unl.edu:9619 -name sleeper@red.unl.edu -const 'JobStatus=?=2' | wc -l  gmetric --name RunningJobsCE",
            "title": "Monitoring tools"
        },
        {
            "location": "/software/ce-test-scaling/#generating-load",
            "text": "",
            "title": "Generating Load"
        },
        {
            "location": "/software/ce-test-scaling/#location",
            "text": "The load_generators are found in the   OSgscal github repo . The binary of interest here is  loadtest_condor",
            "title": "Location"
        },
        {
            "location": "/software/ce-test-scaling/#use",
            "text": "Just untar it or check it out from mas on the HTCondor submit node (see above):  git checkout https://github.com/efajardo/osgscal  cd load_generators/loadtest_condor/trunk/bin   Keep in mind that you also need a valid proxy for grid submissions.  For example, if the goal is to keep 1,000 jobs in the queue and run 6-hour sleep jobs (on average), you can run this command:  ./loadtest_condor.sh -type grid condor sleeper@red.unl.edu red.unl.edu:9619 -jobs 40000 -cluster 10 -proxy /home/submituser/.globus/cmspilot01.proxy -end random 21600 -maxidle 1000 -in sandbox 50",
            "title": "Use"
        },
        {
            "location": "/software/ipv6-testing/",
            "text": "Testing Software with IPv6\n\u00b6\n\n\nAbout this Document\n\u00b6\n\n\nThis document provides instructions on setting up a host with an IPv6 address for testing the OSG software stack. The plan is to be able to spin up special Fermicloud VM\u2019s that have corresponding public IPv6 addresses meaning that there will be a limit of ~15 VM\u2019s at one time.\n\n\nFor more information on IPv6, consult \nWikipedia\n.\n\n\nRequirements\n\u00b6\n\n\n\n\nBe familiar with your institute's network policy and firewall configuration 1 \nRoot\n access is required to configure \niptables\n\n\n\n\nEnabling IPV6\n\u00b6\n\n\n\n\n\n\nDetermine the public IPv6 address of your host. In the example below that would be \n2001:400:2410:29::182\n:\n\n\nuser@host $\n nslookup -type\n=\naaaa <HOSTNAME>\n\nServer:     132.239.0.252      \n\n\nAddress:    132.239.0.252#53\n\n\n\nNon-authoritative answer:\n\n\nipv6vm001.fnal.gov  has AAAA address 2001:400:2410:29::182\n\n\n\n\n\n\nReplacing \n<HOSTNAME>\n with your machine's hostname.\n\n\n\n\n\n\nAsk your network administrator for your IPv6 default gateway\n\n\n\n\n\n\nModify \n/etc/sysconfig/network-scripts/ifcfg-eth0\n and be sure these lines exist, and : \n\n\nIPV6INIT=yes\n\n\nIPV6_AUTOCONF=no\n\n\nIPV6ADDR=<IPV6 ADDRESS>\"\n\n\nIPV6_DEFAULTGW=\"The IPV6 Default Gateway\"\n\n\n\n\n\n\nReplace \n<IPV6 ADDRESS>\n with the address found in step 1.\n\n\n\n\n\n\nRestart the network devices:\n\n\nroot@host #\n service network restart\n\nShutting down interface eth0:                              [  OK  ]\n\n\nShutting down loopback interface:                          [  OK  ]\n\n\nBringing up loopback interface:                            [  OK  ]\n\n\nBringing up interface eth0:                                [  OK  ]\n\n\n\n\n\n\n\n\n\n\nTesting IPv6 connectivity\n\u00b6\n\n\nTo verify that the VM is capable of IPv6 we will be using the \nping6\n command between the test VM and another IPv6 capable machine\n\n\n\n\n\n\nFrom another IPv6 capable machine, ping your VM:\n\n\nuser@host $\n ping6 ipv6vm001.fnal.gov\n\nPING ipv6vm001.fnal.gov(ipv6vm001.fnal.gov) 56 data bytes\n\n\n64 bytes from ipv6vm001.fnal.gov: icmp_seq=1 ttl=51 time=68.1 ms\n\n\n64 bytes from ipv6vm001.fnal.gov: icmp_seq=2 ttl=51 time=57.6 ms\n\n\n\n\n\n\n\n\n\n\nFrom your test VM, ping another IPv6 capable machine (a list of IPv6 machines can be found \nhere\n):\n\n\n[efajardo@ipv6vm001 ~]#\n ping6 uaf-4.t2.ucsd.edu\n\nPING uaf-4.t2.ucsd.edu(uaf-4.t2.ucsd.edu) 56 data bytes\n\n\n64 bytes from uaf-4.t2.ucsd.edu: icmp_seq=1 ttl=51 time=57.6 ms\n\n\n\n\n\n\n\n\n\n\nVerifying SSH over IPv6\n\u00b6\n\n\nMake sure you can login to your VM over IPv6. Currently, Fermilab's kerberos does not support SSH over IPv6.\n\n\n\n\n\n\nAdd your ssh_key to your machine and make sure \n/etc/ssh/sshd_config\n has the following lines: \n\n\nRSAAuthentication yes\nPubkeyAuthentication yes\n\n\n\n\n\n\n\n\n\nTry connecting to you IPv6 enabled machine over SSH: \n\n\nefajardo@uaf-4 ~$\n ssh -6 root@ipv6vm001.fnal.gov\n\nLast login: Wed Jun 11 14:51:47 2014 from 2607:f720:1700:1b30:21f:c6ff:feeb:2631\n\n\n[root@ipv6vm001 ~]#\n\n\n\n\n\n\n\n\n\n\nDisabling IPv4\n\u00b6\n\n\nIf you were able to log into your VM over IPv6, you can disable IPv4 and try to communicate exclusively over IPv6.\n\n\n\n\n\n\nComment the \nIPADDR\n line in \n/etc/sysconfig/network-scripts/ifcfg-eth0\n:\n\n\n#IPADDR=131.225.41.182\nIPV6ADDR=\"2607:f720:1700:1b30::9b\"\n\n\n\n\n\n\n\nNote\n\n\nEnsure that your \nIPV6ADDR\n is uncommented otherwise you will not be able to connect to the host again\n\n\n\n\n\n\n\n\nRestart the network services: \n\n\nroot@host #\n service network restart\n\n\n\n\n\n\n\n\n\nThe ping command should no longer work: \n\n\nroot@host #\n ping ipv6vm001.fnal.gov\n\nPING ipv6vm001.fnal.gov (131.225.41.182): 56 data bytes\n\n\nRequest timeout for icmp_seq 0\n\n\nRequest timeout for icmp_seq 1\n\n\n\n\n\n\n\n\n\n\nDisabling IPv6\n\u00b6\n\n\nIn your testing, you may find the need to disable IPv6.\n\n\nroot@host #\n sysctl -w net.ipv6.conf.all.disable_ipv6\n=\n1\n\n\nroot@host #\n service network restart\n\n\n\n\n\nThe \nping6\n command should no longer work: \n\n\nroot@host #\n ping6 ipv6vm001.fnal.gov\n\nRequest timeout for icmp_seq 0\n\n\nRequest timeout for icmp_seq 1\n\n\n\n\n\n\nTesting in mixed mode\n\u00b6\n\n\nTo test IPv6 in mixed mode, you can use the \nntop\n tool to monitor traffic over IPv6. \nntop\n is installed on all the test machines and you can access the web interface at \nhostname:3000\n. To see a table that displays network traffic between your VM and another host by going to \nAll Protocols\n -> \nTraffic\n and looking at the IPv6 column.\n\n\n\n\nEnforcing communication over IPv6\n\u00b6\n\n\nIf you want to enforce IPv6 over mixed mode you can try using the IPv6 address for whatever software that you are testing. For example with xrdcp:\n\n\nroot@host #\n xrdcp -d \n1\n /tmp/first_test root://\n[\n2607\n:f720:1700:1b30::a4\n]\n:1094//tmp/first_test_8\n\n[19B/19B][100%][==================================================][0B/s] \n\n\n\n\n\n\nNotice that the IPv6 address follows \nRFC2732\n.",
            "title": "IPv6 Testing"
        },
        {
            "location": "/software/ipv6-testing/#testing-software-with-ipv6",
            "text": "",
            "title": "Testing Software with IPv6"
        },
        {
            "location": "/software/ipv6-testing/#about-this-document",
            "text": "This document provides instructions on setting up a host with an IPv6 address for testing the OSG software stack. The plan is to be able to spin up special Fermicloud VM\u2019s that have corresponding public IPv6 addresses meaning that there will be a limit of ~15 VM\u2019s at one time.  For more information on IPv6, consult  Wikipedia .",
            "title": "About this Document"
        },
        {
            "location": "/software/ipv6-testing/#requirements",
            "text": "Be familiar with your institute's network policy and firewall configuration 1  Root  access is required to configure  iptables",
            "title": "Requirements"
        },
        {
            "location": "/software/ipv6-testing/#enabling-ipv6",
            "text": "Determine the public IPv6 address of your host. In the example below that would be  2001:400:2410:29::182 :  user@host $  nslookup -type = aaaa <HOSTNAME> Server:     132.239.0.252        Address:    132.239.0.252#53  Non-authoritative answer:  ipv6vm001.fnal.gov  has AAAA address 2001:400:2410:29::182   Replacing  <HOSTNAME>  with your machine's hostname.    Ask your network administrator for your IPv6 default gateway    Modify  /etc/sysconfig/network-scripts/ifcfg-eth0  and be sure these lines exist, and :   IPV6INIT=yes  IPV6_AUTOCONF=no  IPV6ADDR=<IPV6 ADDRESS>\"  IPV6_DEFAULTGW=\"The IPV6 Default Gateway\"   Replace  <IPV6 ADDRESS>  with the address found in step 1.    Restart the network devices:  root@host #  service network restart Shutting down interface eth0:                              [  OK  ]  Shutting down loopback interface:                          [  OK  ]  Bringing up loopback interface:                            [  OK  ]  Bringing up interface eth0:                                [  OK  ]",
            "title": "Enabling IPV6"
        },
        {
            "location": "/software/ipv6-testing/#testing-ipv6-connectivity",
            "text": "To verify that the VM is capable of IPv6 we will be using the  ping6  command between the test VM and another IPv6 capable machine    From another IPv6 capable machine, ping your VM:  user@host $  ping6 ipv6vm001.fnal.gov PING ipv6vm001.fnal.gov(ipv6vm001.fnal.gov) 56 data bytes  64 bytes from ipv6vm001.fnal.gov: icmp_seq=1 ttl=51 time=68.1 ms  64 bytes from ipv6vm001.fnal.gov: icmp_seq=2 ttl=51 time=57.6 ms     From your test VM, ping another IPv6 capable machine (a list of IPv6 machines can be found  here ):  [efajardo@ipv6vm001 ~]#  ping6 uaf-4.t2.ucsd.edu PING uaf-4.t2.ucsd.edu(uaf-4.t2.ucsd.edu) 56 data bytes  64 bytes from uaf-4.t2.ucsd.edu: icmp_seq=1 ttl=51 time=57.6 ms",
            "title": "Testing IPv6 connectivity"
        },
        {
            "location": "/software/ipv6-testing/#verifying-ssh-over-ipv6",
            "text": "Make sure you can login to your VM over IPv6. Currently, Fermilab's kerberos does not support SSH over IPv6.    Add your ssh_key to your machine and make sure  /etc/ssh/sshd_config  has the following lines:   RSAAuthentication yes\nPubkeyAuthentication yes    Try connecting to you IPv6 enabled machine over SSH:   efajardo@uaf-4 ~$  ssh -6 root@ipv6vm001.fnal.gov Last login: Wed Jun 11 14:51:47 2014 from 2607:f720:1700:1b30:21f:c6ff:feeb:2631  [root@ipv6vm001 ~]#",
            "title": "Verifying SSH over IPv6"
        },
        {
            "location": "/software/ipv6-testing/#disabling-ipv4",
            "text": "If you were able to log into your VM over IPv6, you can disable IPv4 and try to communicate exclusively over IPv6.    Comment the  IPADDR  line in  /etc/sysconfig/network-scripts/ifcfg-eth0 :  #IPADDR=131.225.41.182\nIPV6ADDR=\"2607:f720:1700:1b30::9b\"   Note  Ensure that your  IPV6ADDR  is uncommented otherwise you will not be able to connect to the host again     Restart the network services:   root@host #  service network restart    The ping command should no longer work:   root@host #  ping ipv6vm001.fnal.gov PING ipv6vm001.fnal.gov (131.225.41.182): 56 data bytes  Request timeout for icmp_seq 0  Request timeout for icmp_seq 1",
            "title": "Disabling IPv4"
        },
        {
            "location": "/software/ipv6-testing/#disabling-ipv6",
            "text": "In your testing, you may find the need to disable IPv6.  root@host #  sysctl -w net.ipv6.conf.all.disable_ipv6 = 1  root@host #  service network restart  The  ping6  command should no longer work:   root@host #  ping6 ipv6vm001.fnal.gov Request timeout for icmp_seq 0  Request timeout for icmp_seq 1",
            "title": "Disabling IPv6"
        },
        {
            "location": "/software/ipv6-testing/#testing-in-mixed-mode",
            "text": "To test IPv6 in mixed mode, you can use the  ntop  tool to monitor traffic over IPv6.  ntop  is installed on all the test machines and you can access the web interface at  hostname:3000 . To see a table that displays network traffic between your VM and another host by going to  All Protocols  ->  Traffic  and looking at the IPv6 column.",
            "title": "Testing in mixed mode"
        },
        {
            "location": "/software/ipv6-testing/#enforcing-communication-over-ipv6",
            "text": "If you want to enforce IPv6 over mixed mode you can try using the IPv6 address for whatever software that you are testing. For example with xrdcp:  root@host #  xrdcp -d  1  /tmp/first_test root:// [ 2607 :f720:1700:1b30::a4 ] :1094//tmp/first_test_8 [19B/19B][100%][==================================================][0B/s]    Notice that the IPv6 address follows  RFC2732 .",
            "title": "Enforcing communication over IPv6"
        },
        {
            "location": "/policy/software-support/",
            "text": "Software Support\n\u00b6\n\n\nThis document describes how OSG Technology Team members should support the OSG Software Stack, including triage duty\nresponsibilities and when to transition from direct support inquiries to a ticketing system such as Freshdesk or JIRA.\n\n\nConsiderations\n\u00b6\n\n\nWhen providing support for our users, remember the following:\n\n\n\n\nWe are a small community and we need to take good care of our users.\n    Please be friendly and patient even when the user is frustrated or lacking in knowledge.\n\n\nAlways sign your ticket with your full name, so people know who is responding.\n    If it's easy for you, include a signature at the bottom of your response.\n\n\nIf you need to collect information about a problematic host, ask users to run \nosg-system-profiler\n.\n    It can shorten the number of times you ask for information because it collects quite a bit for you.\n\n\nIf you run across a problem that has a chance of being hit by other users:\n\n\nIs there a bug we should fix in the software?\n    Or something we could improve in the software?\n\n\nIs there a way to improve our documentation?\n\n\nCan you extend our troubleshooting documents to help people track this down more quickly?\n    Consider the troubleshooting documents to be as much for us as for our users.\n\n\nIs this something that other Technology Team members should be aware of?\n    Note it during the support discussion during the weekly OSG Technology meeting, or email the Technology Team if\n    it seems more urgent.\n\n\n\n\n\n\n\n\nTriage Duty\n\u00b6\n\n\nThe OSG uses \nFreshdesk\n to track support issues so you will need a Freshworks account with agent privileges\n(contact the OSG Software Team Manager for access).\n\n\n\n\nLogging in as an agent\n\n\nDon't enter your credentials directly into the \nlogin page\n!\nClick the agent login link instead so that you don't have to enter your credentials twice.\n\n\n\n\nDuring normal work hours, the OSG Technology Team splits responsibilities for managing incoming OSG Software support\nrequests based upon a \nweekly rotation\n.\nIf you are on triage duty, your responsibilities are as follows:\n\n\n\n\nWatch for new software tickets:\n review the\n    \nUnresolved Software Tickets\n and\n    \nAll Unassigned Tickets\n filters at least twice\n    daily for new OSG Software-related tickets.\n    For any such unassigned tickets, assign it as follows:\n\n\nIf you can handle an incoming ticket,\n assign it to yourself.\n    Inasmuch as possible, you should strive to handle the easier tickets and not pass them off to other people.\n\n\nIf you cannot handle an incoming ticket,\n collect initial details such as relevant versions, logs, etc., and\n    assign the ticket to the most appropriate Technology Team member.\n    Where appropriate, CC people from other OSG teams, sites, or VOs.\n\n\n\n\n\n\nReview assigned software tickets.\n\n    For tickets that are not being handled in a timely fashion (pay special attention to \nOVERDUE\n and \nCustomer\n    Responded\n tickets):\n\n\nIf the ticket is pending and the assignee has not responded in > 2 business days,\n\n    notify the ticket assignee via private note that they need to revisit the ticket.\n\n\nIf the ticket is waiting on the customer or a third party and they have not responded in > 1 week,\n\n    reply to the ticket asking if they've had the time to review the Technology Team's latest response(s).\n\n\nIf the ticket is waiting on the customer and they have not responded in > 2 weeks,\n close the ticket and let\n    the customer know that they can re-open it by responding whenever they're ready to tackle the issue again.\n\n\n\n\n\n\nRe-assign non-software tickets:\n\n    Tickets that have been mistakenly assigned to the Software group should be re-assigned to the appropriate group.\n\n\nMerge duplicate tickets:\n\n   Responses to a ticket sometimes results in creation of a new ticket; these new tickets should be merged into the\n   original ticket.\n   See \nthis documentation\n.\n\n\nClean up spam:\n\n    Mark the ticket as spam and block the user.\n    See \nthis documentation\n.\n\n\n\n\n\n\nQuestion\n\n\nIf you have questions concerning a ticket, consult the OSG Software Team Manager and/or the \n#software\n channel in\nthe OSG Slack.\n\n\n\n\nUpdating the triage calendar\n\u00b6\n\n\nThe current triage duty schedule can be found in the OSG Software calendar, hosted on Tim Cartwright\u2019s Google account.\nIf you need privileges to edit the calendar, ask the OSG Software Team Manager.\nTo update the triage duty schedule:\n\n\n\n\nClone the \ngit repo\n\n\n\n\nGenerate next rotation:\n\n\n./triage.py --generateNextRotation > rotation.txt\n\n\n\n\n\n\n\n\n\nCheck and update assignments according to team member outages\n\n\n\n\nLoad triage assignments into Google Calendar:\n./triage.py --load rotation.txt\n\n\n\n\n\n\n\n\n\nTo subscribe to this calendar in your calendar program, use the iCal URL:\n\nhttps://www.google.com/calendar/ical/h5t4mns6omp49db1e4qtqrrf4g%40group.calendar.google.com/public/basic.ics\n\n\n\n\n\nTicket Systems\n\u00b6\n\n\nThe OSG Technology Team uses the \nFreshdesk\n and\n\nJIRA\n ticketing systems to track support and all other work, respectively.\nThis section describes the differences between the two as well as some OSG Technology Freshdesk conventions.\n\n\nDirect Email\n\u00b6\n\n\nSometimes users may email you directly with support inquiries.\nIf someone emails you directly for support, you have the choice of when to move it to a ticket.\nThe recommended criteria are:\n\n\n\n\nIf it's easy to handle and you can definitely do it yourself, leave it in email.\n\n\nIf there's a chance that you can't do it in a timely fashion, turn it into a ticket.\n\n\nIf there's a chance that you might lose track of the email, turn it into a ticket.\n\n\nIf there's a chance that you might need help from others, turn it into a ticket.\n\n\nIf it's an unusual topic and other people would benefit from seeing the ticket (now or in the future), turn it into\n    a ticket.\n\n\n\n\nFreshdesk\n\u00b6\n\n\n\n\nFreshdesk access\n\n\nThe OSG uses \nFreshdesk\n to track support issues so you will need a Freshworks account with agent\nprivileges (contact the OSG Software Team Manager for access).\n\n\n\n\nFreshdesk tickets are for user support, i.e. this is where we help users debug, understand their problems, etc.\nWhen replying to or otherwise updating a Freshdesk ticket, there are a few things to note:\n\n\n\n\nFreshdesk auto-populates the contact's name when replying through the web interface, e.g. \nHi Brian\n.\n    Ensure that the name is correct, especially if there are multiple parties involved in a single ticket.\n    If the auto-populated name looks incorrect, e.g. \nHi blin.wisc\n, fix the contact's First and Last name fields.\n\n\n\n\nMake sure to set the state of the ticket, which is helpful for those on triage:\n\n\n\n\n\n\n\n\nState\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nPending\n\n\nAssignee is responsible for next actions\n\n\n\n\n\n\nWaiting on Customer\n\n\nAssignee needs the reporter to respond\n\n\n\n\n\n\nWaiting on Third Party\n\n\nAssignee needs a response from a CC\n\n\n\n\n\n\nClosed\n\n\nSupport is complete or the user is unresponsive. \nSee above\n.\n\n\n\n\n\n\nOpen\n\n\nTicket has not yet been assigned (initial ticket state)\n\n\n\n\n\n\nResolved\n\n\nDO NOT USE\n. Similar to \nClosed\n but sends a user survey.\n\n\n\n\n\n\n\n\n\n\n\n\nIf actionable Technology Team tasks arise from a Freshdesk ticket, \nJIRA\n ticket(s) should be created to track\nthat work.\nResultant JIRA tickets should include a link to the original Freshdesk ticket, a description of the problem or feature\nrequest, and a proposed solution or implementation.\n\n\nAfter the relevant JIRA tickets have been created, ask the user if they would be ok with tracking the issue via JIRA. \nIf they say yes, close the Freshdesk ticket.\n\n\nJIRA\n\u00b6\n\n\nJIRA is for tracking our work and it's meant for internal usage, not for user support.\nIn general, users should not ask for support via JIRA.\nA single user support ticket might result in zero, one, or multiple JIRA tickets.",
            "title": "Software Support"
        },
        {
            "location": "/policy/software-support/#software-support",
            "text": "This document describes how OSG Technology Team members should support the OSG Software Stack, including triage duty\nresponsibilities and when to transition from direct support inquiries to a ticketing system such as Freshdesk or JIRA.",
            "title": "Software Support"
        },
        {
            "location": "/policy/software-support/#considerations",
            "text": "When providing support for our users, remember the following:   We are a small community and we need to take good care of our users.\n    Please be friendly and patient even when the user is frustrated or lacking in knowledge.  Always sign your ticket with your full name, so people know who is responding.\n    If it's easy for you, include a signature at the bottom of your response.  If you need to collect information about a problematic host, ask users to run  osg-system-profiler .\n    It can shorten the number of times you ask for information because it collects quite a bit for you.  If you run across a problem that has a chance of being hit by other users:  Is there a bug we should fix in the software?\n    Or something we could improve in the software?  Is there a way to improve our documentation?  Can you extend our troubleshooting documents to help people track this down more quickly?\n    Consider the troubleshooting documents to be as much for us as for our users.  Is this something that other Technology Team members should be aware of?\n    Note it during the support discussion during the weekly OSG Technology meeting, or email the Technology Team if\n    it seems more urgent.",
            "title": "Considerations"
        },
        {
            "location": "/policy/software-support/#triage-duty",
            "text": "The OSG uses  Freshdesk  to track support issues so you will need a Freshworks account with agent privileges\n(contact the OSG Software Team Manager for access).   Logging in as an agent  Don't enter your credentials directly into the  login page !\nClick the agent login link instead so that you don't have to enter your credentials twice.   During normal work hours, the OSG Technology Team splits responsibilities for managing incoming OSG Software support\nrequests based upon a  weekly rotation .\nIf you are on triage duty, your responsibilities are as follows:   Watch for new software tickets:  review the\n     Unresolved Software Tickets  and\n     All Unassigned Tickets  filters at least twice\n    daily for new OSG Software-related tickets.\n    For any such unassigned tickets, assign it as follows:  If you can handle an incoming ticket,  assign it to yourself.\n    Inasmuch as possible, you should strive to handle the easier tickets and not pass them off to other people.  If you cannot handle an incoming ticket,  collect initial details such as relevant versions, logs, etc., and\n    assign the ticket to the most appropriate Technology Team member.\n    Where appropriate, CC people from other OSG teams, sites, or VOs.    Review assigned software tickets. \n    For tickets that are not being handled in a timely fashion (pay special attention to  OVERDUE  and  Customer\n    Responded  tickets):  If the ticket is pending and the assignee has not responded in > 2 business days, \n    notify the ticket assignee via private note that they need to revisit the ticket.  If the ticket is waiting on the customer or a third party and they have not responded in > 1 week, \n    reply to the ticket asking if they've had the time to review the Technology Team's latest response(s).  If the ticket is waiting on the customer and they have not responded in > 2 weeks,  close the ticket and let\n    the customer know that they can re-open it by responding whenever they're ready to tackle the issue again.    Re-assign non-software tickets: \n    Tickets that have been mistakenly assigned to the Software group should be re-assigned to the appropriate group.  Merge duplicate tickets: \n   Responses to a ticket sometimes results in creation of a new ticket; these new tickets should be merged into the\n   original ticket.\n   See  this documentation .  Clean up spam: \n    Mark the ticket as spam and block the user.\n    See  this documentation .    Question  If you have questions concerning a ticket, consult the OSG Software Team Manager and/or the  #software  channel in\nthe OSG Slack.",
            "title": "Triage Duty"
        },
        {
            "location": "/policy/software-support/#updating-the-triage-calendar",
            "text": "The current triage duty schedule can be found in the OSG Software calendar, hosted on Tim Cartwright\u2019s Google account.\nIf you need privileges to edit the calendar, ask the OSG Software Team Manager.\nTo update the triage duty schedule:   Clone the  git repo   Generate next rotation:  ./triage.py --generateNextRotation > rotation.txt    Check and update assignments according to team member outages   Load triage assignments into Google Calendar: ./triage.py --load rotation.txt    To subscribe to this calendar in your calendar program, use the iCal URL: https://www.google.com/calendar/ical/h5t4mns6omp49db1e4qtqrrf4g%40group.calendar.google.com/public/basic.ics",
            "title": "Updating the triage calendar"
        },
        {
            "location": "/policy/software-support/#ticket-systems",
            "text": "The OSG Technology Team uses the  Freshdesk  and JIRA  ticketing systems to track support and all other work, respectively.\nThis section describes the differences between the two as well as some OSG Technology Freshdesk conventions.",
            "title": "Ticket Systems"
        },
        {
            "location": "/policy/software-support/#direct-email",
            "text": "Sometimes users may email you directly with support inquiries.\nIf someone emails you directly for support, you have the choice of when to move it to a ticket.\nThe recommended criteria are:   If it's easy to handle and you can definitely do it yourself, leave it in email.  If there's a chance that you can't do it in a timely fashion, turn it into a ticket.  If there's a chance that you might lose track of the email, turn it into a ticket.  If there's a chance that you might need help from others, turn it into a ticket.  If it's an unusual topic and other people would benefit from seeing the ticket (now or in the future), turn it into\n    a ticket.",
            "title": "Direct Email"
        },
        {
            "location": "/policy/software-support/#freshdesk",
            "text": "Freshdesk access  The OSG uses  Freshdesk  to track support issues so you will need a Freshworks account with agent\nprivileges (contact the OSG Software Team Manager for access).   Freshdesk tickets are for user support, i.e. this is where we help users debug, understand their problems, etc.\nWhen replying to or otherwise updating a Freshdesk ticket, there are a few things to note:   Freshdesk auto-populates the contact's name when replying through the web interface, e.g.  Hi Brian .\n    Ensure that the name is correct, especially if there are multiple parties involved in a single ticket.\n    If the auto-populated name looks incorrect, e.g.  Hi blin.wisc , fix the contact's First and Last name fields.   Make sure to set the state of the ticket, which is helpful for those on triage:     State  Description      Pending  Assignee is responsible for next actions    Waiting on Customer  Assignee needs the reporter to respond    Waiting on Third Party  Assignee needs a response from a CC    Closed  Support is complete or the user is unresponsive.  See above .    Open  Ticket has not yet been assigned (initial ticket state)    Resolved  DO NOT USE . Similar to  Closed  but sends a user survey.       If actionable Technology Team tasks arise from a Freshdesk ticket,  JIRA  ticket(s) should be created to track\nthat work.\nResultant JIRA tickets should include a link to the original Freshdesk ticket, a description of the problem or feature\nrequest, and a proposed solution or implementation.  After the relevant JIRA tickets have been created, ask the user if they would be ok with tracking the issue via JIRA. \nIf they say yes, close the Freshdesk ticket.",
            "title": "Freshdesk"
        },
        {
            "location": "/policy/software-support/#jira",
            "text": "JIRA is for tracking our work and it's meant for internal usage, not for user support.\nIn general, users should not ask for support via JIRA.\nA single user support ticket might result in zero, one, or multiple JIRA tickets.",
            "title": "JIRA"
        },
        {
            "location": "/software/effort-tracking/",
            "text": "Effort Tracking\n\u00b6\n\n\nThis page describes a simple plan for tracking effort in the OSG Technology teams.\n\n\nBasic Ideas\n\u00b6\n\n\nAt its simplest, we would like to understand how much effort is spent on various OSG Technology activities over time. The focus is on having reasonably accurate, unbiased data. We might use the data later, for example, to hone future OSG proposals. And of course, all federal funding is subject to effort tracking.\n\n\nThere are just a few simple ideas to keep in mind:\n\n\n\n\n\n\nEach week, report your effort on OSG Technology activities\n\n\nUpdate your numbers in the effort tracking google spreadsheet (ask BrianL for access) and include a section in your weekly status report; here is an example:\n\n\nEFFORT\nExternal development: 63% \nSupport: 12% \nLeave: 20% \nOutside: 5\n\n\n\n\n\n\n\n\n\nFollow standard federal regulations for calculating effort\n (e.g., OMB Circular A-21)\n\n\nThe main idea is that \nall\n of your job-related activity for a week equals 100%, whether that is exactly 40 hours of work, a little less (subject to your local institution\u2019s rules), or more. This implies that the same hours worked could result in different effort percentages reported from week to week; for example, 4 hours in a 40-hour week is 10%, but 4 hours in a 50-hour week (which I hope is exceedingly rare) is 8%.\n\n\nReport 100% of your effort each week, but note that all effort outside of the Technology area falls into a single category. Unless you work at UW\u2013Madison, we do not need to know any details about your effort outside of the Technology area. (BrianL will talk to UW\u2013Madison folks about local expectations.)\n\n\nIf you are assigned to the Technology area for less than 100%, please report your actual Technology effort accurately. Workloads vary from week to week. For example, suppose you are 50% Technology in general, but you actually work 24 hours in a 40-hour week; you should report 60% effort for that week. The goal is to present reality, not what you think management wants to see.\n\n\n\n\n\n\nEffort is reported as \ninteger\n percentages, no less accurate than 5% intervals\n \n     So please do not report percentages like 43.21% and please do not round to the nearest 10%.\n\n\n\n\n\n\nEffort Categories\n\u00b6\n\n\nHere are the categories in which to track effort:\n\n\n\n\n\n\n\n\nInvestigations\n\n\nWork on the Investigations team\n\n\n\n\n\n\n\n\n\n\nExternal\n\n\nSoftware work that (generally) benefits our users; e.g., creating packages; updating existing ones; designing, coding, and testing new tools, existing tools, patches, or our software components\n\n\n\n\n\n\nInternal\n\n\nSoftware work on tools that we use to get work done; e.g., working on osg-test (for now), osg-build, Koji maintenance, the UW or UC ITB instances\n\n\n\n\n\n\nDocumentation\n\n\nWork on our TWiki or Markdown documentation\n\n\n\n\n\n\nRelease\n\n\nRelease team activities, primarily acceptance testing and cutting releases\n\n\n\n\n\n\nSupport\n\n\nUser support, including working on GOC tickets, direct support emails, some JIRA tickets that are more support than development, etc. It might be tricky to decide when support work becomes development work; generally, once a support ticket turns into a JIRA ticket and goes through the normal development lifecycle, then the JIRA-based work is development. If there is still extensive communication with GOC ticket users, that is still support.\n\n\n\n\n\n\nManagement\n\n\nThis is mainly for team leads; e.g., managing team activities and tickets (generally); hiring; \nleading\n (not just attending) meetings\n\n\n\n\n\n\nEducation\n\n\nNot for general learning or training activities\n The OSG Education area is essentially part of the Software area, because many technology-area members contribute to the OSG School. So this category is for OSG School effort (or other sanctioned OSG Education activities.\n\n\n\n\n\n\nAdmin\n\n\nGeneral administrative activities that benefit the OSG Technology area but that do not fit elsewhere \u2014 \nuse sparingly!!\n\n\n\n\n\n\nOutside\n\n\nFor all activities outside of the OSG Technology area (Madison team members should provide extra details, see BrianL)\n\n\n\n\n\n\nLeave\n\n\nThis is for holidays, vacation, and sick leave; count a full day of leave as 8.0 hours, count a half day as 4.0 hours\n\n\n\n\n\n\n\n\nA few thoughts about tricky situations:\n\n\n\n\n\n\nMeetings. If a meeting is specific to one of the categories above, use that category. If the meeting is more general (e.g., the weekly Monday meeting, or the OSG AHM), amortize your time according to your usual breakdown by category. For example, someone who spends nearly all of their time working on development tasks should count the Monday meeting as development time.\n\n\n\n\n\n\nAdministrative activities. This is probably the trickiest category. It certainly covers any administrative work that pertains to your activity in the OSG Technology area. But what about administrative activities that pertain to your employment in general, and not to any particular activity? In that case, and that case only, you should amortize the administrative activity between \nAdmin\n and \nOutside\n according to either (a) your appointment percentages between OSG Technology and non-Technology activities, or (b) your actual percentages between OSG Technology and non-Technology activities.\n\n\n\n\n\n\nOutside (non-Technology) activities that benefit the OSG Technology area. The simplest approach is to amortize the time. The more correct approach is to figure out where credit will be given for the work; if the OSG Annual Report will describe the work in one of the Technology sections, then it should be a Technology category; otherwise not.\n\n\n\n\n\n\nLearning activities. Put short amounts of learning time in their relevant development category. For instance, if Igor is showing Edgar how to use GlideTester, that goes into \nInternal\n. But for longer training events, or for events that are less obviously related to day-to-day activities, mark the time as \nAdmin\n, and maybe add a comment explaining the activity.\n\n\n\n\n\n\nUltimately, if you are not sure how to deal with a situation, ask BrianL and he will make something up and document it here (generically) for future reference.",
            "title": "Effort Tracking"
        },
        {
            "location": "/software/effort-tracking/#effort-tracking",
            "text": "This page describes a simple plan for tracking effort in the OSG Technology teams.",
            "title": "Effort Tracking"
        },
        {
            "location": "/software/effort-tracking/#basic-ideas",
            "text": "At its simplest, we would like to understand how much effort is spent on various OSG Technology activities over time. The focus is on having reasonably accurate, unbiased data. We might use the data later, for example, to hone future OSG proposals. And of course, all federal funding is subject to effort tracking.  There are just a few simple ideas to keep in mind:    Each week, report your effort on OSG Technology activities  Update your numbers in the effort tracking google spreadsheet (ask BrianL for access) and include a section in your weekly status report; here is an example:  EFFORT\nExternal development: 63% \nSupport: 12% \nLeave: 20% \nOutside: 5    Follow standard federal regulations for calculating effort  (e.g., OMB Circular A-21)  The main idea is that  all  of your job-related activity for a week equals 100%, whether that is exactly 40 hours of work, a little less (subject to your local institution\u2019s rules), or more. This implies that the same hours worked could result in different effort percentages reported from week to week; for example, 4 hours in a 40-hour week is 10%, but 4 hours in a 50-hour week (which I hope is exceedingly rare) is 8%.  Report 100% of your effort each week, but note that all effort outside of the Technology area falls into a single category. Unless you work at UW\u2013Madison, we do not need to know any details about your effort outside of the Technology area. (BrianL will talk to UW\u2013Madison folks about local expectations.)  If you are assigned to the Technology area for less than 100%, please report your actual Technology effort accurately. Workloads vary from week to week. For example, suppose you are 50% Technology in general, but you actually work 24 hours in a 40-hour week; you should report 60% effort for that week. The goal is to present reality, not what you think management wants to see.    Effort is reported as  integer  percentages, no less accurate than 5% intervals  \n     So please do not report percentages like 43.21% and please do not round to the nearest 10%.",
            "title": "Basic Ideas"
        },
        {
            "location": "/software/effort-tracking/#effort-categories",
            "text": "Here are the categories in which to track effort:     Investigations  Work on the Investigations team      External  Software work that (generally) benefits our users; e.g., creating packages; updating existing ones; designing, coding, and testing new tools, existing tools, patches, or our software components    Internal  Software work on tools that we use to get work done; e.g., working on osg-test (for now), osg-build, Koji maintenance, the UW or UC ITB instances    Documentation  Work on our TWiki or Markdown documentation    Release  Release team activities, primarily acceptance testing and cutting releases    Support  User support, including working on GOC tickets, direct support emails, some JIRA tickets that are more support than development, etc. It might be tricky to decide when support work becomes development work; generally, once a support ticket turns into a JIRA ticket and goes through the normal development lifecycle, then the JIRA-based work is development. If there is still extensive communication with GOC ticket users, that is still support.    Management  This is mainly for team leads; e.g., managing team activities and tickets (generally); hiring;  leading  (not just attending) meetings    Education  Not for general learning or training activities  The OSG Education area is essentially part of the Software area, because many technology-area members contribute to the OSG School. So this category is for OSG School effort (or other sanctioned OSG Education activities.    Admin  General administrative activities that benefit the OSG Technology area but that do not fit elsewhere \u2014  use sparingly!!    Outside  For all activities outside of the OSG Technology area (Madison team members should provide extra details, see BrianL)    Leave  This is for holidays, vacation, and sick leave; count a full day of leave as 8.0 hours, count a half day as 4.0 hours     A few thoughts about tricky situations:    Meetings. If a meeting is specific to one of the categories above, use that category. If the meeting is more general (e.g., the weekly Monday meeting, or the OSG AHM), amortize your time according to your usual breakdown by category. For example, someone who spends nearly all of their time working on development tasks should count the Monday meeting as development time.    Administrative activities. This is probably the trickiest category. It certainly covers any administrative work that pertains to your activity in the OSG Technology area. But what about administrative activities that pertain to your employment in general, and not to any particular activity? In that case, and that case only, you should amortize the administrative activity between  Admin  and  Outside  according to either (a) your appointment percentages between OSG Technology and non-Technology activities, or (b) your actual percentages between OSG Technology and non-Technology activities.    Outside (non-Technology) activities that benefit the OSG Technology area. The simplest approach is to amortize the time. The more correct approach is to figure out where credit will be given for the work; if the OSG Annual Report will describe the work in one of the Technology sections, then it should be a Technology category; otherwise not.    Learning activities. Put short amounts of learning time in their relevant development category. For instance, if Igor is showing Edgar how to use GlideTester, that goes into  Internal . But for longer training events, or for events that are less obviously related to day-to-day activities, mark the time as  Admin , and maybe add a comment explaining the activity.    Ultimately, if you are not sure how to deal with a situation, ask BrianL and he will make something up and document it here (generically) for future reference.",
            "title": "Effort Categories"
        },
        {
            "location": "/software/release-planning/",
            "text": "Plans for Future Releases\n\u00b6\n\n\nThis informal page is the mapping of \"technology goals\" (e.g., \"release software Foo version X\") to release numbers. It is meant to be updated as the releases evolve (and items are moved back in schedule). For package support policy between release series, see \nthis page\n.\n\n\nUnless explicitly noted, bullet points refer to software in the release repo.\n\n\nThis page is not meant to track minor bugfixes or updates -- rather, its focus should be new features.\n\n\nOSG 3.4 (May 2017)\n\u00b6\n\n\n\n\n\n\n\n\nPackage(s)\n\n\nChange in osg-release\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nBeStMan2\n\n\nDrop\n\n\nRetirement policy\n\n\n\n\n\n\nedg-mkgridmap\n\n\nDrop\n\n\nSOFTWARE-2600\n\n\n\n\n\n\nfrontier-squid\n\n\nModify\n\n\nVersion 3\n\n\n\n\n\n\nglexec\n\n\nDrop\n\n\nSOFTWARE-2620\n\n\n\n\n\n\nGRAM\n\n\nDrop\n\n\nSOFTWARE-2530\n\n\n\n\n\n\nGUMS\n\n\nDrop\n\n\nRetirement policy\n, \nSOFTWARE-2600\n\n\n\n\n\n\njglobus\n\n\nDrop\n\n\nSOFTWARE-2606\n\n\n\n\n\n\nnetlogger\n\n\nDrop\n\n\n\n\n\n\n\n\nosg-ce\n\n\nModify\n\n\nDrop \nGridFTP\n, \ngums-client\n\n\n\n\n\n\nosg-info-services\n\n\nDrop\n\n\n\n\n\n\n\n\nosg-version\n\n\nDrop\n\n\n\n\n\n\n\n\nsingularity\n\n\nAdd\n\n\n\n\n\n\n\n\nvoms-admin-server\n\n\nDrop\n\n\nRetirement policy\n\n\n\n\n\n\n\n\nTrack OSG 3.4 updates through its \nJIRA epic\n.\n\n\nSupport Policy for OSG 3.3\n\u00b6\n\n\nAccording to our \nrelease support policy\n and the release date of May 2017 for OSG 3.4, OSG 3.3 will receive routine software updates until November 2017 and critical updates until May 2018.\n\n\nPrevious Releases\n\u00b6\n\n\n12 November 2013\n\u00b6\n\n\n\n\nOSG 3.1\n\n\nHTCondor-CE with PBS\n\n\nosg-configure emits an ERROR if squid defaults are not changed (\"UNAVAILABLE\" is a valid change)\n\n\n\n\n\n\nOSG 3.2\n\n\nInitial release (\nhow to create\n)\n\n\nHDFS 2.0.0 (already done in Upcoming)\n\n\nHTCondor 8.0.4\n\n\nglideinWMS 3.2.0\n\n\nosg-info-services (Note: ReSS will likely be retired around year-end)\n\n\nOSG 3.1 updates\n\n\n\n\n\n\nUpcoming\n\n\nHTCondor 8.1 with unified RPM\n\n\nBOSCO\n\n\n\n\n\n\n\n\n10 December 2013\n\u00b6\n\n\n\n\nOSG 3.2\n\n\nRSV-for-VOs\n\n\nSquid must be present on OSG-CE (??? what does this mean?)",
            "title": "Release Planning"
        },
        {
            "location": "/software/release-planning/#plans-for-future-releases",
            "text": "This informal page is the mapping of \"technology goals\" (e.g., \"release software Foo version X\") to release numbers. It is meant to be updated as the releases evolve (and items are moved back in schedule). For package support policy between release series, see  this page .  Unless explicitly noted, bullet points refer to software in the release repo.  This page is not meant to track minor bugfixes or updates -- rather, its focus should be new features.",
            "title": "Plans for Future Releases"
        },
        {
            "location": "/software/release-planning/#osg-34-may-2017",
            "text": "Package(s)  Change in osg-release  Notes      BeStMan2  Drop  Retirement policy    edg-mkgridmap  Drop  SOFTWARE-2600    frontier-squid  Modify  Version 3    glexec  Drop  SOFTWARE-2620    GRAM  Drop  SOFTWARE-2530    GUMS  Drop  Retirement policy ,  SOFTWARE-2600    jglobus  Drop  SOFTWARE-2606    netlogger  Drop     osg-ce  Modify  Drop  GridFTP ,  gums-client    osg-info-services  Drop     osg-version  Drop     singularity  Add     voms-admin-server  Drop  Retirement policy     Track OSG 3.4 updates through its  JIRA epic .",
            "title": "OSG 3.4 (May 2017)"
        },
        {
            "location": "/software/release-planning/#support-policy-for-osg-33",
            "text": "According to our  release support policy  and the release date of May 2017 for OSG 3.4, OSG 3.3 will receive routine software updates until November 2017 and critical updates until May 2018.",
            "title": "Support Policy for OSG 3.3"
        },
        {
            "location": "/software/release-planning/#previous-releases",
            "text": "",
            "title": "Previous Releases"
        },
        {
            "location": "/software/release-planning/#12-november-2013",
            "text": "OSG 3.1  HTCondor-CE with PBS  osg-configure emits an ERROR if squid defaults are not changed (\"UNAVAILABLE\" is a valid change)    OSG 3.2  Initial release ( how to create )  HDFS 2.0.0 (already done in Upcoming)  HTCondor 8.0.4  glideinWMS 3.2.0  osg-info-services (Note: ReSS will likely be retired around year-end)  OSG 3.1 updates    Upcoming  HTCondor 8.1 with unified RPM  BOSCO",
            "title": "12 November 2013"
        },
        {
            "location": "/software/release-planning/#10-december-2013",
            "text": "OSG 3.2  RSV-for-VOs  Squid must be present on OSG-CE (??? what does this mean?)",
            "title": "10 December 2013"
        },
        {
            "location": "/software/new-team-member/",
            "text": "Setup Instructions for New Team Members\n\u00b6\n\n\n\n\nComputing account at FNAL\n\n\nTo get this, follow the instructions at \nhttps://fermi.service-now.com/kb_view.do?sysparm_article=KB0010797\n\n\n\n\n\n\nssh access to a UW CompSci account, including AFS access\n\n\nSend email to Tim C with top 3 requested usernames\n\n\n\n\n\n\nRead/write access to the UW Subversion repository;\n\n\nSend email to Mat or Tim C\n\n\n\n\n\n\nUser certificate\n\n\nObtain a user certificate here: \nhttps://oim.opensciencegrid.org/oim/certificate\n\n\nImport the certificate into your browser of choice\n\n\n\n\n\n\nAccess to FermiCloud\n\n\nhttps://cdcvs.fnal.gov/redmine/projects/fcl/wiki\n\n\n\n\n\n\n\n\nRegister\n for a GGUS account with the following information:\n\n\n\n\nYour certificate's subject DN\n\n\nSelect \nnone\n from the \"Virtual Organization\" drop-down\n\n\nSelect \nyes\n for \"Do you want to have support access?\" and answer \"Why?\" with the following:\nYes, I need to comment on tickets as a member of the OSG Software & Release Team\n(https://www.opensciencegrid.org/technology/#the-team)\n\n\n\n\n\n\n\n\n\n\n\n\n\nJira ticket system\n\n\n\n\nSend email to \ngoc@opensciencegrid.org\n and request access to JIRA\n\n\n\n\n\n\nAccess to Koji\n\n\nFollow the instructions on the \nKoji User Management doc\n\n\n\n\n\n\nSign up for mailing lists\n\n\nosg-software@opensciencegrid.org\n\n\nosg-general@opensciencegrid.org\n\n\nosg-sites@opensciencegrid.org\n\n\nosg-commits@cs.wisc.edu\n\n\n\n\n\n\nGitHub team membership\n\n\nhttps://github.com/orgs/opensciencegrid/teams/software-and-release/members\n\n\n\n\n\n\nUNL repository access\n\n\nSend SSH public key to Tim T, Derek, or Brian L to gain access to the UNL repository (osgcollab@hcc-osg-software.unl.edu)\n\n\n\n\n\n\nIf > 50% S&R, add them to the \ntriage schedule",
            "title": "New Team Member"
        },
        {
            "location": "/software/new-team-member/#setup-instructions-for-new-team-members",
            "text": "Computing account at FNAL  To get this, follow the instructions at  https://fermi.service-now.com/kb_view.do?sysparm_article=KB0010797    ssh access to a UW CompSci account, including AFS access  Send email to Tim C with top 3 requested usernames    Read/write access to the UW Subversion repository;  Send email to Mat or Tim C    User certificate  Obtain a user certificate here:  https://oim.opensciencegrid.org/oim/certificate  Import the certificate into your browser of choice    Access to FermiCloud  https://cdcvs.fnal.gov/redmine/projects/fcl/wiki     Register  for a GGUS account with the following information:   Your certificate's subject DN  Select  none  from the \"Virtual Organization\" drop-down  Select  yes  for \"Do you want to have support access?\" and answer \"Why?\" with the following: Yes, I need to comment on tickets as a member of the OSG Software & Release Team\n(https://www.opensciencegrid.org/technology/#the-team)      Jira ticket system   Send email to  goc@opensciencegrid.org  and request access to JIRA    Access to Koji  Follow the instructions on the  Koji User Management doc    Sign up for mailing lists  osg-software@opensciencegrid.org  osg-general@opensciencegrid.org  osg-sites@opensciencegrid.org  osg-commits@cs.wisc.edu    GitHub team membership  https://github.com/orgs/opensciencegrid/teams/software-and-release/members    UNL repository access  Send SSH public key to Tim T, Derek, or Brian L to gain access to the UNL repository (osgcollab@hcc-osg-software.unl.edu)    If > 50% S&R, add them to the  triage schedule",
            "title": "Setup Instructions for New Team Members"
        },
        {
            "location": "/release/cut-sw-release/",
            "text": "Note\n\n\nIf you are performing a data release, please follow the instructions \nhere\n\n\n\n\nHow to Cut a Software Release\n\u00b6\n\n\nThis document details the process for releasing new OSG Release version(s).\nThis document does NOT discuss the policy for deciding what goes into a release, which can be found\n\nhere\n.\n\n\nDue to the length of time that this process takes, it is recommended to do the release over three or more days to allow for errors to be corrected and tests to be run.\n\n\nRequirements\n\u00b6\n\n\n\n\nUser certificate registered with OSG's koji with build and release team privileges\n\n\nAn account on UW CS machines (e.g. \nmoria\n) to access UW's AFS\n\n\nrelease-tools\n scripts in your \nPATH\n (\nGitHub\n)\n\n\nosg-build\n scripts in your \nPATH\n (installed via OSG yum repos or \nsource\n)\n\n\nAccess to the tarball repository at UNL (osgcollab@repo.opensciencegrid.org)\n\n\n\n\nPick the Version Number\n\u00b6\n\n\nThe rest of this document makes references to \n<VERSION(S)>\n and \n<NON-UPCOMING VERSIONS(S)>\n, which refer to a space-delimited list of OSG version(s) and that same list minus \nupcoming\n (e.g. \n3.3.28 3.4.3 upcoming\n and \n3.3.28 3.4.3\n). If you are unsure about either the version or revision, please consult the release manager.\n\n\nDay 0: Generate Preliminary Release List\n\u00b6\n\n\nThe release manager often needs a tentative list of packages to be released. This is done by finding the package differences between osg-testing and the current release.\n\n\nStep 1: Update the osg-version RPM (3.4 only)\n\u00b6\n\n\nFor each release (excluding upcoming), update the version number in the osg-version RPM's spec file and build it in koji:\n\n\n# If building for the latest release out of trunk\n\nosg-build koji osg-version\n\n# If building for an older release out of a branch:\n\n\nMAJOR_VERSION\n=\n<MAJOR VERSION>\nosg-build koji --repo\n=\n$MAJOR_VERSION\n osg-version\n\n\n\n\n\nWhere \n<MAJOR VERSION>\n is of the format \nx.y\n (e.g. \n3.2\n).\n\n\nStep 2: Promote osg-version (3.4 only) and generate the release list\n\u00b6\n\n\nRun \n0-generate-pkg-list\n from a machine that has your koji-registered user certificate:\n\n\nVERSIONS\n=\n\"<VERSION(S)>\"\n\n\n\n\n\n\ngit clone https://github.com/opensciencegrid/release-tools.git\n\ncd\n release-tools\n\n0\n-generate-pkg-list \n$VERSIONS\n\n\n\n\n\n\nDay 1: Verify Pre-Release and Generate Tarballs\n\u00b6\n\n\nThis section is to be performed 1-2 days before the release (as designated by the release manager) to perform last checks of the release and create the client tarballs.\n\n\nStep 1: Verify Pre-Release\n\u00b6\n\n\nCompare the list of packages already in pre-release to the final list for the release put together by the OSG Release Coordinator (who should have updated \nrelease-list\n in git). To do this, run the \n1-verify-prerelease\n script from git:\n\n\nVERSIONS\n=\n\"<VERSION(S)>\"\n\n\n\n\n\n\n1\n-verify-prerelease \n$VERSIONS\n\n\n\n\n\n\nIf there are any discrepancies, consult the release manager. You may have to tag or untag packages with the \nosg-koji\n tool.\n\n\n\n\nNote\n\n\nVerify that if there is a new version of the \nosg-tested-internal\n RPM, then it is included in the release as well!\nFor 3.4 releases, also verify that the \nosg-version\n RPM is in your set of packages for the release!\n\n\n\n\nStep 2: Test Pre-Release in VM Universe\n\u00b6\n\n\nTo test pre-release, you will be kicking off a manual VM universe test run from \nosghost.chtc.wisc.edu\n.\n\n\n\n\nEnsure that you meet the \npre-requisites\n for submitting VM universe test runs\n\n\n\n\nPrepare the test suite by running:\n\n\nosg-run-tests -P 'Testing OSG pre-release'\n\n\n\n\n\n\n\n\n\ncd\n into the directory specified in the output of the previous command\n\n\n\n\nSubmit the DAG:\ncondor_submit_dag master-run.dag\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nIf there are failures, consult the release-manager before proceeding.\n\n\n\n\nStep 3: Test Pre-Release on the Madison ITB site\n\u00b6\n\n\nTest the pre-release on the Madison ITB by following the \nITB pre-release testing instructions\n.\nIf you not local to Madison, consult the release manager for the designated person to do this testing.\n\n\nStep 4: Regenerate the build repositories\n\u00b6\n\n\nTo avoid 404 errors when retrieving packages, it's necessary to regenerate the build repositories. Run the following script from a machine with your koji-registered user certificate:\n\n\nNON_UPCOMING_VERSIONS\n=\n\"<NON-UPCOMING VERSION(S)>\"\n\n\n\n\n\n\n1\n-regen-repos \n$NON_UPCOMING_VERSIONS\n\n\n\n\n\n\nStep 5: Create the client tarballs\n\u00b6\n\n\nCreate the client tarballs as root on an EL7 fermicloud machine using the relevant script from git:\n\n\nNON_UPCOMING_VERSIONS\n=\n\"<NON-UPCOMING VERSION(S)>\"\n\n\n\n\n\n\ngit clone https://github.com/opensciencegrid/release-tools.git\n\ncd\n release-tools\n./1-client-tarballs \n$NON_UPCOMING_VERSIONS\n\n\n\n\n\n\nStep 6: Briefly test the client tarballs\n\u00b6\n\n\nAs an \nunprivileged user\n, extract each tarball into a separate directory. Make sure osg-post-install works. Make sure \nosgrun osg-version\n works by running the following tests, replacing \n<NON-UPCOMING VERSION(S)\n with the appropriate version numbers:\n\n\nNON_UPCOMING_VERSIONS\n=\n\"<NON-UPCOMING VERSION(S)>\"\n\n\n\n\n\n\n./1-verify-tarballs \n$NON_UPCOMING_VERSIONS\n\n\n\n\n\n\nIf you have time, try some of the binaries, such as grid-proxy-init.\n\n\n\n\nTodo\n\n\nWe need to automate this and have it run on the proper architectures and version of RHEL.\n\n\n\n\nStep 7: Update the UW AFS installation of the tarball client\n\u00b6\n\n\nThe UW keeps an install of the tarball client in \n/p/vdt/workspace/tarball-client\n on the UW's AFS. To update it, run the following commands:\n\n\nNON_UPCOMING_VERSIONS\n=\n\"<NON-UPCOMING VERSION(S)>\"\n\n\n\n\n\n\nfor\n ver in \n$NON_UPCOMING_VERSIONS\n;\n \ndo\n\n    /p/vdt/workspace/tarball-client/afs-install-tarball-client \n$ver\n\n\ndone\n\n\n\n\n\n\nStep 8: Wait\n\u00b6\n\n\nWait for clearance. The OSG Release Coordinator (in consultation with the Software Team and any testers) need to sign off on the update before it is released. If you are releasing things over two days, this is a good place to stop for the day.\n\n\nDay 2: Pushing the Release\n\u00b6\n\n\nStep 1: Push from pre-release to release\n\u00b6\n\n\nThis script moves the packages into release, clones releases into new version-specific release repos,\nlocks the repos and regenerates them.\n\n\nVERSIONS\n=\n\"<VERSION(S)>\"\n\n\n\n\n\n\n2\n-push-release \n$VERSIONS\n\n\n\n\n\n\nStep 2: Generate the release notes\n\u00b6\n\n\nThis script generates the release notes and updates the release information in AFS.\n\n\nVERSIONS\n=\n\"<VERSION(S)>\"\n\n\n\n\n\n\n2\n-make-notes \n$VERSIONS\n\n\n\n\n\n\n\n\n*.txt\n files are created and it should be verified that they've been moved to /p/vdt/public/html/release-info/ on UW's AFS.\n\n\nFor each release version, use the \n*release-note*\n files to update the relevant sections of the release note pages.\n\n\n\n\nStep 3: Upload the client tarballs\n\u00b6\n\n\nUpload the tarballs to the repository with the following procedure from a UW CS machine (e.g., \ningwe\n):\n\n\nNON_UPCOMING_VERSIONS\n=\n\"<NON-UPCOMING VERSION(S)>\"\n\n\n\n\n\n\n./2-upload-tarballs \n$NON_UPCOMING_VERSIONS\n\n\n\n\n\n\nStep 4: Install the tarballs into OASIS\n\u00b6\n\n\n\n\nNote\n\n\nYou must be an OASIS manager of the \nmis\n VO to do these steps. Known managers as of 2014-07-22: Mat, Tim C, Tim T, Brian L. \n\n\n\n\nGet the uploader script from Git and run it with \nosgrun\n from the UW AFS install of the tarball client you made earlier. On a UW CSL machine:\n\n\nNON_UPCOMING_VERSIONS\n=\n\"<NON-UPCOMING VERSION(S)>\"\n\n\n\n\n\n\ncd\n /tmp\ngit clone --depth \n1\n file:///p/vdt/workspace/git/repo/tarball-client.git\n\nfor\n ver in \n$NON_UPCOMING_VERSIONS\n;\n \ndo\n\n    /p/vdt/workspace/tarball-client/current/sys/osgrun bash -x /tmp/tarball-client/upload-tarballs-to-oasis \n$ver\n\n\ndone\n\n\n\n\n\n\nThe script will automatically ssh you to oasis-login.opensciencegrid.org and give you instructions to complete the process.\n\n\nStep 5: Remove old UW AFS installations of the tarball client\n\u00b6\n\n\nTo keep space usage down, remove tarball client installations and symlinks under \n/p/vdt/workspace/tarball-client\n on UW's AFS that are more than 2 months old.\nTo remove them, first check the list:\n\n\nfind /p/vdt/workspace/tarball-client -maxdepth \n1\n -mtime +60 -name \n3\n\\*\n -ls\n\n\n\n\n\nThen if the output looks reasonable\n(contains at least one installation, but does not contain recent installations),\nremove them:\n\n\nfind /p/vdt/workspace/tarball-client -maxdepth \n1\n -mtime +60 -name \n3\n\\*\n -exec rm -rf \n{}\n +\n\n\n\n\n\nStep 6: Update the Docker WN client\n\u00b6\n\n\nUpdate the GitHub repo at \nopensciencegrid/docker-osg-wn\n using the \nupdate-all\n script found in \nopensciencegrid/docker-osg-wn-scripts\n. This requires push access to the \nopensciencegrid/docker-osg-wn\n repo.\n\n\nInstructions for using the script:\n\n\ngit clone git@github.com:opensciencegrid/docker-osg-wn-scripts.git\ngit clone git@github.com:opensciencegrid/docker-osg-wn.git\ndocker-osg-wn-scripts/update-all docker-osg-wn\n\ncd\n docker-osg-wn\n\n# Verify everything looks fine and run the 'git push' command\n\n\n# that 'update-all' should have printed\n\n\n\n\n\n\nStep 7: Merge any pending documentation\n\u00b6\n\n\nFor each documentation ticket in this release, merge the pull requests mentioned in the description or comments.\n\n\nStep 8: Announce the release\n\u00b6\n\n\nThe following instructions are meant for the release manager (or interim release manager). If you are not the release manager, let the release manager know that they can announce the release.\n\n\n\n\n\n\nThe release manager writes the a release announcement for each version and sends it out.\n    The announcement should mention a handful of the most important updates.\n    Due to downstream formatting issues, each major change should end at column 76 or earlier.\n    Here is a sample, replace \n<BRACKETED TEXT>\n with the appropriate values:\n\n\nSubject: Announcing OSG Software version <VERSION>\n\nWe are pleased to announce OSG Software version <VERSION>!\n\nChanges to OSG <VERSION> include:\n- Major Change 1\n- Major Change 2\n- Major Change 3\n\nRelease notes and pointers to more documentation can be found at:\n\nhttp://www.opensciencegrid.org/docs/release/<SERIES.VERSION>/release-<RELEASE-VERSION>/\n\nNeed help? Let us know:\n\nhttp://www.opensciencegrid.org/docs/common/help/\n\nWe welcome feedback on this release!\n\n\n\n\n\n\n\n\n\nThe release manager uses the \nosg-notify tool\n\n    on \nsubmit-1.chtc.wisc.edu\n to send the release announcement using the following command:\n\n\n$\n \ncd\n topology\n\n$\n git pull\n\n$\n python bin/osg-notify --cert your-cert.pem --key your-key.pem \n\\\n\n    --no-sign --type production --message message-file \n\\\n\n    --subject \n'<EMAIL SUBJECT>'\n \n\\\n\n    --recipients \n\"osg-general@opensciencegrid.org osg-operations@opensciencegrid.org osg-sites@opensciencegrid.org vdt-discuss@opensciencegrid.org\"\n \n\\\n\n    --oim-recipients resources --oim-contact-type administrative\n\n\n\n\n\nReplace \n<EMAIL SUBJECT>\n with an appropriate subject for your announcement.\n\n\n\n\n\n\nThe release manager closes the tickets marked 'Ready for Release' in the release's JIRA filter using the 'bulk change' function.\n    Also set the Fix Versions field to the appropriate value(s) and uncheck the box that reads \"Send mail for this update\"\n\n\n\n\n\n\nDay 3: Update the ITB\n\u00b6\n\n\nNow that the release has had a chance to propagate to all the mirrors, update the Madison ITB site by following\nthe \nyum update section\n of the Madison ITB document.\nIf you are not local to Madison, consult the release manager for the designated person to do the update.\nRemember to stop the HTCondor and HTCondor-CE daemons according to the \nHTCondor pre-release testing instructions\n.\nThose daemons will need to be restarted after the upgrade.",
            "title": "How to Cut a Release"
        },
        {
            "location": "/release/cut-sw-release/#how-to-cut-a-software-release",
            "text": "This document details the process for releasing new OSG Release version(s).\nThis document does NOT discuss the policy for deciding what goes into a release, which can be found here .  Due to the length of time that this process takes, it is recommended to do the release over three or more days to allow for errors to be corrected and tests to be run.",
            "title": "How to Cut a Software Release"
        },
        {
            "location": "/release/cut-sw-release/#requirements",
            "text": "User certificate registered with OSG's koji with build and release team privileges  An account on UW CS machines (e.g.  moria ) to access UW's AFS  release-tools  scripts in your  PATH  ( GitHub )  osg-build  scripts in your  PATH  (installed via OSG yum repos or  source )  Access to the tarball repository at UNL (osgcollab@repo.opensciencegrid.org)",
            "title": "Requirements"
        },
        {
            "location": "/release/cut-sw-release/#pick-the-version-number",
            "text": "The rest of this document makes references to  <VERSION(S)>  and  <NON-UPCOMING VERSIONS(S)> , which refer to a space-delimited list of OSG version(s) and that same list minus  upcoming  (e.g.  3.3.28 3.4.3 upcoming  and  3.3.28 3.4.3 ). If you are unsure about either the version or revision, please consult the release manager.",
            "title": "Pick the Version Number"
        },
        {
            "location": "/release/cut-sw-release/#day-0-generate-preliminary-release-list",
            "text": "The release manager often needs a tentative list of packages to be released. This is done by finding the package differences between osg-testing and the current release.",
            "title": "Day 0: Generate Preliminary Release List"
        },
        {
            "location": "/release/cut-sw-release/#step-1-update-the-osg-version-rpm-34-only",
            "text": "For each release (excluding upcoming), update the version number in the osg-version RPM's spec file and build it in koji:  # If building for the latest release out of trunk \nosg-build koji osg-version # If building for an older release out of a branch:  MAJOR_VERSION = <MAJOR VERSION>\nosg-build koji --repo = $MAJOR_VERSION  osg-version  Where  <MAJOR VERSION>  is of the format  x.y  (e.g.  3.2 ).",
            "title": "Step 1: Update the osg-version RPM (3.4 only)"
        },
        {
            "location": "/release/cut-sw-release/#step-2-promote-osg-version-34-only-and-generate-the-release-list",
            "text": "Run  0-generate-pkg-list  from a machine that has your koji-registered user certificate:  VERSIONS = \"<VERSION(S)>\"   git clone https://github.com/opensciencegrid/release-tools.git cd  release-tools 0 -generate-pkg-list  $VERSIONS",
            "title": "Step 2: Promote osg-version (3.4 only) and generate the release list"
        },
        {
            "location": "/release/cut-sw-release/#day-1-verify-pre-release-and-generate-tarballs",
            "text": "This section is to be performed 1-2 days before the release (as designated by the release manager) to perform last checks of the release and create the client tarballs.",
            "title": "Day 1: Verify Pre-Release and Generate Tarballs"
        },
        {
            "location": "/release/cut-sw-release/#step-1-verify-pre-release",
            "text": "Compare the list of packages already in pre-release to the final list for the release put together by the OSG Release Coordinator (who should have updated  release-list  in git). To do this, run the  1-verify-prerelease  script from git:  VERSIONS = \"<VERSION(S)>\"   1 -verify-prerelease  $VERSIONS   If there are any discrepancies, consult the release manager. You may have to tag or untag packages with the  osg-koji  tool.   Note  Verify that if there is a new version of the  osg-tested-internal  RPM, then it is included in the release as well!\nFor 3.4 releases, also verify that the  osg-version  RPM is in your set of packages for the release!",
            "title": "Step 1: Verify Pre-Release"
        },
        {
            "location": "/release/cut-sw-release/#step-2-test-pre-release-in-vm-universe",
            "text": "To test pre-release, you will be kicking off a manual VM universe test run from  osghost.chtc.wisc.edu .   Ensure that you meet the  pre-requisites  for submitting VM universe test runs   Prepare the test suite by running:  osg-run-tests -P 'Testing OSG pre-release'    cd  into the directory specified in the output of the previous command   Submit the DAG: condor_submit_dag master-run.dag     Note  If there are failures, consult the release-manager before proceeding.",
            "title": "Step 2: Test Pre-Release in VM Universe"
        },
        {
            "location": "/release/cut-sw-release/#step-3-test-pre-release-on-the-madison-itb-site",
            "text": "Test the pre-release on the Madison ITB by following the  ITB pre-release testing instructions .\nIf you not local to Madison, consult the release manager for the designated person to do this testing.",
            "title": "Step 3: Test Pre-Release on the Madison ITB site"
        },
        {
            "location": "/release/cut-sw-release/#step-4-regenerate-the-build-repositories",
            "text": "To avoid 404 errors when retrieving packages, it's necessary to regenerate the build repositories. Run the following script from a machine with your koji-registered user certificate:  NON_UPCOMING_VERSIONS = \"<NON-UPCOMING VERSION(S)>\"   1 -regen-repos  $NON_UPCOMING_VERSIONS",
            "title": "Step 4: Regenerate the build repositories"
        },
        {
            "location": "/release/cut-sw-release/#step-5-create-the-client-tarballs",
            "text": "Create the client tarballs as root on an EL7 fermicloud machine using the relevant script from git:  NON_UPCOMING_VERSIONS = \"<NON-UPCOMING VERSION(S)>\"   git clone https://github.com/opensciencegrid/release-tools.git cd  release-tools\n./1-client-tarballs  $NON_UPCOMING_VERSIONS",
            "title": "Step 5: Create the client tarballs"
        },
        {
            "location": "/release/cut-sw-release/#step-6-briefly-test-the-client-tarballs",
            "text": "As an  unprivileged user , extract each tarball into a separate directory. Make sure osg-post-install works. Make sure  osgrun osg-version  works by running the following tests, replacing  <NON-UPCOMING VERSION(S)  with the appropriate version numbers:  NON_UPCOMING_VERSIONS = \"<NON-UPCOMING VERSION(S)>\"   ./1-verify-tarballs  $NON_UPCOMING_VERSIONS   If you have time, try some of the binaries, such as grid-proxy-init.   Todo  We need to automate this and have it run on the proper architectures and version of RHEL.",
            "title": "Step 6: Briefly test the client tarballs"
        },
        {
            "location": "/release/cut-sw-release/#step-7-update-the-uw-afs-installation-of-the-tarball-client",
            "text": "The UW keeps an install of the tarball client in  /p/vdt/workspace/tarball-client  on the UW's AFS. To update it, run the following commands:  NON_UPCOMING_VERSIONS = \"<NON-UPCOMING VERSION(S)>\"   for  ver in  $NON_UPCOMING_VERSIONS ;   do \n    /p/vdt/workspace/tarball-client/afs-install-tarball-client  $ver  done",
            "title": "Step 7: Update the UW AFS installation of the tarball client"
        },
        {
            "location": "/release/cut-sw-release/#step-8-wait",
            "text": "Wait for clearance. The OSG Release Coordinator (in consultation with the Software Team and any testers) need to sign off on the update before it is released. If you are releasing things over two days, this is a good place to stop for the day.",
            "title": "Step 8: Wait"
        },
        {
            "location": "/release/cut-sw-release/#day-2-pushing-the-release",
            "text": "",
            "title": "Day 2: Pushing the Release"
        },
        {
            "location": "/release/cut-sw-release/#step-1-push-from-pre-release-to-release",
            "text": "This script moves the packages into release, clones releases into new version-specific release repos,\nlocks the repos and regenerates them.  VERSIONS = \"<VERSION(S)>\"   2 -push-release  $VERSIONS",
            "title": "Step 1: Push from pre-release to release"
        },
        {
            "location": "/release/cut-sw-release/#step-2-generate-the-release-notes",
            "text": "This script generates the release notes and updates the release information in AFS.  VERSIONS = \"<VERSION(S)>\"   2 -make-notes  $VERSIONS    *.txt  files are created and it should be verified that they've been moved to /p/vdt/public/html/release-info/ on UW's AFS.  For each release version, use the  *release-note*  files to update the relevant sections of the release note pages.",
            "title": "Step 2: Generate the release notes"
        },
        {
            "location": "/release/cut-sw-release/#step-3-upload-the-client-tarballs",
            "text": "Upload the tarballs to the repository with the following procedure from a UW CS machine (e.g.,  ingwe ):  NON_UPCOMING_VERSIONS = \"<NON-UPCOMING VERSION(S)>\"   ./2-upload-tarballs  $NON_UPCOMING_VERSIONS",
            "title": "Step 3: Upload the client tarballs"
        },
        {
            "location": "/release/cut-sw-release/#step-4-install-the-tarballs-into-oasis",
            "text": "Note  You must be an OASIS manager of the  mis  VO to do these steps. Known managers as of 2014-07-22: Mat, Tim C, Tim T, Brian L.    Get the uploader script from Git and run it with  osgrun  from the UW AFS install of the tarball client you made earlier. On a UW CSL machine:  NON_UPCOMING_VERSIONS = \"<NON-UPCOMING VERSION(S)>\"   cd  /tmp\ngit clone --depth  1  file:///p/vdt/workspace/git/repo/tarball-client.git for  ver in  $NON_UPCOMING_VERSIONS ;   do \n    /p/vdt/workspace/tarball-client/current/sys/osgrun bash -x /tmp/tarball-client/upload-tarballs-to-oasis  $ver  done   The script will automatically ssh you to oasis-login.opensciencegrid.org and give you instructions to complete the process.",
            "title": "Step 4: Install the tarballs into OASIS"
        },
        {
            "location": "/release/cut-sw-release/#step-5-remove-old-uw-afs-installations-of-the-tarball-client",
            "text": "To keep space usage down, remove tarball client installations and symlinks under  /p/vdt/workspace/tarball-client  on UW's AFS that are more than 2 months old.\nTo remove them, first check the list:  find /p/vdt/workspace/tarball-client -maxdepth  1  -mtime +60 -name  3 \\*  -ls  Then if the output looks reasonable\n(contains at least one installation, but does not contain recent installations),\nremove them:  find /p/vdt/workspace/tarball-client -maxdepth  1  -mtime +60 -name  3 \\*  -exec rm -rf  {}  +",
            "title": "Step 5: Remove old UW AFS installations of the tarball client"
        },
        {
            "location": "/release/cut-sw-release/#step-6-update-the-docker-wn-client",
            "text": "Update the GitHub repo at  opensciencegrid/docker-osg-wn  using the  update-all  script found in  opensciencegrid/docker-osg-wn-scripts . This requires push access to the  opensciencegrid/docker-osg-wn  repo.  Instructions for using the script:  git clone git@github.com:opensciencegrid/docker-osg-wn-scripts.git\ngit clone git@github.com:opensciencegrid/docker-osg-wn.git\ndocker-osg-wn-scripts/update-all docker-osg-wn cd  docker-osg-wn # Verify everything looks fine and run the 'git push' command  # that 'update-all' should have printed",
            "title": "Step 6: Update the Docker WN client"
        },
        {
            "location": "/release/cut-sw-release/#step-7-merge-any-pending-documentation",
            "text": "For each documentation ticket in this release, merge the pull requests mentioned in the description or comments.",
            "title": "Step 7: Merge any pending documentation"
        },
        {
            "location": "/release/cut-sw-release/#step-8-announce-the-release",
            "text": "The following instructions are meant for the release manager (or interim release manager). If you are not the release manager, let the release manager know that they can announce the release.    The release manager writes the a release announcement for each version and sends it out.\n    The announcement should mention a handful of the most important updates.\n    Due to downstream formatting issues, each major change should end at column 76 or earlier.\n    Here is a sample, replace  <BRACKETED TEXT>  with the appropriate values:  Subject: Announcing OSG Software version <VERSION>\n\nWe are pleased to announce OSG Software version <VERSION>!\n\nChanges to OSG <VERSION> include:\n- Major Change 1\n- Major Change 2\n- Major Change 3\n\nRelease notes and pointers to more documentation can be found at:\n\nhttp://www.opensciencegrid.org/docs/release/<SERIES.VERSION>/release-<RELEASE-VERSION>/\n\nNeed help? Let us know:\n\nhttp://www.opensciencegrid.org/docs/common/help/\n\nWe welcome feedback on this release!    The release manager uses the  osg-notify tool \n    on  submit-1.chtc.wisc.edu  to send the release announcement using the following command:  $   cd  topology $  git pull $  python bin/osg-notify --cert your-cert.pem --key your-key.pem  \\ \n    --no-sign --type production --message message-file  \\ \n    --subject  '<EMAIL SUBJECT>'   \\ \n    --recipients  \"osg-general@opensciencegrid.org osg-operations@opensciencegrid.org osg-sites@opensciencegrid.org vdt-discuss@opensciencegrid.org\"   \\ \n    --oim-recipients resources --oim-contact-type administrative  Replace  <EMAIL SUBJECT>  with an appropriate subject for your announcement.    The release manager closes the tickets marked 'Ready for Release' in the release's JIRA filter using the 'bulk change' function.\n    Also set the Fix Versions field to the appropriate value(s) and uncheck the box that reads \"Send mail for this update\"",
            "title": "Step 8: Announce the release"
        },
        {
            "location": "/release/cut-sw-release/#day-3-update-the-itb",
            "text": "Now that the release has had a chance to propagate to all the mirrors, update the Madison ITB site by following\nthe  yum update section  of the Madison ITB document.\nIf you are not local to Madison, consult the release manager for the designated person to do the update.\nRemember to stop the HTCondor and HTCondor-CE daemons according to the  HTCondor pre-release testing instructions .\nThose daemons will need to be restarted after the upgrade.",
            "title": "Day 3: Update the ITB"
        },
        {
            "location": "/release/cut-data-release/",
            "text": "Note\n\n\nIf you are performing a software release, please follow the instructions \nhere\n\n\n\n\nHow to Cut a Data Release\n\u00b6\n\n\nThis document details the process for releasing new OSG Data Release version(s).\nThis document does NOT discuss the policy for deciding what goes into a release, which can be found\n\nhere\n.\n\n\nDue to the length of time that this process takes, it is recommended to do the release over three or more days to allow for errors to be corrected and tests to be run.\n\n\nRequirements\n\u00b6\n\n\n\n\nUser certificate registered with OSG's koji with build and release team privileges\n\n\nAn account on UW CS machines (e.g. \nlibrary\n, \ningwe\n) to access UW's AFS\n\n\nrelease-tools\n scripts in your \nPATH\n (\nGitHub\n)\n\n\nosg-build\n scripts in your \nPATH\n (installed via OSG yum repos or \nsource\n)\n\n\n\n\nPick the Version and Revision Numbers\n\u00b6\n\n\nThe rest of this document makes references to \n<REVISION>\n and \n<VERSION(S)>\n , which refer to the space-delimited list of OSG version(s) and data revision, respectively (e.g. \n3.3.28 3.4.3\n and \n2\n, respectively). If you are unsure about either the version or revision, please consult the release manager.\n\n\nDay 0: Generate Preliminary Release List\n\u00b6\n\n\nThe release manager often needs a tentative list of packages to be released. This is done by finding the package differences between osg-testing and the current release. Run \n0-generate-pkg-list\n from a machine that has your koji-registered user certificate:\n\n\nVERSIONS\n=\n'<VERSION(S)>'\n\n\nREVISION\n=\n<REVISION>\n\n\n\n\n\ngit clone https://github.com/opensciencegrid/release-tools.git\n\ncd\n release-tools\n\n0\n-generate-pkg-list -d \n$REVISION\n \n$VERSIONS\n\n\n\n\n\n\nDay 1: Verify Pre-Release\n\u00b6\n\n\nThis section is to be performed 1-2 days before the release (as designated by the release manager) to perform last checks of the release.\n\n\nStep 1: Generate the release list\n\u00b6\n\n\nCompare the list of packages already in pre-release to the final list for the release put together by the OSG Release Coordinator (who should have updated \nrelease-list\n in git). To do this, run the \n1-verify-prerelease\n script from git:\n\n\nVERSIONS\n=\n'<VERSION(S)>'\n\n\nREVISION\n=\n<REVISION>\n\n\n\n\n\n1\n-verify-prerelease -d \n$REVISION\n \n$VERSIONS\n\n\n\n\n\n\nIf there are any discrepancies consult the release manager. You may have to tag packages with the \nosg-koji\n tool.\n\n\nStep 2: Test the Pre-Release on the Madison ITB site\n\u00b6\n\n\nTest the pre-release on the Madison ITB by following the \nITB pre-release testing instructions\n.\n\n\nDay 2: Pushing the Release\n\u00b6\n\n\nStep 1: Push from pre-release to release\n\u00b6\n\n\nThis script moves the packages into release, clones releases into new version-specific release repos,\nlocks the repos and regenerates them.\n\n\nVERSIONS\n=\n'VERSION(S)>'\n\n\nREVISION\n=\n<REVISION>\n\n\n\n\n\n2\n-push-release -d \n$REVISION\n \n$VERSIONS\n\n\n\n\n\n\nStep 2: Generate the release notes\n\u00b6\n\n\nThis script generates the release notes and updates the release information in AFS.\n\n\nVERSIONS\n=\n'VERSION(S)>'\n\n\nREVISION\n=\n<REVISION>\n\n\n\n\n\n2\n-make-notes -d \n$REVISION\n \n$VERSIONS\n\n\n\n\n\n\n\n\n*.txt\n files are created and it should be verified that they've been moved to /p/vdt/public/html/release-info/ on UW's AFS.\n\n\nFor each release version, use the \n*release-note*\n files to update the relevant sections of the release note pages.\n\n\n\n\nStep 3: Update the Docker WN client\n\u00b6\n\n\nUpdate the GitHub repo at \nopensciencegrid/docker-osg-wn\n using the \nupdate-all\n script found in \nopensciencegrid/docker-osg-wn-scripts\n. This requires push access to the \nopensciencegrid/docker-osg-wn\n repo.\n\n\nInstructions for using the script:\n\n\ngit clone git@github.com:opensciencegrid/docker-osg-wn-scripts.git\ngit clone git@github.com:opensciencegrid/docker-osg-wn.git\ndocker-osg-wn-scripts/update-all docker-osg-wn\n\ncd\n docker-osg-wn\n\n# Verify everything looks fine and run the 'git push' command\n\n\n# that 'update-all' should have printed\n\n\n\n\n\n\nStep 4: Verify the VO Package and/or CA certificates\n\u00b6\n\n\nWait for the \nCA certificates\n to be updated.\nIt may take a while for the updates to reach the mirror used to update the web site.\nThe repository is checked hourly for updated CA certificates.\nOnce the web page is updated, run the following command to update the VO Package and/or CA certificates in the tarball installations and\nverify that the version of the VO Package and/or CA certificates match the version that was promoted to release.\n\n\n/p/vdt/workspace/tarball-client/current/amd64_rhel6/osgrun osg-update-data\n/p/vdt/workspace/tarball-client/current/amd64_rhel7/osgrun osg-update-data\n\n\n\n\n\nStep 5: Announce the release\n\u00b6\n\n\nThe following instructions are meant for the release manager (or interim release manager). If you are not the release manager, let the release manager know that they can announce the release.\n\n\n\n\n\n\nThe release manager writes the a release announcement for each version and sends it out.\n    The announcement should mention a handful of the most important updates.\n    Due to downstream formatting issues, each major change should end at column 76 or earlier.\n    Here is a sample, replace \n<BRACKETED TEXT>\n with the appropriate values:\n    If you are only updating certificates or only updated the VO package, delete the corresponding text:\n\n\nSubject: Announcing OSG CA Certificate and VO Package Updates\nSubject: Announcing OSG CA Certificate Update\nSubject: Announcing VO Package Update\n\nWe are pleased to announce a data release for the OSG Software Stack.\nData releases do not contain any software changes.\n\nThis release contains updated CA Certificates based on IGTF <VERSION>:\n- <Change 1 from IGTF changelog>\n- <Change 2 from IGTF changelog>\n\nThis release contains VO Package v<VERSION>:\nThis release also contains VO Package v<VERSION>:\n- <Change 1 from VO changelog>\n- <Change 2 from VO changelog>\n\nRelease notes and pointers to more documentation can be found at:\n\nhttp://www.opensciencegrid.org/docs/release/<SERIES.VERSION>/release-<RELEASE-VERSION>/\n\nNeed help? Let us know:\n\nhttp://www.opensciencegrid.org/docs/common/help/\n\nWe welcome feedback on this release!\n\n\n\n\n\n\n\n\n\nThe release manager uses the \nosg-notify tool\n\n    on \nsubmit-1.chtc.wisc.edu\n to send the release announcement using the following command:\n\n\n$\n \ncd\n topology\n\n$\n git pull\n\n$\n python bin/osg-notify --cert your-cert.pem --key your-key.pem \n\\\n\n    --no-sign --type production --message message-file \n\\\n\n    --subject \n'<EMAIL SUBJECT>'\n \n\\\n\n    --recipients \n\"osg-general@opensciencegrid.org osg-operations@opensciencegrid.org osg-sites@opensciencegrid.org vdt-discuss@opensciencegrid.org\"\n \n\\\n\n    --oim-recipients resources --oim-contact-type administrative\n\n\n\n\n\nReplace \n<EMAIL SUBJECT>\n with an appropriate subject for your announcement.\n\n\n\n\n\n\nThe release manager closes the tickets marked 'Ready for Release' in the release's JIRA filter using the 'bulk change' function. Uncheck the box that reads \"Send mail for this update\"\n\n\n\n\n\n\nDay 3: Update the ITB\n\u00b6\n\n\nNow that the release has had a chance to propagate to all the mirrors, update the Madison ITB site by following\nthe \nyum update section\n of the Madison ITB document.",
            "title": "How to Cut a Data Release"
        },
        {
            "location": "/release/cut-data-release/#how-to-cut-a-data-release",
            "text": "This document details the process for releasing new OSG Data Release version(s).\nThis document does NOT discuss the policy for deciding what goes into a release, which can be found here .  Due to the length of time that this process takes, it is recommended to do the release over three or more days to allow for errors to be corrected and tests to be run.",
            "title": "How to Cut a Data Release"
        },
        {
            "location": "/release/cut-data-release/#requirements",
            "text": "User certificate registered with OSG's koji with build and release team privileges  An account on UW CS machines (e.g.  library ,  ingwe ) to access UW's AFS  release-tools  scripts in your  PATH  ( GitHub )  osg-build  scripts in your  PATH  (installed via OSG yum repos or  source )",
            "title": "Requirements"
        },
        {
            "location": "/release/cut-data-release/#pick-the-version-and-revision-numbers",
            "text": "The rest of this document makes references to  <REVISION>  and  <VERSION(S)>  , which refer to the space-delimited list of OSG version(s) and data revision, respectively (e.g.  3.3.28 3.4.3  and  2 , respectively). If you are unsure about either the version or revision, please consult the release manager.",
            "title": "Pick the Version and Revision Numbers"
        },
        {
            "location": "/release/cut-data-release/#day-0-generate-preliminary-release-list",
            "text": "The release manager often needs a tentative list of packages to be released. This is done by finding the package differences between osg-testing and the current release. Run  0-generate-pkg-list  from a machine that has your koji-registered user certificate:  VERSIONS = '<VERSION(S)>'  REVISION = <REVISION>  git clone https://github.com/opensciencegrid/release-tools.git cd  release-tools 0 -generate-pkg-list -d  $REVISION   $VERSIONS",
            "title": "Day 0: Generate Preliminary Release List"
        },
        {
            "location": "/release/cut-data-release/#day-1-verify-pre-release",
            "text": "This section is to be performed 1-2 days before the release (as designated by the release manager) to perform last checks of the release.",
            "title": "Day 1: Verify Pre-Release"
        },
        {
            "location": "/release/cut-data-release/#step-1-generate-the-release-list",
            "text": "Compare the list of packages already in pre-release to the final list for the release put together by the OSG Release Coordinator (who should have updated  release-list  in git). To do this, run the  1-verify-prerelease  script from git:  VERSIONS = '<VERSION(S)>'  REVISION = <REVISION>  1 -verify-prerelease -d  $REVISION   $VERSIONS   If there are any discrepancies consult the release manager. You may have to tag packages with the  osg-koji  tool.",
            "title": "Step 1: Generate the release list"
        },
        {
            "location": "/release/cut-data-release/#step-2-test-the-pre-release-on-the-madison-itb-site",
            "text": "Test the pre-release on the Madison ITB by following the  ITB pre-release testing instructions .",
            "title": "Step 2: Test the Pre-Release on the Madison ITB site"
        },
        {
            "location": "/release/cut-data-release/#day-2-pushing-the-release",
            "text": "",
            "title": "Day 2: Pushing the Release"
        },
        {
            "location": "/release/cut-data-release/#step-1-push-from-pre-release-to-release",
            "text": "This script moves the packages into release, clones releases into new version-specific release repos,\nlocks the repos and regenerates them.  VERSIONS = 'VERSION(S)>'  REVISION = <REVISION>  2 -push-release -d  $REVISION   $VERSIONS",
            "title": "Step 1: Push from pre-release to release"
        },
        {
            "location": "/release/cut-data-release/#step-2-generate-the-release-notes",
            "text": "This script generates the release notes and updates the release information in AFS.  VERSIONS = 'VERSION(S)>'  REVISION = <REVISION>  2 -make-notes -d  $REVISION   $VERSIONS    *.txt  files are created and it should be verified that they've been moved to /p/vdt/public/html/release-info/ on UW's AFS.  For each release version, use the  *release-note*  files to update the relevant sections of the release note pages.",
            "title": "Step 2: Generate the release notes"
        },
        {
            "location": "/release/cut-data-release/#step-3-update-the-docker-wn-client",
            "text": "Update the GitHub repo at  opensciencegrid/docker-osg-wn  using the  update-all  script found in  opensciencegrid/docker-osg-wn-scripts . This requires push access to the  opensciencegrid/docker-osg-wn  repo.  Instructions for using the script:  git clone git@github.com:opensciencegrid/docker-osg-wn-scripts.git\ngit clone git@github.com:opensciencegrid/docker-osg-wn.git\ndocker-osg-wn-scripts/update-all docker-osg-wn cd  docker-osg-wn # Verify everything looks fine and run the 'git push' command  # that 'update-all' should have printed",
            "title": "Step 3: Update the Docker WN client"
        },
        {
            "location": "/release/cut-data-release/#step-4-verify-the-vo-package-andor-ca-certificates",
            "text": "Wait for the  CA certificates  to be updated.\nIt may take a while for the updates to reach the mirror used to update the web site.\nThe repository is checked hourly for updated CA certificates.\nOnce the web page is updated, run the following command to update the VO Package and/or CA certificates in the tarball installations and\nverify that the version of the VO Package and/or CA certificates match the version that was promoted to release.  /p/vdt/workspace/tarball-client/current/amd64_rhel6/osgrun osg-update-data\n/p/vdt/workspace/tarball-client/current/amd64_rhel7/osgrun osg-update-data",
            "title": "Step 4: Verify the VO Package and/or CA certificates"
        },
        {
            "location": "/release/cut-data-release/#step-5-announce-the-release",
            "text": "The following instructions are meant for the release manager (or interim release manager). If you are not the release manager, let the release manager know that they can announce the release.    The release manager writes the a release announcement for each version and sends it out.\n    The announcement should mention a handful of the most important updates.\n    Due to downstream formatting issues, each major change should end at column 76 or earlier.\n    Here is a sample, replace  <BRACKETED TEXT>  with the appropriate values:\n    If you are only updating certificates or only updated the VO package, delete the corresponding text:  Subject: Announcing OSG CA Certificate and VO Package Updates\nSubject: Announcing OSG CA Certificate Update\nSubject: Announcing VO Package Update\n\nWe are pleased to announce a data release for the OSG Software Stack.\nData releases do not contain any software changes.\n\nThis release contains updated CA Certificates based on IGTF <VERSION>:\n- <Change 1 from IGTF changelog>\n- <Change 2 from IGTF changelog>\n\nThis release contains VO Package v<VERSION>:\nThis release also contains VO Package v<VERSION>:\n- <Change 1 from VO changelog>\n- <Change 2 from VO changelog>\n\nRelease notes and pointers to more documentation can be found at:\n\nhttp://www.opensciencegrid.org/docs/release/<SERIES.VERSION>/release-<RELEASE-VERSION>/\n\nNeed help? Let us know:\n\nhttp://www.opensciencegrid.org/docs/common/help/\n\nWe welcome feedback on this release!    The release manager uses the  osg-notify tool \n    on  submit-1.chtc.wisc.edu  to send the release announcement using the following command:  $   cd  topology $  git pull $  python bin/osg-notify --cert your-cert.pem --key your-key.pem  \\ \n    --no-sign --type production --message message-file  \\ \n    --subject  '<EMAIL SUBJECT>'   \\ \n    --recipients  \"osg-general@opensciencegrid.org osg-operations@opensciencegrid.org osg-sites@opensciencegrid.org vdt-discuss@opensciencegrid.org\"   \\ \n    --oim-recipients resources --oim-contact-type administrative  Replace  <EMAIL SUBJECT>  with an appropriate subject for your announcement.    The release manager closes the tickets marked 'Ready for Release' in the release's JIRA filter using the 'bulk change' function. Uncheck the box that reads \"Send mail for this update\"",
            "title": "Step 5: Announce the release"
        },
        {
            "location": "/release/cut-data-release/#day-3-update-the-itb",
            "text": "Now that the release has had a chance to propagate to all the mirrors, update the Madison ITB site by following\nthe  yum update section  of the Madison ITB document.",
            "title": "Day 3: Update the ITB"
        },
        {
            "location": "/release/new-release-series/",
            "text": "How to Prepare a New Release Series\n\u00b6\n\n\nThroughout this document, we will refer to the new release series as \n3.X\n, and the previous release series as \n3.OLD\n.\nFor example, if we are creating OSG 3.6, then \n3.X\n refers to \n3.6\n, and \n3.OLD\n refers to \n3.5\n.\n\n\nDo first, anytime before the month of the release\n\u00b6\n\n\n\n\n\n\nAdd 3.X koji tags and targets\n\n\n\n\n\n\nModify this script as appropriate and run:\n    \nhttps://github.com/opensciencegrid/osg-next-tools/blob/master/koji/create-new-koji-osg3X-tags-etc\n\n\nIn particular, update \nSERIES\n as appropriate, and include any applicable enterprise linux versions to the\n\nEL\n loop (eg, \nel7 el8\n)\n    -   Note that, at first, upcoming-build will continue to inherit from 3.OLD-devel\n\n\n\n\n\n\n\n\n\n\nAdd Koji package signing\n\n\n\n\nOn koji.chtc.wisc.edu, \n/etc/koji-hub/plugins/sign.conf\n; copy all the \n[osg-3.OLD-*]\n entries to new entries,\n    renaming the \n3.OLD\n parts in the new enties to \n3.X\n.\n\n\nEnsure the permissions for \n/etc/koji-hub/plugins/sign.conf\n are 0600 apache:apache\n\n\nSave the result with \netckeeper commit\n\n\n\n\n\n\n\n\nUpdate \nosg-build\n to use the new koji tags and targets (not by default of course)\n\n\n\n\nSee the \nGit commits\n on opensciencegrid/osg-build for SOFTWARE-2693 for details on how to do this\n\n\nYou will be using this version of \nosg-build\n for some tasks, even if it hasn't been released\n\n\n\n\n\n\n\n\nDo afterward, anytime before the month of the release\n\u00b6\n\n\n\n\n\n\nCreate a blank \nosg-3.X\n SVN branch and add \nbuildsys-macros\n package\n\n\n\n\n\n\nsvn copy \nbuildsys-macros\n from trunk and hand-edit it to hardcode the new \nosg_version\n and \ndver\n values\n\n\nDo the following steps for all EL versions relevant to the new series; e.g., for EL 7:\n\n\n\n\nEdit the spec file and set \ndver\n to \n7\n, and \nosg_version\n to \n3.X\n\n\nRun the following commands (adjust the NVR as necessary):\n$\n osg-build rpmbuild --el7\n\n$\n osg-koji import _build_results/buildsys-macros-*.el7.src.rpm\n\n$\n osg-koji import _build_results/buildsys-macros-*.el7.noarch.rpm\n\n$\n \npkg\n=\n$(\nbasename _build_results/buildsys-macros-*.el7.src.rpm\n)\n\n\n$\n \npkg\n=\n${\npkg\n%.src.rpm\n}\n\n\n$\n osg-koji tag-pkg osg-3.X-el7-development \n\"\n$pkg\n\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo a 'real' build of \nbuildsys-macros\n\n\n\n\nBump the revision in the \nbuildsys-macros\n spec file and edit the \n%changelog\n.\n    \nAgain, you will need a version of osg-build with 3.X support.\n\n\n\n\nDo the following steps for all EL versions relevant to the new series; e.g., for EL 7:\n\n\n\n\nSet \ndver\n to 7. Commit\n$\n osg-build koji --repo\n=\n3\n.X --el7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUpdate \ntarball-client\n scripts\n\n\n\n\nbundles.ini\n\n\npatches/\n\n\nupload-tarballs-to-oasis\n (for 3.X, \nforeach_dver_arch\n will need to be updated for the new set of 3.X \ndver_arches\n)\n\n\n\n\n\n\n\n\nPopulate the \nbootstrap\n tags\n\n\nNeed to have them inherit from the 3.OLD development tags, but only packages, not builds (hence the \n--noconfig\n; yes, the name is weird)\n\n\n#\n \nset\n \n3\n.OLD and \n3\n.X as appropriate, specify any relevant dvers \nfor\n el\n\n\n$\n \nfor\n el in el7\n;\n \ndo\n \n\\\n\n    \nfor\n repo in \n3\n.OLD upcoming\n;\n \ndo\n \n\\\n\n        osg-koji add-tag-inheritance --noconfig --priority\n=\n2\n \n\\\n\n            osg-3.X-\n$el\n-bootstrap osg-\n$repo\n-\n$el\n-development\n;\n \n\\\n\n    \ndone\n;\n \n\\\n\n\ndone\n\n\n\n\n\n\n\n\n\n\nGet the actual NVRs to tag\n\n\n\n\nI put Brian's spreadsheet into Excel and used its filtering feature to separate out:\n\n\nthe packages going into 3.X.0\n\n\npackage differences between each dver (eg, el7 vs el8)\n\n\n\n\n\n\nsave the NVRs for each dver to a separate file, eg, pkgtotag-el7.txt and pkgtotag-el8.txt\n\n\n\n\nTagging:\n\n\n#\n \nset\n \n3\n.X as appropriate, specify any relevant dvers \nfor\n el\n\n\n$\n \nfor\n el in el7 el8\n;\n \ndo\n \n\\\n\n    xargs -a pkgtotag-\n$el\n osg-koji tag-pkg osg-3.X-\n$el\n-bootstrap\n;\n \n\\\n\n\ndone\n\n\n\n\n\n\n(btw, xargs -a doesn't work on a Mac)\n\n\n\n\n\n\n\n\n\n\nIn order to make testing easier, build the new \nosg-release\n and \nosg-release-itb\n packages and promote them all\n    the way to release, so that all the 3.X repos exist and have at least one rpm in them.\n\n\n\n\n\n\nDo on the month of the 3.X.0 release\n\u00b6\n\n\n\n\nPopulate SVN branch and tags (as in fill it with the packages we're going to release for 3.X)\n\n\nMass rebuild\n\n\nDon't forget to update the \nempty\n and \ncontrib\n tags with the appropriate packages;\n    \nremove the \nempty*\n packages from the development tags after they've been tagged into the \nempty\n tags\n\n\n\n\n\n\nUpdate mash\n\n\nOn repo-itb\n\n\nOn repo\n\n\n\n\n\n\nUpdate documentation \nhere\n\n\nUpdate osg-test / vmu-test-runs\n\n\nThey're only going to test from minefield (and eventurally testing) until the release\n\n\n\n\n\n\nDrop the \nosg-3.X-elY-bootstrap\n koji tags (after the successful mass rebuild only)\n\n\nUpdate \ndocker-software-base\n\n  and any container images that are based on it\n\n\n\n\nDo immediately after the 3.X.0 release\n\u00b6\n\n\n\n\nUpdate tag inheritance on the \nupcoming-build\n tags to inherit from \n3.X-devel\n instead of \n3.OLD-devel\n\n\n\n\nDo sometime after the 3.X.0 release\n\u00b6\n\n\n\n\nDo these three at the same time:\n\n\nMove the SVN \ntrunk\n to \nbranches/osg-3.OLD\n and move \nbranches/osg-3.X\n to \ntrunk\n\n\nUpdate the koji \nosg-elY\n build targets to build from and to \n3.X\n instead of \n3.OLD\n\n\nNotify the software list of this change\n\n\n\n\n\n\nUpdate osg-test / vmu-test-runs again to add release and release -> testing tests\n\n\n\n\nUpdate the docker-osg-wn-client scripts to build from \n3.X\n (need direct push access)\n\n\n\n\nUpdate the constants in the \ngenbranches\n script in the \ndocker-osg-wn-scripts\n repo\n\n\n\n\nUpdate the branches in \ndocker-osg-wn-client\n; a script like this ought to work:\n\n\ngit clone git@github.com:opensciencegrid/docker-osg-wn-scripts.git\ngit clone git@github.com:opensciencegrid/docker-osg-wn.git\n\ncd\n docker-osg-wn-scripts\n./genbranches\n\ncd\n ../docker-osg-wn\n\nfor\n bpath in ../docker-osg-wn-scripts/branches/*\n;\n \ndo\n\n    \nb\n=\n${\nbpath\n##*/\n}\n\n    git checkout -b \n$b\n master \n&&\n \n\\\n\n        mv \n$bpath\n Dockerfile.in \n&&\n \n\\\n\n        git add Dockerfile.in \n&&\n \n\\\n\n        git commit -m \n\"Add branch \n$b\n\"\n\n\ndone\n\n\n\n\n\n\nand then run a similar script to update the existing branches\nCheck the results before pushing, and then run \ngit push --all\n\n\n\n\n\n\nUpdate the arrays in \nupdate-all\n and \nosg-wn-nightly-build\n in \ndocker-osg-wn-scripts\n\n\n\n\n\n\n\n\n\n\nUpdate the default promotion route aliases in \nosg-promote\n\n\n\n\n\n\nUpdate \ndocumentation\n again to reflect that \n3.X\n is now the \nmain\n branch and\n    \n3.OLD\n is the \nmaintenance\n branch\n\n\n\n\n\n\nNotes on lessons learned\n\u00b6\n\n\nSince the \nupcoming\n repos are not tied to an upcoming relative to \n3.OLD\n or \n3.X\n, the meaning of the \nupcoming\n repo\nchanges when the new OSG series is released.\nUsers which have the \nupcoming\n repo enabled before the cutover to \n3.X\n will find that a yum update will pull down\npackages relative to the \nnew\n \nupcoming\n, relative to \n3.X\n, instead of the old upcoming, which was relative to\n\n3.OLD\n.\n\n\nThis may catch them by surprise, as it happens whether or not they update their \nosg-release\n package to the new \n3.X\n\nversion.\n\n\nIf it is not their intention to update to packages in the \nnew\n \nupcoming\n, users should disable their \nupcoming\n yum\nrepo by the time of the new OSG series cutover, and the continuation of their old \nupcoming\n packages will effectively\nbe the main \nosg\n repo for the new \n3.X\n series, after they have updated their \nosg-release\n package (usually by\ninstalling \nosg-3.X-elY-release-latest.rpm\n).",
            "title": "New Release Series"
        },
        {
            "location": "/release/new-release-series/#how-to-prepare-a-new-release-series",
            "text": "Throughout this document, we will refer to the new release series as  3.X , and the previous release series as  3.OLD .\nFor example, if we are creating OSG 3.6, then  3.X  refers to  3.6 , and  3.OLD  refers to  3.5 .",
            "title": "How to Prepare a New Release Series"
        },
        {
            "location": "/release/new-release-series/#do-first-anytime-before-the-month-of-the-release",
            "text": "Add 3.X koji tags and targets    Modify this script as appropriate and run:\n     https://github.com/opensciencegrid/osg-next-tools/blob/master/koji/create-new-koji-osg3X-tags-etc  In particular, update  SERIES  as appropriate, and include any applicable enterprise linux versions to the EL  loop (eg,  el7 el8 )\n    -   Note that, at first, upcoming-build will continue to inherit from 3.OLD-devel      Add Koji package signing   On koji.chtc.wisc.edu,  /etc/koji-hub/plugins/sign.conf ; copy all the  [osg-3.OLD-*]  entries to new entries,\n    renaming the  3.OLD  parts in the new enties to  3.X .  Ensure the permissions for  /etc/koji-hub/plugins/sign.conf  are 0600 apache:apache  Save the result with  etckeeper commit     Update  osg-build  to use the new koji tags and targets (not by default of course)   See the  Git commits  on opensciencegrid/osg-build for SOFTWARE-2693 for details on how to do this  You will be using this version of  osg-build  for some tasks, even if it hasn't been released",
            "title": "Do first, anytime before the month of the release"
        },
        {
            "location": "/release/new-release-series/#do-afterward-anytime-before-the-month-of-the-release",
            "text": "Create a blank  osg-3.X  SVN branch and add  buildsys-macros  package    svn copy  buildsys-macros  from trunk and hand-edit it to hardcode the new  osg_version  and  dver  values  Do the following steps for all EL versions relevant to the new series; e.g., for EL 7:   Edit the spec file and set  dver  to  7 , and  osg_version  to  3.X  Run the following commands (adjust the NVR as necessary): $  osg-build rpmbuild --el7 $  osg-koji import _build_results/buildsys-macros-*.el7.src.rpm $  osg-koji import _build_results/buildsys-macros-*.el7.noarch.rpm $   pkg = $( basename _build_results/buildsys-macros-*.el7.src.rpm )  $   pkg = ${ pkg %.src.rpm }  $  osg-koji tag-pkg osg-3.X-el7-development  \" $pkg \"       Do a 'real' build of  buildsys-macros   Bump the revision in the  buildsys-macros  spec file and edit the  %changelog .\n     Again, you will need a version of osg-build with 3.X support.   Do the following steps for all EL versions relevant to the new series; e.g., for EL 7:   Set  dver  to 7. Commit $  osg-build koji --repo = 3 .X --el7        Update  tarball-client  scripts   bundles.ini  patches/  upload-tarballs-to-oasis  (for 3.X,  foreach_dver_arch  will need to be updated for the new set of 3.X  dver_arches )     Populate the  bootstrap  tags  Need to have them inherit from the 3.OLD development tags, but only packages, not builds (hence the  --noconfig ; yes, the name is weird)  #   set   3 .OLD and  3 .X as appropriate, specify any relevant dvers  for  el $   for  el in el7 ;   do   \\ \n     for  repo in  3 .OLD upcoming ;   do   \\ \n        osg-koji add-tag-inheritance --noconfig --priority = 2   \\ \n            osg-3.X- $el -bootstrap osg- $repo - $el -development ;   \\ \n     done ;   \\  done     Get the actual NVRs to tag   I put Brian's spreadsheet into Excel and used its filtering feature to separate out:  the packages going into 3.X.0  package differences between each dver (eg, el7 vs el8)    save the NVRs for each dver to a separate file, eg, pkgtotag-el7.txt and pkgtotag-el8.txt   Tagging:  #   set   3 .X as appropriate, specify any relevant dvers  for  el $   for  el in el7 el8 ;   do   \\ \n    xargs -a pkgtotag- $el  osg-koji tag-pkg osg-3.X- $el -bootstrap ;   \\  done   (btw, xargs -a doesn't work on a Mac)      In order to make testing easier, build the new  osg-release  and  osg-release-itb  packages and promote them all\n    the way to release, so that all the 3.X repos exist and have at least one rpm in them.",
            "title": "Do afterward, anytime before the month of the release"
        },
        {
            "location": "/release/new-release-series/#do-on-the-month-of-the-3x0-release",
            "text": "Populate SVN branch and tags (as in fill it with the packages we're going to release for 3.X)  Mass rebuild  Don't forget to update the  empty  and  contrib  tags with the appropriate packages;\n     remove the  empty*  packages from the development tags after they've been tagged into the  empty  tags    Update mash  On repo-itb  On repo    Update documentation  here  Update osg-test / vmu-test-runs  They're only going to test from minefield (and eventurally testing) until the release    Drop the  osg-3.X-elY-bootstrap  koji tags (after the successful mass rebuild only)  Update  docker-software-base \n  and any container images that are based on it",
            "title": "Do on the month of the 3.X.0 release"
        },
        {
            "location": "/release/new-release-series/#do-immediately-after-the-3x0-release",
            "text": "Update tag inheritance on the  upcoming-build  tags to inherit from  3.X-devel  instead of  3.OLD-devel",
            "title": "Do immediately after the 3.X.0 release"
        },
        {
            "location": "/release/new-release-series/#do-sometime-after-the-3x0-release",
            "text": "Do these three at the same time:  Move the SVN  trunk  to  branches/osg-3.OLD  and move  branches/osg-3.X  to  trunk  Update the koji  osg-elY  build targets to build from and to  3.X  instead of  3.OLD  Notify the software list of this change    Update osg-test / vmu-test-runs again to add release and release -> testing tests   Update the docker-osg-wn-client scripts to build from  3.X  (need direct push access)   Update the constants in the  genbranches  script in the  docker-osg-wn-scripts  repo   Update the branches in  docker-osg-wn-client ; a script like this ought to work:  git clone git@github.com:opensciencegrid/docker-osg-wn-scripts.git\ngit clone git@github.com:opensciencegrid/docker-osg-wn.git cd  docker-osg-wn-scripts\n./genbranches cd  ../docker-osg-wn for  bpath in ../docker-osg-wn-scripts/branches/* ;   do \n     b = ${ bpath ##*/ } \n    git checkout -b  $b  master  &&   \\ \n        mv  $bpath  Dockerfile.in  &&   \\ \n        git add Dockerfile.in  &&   \\ \n        git commit -m  \"Add branch  $b \"  done   and then run a similar script to update the existing branches\nCheck the results before pushing, and then run  git push --all    Update the arrays in  update-all  and  osg-wn-nightly-build  in  docker-osg-wn-scripts      Update the default promotion route aliases in  osg-promote    Update  documentation  again to reflect that  3.X  is now the  main  branch and\n     3.OLD  is the  maintenance  branch",
            "title": "Do sometime after the 3.X.0 release"
        },
        {
            "location": "/release/new-release-series/#notes-on-lessons-learned",
            "text": "Since the  upcoming  repos are not tied to an upcoming relative to  3.OLD  or  3.X , the meaning of the  upcoming  repo\nchanges when the new OSG series is released.\nUsers which have the  upcoming  repo enabled before the cutover to  3.X  will find that a yum update will pull down\npackages relative to the  new   upcoming , relative to  3.X , instead of the old upcoming, which was relative to 3.OLD .  This may catch them by surprise, as it happens whether or not they update their  osg-release  package to the new  3.X \nversion.  If it is not their intention to update to packages in the  new   upcoming , users should disable their  upcoming  yum\nrepo by the time of the new OSG series cutover, and the continuation of their old  upcoming  packages will effectively\nbe the main  osg  repo for the new  3.X  series, after they have updated their  osg-release  package (usually by\ninstalling  osg-3.X-elY-release-latest.rpm ).",
            "title": "Notes on lessons learned"
        },
        {
            "location": "/release/old-release-removal/",
            "text": "Old Release Series Removal Plan\n\u00b6\n\n\nIn order to reduce clutter and disk usage on our repositories and build system,\nwe will remove older OSG Software release series.  This will result in packages\nfrom those series becoming unavailable, so we will remove a release series when\nits packages are no longer needed.\n\n\nWe will remove a release series no earlier than when the \nfollowing\n series is completely out of support.\nFor example, OSG 3.1 will be removed when OSG 3.2 is out of support, and OSG 3.2 will be removed when OSG 3.3 is out of\nsupport.\n\n\nTasks\n\u00b6\n\n\nRemoving a release series requires work from both Operations and Software &\nRelease.  The first step is to create a JIRA ticket in the SOFTWARE project to\ntrack the work.  Second, Software & Release will enumerate the directories for\nOperations to remove.\n\n\nOperations tasks should be completed before Software & Release tasks.\n\n\nOperations\n\u00b6\n\n\nThese tasks should be completed in order.\n\n\n\n\n\n\nTwo weeks in advance, notify sites (including mirror sites) that the\n    release series is going away.  See the \ntemplate email\n\n    below.\n\n\n\n\n\n\nRemove the series from the mash configs on the repo.opensciencegrid.org machines:\n\n\n\n\n\n\nAdd the koji tags for the old series to the \n/usr/local/osg-tags.excluded\n file:\n\n\n#\n \ncd\n /usr/local\n\n#\n fgrep osg-3.1 osg-tags\n\nosg-3.1-el5-contrib\n\n\nosg-3.1-el5-development\n\n\nosg-3.1-el5-release\n\n\nosg-3.1-el5-testing\n\n\nosg-3.1-el6-contrib\n\n\nosg-3.1-el6-development\n\n\nosg-3.1-el6-release\n\n\nosg-3.1-el6-testing\n\n\n#\n fgrep osg-3.1 osg-tags >> osg-tags.exclude\n\n\n\n\n\n\n\n\n\nRe-run \nupdate_mashfiles.sh\n to update the mash config files:\n\n\n#\n ./update_mashfiles.sh\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemove the appropriate repo directories from \n/usr/local/repo/osg\n.\n\n\n#\n rm -rf repo*/osg/3.1/\n\n\n\n\n\n\n\n\n\nReclaim space from any cached rpms in the mash cache which are no longer linked elsewhere:\n\n\n#\n find mash/cache/ -name \n\\*\n.rpm -type f -links \n1\n -delete\n\n\n\n\n\n\n\n\n\nWait for mash to run and verify that the repos are no longer getting\n    updated:\n\n\n\n\nLook at the mash logs in \n/var/log/repo\n.\n\n\nVerify that mash did not recreate the repo directory under\n   \n/usr/local/repo/osg\n corresponding to the old release series.\n\n\n\n\n\n\n\n\nSoftware & Release\n\u00b6\n\n\nThese tasks can be completed in any order.\n\n\n\n\n\n\nTag and remove the SVN branch corresponding to the release series.\n\n\n\n\n\n\nEdit \nvm-test-runs\n and remove any \"long tail\" tests that reference the\n  series.\n\n\n\n\n\n\nEdit \ntarball-client\n:\n\n\n\n\nRemove bundles from \nbundles.ini\n.\n\n\nRemove patch and other files that were used only by those bundles.\n\n\nTest that the current bundles didn't get broken by your changes.\n\n\n\n\n\n\n\n\nEdit \nosg-build\n:\n\n\n\n\nRemove the promotion routes from \npromoter.ini\n.\n\n\nRemove references in \nconstants.py\n.\n\n\nTest your changes; also run the unit tests.\n\n\n\n\n\n\n\n\nRemove things from Koji:\n\n\n\n\nAll targets referencing the series.\n\n\nAll tags referencing the series.\n\n\n\n\n\n\n\n\nRemove references to the series from \nopensciencegrid/docker-osg-wn-scripts\n\n  on GitHub, including the \ngenbranches\n and \nupdate-all\n scripts.\n\n\n\n\n\n\nRemove branches from \nopensciencegrid/docker-osg-wn\n on GitHub.\n\n\n\n\n\n\nMove files in \n/p/vdt/public/html/release-info\n to its \nattic\n subdirectory.\n\n\n\n\n\n\nUndoing\n\u00b6\n\n\nIf we really need RPMs from a removed release series, we can look at the text\nfiles in \n/p/vdt/public/html/release-info/attic\n to determine the exact NVRs we\nneed, and download them from Koji.\n\n\nTemplate Email\n\u00b6\n\n\nSubject: OSG 3.X packages will be removed from the repositories YYYY-MM-DD\n\n\n\n\n\nOn <DAYNAME, MONTH DAY>, the OSG will be removing the OSG <3.X> release\nseries from our repositories.  This includes both RPMs and tarballs hosted\non repo.opensciencegrid.org.\n\nAs a reminder, support for OSG <3.X> ended after <MONTH YEAR>.\n\nIf your site is running OSG <3.X>, you should upgrade to the current release\nseries, OSG 3.Y.  See our upgrade documentation [1] for instructions.  If you\nneed assistance upgrading, please contact us at help@opensciencegrid.org.\n\n[1] https://opensciencegrid.org/docs/release/release_series/#updating-from-osg-31-32-33-to-34\n\n\n\n\n\nIf we're dropping support for a distro (e.g. EL 5 when we drop OSG 3.2), add\nthe following after the first paragraph:\n\n\nNote that OSG <3.X> was the last release that supported Enterprise Linux <Z>\ndistributions.  If you believe that you still need support for this operating\nsystem series, please contact us at help@opensciencegrid.org.\n\n\n\n\n\nSince we're dropping support for i386 (32-bit) when we drop OSG 3.3, add the\nfollowing after the first paragraph:\n\n\nNote that OSG 3.3 was the last release that contained 32-bit packages.  If\nyou believe that you still need support for this architecture, please\ncontacts us at help@opensciencegrid.org.",
            "title": "Old Release Series Removal"
        },
        {
            "location": "/release/old-release-removal/#old-release-series-removal-plan",
            "text": "In order to reduce clutter and disk usage on our repositories and build system,\nwe will remove older OSG Software release series.  This will result in packages\nfrom those series becoming unavailable, so we will remove a release series when\nits packages are no longer needed.  We will remove a release series no earlier than when the  following  series is completely out of support.\nFor example, OSG 3.1 will be removed when OSG 3.2 is out of support, and OSG 3.2 will be removed when OSG 3.3 is out of\nsupport.",
            "title": "Old Release Series Removal Plan"
        },
        {
            "location": "/release/old-release-removal/#tasks",
            "text": "Removing a release series requires work from both Operations and Software &\nRelease.  The first step is to create a JIRA ticket in the SOFTWARE project to\ntrack the work.  Second, Software & Release will enumerate the directories for\nOperations to remove.  Operations tasks should be completed before Software & Release tasks.",
            "title": "Tasks"
        },
        {
            "location": "/release/old-release-removal/#operations",
            "text": "These tasks should be completed in order.    Two weeks in advance, notify sites (including mirror sites) that the\n    release series is going away.  See the  template email \n    below.    Remove the series from the mash configs on the repo.opensciencegrid.org machines:    Add the koji tags for the old series to the  /usr/local/osg-tags.excluded  file:  #   cd  /usr/local #  fgrep osg-3.1 osg-tags osg-3.1-el5-contrib  osg-3.1-el5-development  osg-3.1-el5-release  osg-3.1-el5-testing  osg-3.1-el6-contrib  osg-3.1-el6-development  osg-3.1-el6-release  osg-3.1-el6-testing  #  fgrep osg-3.1 osg-tags >> osg-tags.exclude    Re-run  update_mashfiles.sh  to update the mash config files:  #  ./update_mashfiles.sh      Remove the appropriate repo directories from  /usr/local/repo/osg .  #  rm -rf repo*/osg/3.1/    Reclaim space from any cached rpms in the mash cache which are no longer linked elsewhere:  #  find mash/cache/ -name  \\* .rpm -type f -links  1  -delete    Wait for mash to run and verify that the repos are no longer getting\n    updated:   Look at the mash logs in  /var/log/repo .  Verify that mash did not recreate the repo directory under\n    /usr/local/repo/osg  corresponding to the old release series.",
            "title": "Operations"
        },
        {
            "location": "/release/old-release-removal/#software-release",
            "text": "These tasks can be completed in any order.    Tag and remove the SVN branch corresponding to the release series.    Edit  vm-test-runs  and remove any \"long tail\" tests that reference the\n  series.    Edit  tarball-client :   Remove bundles from  bundles.ini .  Remove patch and other files that were used only by those bundles.  Test that the current bundles didn't get broken by your changes.     Edit  osg-build :   Remove the promotion routes from  promoter.ini .  Remove references in  constants.py .  Test your changes; also run the unit tests.     Remove things from Koji:   All targets referencing the series.  All tags referencing the series.     Remove references to the series from  opensciencegrid/docker-osg-wn-scripts \n  on GitHub, including the  genbranches  and  update-all  scripts.    Remove branches from  opensciencegrid/docker-osg-wn  on GitHub.    Move files in  /p/vdt/public/html/release-info  to its  attic  subdirectory.",
            "title": "Software &amp; Release"
        },
        {
            "location": "/release/old-release-removal/#undoing",
            "text": "If we really need RPMs from a removed release series, we can look at the text\nfiles in  /p/vdt/public/html/release-info/attic  to determine the exact NVRs we\nneed, and download them from Koji.",
            "title": "Undoing"
        },
        {
            "location": "/release/old-release-removal/#template-email",
            "text": "Subject: OSG 3.X packages will be removed from the repositories YYYY-MM-DD  On <DAYNAME, MONTH DAY>, the OSG will be removing the OSG <3.X> release\nseries from our repositories.  This includes both RPMs and tarballs hosted\non repo.opensciencegrid.org.\n\nAs a reminder, support for OSG <3.X> ended after <MONTH YEAR>.\n\nIf your site is running OSG <3.X>, you should upgrade to the current release\nseries, OSG 3.Y.  See our upgrade documentation [1] for instructions.  If you\nneed assistance upgrading, please contact us at help@opensciencegrid.org.\n\n[1] https://opensciencegrid.org/docs/release/release_series/#updating-from-osg-31-32-33-to-34  If we're dropping support for a distro (e.g. EL 5 when we drop OSG 3.2), add\nthe following after the first paragraph:  Note that OSG <3.X> was the last release that supported Enterprise Linux <Z>\ndistributions.  If you believe that you still need support for this operating\nsystem series, please contact us at help@opensciencegrid.org.  Since we're dropping support for i386 (32-bit) when we drop OSG 3.3, add the\nfollowing after the first paragraph:  Note that OSG 3.3 was the last release that contained 32-bit packages.  If\nyou believe that you still need support for this architecture, please\ncontacts us at help@opensciencegrid.org.",
            "title": "Template Email"
        },
        {
            "location": "/release/itb-testing/",
            "text": "Testing OSG Software Prereleases on the Madison ITB Site\n\u00b6\n\n\nThis document contains basic recipes for testing a OSG software prereleases on the Madison ITB site, which includes\nHTCondor prerelease builds and full OSG software stack prereleases from Yum.\n\n\nPrerequisites\n\u00b6\n\n\nThe following items are known prerequisites to using this recipe.  If you are not running the Ansible commands from\nosghost, there are almost certainly other prerequisites that are not listed below.  And even using osghost for Ansible\nand itb-submit for the submissions, there may be other prerequisites missing.  Please improve this document by adding\nother prerequisites as they are identified!\n\n\n\n\nA checkout of the osgitb directory from our local git instance (not GitHub)\n\n\nYour X.509 DN in the \nosgitb/unmanaged/htcondor-ce/grid-mapfile\n file and (via Ansible) on \nitb-ce1\n and \nitb-ce2\n\n\n\n\nGathering Information\n\u00b6\n\n\nTechnically skippable, this section is about checking on the state of the ITB machines before making changes.  The plan\nis to keep the ITB machines generally up-to-date independently, so those steps are not listed here.  And honestly, the\nsteps below are just some ideas; do whatever makes sense for the given update.\n\n\nThe commands can be run as-is from within the \nosgitb\n directory from git.\n\n\n\n\n\n\nCheck OS versions for all current ITB hosts:\n\n\nansible current -i inventory -f 20 -o -m command -a 'cat /etc/redhat-release'\n\n\n\n\n\n\n\n\n\n\nCheck the date and time on all hosts (in case NTP stops working):\n\n\nansible current -i inventory -f 20 -o -m command -a 'date'\n\n\n\n\n\n\n\n\n\n\nCheck software versions for certain hosts (e.g., for the \ncondor\n package on hosts in the \nworkers\n group):\n\n\nansible workers -i inventory -f 20 -o -m command -a 'rpm -q condor'\n\n\n\n\n\n\n\n\n\n\nInstalling HTCondor Prerelease\n\u00b6\n\n\nUse this section to install a new version of HTCondor, specifically a prerelease build from the development or\nupcoming-development repository, on the test hosts.\n\n\n\n\n\n\nObtain the NVR of the HTCondor prerelease build from OSG to test.  Do this by talking to Tim\u00a0T. and checking\n   Koji.\n\n\n\n\n\n\nShut down HTCondor and HTCondor-CE on prerelease machines:\n\n\nansible 'testing:&ces' -i inventory -bK -f 20 -m service -a 'name=condor-ce state=stopped'\n\n\nansible 'testing:&condor' -i inventory -bK -f 20 -m service -a 'name=condor state=stopped'\n\n\n\n\n\n\n\n\n\n\nInstall new version of HTCondor on prerelease machines:\n\n\nansible 'testing:&condor' -i inventory -bK -f 10 -m command -a 'yum --enablerepo=osg-development --assumeyes update condor'\n\n\n\n\n\n\nor, if you need to install an NVR that is \u201cearlier\u201d (in the RPM sense) than what is currently installed:\n\n\nansible 'testing:&condor' -i inventory -bK -f 10 -m command -a 'yum --enablerepo=osg-development --assumeyes downgrade condor condor-classads condor-python condor-procd blahp'\n\n\n\n\n\n\n\n\n\n\nVerify correct RPM versions across the site:\n\n\nansible condor -i inventory -f 20 -o -m command -a 'rpm -q condor'\n\n\n\n\n\n\n\n\n\n\nRestart HTCondor and HTCondor-CE on prerelease machines:\n\n\nansible 'testing:&condor' -i inventory -bK -f 20 -m service -a 'name=condor state=started'\n\n\nansible 'testing:&ces' -i inventory -bK -f 20 -m service -a 'name=condor-ce state=started'\n\n\n\n\n\n\n\n\n\n\nInstalling a Prerelease of the OSG Software Stack\n\u00b6\n\n\nUse this section to install new versions of all OSG software from a prerelease repository in Yum.\n\n\n\n\n\n\nCheck with the Release Manager to make sure that the prerelease repository has been populated with the desired\n   package versions.\n\n\n\n\n\n\nMake sure that software is generally up-to-date on the hosts\u00a0\u2014 see\n   \nthe Madison ITB Site doc\n for more details\n\n\nIt may be desirable to update only non-OSG software at this stage, in which case one could simply disable the OSG\nrepositories by adding command-line options to the \nyum update\n commands.\n\n\n\n\n\n\nInstall new software on prerelease hosts:\n\n\nansible testing -i inventory -bK -f 20 -m command -a 'yum --enablerepo=osg-prerelease --assumeyes update'\n\n\n\n\n\n\n\n\n\n\nRead the Yum output carefully, and follow up on any warnings, etc.\n\n\n\n\n\n\nIf the \nosg-configure\n package was updated on any host(s), run the \nosg-configure\n command on the host(s):\n\n\nansible testing -i inventory -bK -f 20 -m command -a 'osg-configure -v' -l [HOST(S)]\n\n\nansible testing -i inventory -bK -f 20 -m command -a 'osg-configure -c' -l [HOST(S)]\n\n\n\n\n\n\n\n\n\n\nVerify OSG software updates by inspecting the Yum output carefully or examining specific package versions:\n\n\nansible current -i inventory -f 20 -o -m command -a 'rpm -q osg-wn-client'\n\n\n\n\n\n\nUse an inventory group and package names that best fit the situation.\n\n\n\n\n\n\nRunning Tests\n\u00b6\n\n\nFor the first two test workflows, use your personal space on \nitb-submit\n.  Copy or checkout the \nosgitb/htcondor-tests\n\ndirectory to get the test directories.\n\n\nPart \u2160: Submitting jobs directly\n\u00b6\n\n\n\n\n\n\nChange into the \n1-direct-jobs\n subdirectory\n\n\n\n\n\n\nIf there are old result files in the directory, remove them:\n\n\nmake distclean\n\n\n\n\n\n\n\n\n\n\nSubmit the test workflow\n\n\ncondor_submit_dag test.dag\n\n\n\n\n\n\n\n\n\n\nMonitor the jobs until they are complete or stuck\n\n\nIn the initial test runs, the entire workflow ran in a few minutes.  If the DAG or jobs exit immediately, go on\nhold, or otherwise fail, then you have some troubleshooting to do!  Keep trying steps 2 and 3 until you get a clean\nrun (or one or more HTCondor bug tickets).\n\n\n\n\n\n\nCheck the final output file:\n\n\ncat count-by-hostnames.txt\n\n\n\n\n\n\nYou should see a reasonable distribution of jobs by hostname, keeping in mind the different number of cores per\nmachine and the fact that HTCondor can and will reuse claims to process many jobs on a single host.  Especially\nwatch out for a case in which no jobs run on the newly updated hosts (at the time of writing: \nitb-data[456]\n).\n\n\n\n\n\n\n(Optional) Clean up, using the \nmake clean\n or \nmake distclean\n commands.  Use the \nclean\n target to remove\n   intermediate result and log files generated by a workflow run but preserve the final output file; use the \ndistclean\n\n   target to remove all workflow-generated files (plus Emacs backup files).\n\n\n\n\n\n\nPart \u2161: Submitting jobs using HTCondor-C\n\u00b6\n\n\nIf direct submissions fail, there is probably no point to doing this step.\n\n\n\n\n\n\nChange into the \n2-htcondor-c-jobs\n subdirectory\n\n\n\n\n\n\nIf there are old result files in the directory, remove them:\n\n\nmake distclean\n\n\n\n\n\n\n\n\n\n\nGet a proxy for your X.509 credentials\n\n\nvoms-proxy-init\n\n\n\n\n\n\n\n\n\n\nSubmit the test workflow\n\n\ncondor_submit_dag test.dag\n\n\n\n\n\n\n\n\n\n\nMonitor the jobs until they are complete or stuck\n\n\nIn the initial test runs, the entire workflow ran in 10 minutes or less; generally, this test takes longer than the\ndirect submission test, because of the layers of indirection.  Also, status updates from the CEs back to the submit\nhost are infrequent.  For direct information about the CEs, log in to \nitb-ce1\n and \nitb-ce2\n to check status; don\u2019t\nforget to check both \ncondor_ce_q\n and \ncondor_q\n on the CEs, probably in that order.\n\n\nIf the DAG or jobs exit immediately, go on hold, or otherwise fail, then you have some troubleshooting to do!  Keep\ntrying steps 2 and 3 until you get a clean run (or one or more HTCondor bug tickets).\n\n\n\n\n\n\nCheck the final output file:\n\n\ncat count-by-hostnames.txt\n\n\n\n\n\n\nAgain, look for a reasonable distribution of jobs by hostname.\n\n\n\n\n\n\n(Optional) Clean up, using the \nmake clean\n or \nmake distclean\n commands.\n\n\n\n\n\n\nPart \u2162: Submitting jobs from a GlideinWMS VO Frontend\n\u00b6\n\n\nFor this workflow, use your personal space on \nglidein3.chtc.wisc.edu\n.  Copy or checkout the \nosgitb/htcondor-tests\n\ndirectory to get the test directories.  Again, if previous steps fail, do not bother with this step.\n\n\n\n\n\n\nChange into the \n3-frontend-jobs\n subdirectory\n\n\n\n\n\n\nIf there are old result files in the directory, remove them:\n\n\nmake distclean\n\n\n\n\n\n\n\n\n\n\nSubmit the test workflow\n\n\ncondor_submit_dag test.dag\n\n\n\n\n\n\n\n\n\n\nMonitor the jobs until they are complete or stuck\n\n\nThis workflow could take much longer than the first two, maybe an hour or so.  Also, unless there are active\nglideins, it will take 10 minutes or longer for the first glideins to appear and start matching jobs.  Thus it is\nhelpful to monitor \ncondor_q -totals\n until all of the jobs are submitted (there should be 2001), then switch to\nmonitoring \ncondor_status\n until glideins start appearing.  After the first jobs start running and finishing, it is\nprobably safe to ignore the rest of the run.  If the jobs do not appear in the local queue, if glideins do not\nappear, or if jobs do not start running on the glideins, it is time to start troubleshooting.\n\n\n\n\n\n\nCheck the final output file:\n\n\ncat count-by-hostnames.txt\n\n\n\n\n\n\nThe distribution of jobs per execute node may be more skewed than in the first two workflows, due to the way in\nwhich pilots ramp up over time and how HTCondor allocates jobs to slots.\n\n\n\n\n\n\n(Optional) Clean up, using the \nmake clean\n or \nmake distclean\n commands.",
            "title": "ITB Prerelease Testing"
        },
        {
            "location": "/release/itb-testing/#testing-osg-software-prereleases-on-the-madison-itb-site",
            "text": "This document contains basic recipes for testing a OSG software prereleases on the Madison ITB site, which includes\nHTCondor prerelease builds and full OSG software stack prereleases from Yum.",
            "title": "Testing OSG Software Prereleases on the Madison ITB Site"
        },
        {
            "location": "/release/itb-testing/#prerequisites",
            "text": "The following items are known prerequisites to using this recipe.  If you are not running the Ansible commands from\nosghost, there are almost certainly other prerequisites that are not listed below.  And even using osghost for Ansible\nand itb-submit for the submissions, there may be other prerequisites missing.  Please improve this document by adding\nother prerequisites as they are identified!   A checkout of the osgitb directory from our local git instance (not GitHub)  Your X.509 DN in the  osgitb/unmanaged/htcondor-ce/grid-mapfile  file and (via Ansible) on  itb-ce1  and  itb-ce2",
            "title": "Prerequisites"
        },
        {
            "location": "/release/itb-testing/#gathering-information",
            "text": "Technically skippable, this section is about checking on the state of the ITB machines before making changes.  The plan\nis to keep the ITB machines generally up-to-date independently, so those steps are not listed here.  And honestly, the\nsteps below are just some ideas; do whatever makes sense for the given update.  The commands can be run as-is from within the  osgitb  directory from git.    Check OS versions for all current ITB hosts:  ansible current -i inventory -f 20 -o -m command -a 'cat /etc/redhat-release'     Check the date and time on all hosts (in case NTP stops working):  ansible current -i inventory -f 20 -o -m command -a 'date'     Check software versions for certain hosts (e.g., for the  condor  package on hosts in the  workers  group):  ansible workers -i inventory -f 20 -o -m command -a 'rpm -q condor'",
            "title": "Gathering Information"
        },
        {
            "location": "/release/itb-testing/#installing-htcondor-prerelease",
            "text": "Use this section to install a new version of HTCondor, specifically a prerelease build from the development or\nupcoming-development repository, on the test hosts.    Obtain the NVR of the HTCondor prerelease build from OSG to test.  Do this by talking to Tim\u00a0T. and checking\n   Koji.    Shut down HTCondor and HTCondor-CE on prerelease machines:  ansible 'testing:&ces' -i inventory -bK -f 20 -m service -a 'name=condor-ce state=stopped'  ansible 'testing:&condor' -i inventory -bK -f 20 -m service -a 'name=condor state=stopped'     Install new version of HTCondor on prerelease machines:  ansible 'testing:&condor' -i inventory -bK -f 10 -m command -a 'yum --enablerepo=osg-development --assumeyes update condor'   or, if you need to install an NVR that is \u201cearlier\u201d (in the RPM sense) than what is currently installed:  ansible 'testing:&condor' -i inventory -bK -f 10 -m command -a 'yum --enablerepo=osg-development --assumeyes downgrade condor condor-classads condor-python condor-procd blahp'     Verify correct RPM versions across the site:  ansible condor -i inventory -f 20 -o -m command -a 'rpm -q condor'     Restart HTCondor and HTCondor-CE on prerelease machines:  ansible 'testing:&condor' -i inventory -bK -f 20 -m service -a 'name=condor state=started'  ansible 'testing:&ces' -i inventory -bK -f 20 -m service -a 'name=condor-ce state=started'",
            "title": "Installing HTCondor Prerelease"
        },
        {
            "location": "/release/itb-testing/#installing-a-prerelease-of-the-osg-software-stack",
            "text": "Use this section to install new versions of all OSG software from a prerelease repository in Yum.    Check with the Release Manager to make sure that the prerelease repository has been populated with the desired\n   package versions.    Make sure that software is generally up-to-date on the hosts\u00a0\u2014 see\n    the Madison ITB Site doc  for more details  It may be desirable to update only non-OSG software at this stage, in which case one could simply disable the OSG\nrepositories by adding command-line options to the  yum update  commands.    Install new software on prerelease hosts:  ansible testing -i inventory -bK -f 20 -m command -a 'yum --enablerepo=osg-prerelease --assumeyes update'     Read the Yum output carefully, and follow up on any warnings, etc.    If the  osg-configure  package was updated on any host(s), run the  osg-configure  command on the host(s):  ansible testing -i inventory -bK -f 20 -m command -a 'osg-configure -v' -l [HOST(S)]  ansible testing -i inventory -bK -f 20 -m command -a 'osg-configure -c' -l [HOST(S)]     Verify OSG software updates by inspecting the Yum output carefully or examining specific package versions:  ansible current -i inventory -f 20 -o -m command -a 'rpm -q osg-wn-client'   Use an inventory group and package names that best fit the situation.",
            "title": "Installing a Prerelease of the OSG Software Stack"
        },
        {
            "location": "/release/itb-testing/#running-tests",
            "text": "For the first two test workflows, use your personal space on  itb-submit .  Copy or checkout the  osgitb/htcondor-tests \ndirectory to get the test directories.",
            "title": "Running Tests"
        },
        {
            "location": "/release/itb-testing/#part-i-submitting-jobs-directly",
            "text": "Change into the  1-direct-jobs  subdirectory    If there are old result files in the directory, remove them:  make distclean     Submit the test workflow  condor_submit_dag test.dag     Monitor the jobs until they are complete or stuck  In the initial test runs, the entire workflow ran in a few minutes.  If the DAG or jobs exit immediately, go on\nhold, or otherwise fail, then you have some troubleshooting to do!  Keep trying steps 2 and 3 until you get a clean\nrun (or one or more HTCondor bug tickets).    Check the final output file:  cat count-by-hostnames.txt   You should see a reasonable distribution of jobs by hostname, keeping in mind the different number of cores per\nmachine and the fact that HTCondor can and will reuse claims to process many jobs on a single host.  Especially\nwatch out for a case in which no jobs run on the newly updated hosts (at the time of writing:  itb-data[456] ).    (Optional) Clean up, using the  make clean  or  make distclean  commands.  Use the  clean  target to remove\n   intermediate result and log files generated by a workflow run but preserve the final output file; use the  distclean \n   target to remove all workflow-generated files (plus Emacs backup files).",
            "title": "Part \u2160: Submitting jobs directly"
        },
        {
            "location": "/release/itb-testing/#part-ii-submitting-jobs-using-htcondor-c",
            "text": "If direct submissions fail, there is probably no point to doing this step.    Change into the  2-htcondor-c-jobs  subdirectory    If there are old result files in the directory, remove them:  make distclean     Get a proxy for your X.509 credentials  voms-proxy-init     Submit the test workflow  condor_submit_dag test.dag     Monitor the jobs until they are complete or stuck  In the initial test runs, the entire workflow ran in 10 minutes or less; generally, this test takes longer than the\ndirect submission test, because of the layers of indirection.  Also, status updates from the CEs back to the submit\nhost are infrequent.  For direct information about the CEs, log in to  itb-ce1  and  itb-ce2  to check status; don\u2019t\nforget to check both  condor_ce_q  and  condor_q  on the CEs, probably in that order.  If the DAG or jobs exit immediately, go on hold, or otherwise fail, then you have some troubleshooting to do!  Keep\ntrying steps 2 and 3 until you get a clean run (or one or more HTCondor bug tickets).    Check the final output file:  cat count-by-hostnames.txt   Again, look for a reasonable distribution of jobs by hostname.    (Optional) Clean up, using the  make clean  or  make distclean  commands.",
            "title": "Part \u2161: Submitting jobs using HTCondor-C"
        },
        {
            "location": "/release/itb-testing/#part-iii-submitting-jobs-from-a-glideinwms-vo-frontend",
            "text": "For this workflow, use your personal space on  glidein3.chtc.wisc.edu .  Copy or checkout the  osgitb/htcondor-tests \ndirectory to get the test directories.  Again, if previous steps fail, do not bother with this step.    Change into the  3-frontend-jobs  subdirectory    If there are old result files in the directory, remove them:  make distclean     Submit the test workflow  condor_submit_dag test.dag     Monitor the jobs until they are complete or stuck  This workflow could take much longer than the first two, maybe an hour or so.  Also, unless there are active\nglideins, it will take 10 minutes or longer for the first glideins to appear and start matching jobs.  Thus it is\nhelpful to monitor  condor_q -totals  until all of the jobs are submitted (there should be 2001), then switch to\nmonitoring  condor_status  until glideins start appearing.  After the first jobs start running and finishing, it is\nprobably safe to ignore the rest of the run.  If the jobs do not appear in the local queue, if glideins do not\nappear, or if jobs do not start running on the glideins, it is time to start troubleshooting.    Check the final output file:  cat count-by-hostnames.txt   The distribution of jobs per execute node may be more skewed than in the first two workflows, due to the way in\nwhich pilots ramp up over time and how HTCondor allocates jobs to slots.    (Optional) Clean up, using the  make clean  or  make distclean  commands.",
            "title": "Part \u2162: Submitting jobs from a GlideinWMS VO Frontend"
        },
        {
            "location": "/release/empty-pkgs/",
            "text": "Procedure for updating empty-* packages\n\u00b6\n\n\nBackground\n\u00b6\n\n\nThe \nempty-*\n packages were introduced a workaround for sites that install certain software (for example HTCondor or CA certs) from tarballs or other means that do not involve Yum/RPM.\n\n\nThe packages contain no files, and exist merely to satisfy RPM dependencies so that other packages can be installed. It is the admin's responsibility to make sure that whatever component they installed the empty package for is functional.\n\n\nThe empty packages are kept in a separate repository to prevent them from being accidentally installed instead of the component they claim to provide. Because of this, they do not go through the normal release process of development to testing to prerelease to release, but are \nmoved\n straight from \nosg-development\n into \nosg-empty\n after developer testing. \n\n\n\n\nWarning\n\n\nIt is important to untag the packages from \nosg-development\n immediately after promotion to \nosg-empty\n\n\n\n\nProcedure\n\u00b6\n\n\n\n\nPrepare the package update, but do not build yet.\n\n\nCoordinate with the Software and Release Managers to set aside a good time to update the package. An empty package should not remain in the development repos for longer than a few hours.\n\n\nBuild into development.\n\n\nTest out of development. \nBe thorough\n, as there is no separate acceptance testing for empty packages.\n\n\nIn the JIRA ticket, document your testing procedure and request permission from \nboth\n the Software and the Release Managers. (Since there is no acceptance testing, both of them have to sign off on the new build).\n\n\nAfter receiving permission, tag the builds into the \nosg-empty\n tags, and untag them from the \nosg-development\n tags. Then regenerate the \nosg-empty\n repos. \n\n\n\n\nosg-koji move-pkg osg-3.3-el6-development osg-3.3-el6-empty <EL6_BUILD_NVR>\nosg-koji move-pkg osg-3.3-el7-development osg-3.3-el7-empty <EL7_BUILD_NVR>\nosg-koji regen-repo --nowait osg-3.3-el6-empty\nosg-koji regen-repo --nowait osg-3.3-el7-empty",
            "title": "Empty Packages"
        },
        {
            "location": "/release/empty-pkgs/#procedure-for-updating-empty-42-packages",
            "text": "",
            "title": "Procedure for updating empty-* packages"
        },
        {
            "location": "/release/empty-pkgs/#background",
            "text": "The  empty-*  packages were introduced a workaround for sites that install certain software (for example HTCondor or CA certs) from tarballs or other means that do not involve Yum/RPM.  The packages contain no files, and exist merely to satisfy RPM dependencies so that other packages can be installed. It is the admin's responsibility to make sure that whatever component they installed the empty package for is functional.  The empty packages are kept in a separate repository to prevent them from being accidentally installed instead of the component they claim to provide. Because of this, they do not go through the normal release process of development to testing to prerelease to release, but are  moved  straight from  osg-development  into  osg-empty  after developer testing.    Warning  It is important to untag the packages from  osg-development  immediately after promotion to  osg-empty",
            "title": "Background"
        },
        {
            "location": "/release/empty-pkgs/#procedure",
            "text": "Prepare the package update, but do not build yet.  Coordinate with the Software and Release Managers to set aside a good time to update the package. An empty package should not remain in the development repos for longer than a few hours.  Build into development.  Test out of development.  Be thorough , as there is no separate acceptance testing for empty packages.  In the JIRA ticket, document your testing procedure and request permission from  both  the Software and the Release Managers. (Since there is no acceptance testing, both of them have to sign off on the new build).  After receiving permission, tag the builds into the  osg-empty  tags, and untag them from the  osg-development  tags. Then regenerate the  osg-empty  repos.    osg-koji move-pkg osg-3.3-el6-development osg-3.3-el6-empty <EL6_BUILD_NVR>\nosg-koji move-pkg osg-3.3-el7-development osg-3.3-el7-empty <EL7_BUILD_NVR>\nosg-koji regen-repo --nowait osg-3.3-el6-empty\nosg-koji regen-repo --nowait osg-3.3-el7-empty",
            "title": "Procedure"
        },
        {
            "location": "/release/acceptance-testing/",
            "text": "Acceptance Testing\n\u00b6\n\n\nThe OSG Release Team collects and maintains testing procedures for major components in the OSG Sofware Stack. These test should verify that basic functionality of the component works in typically deployed configurations.\n\n\nCVMFS\n\u00b6\n\n\n\n\nNote\n\n\nThis acceptance testing recipe was created when access to a machine with sufficient disk space to make a complete replica of OASIS was not available.\n\n\n\n\nCreating a CVMFS Repository Server (Stratum 0)\n\u00b6\n\n\n\n\n\n\nDisable SELinux by setting the following in \n/etc/selinux/config\n.\n\n\nSELINUX=disabled\n\n\n\n\n\n\n\n\n\nCheck kernel version.\n\n\nuname -a\n\n\n\n\n\n\n\n\n\n\nCVMFS for EL7 requires OverlayFS (as of kernel version 4.2.x). If default kernel is <= 4.2.x, update kernel.\n\n\nroot@host #\n rpm --import <https://www.elrepo.org/RPM-GPG-KEY-elrepo.org>\n\nroot@host #\n rpm -Uvh <http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm>\n\nroot@host #\n yum install yum-plugin-fastestmirror\n\nroot@host #\n yum --enablerepo\n=\nelrepo-kernel install kernel-ml\n\n\n\n\n\n\n\n\n\nSelect updated kernel by editing \n/etc/default/grub\n.\n\n\nGRUB_DEFAULT=0\n\n\n\n\n\nand run:\n\n\nroot@host #\n grub2-mkconfig -o /boot/grub2/grub.cfg\n\n\n\n\n\n\n\n\n\nReboot system. \n\n\n\n\n\n\nCheck kernel version again and make sure SELinux is disabled.\n\n\nroot@host #\n uname -a\n\nroot@host #\n sestatus\n\n\n\n\n\n\n\n\n\nIf kernel >= 4.2 and SELinux is disabled, then update system and install CVMFS server and client packages.\n\n\nroot@host #\n yum update\n\nroot@host #\n yum install epel-release\n\nroot@host #\n yum install yum-plugin-priorities\n\nroot@host #\n rpm -Uvh <https://repo.opensciencegrid.org/osg/3.3/osg-3.3-el7-release-latest.rpm>\n\nroot@host #\n yum install cvmfs cvmfs-server\n\n\n\n\n\n\n\n\n\nConfigure web server and start it up. Edit \n/etc/httpd/conf.d/cvmfs.conf\n:\n\n\nListen 8000\nKeepAlive On\n\n\n\n\n\nand run:\n\n\nroot@host #\n chkconfig httpd on\n\nroot@host #\n service httpd start\n\n\n\n\n\n\n\n\n\nMake new repository.\n\n\nroot@host #\n cvmfs_server mkfs test.cvmfs-stratum-0.novalocal\n\n\n\n\n\n\n\n\n\nRun transaction on new repository to enable write access.\n\n\nroot@host #\n cvmfs_server transaction test.cvmfs-stratum-0.novalocal\n\n\n\n\n\n\n\n\n\nPlace some sample code in new repository directory and then publish it.\n\n\nroot@host #\n \ncd\n /cvmfs/test.cvmfs-stratum-0.novalocal\n\nroot@host #\n vi \n[\nbash\n\\_\npi.sh\n](\n%ATTACHURL%/bash_pi.sh\n)\n\n\nroot@host #\n chmod +x bash\n\\_\npi.sh\n\nroot@host #\n cvmfs\n\\_\nserver publish test.cvmfs-stratum-0.novalocal\n\n\n\n\n\n\n\n\n\nCheck repository status after publication.\n\n\nroot@host #\n cvmfs\n\\_\nserver check\n\nroot@host #\n cvmfs\n\\_\nserver tag\n\nroot@host #\n wget -qO- <http://localhost:8000/cvmfs/test.cvmfs-stratum-0.novalocal/.cvmfswhitelist%7Ccat> -v\n\n\n\n\n\n\n\n\n\nDownload a copy of the CVMFS repository's public key e.g., /etc/cvmfs/keys/test.cvmfs-stratum-0.novalocal.pub\n\n\n\n\n\n\nCreating a CVMFS Replica Server (Stratum 1)\n\u00b6\n\n\n\n\n\n\nRepeat steps 1 though 8 in the previous section on \"Creating a CVMFS Repository Server \". However, now also install \nmod_wsgi\n.\n\n\nroot@host #\n yum install cvmfs cvmfs-server mod\n\\_\nwsgi\n\n\n\n\n\n\n\n\n\nUpload a copy of the CVMFS repository's public key and place in \n/etc/cvmfs/keys\n directory. \n\n\n\n\n\n\nAdd replica of the repository.\n\n\nroot@host #\n cvmfs_server add-replica -o root <http://10.128.3.96:8000/cvmfs/test.cvmfs-stratum-0.novalocal> /etc/cvmfs/keys/test.cvmfs-stratum-0.novalocal.pub\n\n\n\n\n\n\n\n\n\nMake a snapshot of the repository.\n\n\nroot@host #\n cvmfs\n\\_\nserver snapshot test.cvmfs-stratum-0.novalocal\n\n\n\n\n\n\n\n\n\nCreating a CVMFS client\n\u00b6\n\n\n\n\n\n\nUpdate system and install CVMFS client package.\n\n\nroot@host #\n yum update\n\nroot@host #\n yum install epel-release\n\nroot@host #\n yum install yum-plugin-priorities\n\nroot@host #\n rpm -Uvh <https://repo.opensciencegrid.org/osg/3.3/osg-3.3-el7-release-latest.rpm>\n\nroot@host #\n yum install cvmfs\n\n\n\n\n\n\n\n\n\nUpload a copy of the CVMFS repository's public key and place in \n/etc/cvmfs/keys\n directory.\n\n\n\n\n\n\nEdit fuse configuration \n/etc/fuse.conf\n.\n\n\nuser_allow_other\n\n\n\n\n\n\n\n\n\nEdit autofs configuration and restart service \n/etc/auto.master\n.\n\n\n/cvmfs /etc/auto.cvmfs\n\n\n\n\n\nand run:\n\n\nroot@host #\n service autofs restart\n\n\n\n\n\n\n\n\n\nEdit cvmfs configuration (\n/etc/cvmfs/default.local\n) to point to replica server.\n\n\nCVMFS_SERVER_URL=\"http://10.128.3.97:8000/cvmfs/@fqrn@\"\nCVMFS_REPOSITORIES=\"test.cvmfs-stratum-0.novalocal\"\nCVMFS_HTTP_PROXY=DIRECT\n\n\n\n\n\n\n\n\n\nRemove OSG CVMFS configuration file.\n\n\nrm /etc/cvmfs/default.d/60-osg.conf\n\n\n\n\n\n\n\n\n\n\nRun CVMFS config probe.\n\n\ncvmfs_config probe test.cvmfs-stratum-0.novalocal\n\n\n\n\n\n\n\n\n\n\nCheck CVMFS config status.\n\n\ncvmfs_config stat -v test.cvmfs-stratum-0.novalocal\n\n\n\n\n\n\n\n\n\n\nExecute sample code published to repository from client.\n\n\n/cvmfs/test.cvmfs-stratum-0.novalocal/bash_pi.sh -b 8 -r 5 -s 10000\n\n\n\n\n\n\n\n\n\n\nCreating an OASIS client\n\u00b6\n\n\n\n\nUpdate system and install CVMFS client package.\n\n\nyum update\n\n\nyum install epel-release\n\n\nyum install yum-plugin-priorities\n\n\nrpm -Uvh \nhttps://repo.opensciencegrid.org/osg/3.3/osg-3.3-el7-release-latest.rpm\n\n\nyum install osg-oasis \n\n\n\n\n\n\nVerify latest versions of cvmfs, cvmfs-config-osg, and cvmfs-x509-helper have been installed. \n\n\nEdit fuse configuration.\n\n\nvi /etc/fuse.conf\n\n\nuser_allow_other \n\n\n\n\n\n\n\n\n\n\nEdit cvmfs configuration to point to replica server.\n\n\nvi /etc/cvmfs/default.local\n\n\nCVMFS_REPOSITORIES=\"`echo $((echo oasis.opensciencegrid.org;echo cms.cern.ch;ls /cvmfs)|sort -u)|tr ' ' ,`\"\n\n\nCVMFS_QUOTA_LIMIT=20000\n\n\nCVMFS_HTTP_PROXY=DIRECT\n\n\n\n\n\n\n\n\n\n\nEdit autofs configuration and restart service.\n\n\nvi /etc/auto.master\n\n\n/cvmfs /etc/auto.cvmfs\n\n\n\n\n\n\nservice autofs restart\n\n\n\n\n\n\nRun CVMFS config probe.\n\n\ncvmfs_config probe \n\n\n\n\n\n\nCheck CVMFS config status.\n\n\ncvmfs_config stat -v oasis.opensciencegrid.org\n\n\n\n\n\n\n\n\nAdditional Documentation\n\u00b6\n\n\n\n\nCERN's CVMFS Documentation\n\n\nOSG's CVMFS Replica Server\n\n\nOSG's CVMFS Client Documentation\n\n\n\n\nOSG's OASIS Documentation\n\n\n\n\n\n\nbash_pi.sh\n: A bash script that uses a simple Monte Carlo method to estimate the value of Pi\n\n\n\n\n\n\nGratia Probe\n\u00b6\n\n\nThis section documents the testing procedure to test the gratia probes sufficiently tested to be promoted to the osg-testing repository. The test procedure is the same on both SL6 and SL7.\n\n\n\n\ninstall or update the \ngratia-probe-condor\n rpm as appropriate\n\n\nOn each VM download the gratia-probe-setup.sh script and run it\n\n\nIn \n/etc/gratia/condor/ProbeConfig\n, verify the following have been changed:\n\n\nchange \nSiteName\n to something aside from \nGeneric Site\n\n\nchange \nEnableProbe\n to 1\n\n\nchange \nCollectorHost\n, \nSSLHost\n, and \nSSLRegistrationHost\n to the an invalid host (E.g. test.com) or the localhost\n\n\n\n\n\n\nCreate \n/var/lib/osg/\n and download the attached \nuser-vo-map\n file and place it in that directory\n\n\nEdit the \nuser-vo-map\n file and change the account from \nsthapa\n to the account you'll be using to submit the condor jobs in the following step\n\n\nDownload and submit the attached condor_submit file (note, on the default fermicloud VM, this takes about 3 hours, so you may want to set \nNUM_CPUS\n to 50 so that 50 jobs will run at a time)\n\n\nRun \n/usr/share/gratia/condor/condor_meter\n\n\nCheck \n/var/lib/gratia/tmp/gratiafiles/\n for a \nsubdir.condor_...\n directory and verify that there are 200 xml jobs and the cpus/wall times are appropriate (either PT0S or PT1M).\n\n\n\n\nGSI OpenSSH\n\u00b6\n\n\n\n\nNote\n\n\nFermicloud policy forbids running the GSI OpenSSH server.\nYou will have to test that part locally.\n\n\n\n\nTo test a fresh installation:\n\n\n\n\nSpin up two VM's and set up the EPEL/OSG repos on both of them.\n\n\nChoose one of the VM's, it will be the server VM. The hostname of this machine will be referenced below as the \n<SERVER HOSTNAME>\n\n    Consult these \ninstructions\n to set up the server.\n\n\n\n\nFrom the other VM (client):\n\n\n\n\n\n\nInstall the necessary packages:\n\n\nroot@host #\n yum install globus-proxy-utils gsi-openssh-clients\n\n\n\n\n\n\n\n\n\nInitialize your proxy. After this, none of the gsi commands should prompt you for your password.\n\n\n\n\n\n\nConnect to the server:\n\n\nuser@host $\n gsissh -p \n2222\n <SERVER HOSTNAME>\n\n\n\n\n\n\n\n\n\nCopy a test file to the server:\n\n\nuser@host $\n gsiscp -p \n2222\n testfile <SERVER HOSTNAME>:/tmp\n\n\n\n\n\n\n\n\n\nConnect to the server via SFTP and grab files:\n\n\nuser@host $\n gsisftp -P \n2222\n <SERVER HOSTNAME>\n\nuser@host $\n \ncd\n /tmp\n\nuser@host $\n get testfile\n\n\n\n\n\n\n\n\n\n\n\n\n\nHTCondor-CE Collector (WIP)\n\u00b6\n\n\nThe CE Collector is a stripped-down version of HTCondor-CE that contains mostly just the collector daemon and configs. It was introduced in htcondor-ce-1.6. The production CE Collectors run at the GOC, but you may want to set up your own for testing.\n\n\n\n\nMake 2 VMs with the EPEL/OSG repos installed: one for the collector, and one for the CE\n\n\n\n\nSetting Up the Collector\n\u00b6\n\n\n\n\nInstall \nhtcondor-ce-collector\n\n\n\n\nCreate a file called \n/etc/condor-ce/config.d/99-local.conf\n that contains this line:\n\n\nCOLLECTOR.ALLOW_ADVERTISE_SCHEDD = $(COLLECTOR.ALLOW_ADVERTISE_SCHEDD), your_htcondor_ce_host.example.net</pre>\n\n\n\n\n\n(with \nyour_htcondor_ce_host\n replaced by the hostname the HTCondor-CE VM)\n\n\n\n\n\n\nRun \nservice condor-ce-collector start\n\n\n\n\n\n\nSetting Up the CE\n\u00b6\n\n\n\n\nInstall \nosg-htcondor-ce-condor\n (replace condor with the batch system of your choice)\n\n\nEnsure osg-configure >= 1.0.60-2 is installed\n\n\n\n\nConfigure your CE using osg-configure\n\n\n\n\nYou should use the \nHTCondor-CE Install Docs\n as a reference, although you can skip several of the steps\n\n\nYou can skip setting up Squid: set \nenabled\n to \nTrue\n and \nlocation\n to \nUNAVAILABLE\n in \n01-squid.ini\n\n\nSet \nhtcondor_gateway_enabled\n to \nTrue\n in \n10-gateway.ini\n\n\nYou probably don't need GUMS, but if you want it, use the Fermi GUMS server (set \ngums_host\n to \ngums.fnal.gov\n and \nauthorization_method\n to \nxacml\n in 10-misc.ini)\n\n\n\n\nTo keep osg-configure from complaining about storage, edit \n10-storage.ini\n:\n\n\n\n\nSet \nse_available\n to \nFalse\n\n\nSet \napp_dir\n to \n/osg/app_dir\n\n\nSet \ndata_dir\n to \n/osg/data_dir\n\n\nDo \nmkdir -p /osg/app_dir/etc; mkdir -p /osg/data_dir; chmod 1777 /osg/app_dir{,/etc}\n\n\n\n\n\n\n\n\nEnable your batch system by setting \nenabled\n to \nTrue\n in \n20-<batch system>.ini\n\n\n\n\nSet up the site info in \n40-siteinfo.ini\n ; in particular, you'll need to set the \nresource\n and \nresource_group\n settings\n    \\ (you just need to pick a name; I concatenate my login name with the short host name and use that, e.g. matyasfermicloud001).\n    \\ You can also use the following settings:\n\n\ngroup=OSG-ITB\n\n\nsponsor=local\n\n\ncity=Batavia, IL\n\n\ncountry=US\n\n\nlongitude=-88\n\n\nlatitude=41\n\n\n\n\n\n\n\n\n\n\n\n\nEdit the file \n/etc/osg/config.d/30-infoservices.ini\n and set \nce_collectors\n to the collector host\n\n\n\n\nRun \nosg-configure -dc\n\n\nStart up your batch system\n\n\nRun \nservice condor-ce start\n\n\n\n\nThe CE will report to the collector host every five minutes. If you want to force it to send now, run \ncondor_ce_reconfig\n. You should see your CE if you run \ncondor_ce_status -schedd\n on the collector host.\n\n\nRSV\n\u00b6\n\n\nTesting a fresh installation:\n\n\n\n\nmake sure the yum repositories required by OSG is installed on your host\n\n\nrpm -Uvh \nhttp://repo.opensciencegrid.org/osg/3.4/osg-3.4-el7-release-latest.rpm\n OR rpm -Uvh \nhttp://repo.opensciencegrid.org/osg/3.4/osg-3.4-el6-release-latest.rpm\n\n\nalso make sure epel repo is set up. \n\n\n\n\n\n\ninstall the rpm\n\n\nyum --enablerepo=osg-testing install rsv \n\n\n\n\n\n\nedit /etc/osg/config.d/30-rsv.ini file\n\n\nin my case, I don't have a service cert for testing, so I use my own personal cert to create the proxy, but later on the owner of the proxy should be changed to \"rsv\" user that is created during the rpm install.\n\n\nin the config file, for the ce_hosts and gridftp_hosts, put in a test server, as the result from this test will be uploaded to OSG GOC, which may mess up your production service monitoring if you chose a production server for the test.\n\n\n\n\n\n\nosg-configure -v\n\n\nosg-configure -c\n\n\n/etc/init.d/condor-cron start\n\n\n/etc/init.d/rsv start\n\n\nrsv-control --list\n\n\nrsv-control --version\n\n\nrsv-control --run --all-enabled 11. make sure the results from the above commands look fine.\n\n\n\n\nTesting an upgrade installation:\n\n\n\n\nmake sure to enable the osg-testing repo, and set its priority higher than the other repos\n\n\nyum --enablerepo=osg-testing upgrade rsv*\n\n\nyou can use the old 30-rsv.ini file for configuration\n\n\nrepeat steps 4)~11) as mentioned in the last section.\n\n\n\n\nSlurm\n\u00b6\n\n\nThis section goes through the steps needed to set up a slurm install on a VM. This is a necessary prerequisite for testing Slurm related components (CE integration, gratia, etc.). Note that the slurm setup used for this uses weak passwords for mysql. It should be sufficient for a quick setup, testing, and then tear down but should not be used without changes if it will be running for any appreciable length of time.\n\n\n\n\nNote\n\n\nneed to have a VM with 2+ GB of memory\n\n\n\n\nInstallation and setup\n\u00b6\n\n\n\n\n\n\nDownload scripts and config files: \n\n\ncd /tmp/\ngit clone <https://github.com/sthapa/utilities.git>\ncd utilities/slurm\n\n\n\n\n\n\n\n\n\nsetup and install slurm components\n\n\nexport username='USERNAME' \\# user that jobs will run as\nexport version='14.11.7' \\# slurm version to install (e.g. 16.05.2 or 14.11.7)\n./slurm-setup.sh\n\n\n\n\n\n\n\n\n\nAfter successful completion, slurm and slurm gratia probes should be setup and enabled.\n\n\n\n\n\n\nRunning a job using slurm\n\u00b6\n\n\n\n\n\n\nGenerate test.sh with the following:\n\n\n#/bin/bash\necho \"In the directory: `pwd`\" echo \"As the user: `whoami`\" echo \u201cHostname:\" /bin/hostname sleep 60 </pre>\n\n\n\n\n\n\n\n\n\nrun \nsbatch test.sh\n\n\n\n\nthe output from the jobs should appear in the current working directory as \ntest.sh.[eo].nnnnn\n where nnnnn is a job id\n\n\n\n\nVO Client\n\u00b6\n\n\nThis document contains a basic recipe for testing a VO Package release\n\n\nPrerequisites\n\u00b6\n\n\nTesting the VO package requires a few components:\n   * X.509 certificate with membership to at least one VO\n   * System with working GUMS installation\n   * System with OSG installation (voms-proxy-init and edg-mkgridmap)\n\n\nTesting \nvoms-proxy-init\n\u00b6\n\n\nLogin in the system that has voms-proxy-init installed.  Make sure that you have the correct \nvo-client rpms installed and that your X.509 certificate is in your home directory.  For each\nVO that you have membership in, run the following \nvoms-proxy-init -voms [VO]\n where \n[VO]\n is \nthe appropriate VO (e.g. osg, cms, etc.).  You should be able to generate a voms-proxy for that\nVO without errors.\n\n\nXRootD VOMS Testing\n\u00b6\n\n\nThis section is intended for OSG Software/Release teams to gather information on testing vomsxrd/xrootd-voms-plugin package. Original plugin named \nvomsxrd\n, similar to lcmaps that extracts information for authorization within xrootd of a proxy's voms extension.\n\n\nYou need an \nxrootd server installation\n\n\nIn the xrootd server yum install the following packages:\n\n\n\n\nxrootd\n\n\nxrootd-voms-plugin\n\n\nvo-client\n\n\n\n\nIn the xrootd client yum install the following packages:\n\n\n\n\nxrootd-client\n\n\nvoms-clients\n\n\nvo-client\n\n\n\n\nIn the xrootd server add this lines to file \n/etc/xrootd/xrootd-clustered.cfg\n\n\nxrootd.seclib /usr/lib64/libXrdSec.so\nsec.protparm gsi -vomsfun:/usr/lib64/libXrdSecgsiVOMS.so -vomsfunparms:certfmt=raw|vos=cms|dbg -vomsat:2\nsec.protocol /usr/lib64 gsi -ca:1 -crl:3\n\n\n\n\n\nThis configuration will only authorize members of VO \ncms\n. You can change it to another VO.\n\n\nMake sure \nfetch-crl\n has been run otherwise the xrootd service may fail to start.\n\n\nIn the xrootd client get a proxy without voms extension or with another VO extension different that the one used in the configuration:\n\n\nuser@host $\n voms-proxy-init -voms mis\n\nEnter GRID pass phrase:\n\n\nYour identity: /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Edgar Mauricio Fajardo Hernandez 2020\n\n\nCreating temporary proxy ........................... Done\n\n\nContacting  voms.opensciencegrid.org:15001 [/DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=Services/CN=http/voms.opensciencegrid.org] \"mis\" Done\n\n\nCreating proxy ............................................... Done\n\n\nuser@host $\n xrdcp vomsxrdtest root://fermicloud024.fnal.gov:1094//tmp/\n\n[0B/0B][100%][==================================================][0B/s]  \n\n\nRun: [FATAL] Auth failed\n\n\n\n\n\n\nNow get a proxy with cms extension and run it again:\n\n\nuser@host $\n voms-proxy-init -voms cms\n\nEnter GRID pass phrase:\n\n\nYour identity: /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Edgar Mauricio Fajardo Hernandez 2020\n\n\nCreating temporary proxy ...................................... Done\n\n\nContacting  voms2.cern.ch:15002 [/DC=ch/DC=cern/OU=computers/CN=voms2.cern.ch] \"cms\" Done\n\n\nCreating proxy .......................................... Done\n\n\nYour proxy is valid until Thu Dec  4 22:53:29 2014\n\n\nuser@host $\n xrdcp vomsxrdtest root://fermicloud024.fnal.gov:1094//tmp/\n\n[0B/0B][100%][==================================================][0B/s] \n\n\n\n\n\n\nHDFS\n\u00b6\n\n\nHadoop name node installation\n\u00b6\n\n\nUse the following script with option 1:\n\n\n#!/bin/bash\nset -e\n\nselect NODETYPE in namenode datanode gridftp; do\n  [[ $NODETYPE ]] && break\ndone\ncase $NODETYPE in\n  namenode ) NAMENODE=$HOSTNAME ;;\n         * ) read -p 'hostname for NAMENODE? ' NAMENODE ;;\nesac\necho NODETYPE=$NODETYPE\necho NAMENODE=$NAMENODE\nread -p 'ok? [y/N] ' ok\ncase $ok in\n  y*|Y*) ;;  # ok\n      *) exit ;;\nesac\n#yum install --enablerepo=osg-minefield osg-se-hadoop-$NODETYPE\nyum install osg-se-hadoop-$NODETYPE\ncase $NODETYPE in\n  namenode|datanode )\n    mkdir -p /data/{hadoop,scratch,checkpoint}\n    chown -R hdfs:hdfs /data\n    sed -i s/NAMENODE/$NAMENODE/ /etc/hadoop/conf.osg/{core,hdfs}-site.xml\n    cp /etc/hadoop/conf.osg/{core,hdfs}-site.xml /etc/hadoop/conf/\n    touch /etc/hosts_exclude\n    ;;\n  gridftp )\n    ln -snf conf.osg /etc/hadoop/conf\n    sed -i s/NAMENODE/$NAMENODE/ /etc/hadoop/conf.osg/{core,hdfs}-site.xml\n    echo \"hadoop-fuse-dfs# /mnt/hadoop fuse server=$NAMENODE,port=9000,rdbuffer=131072,allow_other 0 0\" >> /etc/fstab\n    mkdir /mnt/hadoop\n    mount /mnt/hadoop\n    cp -v /etc/redhat-release /mnt/hadoop/test-file\n    sed -i '/globus_mapping/s/^# *//' /etc/grid-security/gsi-authz.conf\n    sed -i s/yourgums.yourdomain/gums.fnal.gov/ /etc/lcmaps.db\n    mkdir /mnt/hadoop/fnalgrid\n    useradd fnalgrid -g fnalgrid\n    chown fnalgrid:fnalgrid /mnt/hadoop/fnalgrid\n    service globus-gridftp-server start\n    if type -t globus-url-copy >/dev/null; then\n      globus-url-copy file:////bin/bash  gsiftp://$HOSTNAME/mnt/hadoop/fnalgrid/first_test\n    else\n      echo globus-url-copy not installed\n    fi\n    ;;\nesac\ncase $NODETYPE in\n  namenode ) su - hdfs -c \"hadoop namenode -format\" ;;\nesac\nservice hadoop-hdfs-$NODETYPE start\n\n\n\n\n\nEdit Configuration\n\u00b6\n\n\n\n\nEdit /etc/hadoop/conf/hdfs-site.xml\n\n\nset dfs.replication to 1   \n\n\nset dfs.replication.min to 1\n\n\n\n\n\n\n\n\nHadoop data node installation\n\u00b6\n\n\n\n\nRun same script as before but with option number 2.\n\n\n\n\nGridFTP installation\n\u00b6\n\n\nRun same as script but with option number 3.\n\n\nOn the name node\n\u00b6\n\n\n[root@fermicloud092 ~]#\n hdfs dfs -ls /test-file\n\nFound 1 items\n\n\n-rw-r--r--   2 root root          0 2014-07-21 15:57 /test-file\n\n\n\n\n\n\nOn the name node\n\u00b6\n\n\n[root@]#\n hadoop fs -mkdir /matyas\n\n[root@]#\n hadoop fs -chown matyas /matyas\n\n[root@]#\n hdfs dfsadmin -setSpaceQuota 123k /matyas\n\n\n\n\n\nuser@host $\n dd \nif\n=\n/dev/zero \nof\n=\n/tmp/blob \nbs\n=\n4096\n \ncount\n=\n10000\n\n\nuser@host $\n kx509\n;\n voms-proxy-init -noregen -voms fermilab\n\nuser@host $\n globus-url-copy -vb file:///tmp/blob gsiftp://\n`\nhostname -f\n`\n/mnt/hadoop/matyas\n\n\n\n\n\nXRootD Plugins\n\u00b6\n\n\n\n\n\n\nInstall xrootd-server:\n\n\nyum install xrootd-server\n\n\n\n\n\n\n\n\n\nInstall xrootd-plugins\n\n\nyum install xrootd-cmstfc xrootd-hdfs\n\n\n\n\n\n\n\n\n\nModify the file \n/etc/xrootd/xrootd-clustered.cfg\n to look like this:\n\n\nxrd.port 1094\n\n# The roles this server will play.                                                                                            \nall.role server\nall.role manager if xrootd.unl.edu\n# The known managers                                                                                                          \nall.manager srm.unl.edu:1213\n#all.manager xrootd.ultralight.org:1213                                                                                       \n\n# Allow any path to be exported; this is further refined in the authfile.                                                     \nall.export / nostage\n\n# Hosts allowed to use this xrootd cluster                                                                                    \ncms.allow host *\n\n### Standard directives                                                                                                       \n# Simple sites probably don't need to touch these.                                                                            \n# Logging verbosity                                                                                                           \nxrootd.trace all -debug\nofs.trace all -debug\nxrd.trace all -debug\ncms.trace all -debug\n\n# Integrate with CMS TFC, placed in /etc/storage.xml                                                                          \noss.namelib /usr/lib64/libXrdCmsTfc.so file:/etc/xrootd/storage.xml?protocol=hadoop\n\nxrootd.seclib /usr/lib64/libXrdSec.so\nxrootd.fslib /usr/lib64/libXrdOfs.so\nofs.osslib /usr/lib64/libXrdHdfs.so\nall.adminpath /var/run/xrootd\nall.pidpath /var/run/xrootd\n\ncms.delay startup 10\ncms.fxhold 60s\ncms.perf int 30s pgm /usr/bin/XrdOlbMonPerf 30\n\noss.space default_stage /opt/xrootd_cache\n\n\n\n\n\nCreate file \n/etc/xrootd/storage.xml\n and place this:\n\n\n<storage-mapping>\n<lfn-to-pfn protocol=\"hadoop\" destination-match=\".*\" path-match=\".*/+tmp2/test-file\" result=\"/test-file\"/>\n</storage-mapping>\n\n\n\n\n\nFor el7 the instrucctions are a little bit different. See:\n\n\nhttps://jira.opensciencegrid.org/browse/SOFTWARE-2198?focusedCommentId=334667&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-334667\n\n\nNow from a node do:\n\n\nxrdcp --debug 3 root://yourdatanode.yourdomain:1094//tmp2/test-file .\n\n\n\n\n\n\nIf it is sucessful it would have tested both cmstfc and hdfs plugins",
            "title": "Acceptance Testing"
        },
        {
            "location": "/release/acceptance-testing/#acceptance-testing",
            "text": "The OSG Release Team collects and maintains testing procedures for major components in the OSG Sofware Stack. These test should verify that basic functionality of the component works in typically deployed configurations.",
            "title": "Acceptance Testing"
        },
        {
            "location": "/release/acceptance-testing/#cvmfs",
            "text": "Note  This acceptance testing recipe was created when access to a machine with sufficient disk space to make a complete replica of OASIS was not available.",
            "title": "CVMFS"
        },
        {
            "location": "/release/acceptance-testing/#creating-a-cvmfs-repository-server-stratum-0",
            "text": "Disable SELinux by setting the following in  /etc/selinux/config .  SELINUX=disabled    Check kernel version.  uname -a     CVMFS for EL7 requires OverlayFS (as of kernel version 4.2.x). If default kernel is <= 4.2.x, update kernel.  root@host #  rpm --import <https://www.elrepo.org/RPM-GPG-KEY-elrepo.org> root@host #  rpm -Uvh <http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm> root@host #  yum install yum-plugin-fastestmirror root@host #  yum --enablerepo = elrepo-kernel install kernel-ml    Select updated kernel by editing  /etc/default/grub .  GRUB_DEFAULT=0  and run:  root@host #  grub2-mkconfig -o /boot/grub2/grub.cfg    Reboot system.     Check kernel version again and make sure SELinux is disabled.  root@host #  uname -a root@host #  sestatus    If kernel >= 4.2 and SELinux is disabled, then update system and install CVMFS server and client packages.  root@host #  yum update root@host #  yum install epel-release root@host #  yum install yum-plugin-priorities root@host #  rpm -Uvh <https://repo.opensciencegrid.org/osg/3.3/osg-3.3-el7-release-latest.rpm> root@host #  yum install cvmfs cvmfs-server    Configure web server and start it up. Edit  /etc/httpd/conf.d/cvmfs.conf :  Listen 8000\nKeepAlive On  and run:  root@host #  chkconfig httpd on root@host #  service httpd start    Make new repository.  root@host #  cvmfs_server mkfs test.cvmfs-stratum-0.novalocal    Run transaction on new repository to enable write access.  root@host #  cvmfs_server transaction test.cvmfs-stratum-0.novalocal    Place some sample code in new repository directory and then publish it.  root@host #   cd  /cvmfs/test.cvmfs-stratum-0.novalocal root@host #  vi  [ bash \\_ pi.sh ]( %ATTACHURL%/bash_pi.sh )  root@host #  chmod +x bash \\_ pi.sh root@host #  cvmfs \\_ server publish test.cvmfs-stratum-0.novalocal    Check repository status after publication.  root@host #  cvmfs \\_ server check root@host #  cvmfs \\_ server tag root@host #  wget -qO- <http://localhost:8000/cvmfs/test.cvmfs-stratum-0.novalocal/.cvmfswhitelist%7Ccat> -v    Download a copy of the CVMFS repository's public key e.g., /etc/cvmfs/keys/test.cvmfs-stratum-0.novalocal.pub",
            "title": "Creating a CVMFS Repository Server (Stratum 0)"
        },
        {
            "location": "/release/acceptance-testing/#creating-a-cvmfs-replica-server-stratum-1",
            "text": "Repeat steps 1 though 8 in the previous section on \"Creating a CVMFS Repository Server \". However, now also install  mod_wsgi .  root@host #  yum install cvmfs cvmfs-server mod \\_ wsgi    Upload a copy of the CVMFS repository's public key and place in  /etc/cvmfs/keys  directory.     Add replica of the repository.  root@host #  cvmfs_server add-replica -o root <http://10.128.3.96:8000/cvmfs/test.cvmfs-stratum-0.novalocal> /etc/cvmfs/keys/test.cvmfs-stratum-0.novalocal.pub    Make a snapshot of the repository.  root@host #  cvmfs \\_ server snapshot test.cvmfs-stratum-0.novalocal",
            "title": "Creating a CVMFS Replica Server (Stratum 1)"
        },
        {
            "location": "/release/acceptance-testing/#creating-a-cvmfs-client",
            "text": "Update system and install CVMFS client package.  root@host #  yum update root@host #  yum install epel-release root@host #  yum install yum-plugin-priorities root@host #  rpm -Uvh <https://repo.opensciencegrid.org/osg/3.3/osg-3.3-el7-release-latest.rpm> root@host #  yum install cvmfs    Upload a copy of the CVMFS repository's public key and place in  /etc/cvmfs/keys  directory.    Edit fuse configuration  /etc/fuse.conf .  user_allow_other    Edit autofs configuration and restart service  /etc/auto.master .  /cvmfs /etc/auto.cvmfs  and run:  root@host #  service autofs restart    Edit cvmfs configuration ( /etc/cvmfs/default.local ) to point to replica server.  CVMFS_SERVER_URL=\"http://10.128.3.97:8000/cvmfs/@fqrn@\"\nCVMFS_REPOSITORIES=\"test.cvmfs-stratum-0.novalocal\"\nCVMFS_HTTP_PROXY=DIRECT    Remove OSG CVMFS configuration file.  rm /etc/cvmfs/default.d/60-osg.conf     Run CVMFS config probe.  cvmfs_config probe test.cvmfs-stratum-0.novalocal     Check CVMFS config status.  cvmfs_config stat -v test.cvmfs-stratum-0.novalocal     Execute sample code published to repository from client.  /cvmfs/test.cvmfs-stratum-0.novalocal/bash_pi.sh -b 8 -r 5 -s 10000",
            "title": "Creating a CVMFS client"
        },
        {
            "location": "/release/acceptance-testing/#creating-an-oasis-client",
            "text": "Update system and install CVMFS client package.  yum update  yum install epel-release  yum install yum-plugin-priorities  rpm -Uvh  https://repo.opensciencegrid.org/osg/3.3/osg-3.3-el7-release-latest.rpm  yum install osg-oasis     Verify latest versions of cvmfs, cvmfs-config-osg, and cvmfs-x509-helper have been installed.   Edit fuse configuration.  vi /etc/fuse.conf  user_allow_other       Edit cvmfs configuration to point to replica server.  vi /etc/cvmfs/default.local  CVMFS_REPOSITORIES=\"`echo $((echo oasis.opensciencegrid.org;echo cms.cern.ch;ls /cvmfs)|sort -u)|tr ' ' ,`\"  CVMFS_QUOTA_LIMIT=20000  CVMFS_HTTP_PROXY=DIRECT      Edit autofs configuration and restart service.  vi /etc/auto.master  /cvmfs /etc/auto.cvmfs    service autofs restart    Run CVMFS config probe.  cvmfs_config probe     Check CVMFS config status.  cvmfs_config stat -v oasis.opensciencegrid.org",
            "title": "Creating an OASIS client"
        },
        {
            "location": "/release/acceptance-testing/#additional-documentation",
            "text": "CERN's CVMFS Documentation  OSG's CVMFS Replica Server  OSG's CVMFS Client Documentation   OSG's OASIS Documentation    bash_pi.sh : A bash script that uses a simple Monte Carlo method to estimate the value of Pi",
            "title": "Additional Documentation"
        },
        {
            "location": "/release/acceptance-testing/#gratia-probe",
            "text": "This section documents the testing procedure to test the gratia probes sufficiently tested to be promoted to the osg-testing repository. The test procedure is the same on both SL6 and SL7.   install or update the  gratia-probe-condor  rpm as appropriate  On each VM download the gratia-probe-setup.sh script and run it  In  /etc/gratia/condor/ProbeConfig , verify the following have been changed:  change  SiteName  to something aside from  Generic Site  change  EnableProbe  to 1  change  CollectorHost ,  SSLHost , and  SSLRegistrationHost  to the an invalid host (E.g. test.com) or the localhost    Create  /var/lib/osg/  and download the attached  user-vo-map  file and place it in that directory  Edit the  user-vo-map  file and change the account from  sthapa  to the account you'll be using to submit the condor jobs in the following step  Download and submit the attached condor_submit file (note, on the default fermicloud VM, this takes about 3 hours, so you may want to set  NUM_CPUS  to 50 so that 50 jobs will run at a time)  Run  /usr/share/gratia/condor/condor_meter  Check  /var/lib/gratia/tmp/gratiafiles/  for a  subdir.condor_...  directory and verify that there are 200 xml jobs and the cpus/wall times are appropriate (either PT0S or PT1M).",
            "title": "Gratia Probe"
        },
        {
            "location": "/release/acceptance-testing/#gsi-openssh",
            "text": "Note  Fermicloud policy forbids running the GSI OpenSSH server.\nYou will have to test that part locally.   To test a fresh installation:   Spin up two VM's and set up the EPEL/OSG repos on both of them.  Choose one of the VM's, it will be the server VM. The hostname of this machine will be referenced below as the  <SERVER HOSTNAME> \n    Consult these  instructions  to set up the server.   From the other VM (client):    Install the necessary packages:  root@host #  yum install globus-proxy-utils gsi-openssh-clients    Initialize your proxy. After this, none of the gsi commands should prompt you for your password.    Connect to the server:  user@host $  gsissh -p  2222  <SERVER HOSTNAME>    Copy a test file to the server:  user@host $  gsiscp -p  2222  testfile <SERVER HOSTNAME>:/tmp    Connect to the server via SFTP and grab files:  user@host $  gsisftp -P  2222  <SERVER HOSTNAME> user@host $   cd  /tmp user@host $  get testfile",
            "title": "GSI OpenSSH"
        },
        {
            "location": "/release/acceptance-testing/#htcondor-ce-collector-wip",
            "text": "The CE Collector is a stripped-down version of HTCondor-CE that contains mostly just the collector daemon and configs. It was introduced in htcondor-ce-1.6. The production CE Collectors run at the GOC, but you may want to set up your own for testing.   Make 2 VMs with the EPEL/OSG repos installed: one for the collector, and one for the CE",
            "title": "HTCondor-CE Collector (WIP)"
        },
        {
            "location": "/release/acceptance-testing/#setting-up-the-collector",
            "text": "Install  htcondor-ce-collector   Create a file called  /etc/condor-ce/config.d/99-local.conf  that contains this line:  COLLECTOR.ALLOW_ADVERTISE_SCHEDD = $(COLLECTOR.ALLOW_ADVERTISE_SCHEDD), your_htcondor_ce_host.example.net</pre>  (with  your_htcondor_ce_host  replaced by the hostname the HTCondor-CE VM)    Run  service condor-ce-collector start",
            "title": "Setting Up the Collector"
        },
        {
            "location": "/release/acceptance-testing/#setting-up-the-ce",
            "text": "Install  osg-htcondor-ce-condor  (replace condor with the batch system of your choice)  Ensure osg-configure >= 1.0.60-2 is installed   Configure your CE using osg-configure   You should use the  HTCondor-CE Install Docs  as a reference, although you can skip several of the steps  You can skip setting up Squid: set  enabled  to  True  and  location  to  UNAVAILABLE  in  01-squid.ini  Set  htcondor_gateway_enabled  to  True  in  10-gateway.ini  You probably don't need GUMS, but if you want it, use the Fermi GUMS server (set  gums_host  to  gums.fnal.gov  and  authorization_method  to  xacml  in 10-misc.ini)   To keep osg-configure from complaining about storage, edit  10-storage.ini :   Set  se_available  to  False  Set  app_dir  to  /osg/app_dir  Set  data_dir  to  /osg/data_dir  Do  mkdir -p /osg/app_dir/etc; mkdir -p /osg/data_dir; chmod 1777 /osg/app_dir{,/etc}     Enable your batch system by setting  enabled  to  True  in  20-<batch system>.ini   Set up the site info in  40-siteinfo.ini  ; in particular, you'll need to set the  resource  and  resource_group  settings\n    \\ (you just need to pick a name; I concatenate my login name with the short host name and use that, e.g. matyasfermicloud001).\n    \\ You can also use the following settings:  group=OSG-ITB  sponsor=local  city=Batavia, IL  country=US  longitude=-88  latitude=41       Edit the file  /etc/osg/config.d/30-infoservices.ini  and set  ce_collectors  to the collector host   Run  osg-configure -dc  Start up your batch system  Run  service condor-ce start   The CE will report to the collector host every five minutes. If you want to force it to send now, run  condor_ce_reconfig . You should see your CE if you run  condor_ce_status -schedd  on the collector host.",
            "title": "Setting Up the CE"
        },
        {
            "location": "/release/acceptance-testing/#rsv",
            "text": "Testing a fresh installation:   make sure the yum repositories required by OSG is installed on your host  rpm -Uvh  http://repo.opensciencegrid.org/osg/3.4/osg-3.4-el7-release-latest.rpm  OR rpm -Uvh  http://repo.opensciencegrid.org/osg/3.4/osg-3.4-el6-release-latest.rpm  also make sure epel repo is set up.     install the rpm  yum --enablerepo=osg-testing install rsv     edit /etc/osg/config.d/30-rsv.ini file  in my case, I don't have a service cert for testing, so I use my own personal cert to create the proxy, but later on the owner of the proxy should be changed to \"rsv\" user that is created during the rpm install.  in the config file, for the ce_hosts and gridftp_hosts, put in a test server, as the result from this test will be uploaded to OSG GOC, which may mess up your production service monitoring if you chose a production server for the test.    osg-configure -v  osg-configure -c  /etc/init.d/condor-cron start  /etc/init.d/rsv start  rsv-control --list  rsv-control --version  rsv-control --run --all-enabled 11. make sure the results from the above commands look fine.   Testing an upgrade installation:   make sure to enable the osg-testing repo, and set its priority higher than the other repos  yum --enablerepo=osg-testing upgrade rsv*  you can use the old 30-rsv.ini file for configuration  repeat steps 4)~11) as mentioned in the last section.",
            "title": "RSV"
        },
        {
            "location": "/release/acceptance-testing/#slurm",
            "text": "This section goes through the steps needed to set up a slurm install on a VM. This is a necessary prerequisite for testing Slurm related components (CE integration, gratia, etc.). Note that the slurm setup used for this uses weak passwords for mysql. It should be sufficient for a quick setup, testing, and then tear down but should not be used without changes if it will be running for any appreciable length of time.   Note  need to have a VM with 2+ GB of memory",
            "title": "Slurm"
        },
        {
            "location": "/release/acceptance-testing/#installation-and-setup",
            "text": "Download scripts and config files:   cd /tmp/\ngit clone <https://github.com/sthapa/utilities.git>\ncd utilities/slurm    setup and install slurm components  export username='USERNAME' \\# user that jobs will run as\nexport version='14.11.7' \\# slurm version to install (e.g. 16.05.2 or 14.11.7)\n./slurm-setup.sh    After successful completion, slurm and slurm gratia probes should be setup and enabled.",
            "title": "Installation and setup"
        },
        {
            "location": "/release/acceptance-testing/#running-a-job-using-slurm",
            "text": "Generate test.sh with the following:  #/bin/bash\necho \"In the directory: `pwd`\" echo \"As the user: `whoami`\" echo \u201cHostname:\" /bin/hostname sleep 60 </pre>    run  sbatch test.sh   the output from the jobs should appear in the current working directory as  test.sh.[eo].nnnnn  where nnnnn is a job id",
            "title": "Running a job using slurm"
        },
        {
            "location": "/release/acceptance-testing/#vo-client",
            "text": "This document contains a basic recipe for testing a VO Package release",
            "title": "VO Client"
        },
        {
            "location": "/release/acceptance-testing/#prerequisites",
            "text": "Testing the VO package requires a few components:\n   * X.509 certificate with membership to at least one VO\n   * System with working GUMS installation\n   * System with OSG installation (voms-proxy-init and edg-mkgridmap)",
            "title": "Prerequisites"
        },
        {
            "location": "/release/acceptance-testing/#testing-voms-proxy-init",
            "text": "Login in the system that has voms-proxy-init installed.  Make sure that you have the correct \nvo-client rpms installed and that your X.509 certificate is in your home directory.  For each\nVO that you have membership in, run the following  voms-proxy-init -voms [VO]  where  [VO]  is \nthe appropriate VO (e.g. osg, cms, etc.).  You should be able to generate a voms-proxy for that\nVO without errors.",
            "title": "Testing voms-proxy-init"
        },
        {
            "location": "/release/acceptance-testing/#xrootd-voms-testing",
            "text": "This section is intended for OSG Software/Release teams to gather information on testing vomsxrd/xrootd-voms-plugin package. Original plugin named  vomsxrd , similar to lcmaps that extracts information for authorization within xrootd of a proxy's voms extension.  You need an  xrootd server installation  In the xrootd server yum install the following packages:   xrootd  xrootd-voms-plugin  vo-client   In the xrootd client yum install the following packages:   xrootd-client  voms-clients  vo-client   In the xrootd server add this lines to file  /etc/xrootd/xrootd-clustered.cfg  xrootd.seclib /usr/lib64/libXrdSec.so\nsec.protparm gsi -vomsfun:/usr/lib64/libXrdSecgsiVOMS.so -vomsfunparms:certfmt=raw|vos=cms|dbg -vomsat:2\nsec.protocol /usr/lib64 gsi -ca:1 -crl:3  This configuration will only authorize members of VO  cms . You can change it to another VO.  Make sure  fetch-crl  has been run otherwise the xrootd service may fail to start.  In the xrootd client get a proxy without voms extension or with another VO extension different that the one used in the configuration:  user@host $  voms-proxy-init -voms mis Enter GRID pass phrase:  Your identity: /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Edgar Mauricio Fajardo Hernandez 2020  Creating temporary proxy ........................... Done  Contacting  voms.opensciencegrid.org:15001 [/DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=Services/CN=http/voms.opensciencegrid.org] \"mis\" Done  Creating proxy ............................................... Done  user@host $  xrdcp vomsxrdtest root://fermicloud024.fnal.gov:1094//tmp/ [0B/0B][100%][==================================================][0B/s]    Run: [FATAL] Auth failed   Now get a proxy with cms extension and run it again:  user@host $  voms-proxy-init -voms cms Enter GRID pass phrase:  Your identity: /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Edgar Mauricio Fajardo Hernandez 2020  Creating temporary proxy ...................................... Done  Contacting  voms2.cern.ch:15002 [/DC=ch/DC=cern/OU=computers/CN=voms2.cern.ch] \"cms\" Done  Creating proxy .......................................... Done  Your proxy is valid until Thu Dec  4 22:53:29 2014  user@host $  xrdcp vomsxrdtest root://fermicloud024.fnal.gov:1094//tmp/ [0B/0B][100%][==================================================][0B/s]",
            "title": "XRootD VOMS Testing"
        },
        {
            "location": "/release/acceptance-testing/#hdfs",
            "text": "",
            "title": "HDFS"
        },
        {
            "location": "/release/acceptance-testing/#hadoop-name-node-installation",
            "text": "Use the following script with option 1:  #!/bin/bash\nset -e\n\nselect NODETYPE in namenode datanode gridftp; do\n  [[ $NODETYPE ]] && break\ndone\ncase $NODETYPE in\n  namenode ) NAMENODE=$HOSTNAME ;;\n         * ) read -p 'hostname for NAMENODE? ' NAMENODE ;;\nesac\necho NODETYPE=$NODETYPE\necho NAMENODE=$NAMENODE\nread -p 'ok? [y/N] ' ok\ncase $ok in\n  y*|Y*) ;;  # ok\n      *) exit ;;\nesac\n#yum install --enablerepo=osg-minefield osg-se-hadoop-$NODETYPE\nyum install osg-se-hadoop-$NODETYPE\ncase $NODETYPE in\n  namenode|datanode )\n    mkdir -p /data/{hadoop,scratch,checkpoint}\n    chown -R hdfs:hdfs /data\n    sed -i s/NAMENODE/$NAMENODE/ /etc/hadoop/conf.osg/{core,hdfs}-site.xml\n    cp /etc/hadoop/conf.osg/{core,hdfs}-site.xml /etc/hadoop/conf/\n    touch /etc/hosts_exclude\n    ;;\n  gridftp )\n    ln -snf conf.osg /etc/hadoop/conf\n    sed -i s/NAMENODE/$NAMENODE/ /etc/hadoop/conf.osg/{core,hdfs}-site.xml\n    echo \"hadoop-fuse-dfs# /mnt/hadoop fuse server=$NAMENODE,port=9000,rdbuffer=131072,allow_other 0 0\" >> /etc/fstab\n    mkdir /mnt/hadoop\n    mount /mnt/hadoop\n    cp -v /etc/redhat-release /mnt/hadoop/test-file\n    sed -i '/globus_mapping/s/^# *//' /etc/grid-security/gsi-authz.conf\n    sed -i s/yourgums.yourdomain/gums.fnal.gov/ /etc/lcmaps.db\n    mkdir /mnt/hadoop/fnalgrid\n    useradd fnalgrid -g fnalgrid\n    chown fnalgrid:fnalgrid /mnt/hadoop/fnalgrid\n    service globus-gridftp-server start\n    if type -t globus-url-copy >/dev/null; then\n      globus-url-copy file:////bin/bash  gsiftp://$HOSTNAME/mnt/hadoop/fnalgrid/first_test\n    else\n      echo globus-url-copy not installed\n    fi\n    ;;\nesac\ncase $NODETYPE in\n  namenode ) su - hdfs -c \"hadoop namenode -format\" ;;\nesac\nservice hadoop-hdfs-$NODETYPE start",
            "title": "Hadoop name node installation"
        },
        {
            "location": "/release/acceptance-testing/#edit-configuration",
            "text": "Edit /etc/hadoop/conf/hdfs-site.xml  set dfs.replication to 1     set dfs.replication.min to 1",
            "title": "Edit Configuration"
        },
        {
            "location": "/release/acceptance-testing/#hadoop-data-node-installation",
            "text": "Run same script as before but with option number 2.",
            "title": "Hadoop data node installation"
        },
        {
            "location": "/release/acceptance-testing/#gridftp-installation",
            "text": "Run same as script but with option number 3.",
            "title": "GridFTP installation"
        },
        {
            "location": "/release/acceptance-testing/#on-the-name-node",
            "text": "[root@fermicloud092 ~]#  hdfs dfs -ls /test-file Found 1 items  -rw-r--r--   2 root root          0 2014-07-21 15:57 /test-file",
            "title": "On the name node"
        },
        {
            "location": "/release/acceptance-testing/#on-the-name-node_1",
            "text": "[root@]#  hadoop fs -mkdir /matyas [root@]#  hadoop fs -chown matyas /matyas [root@]#  hdfs dfsadmin -setSpaceQuota 123k /matyas  user@host $  dd  if = /dev/zero  of = /tmp/blob  bs = 4096   count = 10000  user@host $  kx509 ;  voms-proxy-init -noregen -voms fermilab user@host $  globus-url-copy -vb file:///tmp/blob gsiftp:// ` hostname -f ` /mnt/hadoop/matyas",
            "title": "On the name node"
        },
        {
            "location": "/release/acceptance-testing/#xrootd-plugins",
            "text": "Install xrootd-server:  yum install xrootd-server    Install xrootd-plugins  yum install xrootd-cmstfc xrootd-hdfs    Modify the file  /etc/xrootd/xrootd-clustered.cfg  to look like this:  xrd.port 1094\n\n# The roles this server will play.                                                                                            \nall.role server\nall.role manager if xrootd.unl.edu\n# The known managers                                                                                                          \nall.manager srm.unl.edu:1213\n#all.manager xrootd.ultralight.org:1213                                                                                       \n\n# Allow any path to be exported; this is further refined in the authfile.                                                     \nall.export / nostage\n\n# Hosts allowed to use this xrootd cluster                                                                                    \ncms.allow host *\n\n### Standard directives                                                                                                       \n# Simple sites probably don't need to touch these.                                                                            \n# Logging verbosity                                                                                                           \nxrootd.trace all -debug\nofs.trace all -debug\nxrd.trace all -debug\ncms.trace all -debug\n\n# Integrate with CMS TFC, placed in /etc/storage.xml                                                                          \noss.namelib /usr/lib64/libXrdCmsTfc.so file:/etc/xrootd/storage.xml?protocol=hadoop\n\nxrootd.seclib /usr/lib64/libXrdSec.so\nxrootd.fslib /usr/lib64/libXrdOfs.so\nofs.osslib /usr/lib64/libXrdHdfs.so\nall.adminpath /var/run/xrootd\nall.pidpath /var/run/xrootd\n\ncms.delay startup 10\ncms.fxhold 60s\ncms.perf int 30s pgm /usr/bin/XrdOlbMonPerf 30\n\noss.space default_stage /opt/xrootd_cache  Create file  /etc/xrootd/storage.xml  and place this:  <storage-mapping>\n<lfn-to-pfn protocol=\"hadoop\" destination-match=\".*\" path-match=\".*/+tmp2/test-file\" result=\"/test-file\"/>\n</storage-mapping>  For el7 the instrucctions are a little bit different. See:  https://jira.opensciencegrid.org/browse/SOFTWARE-2198?focusedCommentId=334667&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-334667  Now from a node do:  xrdcp --debug 3 root://yourdatanode.yourdomain:1094//tmp2/test-file .   If it is sucessful it would have tested both cmstfc and hdfs plugins",
            "title": "XRootD Plugins"
        },
        {
            "location": "/policy/campus-cyberinfrastructure/",
            "text": "The OSG and NSF Campus Cyberinfrastructure\n\u00b6\n\n\nThe NSF Campus Cyberinfrastructure (CC*) program invests in coordinated campus-level networking and cyberinfrastructure\nimprovements, innovation, integration, and engineering for science applications and distributed research projects.\n\n\nIn the most recent call for proposals (\nNSF 20-507\n), joining the\n\nOpen Science Grid\n (OSG) is mentioned as a potential path to sharing resources with\nthe wider research community:\n\n\n\n\nProposals should commit to a minimum of 20% shared time on the cluster and describe their approach to making the\ncluster available as a shared resource external to the campus. [...]\n\nOne possible approach to implementing such a federated distributed computing solution is joining the Open Science\nGrid.\n\n\n\n\nContributing to the OSG\n\u00b6\n\n\nThe OSG consortium provides common services and support for computational resource providers (i.e., \"sites\") using a\n\ndistributed fabric\n of high throughput computational (HTC) services.\nThese distributed-HTC (dHTC) services communicate with the site's autonomous resource management systems to provision\nresources for OSG users.\nThe OSG itself does not own resources but provides software and services to users and resource providers alike to enable\nthe sharing of resources across physical and administrative boundaries.\n\n\nTo contribute computational resources to the OSG, the following will be needed:\n\n\n\n\nAn existing compute cluster running on a \nsupported operating system\n\n  with a supported resource management system:\n  \nGrid Engine\n,\n  \nHTCondor\n,\n  \nLSF\n,\n  \nPBS Pro\n/\nTorque\n,\n  or \nSlurm\n.\n\n\nOutbound network connectivity from the cluster's worker nodes\n\n\nTemporary scratch space\n on each\n  worker node\n\n\nSSH access to your local cluster's submit node from a known IP address\n\n\nShared home directories on each cluster node\n\n\n\n\n\n\nNext steps\n\n\nIf you are interested in OSG-offered services, please \ncontact us\n for a\nconsultation, even if your site does not meet all the conditions as outlined above!\n\n\n\n\nAdditional Materials\n\u00b6\n\n\nIf you are interested in learning more about the OSG and what it means to share resources via the OSG services, consider\nreviewing the following slides that were presented at the recent CC* PI meeting:\n\n\n\n\nIntroduction to OSG and OSG Participants\n\n\nHow Resources are Shared and Used via OSG\n\n\nHosted CE options/process and implementation\n\n\nUsing and Facilitating the Use of OSG Resources",
            "title": "Campus Cyberinfrastructure"
        },
        {
            "location": "/policy/campus-cyberinfrastructure/#the-osg-and-nsf-campus-cyberinfrastructure",
            "text": "The NSF Campus Cyberinfrastructure (CC*) program invests in coordinated campus-level networking and cyberinfrastructure\nimprovements, innovation, integration, and engineering for science applications and distributed research projects.  In the most recent call for proposals ( NSF 20-507 ), joining the Open Science Grid  (OSG) is mentioned as a potential path to sharing resources with\nthe wider research community:   Proposals should commit to a minimum of 20% shared time on the cluster and describe their approach to making the\ncluster available as a shared resource external to the campus. [...] One possible approach to implementing such a federated distributed computing solution is joining the Open Science\nGrid.",
            "title": "The OSG and NSF Campus Cyberinfrastructure"
        },
        {
            "location": "/policy/campus-cyberinfrastructure/#contributing-to-the-osg",
            "text": "The OSG consortium provides common services and support for computational resource providers (i.e., \"sites\") using a distributed fabric  of high throughput computational (HTC) services.\nThese distributed-HTC (dHTC) services communicate with the site's autonomous resource management systems to provision\nresources for OSG users.\nThe OSG itself does not own resources but provides software and services to users and resource providers alike to enable\nthe sharing of resources across physical and administrative boundaries.  To contribute computational resources to the OSG, the following will be needed:   An existing compute cluster running on a  supported operating system \n  with a supported resource management system:\n   Grid Engine ,\n   HTCondor ,\n   LSF ,\n   PBS Pro / Torque ,\n  or  Slurm .  Outbound network connectivity from the cluster's worker nodes  Temporary scratch space  on each\n  worker node  SSH access to your local cluster's submit node from a known IP address  Shared home directories on each cluster node    Next steps  If you are interested in OSG-offered services, please  contact us  for a\nconsultation, even if your site does not meet all the conditions as outlined above!",
            "title": "Contributing to the OSG"
        },
        {
            "location": "/policy/campus-cyberinfrastructure/#additional-materials",
            "text": "If you are interested in learning more about the OSG and what it means to share resources via the OSG services, consider\nreviewing the following slides that were presented at the recent CC* PI meeting:   Introduction to OSG and OSG Participants  How Resources are Shared and Used via OSG  Hosted CE options/process and implementation  Using and Facilitating the Use of OSG Resources",
            "title": "Additional Materials"
        },
        {
            "location": "/policy/cream-support/",
            "text": "OSG/HTCondor CREAM-CE Support\n\u00b6\n\n\nThe CREAM working group has \nrecently announced\n official support for the\nCREAM-CE will cease in December 2020.  With this email, we are soliciting\nfeedback on OSG and HTCondor\u2019s transition plan.  OSG and HTCondor remain committed\nto supporting VOs who need to access to CREAM-CE based resources throughout the\ntransition period; we will continue to support submission to CREAM-CE endpoints\nand offer assistance to VOs to manage the transition.\n\n\nOSG runs a glidein submission service that submits to grid infrastructures worldwide\non behalf of dozens of science projects.  This service currently submits to\napproximately 100 CREAM-CE endpoints; we will continue to maintain the capability\nto access these endpoints while we assist sites in testing and enabling ARC-CE\nand/or HTCondor-CE replacement services.\n\n\nThe HTCondor team plans to support the CREAM-CE on EL6/7 in the 8.8.x stable release\nseries and will maintain support for 8.8.x through December 2020.  CREAM-CE support\nwill remain enabled at the start of the 8.9.x developer series; in early 2020, the\nHTCondor team will re-evaluate, based on community need, whether CREAM-CE support\nwill be available in the next stable series.\n\n\nWe realize that software retirements can be very disruptive; the OSG and HTCondor\nteams are committed to assisting user communities through the process.  If you\nbelieve our plan does not fit the needs of your user community, please contact\n\nhelp@opensciencegrid.org\n.\n\n\nRegards,\n\n\nBrian Bockelman, OSG Technology Area Coordinator\n\n\nTodd Tannenbaum, HTCondor Technical Lead\n\n\nReference\n\u00b6\n\n\nEGI broadcast about CREAM retirement\n;\nthe EGI link requires authentication; statement has been reproduced below:\n\n\n\n\nDear Users \n\n\nThe CREAM working group has announced that official support for the CREAM-CE component will\ncease at the end of the EOSC-hub project, i.e. in Dec 2020. To prepare for this, EGI\nFoundation and CERN are actively working to help to minimise disruption. This will include\nhelping users migrate to alternative solutions, i.e. ARC-CE or HTCondor-CE. \n\n\nThe CREAM working group will be providing full support until the end of 2019, including one\nminor release already scheduled. During 2020 only security updates will be released. \n\n\nIf you have any concerns or queries, please open a support ticket at https://ggus.eu/ \n\n\nBest regards \n\n\nEGI Foundation and CERN Operations Teams",
            "title": "CREAM-CE Support"
        },
        {
            "location": "/policy/cream-support/#osghtcondor-cream-ce-support",
            "text": "The CREAM working group has  recently announced  official support for the\nCREAM-CE will cease in December 2020.  With this email, we are soliciting\nfeedback on OSG and HTCondor\u2019s transition plan.  OSG and HTCondor remain committed\nto supporting VOs who need to access to CREAM-CE based resources throughout the\ntransition period; we will continue to support submission to CREAM-CE endpoints\nand offer assistance to VOs to manage the transition.  OSG runs a glidein submission service that submits to grid infrastructures worldwide\non behalf of dozens of science projects.  This service currently submits to\napproximately 100 CREAM-CE endpoints; we will continue to maintain the capability\nto access these endpoints while we assist sites in testing and enabling ARC-CE\nand/or HTCondor-CE replacement services.  The HTCondor team plans to support the CREAM-CE on EL6/7 in the 8.8.x stable release\nseries and will maintain support for 8.8.x through December 2020.  CREAM-CE support\nwill remain enabled at the start of the 8.9.x developer series; in early 2020, the\nHTCondor team will re-evaluate, based on community need, whether CREAM-CE support\nwill be available in the next stable series.  We realize that software retirements can be very disruptive; the OSG and HTCondor\nteams are committed to assisting user communities through the process.  If you\nbelieve our plan does not fit the needs of your user community, please contact help@opensciencegrid.org .  Regards,  Brian Bockelman, OSG Technology Area Coordinator  Todd Tannenbaum, HTCondor Technical Lead",
            "title": "OSG/HTCondor CREAM-CE Support"
        },
        {
            "location": "/policy/cream-support/#reference",
            "text": "EGI broadcast about CREAM retirement ;\nthe EGI link requires authentication; statement has been reproduced below:   Dear Users   The CREAM working group has announced that official support for the CREAM-CE component will\ncease at the end of the EOSC-hub project, i.e. in Dec 2020. To prepare for this, EGI\nFoundation and CERN are actively working to help to minimise disruption. This will include\nhelping users migrate to alternative solutions, i.e. ARC-CE or HTCondor-CE.   The CREAM working group will be providing full support until the end of 2019, including one\nminor release already scheduled. During 2020 only security updates will be released.   If you have any concerns or queries, please open a support ticket at https://ggus.eu/   Best regards   EGI Foundation and CERN Operations Teams",
            "title": "Reference"
        },
        {
            "location": "/policy/service-migrations-spring-2018/",
            "text": "Service Migrations - Spring 2018\n\u00b6\n\n\nThe Open Science Grid (OSG) has transitioned effort from Indiana, requiring a redistribution of support and services.\nSome services were retired, most services were migrated to other locations (with minimal expected sites impact),\nand some services were migrated that resulted in significant impact on sites.\n\n\nThis document was intended to guide OSG site administrators through these changes, highlighting where the site\nadministrator action is required.\n\n\nIf you have questions or concerns that are not addressed in this document, see the \nGetting Help section\n\nfor details.\n\n\nGetting Help\n\u00b6\n\n\nIf you have questions or concerns that are not addressed in this document, please contact us at the usual locations:\n\n\n\n\nhelp@opensciencegrid.org\n\n\nosg-software@opensciencegrid.org\n - General discussion amongst team members\n\n\nSlack channel\n - if you can't create an account, \n   send an e-mail to \nosg-software@opensciencegrid.org\n\n\n\n\nSupport Changes\n\u00b6\n\n\nThe Footprints ticketing system at \nhttps://ticket.opensciencegrid.org\n was used to track support and security issues as\nwell as certificate and membership requests.\nThis service was retired in favor of two different ticketing systems, depending on the VOs you support at your site:\n\n\n\n\n\n\n\n\nIf your site primarily supports...\n\n\nSubmit new tickets to...\n\n\n\n\n\n\n\n\n\n\nLHC VOs\n\n\nGGUS\n\n\n\n\n\n\nAnyone else\n\n\nFreshdesk\n\n\n\n\n\n\n\n\nIf you experience any problems with ticketing, please contact us at\n\nhelp@opensciencegrid.org\n.\n\n\nService-specific details\n\u00b6\n\n\nOSG CA\n\u00b6\n\n\nThe OSG CA service offered certificate request, renewal, and revocation through the \nOIM\n web interface, \nthe OIM REST API, and the \nosg-pki-tools\n command-line tool.\nThis service was retired on May 31 but the OSG CA certificate remains in the IGTF distribution, so any certificates\nissued by the OSG CA remain valid until they expire.\n\n\nThe OSG recommends using the following CA certificate services:\n\n\n\n\n\n\n\n\nFor...\n\n\nWe plan to use the following Certificate Authorities...\n\n\n\n\n\n\n\n\n\n\nHost  Certificates\n\n\nInCommon\n and \nLet\u2019s Encrypt\n\n\n\n\n\n\nUser Certificates\n\n\nCILogon Basic\n for non-LHC users\n\n\n\n\n\n\n\n\nLHC users should continue to request their user certificates from CERN.\n\n\n\n\n\n\nWeb-Based services\n\n\nLet's Encrypt\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe semantics of Let's Encrypt certificates are different from those of previous CAs.\nPlease see\n\nthe security team's position on Let's Encrypt\n\nfor the security and setup implications of switching to a Let's Encrypt host or service certificate.\n\n\n\n\nIf you experience any problems acquiring host or service certificates, please contact us at\n\nhelp@opensciencegrid.org\n.\n\n\nSoftware Repository\n\u00b6\n\n\nThe OSG Software repository includes the YUM repositories, client tarballs, and CA tarballs.\nThe physical hosting location changed during the migration but was otherwise unchanged.\n\n\nIf you experience any problems with the OSG Software repository, please contact us at\n\nhelp@opensciencegrid.org\n.\n\n\nMyOSG and OIM\n\u00b6\n\n\nThe MyOSG service used to provide web and REST interfaces to access information about OSG resource topology, projects,\nand VOs.\nThe MyOSG web interface was retired but we continue to offer the same REST interface at \nhttps://my.opensciencegrid.org\n.\n\n\nOIM\n served as the database for the information used by MyOSG with a web\ninterface for data updates.\nThe OIM web interface was retired but its data was migrated to the \ntopology repository\n.\nUpdates to the aforementioned data can be requested via email or pull request.\n\n\n\n\nNote\n\n\nPlease see the \nOSG CA\n section for information regarding the OIM certificate service.\n\n\n\n\nIf you experience any problems with MyOSG or the topology repository, please contact us at\n\nhelp@opensciencegrid.org\n.\n\n\nGRACC Accounting and WLCG Accounting\n\u00b6\n\n\nNo changes were made to the \nGRACC accounting\n\nservice during the service migration.\n\n\nIf you experience any problems with GRACC accounting, please contact us at\n\nhelp@opensciencegrid.org\n.\n\n\nOASIS and CVMFS\n\u00b6\n\n\nThe OASIS (OSG Application and Software Installation Service) is a service used to distribute common applications and\nsoftware to OSG sites via CVMFS.\nThe OSG hosts a CVMFS Stratum-0 for keysigning, a repository server, and a CVMFS Stratum-1.\nThe physical hosting location of these services were moved to Nebraska without any other changes.\n\n\nIf you experience any problems with OASIS or CVMFS, please contact us at\n\nhelp@opensciencegrid.org\n.\n\n\nVOMS Admin Server\n\u00b6\n\n\nThe OSG VOMS service was used to sign VOMS attributes for members of the OSG VO and responded to queries for a list of\nVO members.\n\nVOMS Admin Server is deprecated\n in the OSG and the OSG VOMS servers were retired as planned.\n\n\nRSV\n\u00b6\n\n\nThe central RSV service was a monitoring tool that displayed every service status information about OSG sites that\nelected to provide it.\nIt was retired since there was no longer a need to monitor OSG site status as a whole.\nIf you would like to monitor your OSG services, you can access the status page of your local\n\nRSV\n instance.\n\n\nCollector\n\u00b6\n\n\nThe \ncentral Collector\n is a central database service that provides details about\npilot jobs currently running in the OSG.\nThe physical hosting location of the central Collector was moved but there were no other changes.\n\n\nIf you experience any problems with the central Collector, please contact us at\n\nhelp@opensciencegrid.org\n.\n\n\nHomepage\n\u00b6\n\n\nThe \nOSG homepage\n was a Wordpress instance that has been moved to a static site.\n\n\nIf you experience any problems with the homepage, please contact us at\n\nhelp@opensciencegrid.org\n.",
            "title": "Service Migrations - Spring 2018"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#service-migrations-spring-2018",
            "text": "The Open Science Grid (OSG) has transitioned effort from Indiana, requiring a redistribution of support and services.\nSome services were retired, most services were migrated to other locations (with minimal expected sites impact),\nand some services were migrated that resulted in significant impact on sites.  This document was intended to guide OSG site administrators through these changes, highlighting where the site\nadministrator action is required.  If you have questions or concerns that are not addressed in this document, see the  Getting Help section \nfor details.",
            "title": "Service Migrations - Spring 2018"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#getting-help",
            "text": "If you have questions or concerns that are not addressed in this document, please contact us at the usual locations:   help@opensciencegrid.org  osg-software@opensciencegrid.org  - General discussion amongst team members  Slack channel  - if you can't create an account, \n   send an e-mail to  osg-software@opensciencegrid.org",
            "title": "Getting Help"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#support-changes",
            "text": "The Footprints ticketing system at  https://ticket.opensciencegrid.org  was used to track support and security issues as\nwell as certificate and membership requests.\nThis service was retired in favor of two different ticketing systems, depending on the VOs you support at your site:     If your site primarily supports...  Submit new tickets to...      LHC VOs  GGUS    Anyone else  Freshdesk     If you experience any problems with ticketing, please contact us at help@opensciencegrid.org .",
            "title": "Support Changes"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#service-specific-details",
            "text": "",
            "title": "Service-specific details"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#osg-ca",
            "text": "The OSG CA service offered certificate request, renewal, and revocation through the  OIM  web interface, \nthe OIM REST API, and the  osg-pki-tools  command-line tool.\nThis service was retired on May 31 but the OSG CA certificate remains in the IGTF distribution, so any certificates\nissued by the OSG CA remain valid until they expire.  The OSG recommends using the following CA certificate services:     For...  We plan to use the following Certificate Authorities...      Host  Certificates  InCommon  and  Let\u2019s Encrypt    User Certificates  CILogon Basic  for non-LHC users     LHC users should continue to request their user certificates from CERN.    Web-Based services  Let's Encrypt      Note  The semantics of Let's Encrypt certificates are different from those of previous CAs.\nPlease see the security team's position on Let's Encrypt \nfor the security and setup implications of switching to a Let's Encrypt host or service certificate.   If you experience any problems acquiring host or service certificates, please contact us at help@opensciencegrid.org .",
            "title": "OSG CA"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#software-repository",
            "text": "The OSG Software repository includes the YUM repositories, client tarballs, and CA tarballs.\nThe physical hosting location changed during the migration but was otherwise unchanged.  If you experience any problems with the OSG Software repository, please contact us at help@opensciencegrid.org .",
            "title": "Software Repository"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#myosg-and-oim",
            "text": "The MyOSG service used to provide web and REST interfaces to access information about OSG resource topology, projects,\nand VOs.\nThe MyOSG web interface was retired but we continue to offer the same REST interface at  https://my.opensciencegrid.org .  OIM  served as the database for the information used by MyOSG with a web\ninterface for data updates.\nThe OIM web interface was retired but its data was migrated to the  topology repository .\nUpdates to the aforementioned data can be requested via email or pull request.   Note  Please see the  OSG CA  section for information regarding the OIM certificate service.   If you experience any problems with MyOSG or the topology repository, please contact us at help@opensciencegrid.org .",
            "title": "MyOSG and OIM"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#gracc-accounting-and-wlcg-accounting",
            "text": "No changes were made to the  GRACC accounting \nservice during the service migration.  If you experience any problems with GRACC accounting, please contact us at help@opensciencegrid.org .",
            "title": "GRACC Accounting and WLCG Accounting"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#oasis-and-cvmfs",
            "text": "The OASIS (OSG Application and Software Installation Service) is a service used to distribute common applications and\nsoftware to OSG sites via CVMFS.\nThe OSG hosts a CVMFS Stratum-0 for keysigning, a repository server, and a CVMFS Stratum-1.\nThe physical hosting location of these services were moved to Nebraska without any other changes.  If you experience any problems with OASIS or CVMFS, please contact us at help@opensciencegrid.org .",
            "title": "OASIS and CVMFS"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#voms-admin-server",
            "text": "The OSG VOMS service was used to sign VOMS attributes for members of the OSG VO and responded to queries for a list of\nVO members. VOMS Admin Server is deprecated  in the OSG and the OSG VOMS servers were retired as planned.",
            "title": "VOMS Admin Server"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#rsv",
            "text": "The central RSV service was a monitoring tool that displayed every service status information about OSG sites that\nelected to provide it.\nIt was retired since there was no longer a need to monitor OSG site status as a whole.\nIf you would like to monitor your OSG services, you can access the status page of your local RSV  instance.",
            "title": "RSV"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#collector",
            "text": "The  central Collector  is a central database service that provides details about\npilot jobs currently running in the OSG.\nThe physical hosting location of the central Collector was moved but there were no other changes.  If you experience any problems with the central Collector, please contact us at help@opensciencegrid.org .",
            "title": "Collector"
        },
        {
            "location": "/policy/service-migrations-spring-2018/#homepage",
            "text": "The  OSG homepage  was a Wordpress instance that has been moved to a static site.  If you experience any problems with the homepage, please contact us at help@opensciencegrid.org .",
            "title": "Homepage"
        },
        {
            "location": "/policy/gums-retire/",
            "text": "GUMS Retirement\n\u00b6\n\n\nThis document provides an overview of the planned retirement of support for GUMS in the OSG Software Stack.\n\n\nIntroduction\n\u00b6\n\n\nGUMS (Grid User Management System) is an authentication system used by OSG resource providers to map grid credentials to\nlocal UNIX accounts. It provides OSG site adminstrators with a centrally managed service that can handle requests from\nmultiple hosts that require authentication e.g., HTCondor-CE, GridFTP, and XRootD servers. In discussion with the OSG\ncommunity, we have found that sites use the following GUMS features:\n\n\n\n\nMapping based on VOMS attributes\n\n\nHost-based mappings\n\n\nBanning users/VOs\n\n\nSupporting pool accounts\n\n\n\n\nGUMS is a large Java web application that is more complex than necessary for the subset of features used in the\nOSG. Additionally, upstream support has tailed off and as a result, the maintenance burden has largely fallen on the OSG\nSoftware team.\n\n\nOSG's plans to retire GUMS has two major components:\n\n\n\n\nFind a suitable replacement for GUMS\n\n\nProvide documentation, tooling, and support to aid in the transition from GUMS to the intended solution\n\n\n\n\nSite Transition Plans\n\u00b6\n\n\nWe have released a configuration of the LCMAPS authorization framework that performs distributed verification of VOMS\nextensions. This configuration, referred to as the LCMAPS VOMS plugin, supports VOMS attribute based mappings as well as\nuser and VO banning. Host-based mappings are not supported however, the simplicity of the plugin's installation and\nthe distributed verification of VOMS extensions makes this feature unnecessary.\n\n\nPool accounts are not supported by the plugin but this feature will be addressed in an upcoming transition-specific\ndocument. The intended solution will revolve around mapping local user accounts via user grid mapfile and we will work\nwith any site for which this solution does not work.\n\n\nLCMAPS VOMS plugin installation and configuration documentation can be\nfound \nhere\n.\n\n\nTimeline\n\u00b6\n\n\n\n\nApril 2017 (completed): \nlcmaps-plugins-voms\n shipped and supported by OSG.\n\n\nMay 2017 (completed): \nosg-configure\n and documentation necessary for using \nlcmaps-plugins-voms\n is shipped.\n\n\nJune 2017 (completed): OSG 3.4.0 is released without VOMS-Admin, \nedg-mkgridmap\n, or GUMS.\n\n\nJuly 2017 (completed): OSG 3.4 CEs can be configured with 3.3 GUMS hosts\n\n\nMarch 2018: Complete transition for sites not using pool accounts\n\n\nMay 2018: Support is dropped for OSG 3.3 series; no further support for GUMS is provided.",
            "title": "GUMS Retirement"
        },
        {
            "location": "/policy/gums-retire/#gums-retirement",
            "text": "This document provides an overview of the planned retirement of support for GUMS in the OSG Software Stack.",
            "title": "GUMS Retirement"
        },
        {
            "location": "/policy/gums-retire/#introduction",
            "text": "GUMS (Grid User Management System) is an authentication system used by OSG resource providers to map grid credentials to\nlocal UNIX accounts. It provides OSG site adminstrators with a centrally managed service that can handle requests from\nmultiple hosts that require authentication e.g., HTCondor-CE, GridFTP, and XRootD servers. In discussion with the OSG\ncommunity, we have found that sites use the following GUMS features:   Mapping based on VOMS attributes  Host-based mappings  Banning users/VOs  Supporting pool accounts   GUMS is a large Java web application that is more complex than necessary for the subset of features used in the\nOSG. Additionally, upstream support has tailed off and as a result, the maintenance burden has largely fallen on the OSG\nSoftware team.  OSG's plans to retire GUMS has two major components:   Find a suitable replacement for GUMS  Provide documentation, tooling, and support to aid in the transition from GUMS to the intended solution",
            "title": "Introduction"
        },
        {
            "location": "/policy/gums-retire/#site-transition-plans",
            "text": "We have released a configuration of the LCMAPS authorization framework that performs distributed verification of VOMS\nextensions. This configuration, referred to as the LCMAPS VOMS plugin, supports VOMS attribute based mappings as well as\nuser and VO banning. Host-based mappings are not supported however, the simplicity of the plugin's installation and\nthe distributed verification of VOMS extensions makes this feature unnecessary.  Pool accounts are not supported by the plugin but this feature will be addressed in an upcoming transition-specific\ndocument. The intended solution will revolve around mapping local user accounts via user grid mapfile and we will work\nwith any site for which this solution does not work.  LCMAPS VOMS plugin installation and configuration documentation can be\nfound  here .",
            "title": "Site Transition Plans"
        },
        {
            "location": "/policy/gums-retire/#timeline",
            "text": "April 2017 (completed):  lcmaps-plugins-voms  shipped and supported by OSG.  May 2017 (completed):  osg-configure  and documentation necessary for using  lcmaps-plugins-voms  is shipped.  June 2017 (completed): OSG 3.4.0 is released without VOMS-Admin,  edg-mkgridmap , or GUMS.  July 2017 (completed): OSG 3.4 CEs can be configured with 3.3 GUMS hosts  March 2018: Complete transition for sites not using pool accounts  May 2018: Support is dropped for OSG 3.3 series; no further support for GUMS is provided.",
            "title": "Timeline"
        },
        {
            "location": "/policy/bestman2-retire/",
            "text": "BeStMan2 Retirement\n\u00b6\n\n\nThis document provides an overview of the planned retirement of support for BeStMan in the OSG Software Stack.\n\n\nIntroduction\n\u00b6\n\n\nBeStMan2 is a standalone implementation of a subset of the Storage Resource Manager v2 (SRMv2) protocol.  SRM was meant to be a high-level management protocol for site storage resources, allowing administrators to manage storage offerings using the abstraction of \"storage tokens.\"  Additionally, SRM can be used to mediate transfer protocol selection.\n\n\nOSG currently supports BeStMan2 in \"gateway mode\" -- in this mode, SRM is only used for metadata operations (listing directory contents), listing total space used, and load-balancing GridFTP servers.  This functionality is redundant to what can be accomplished with GridFTP alone.\n\n\nBeStMan2 has not received upstream support for approximately five years; the existing code base (about 150,000 lines of Java - similar in size to Globus GridFTP) and its extensive set of dependencies (such as JGlobus) are now quite outdated and would require significant investment to modernize.  OSG has worked at length with our stakeholders to replace SRM-specific use cases with other equivalents.  We believe none of our stakeholders require sites to have an SRM endpoint: this document describes the site transition plan.\n\n\nSite Transition Plans\n\u00b6\n\n\nWe have released \ndocumentation\n\nfor a configuration of GridFTP that takes advantage of Linux Virtual Server (LVS) for load balancing between multiple\nGridFTP endpoints.\n\n\nSites should work with their supported VOs (typically, CMS or ATLAS) to identify any VO-specific usage and replacement plans for BeStMan2.\n\n\nTimeline\n\u00b6\n\n\n\n\nMarch 2017 (completed):\n  Release \nload balanced GridFTP\n\n  documentation\n\n\nJune 2017 (completed): OSG 3.4.0 is released without BeStMan\n\n\nDecember 2018 (completed): Security-only support for OSG 3.3 series and BeStMan is provided\n\n\nMay 2018 (completed): Support is dropped for OSG 3.3 series; no further support for BeStMan is provided.",
            "title": "BeStMan2 Retirement"
        },
        {
            "location": "/policy/bestman2-retire/#bestman2-retirement",
            "text": "This document provides an overview of the planned retirement of support for BeStMan in the OSG Software Stack.",
            "title": "BeStMan2 Retirement"
        },
        {
            "location": "/policy/bestman2-retire/#introduction",
            "text": "BeStMan2 is a standalone implementation of a subset of the Storage Resource Manager v2 (SRMv2) protocol.  SRM was meant to be a high-level management protocol for site storage resources, allowing administrators to manage storage offerings using the abstraction of \"storage tokens.\"  Additionally, SRM can be used to mediate transfer protocol selection.  OSG currently supports BeStMan2 in \"gateway mode\" -- in this mode, SRM is only used for metadata operations (listing directory contents), listing total space used, and load-balancing GridFTP servers.  This functionality is redundant to what can be accomplished with GridFTP alone.  BeStMan2 has not received upstream support for approximately five years; the existing code base (about 150,000 lines of Java - similar in size to Globus GridFTP) and its extensive set of dependencies (such as JGlobus) are now quite outdated and would require significant investment to modernize.  OSG has worked at length with our stakeholders to replace SRM-specific use cases with other equivalents.  We believe none of our stakeholders require sites to have an SRM endpoint: this document describes the site transition plan.",
            "title": "Introduction"
        },
        {
            "location": "/policy/bestman2-retire/#site-transition-plans",
            "text": "We have released  documentation \nfor a configuration of GridFTP that takes advantage of Linux Virtual Server (LVS) for load balancing between multiple\nGridFTP endpoints.  Sites should work with their supported VOs (typically, CMS or ATLAS) to identify any VO-specific usage and replacement plans for BeStMan2.",
            "title": "Site Transition Plans"
        },
        {
            "location": "/policy/bestman2-retire/#timeline",
            "text": "March 2017 (completed):\n  Release  load balanced GridFTP \n  documentation  June 2017 (completed): OSG 3.4.0 is released without BeStMan  December 2018 (completed): Security-only support for OSG 3.3 series and BeStMan is provided  May 2018 (completed): Support is dropped for OSG 3.3 series; no further support for BeStMan is provided.",
            "title": "Timeline"
        },
        {
            "location": "/policy/voms-admin-retire/",
            "text": "VOMS-Admin Retirement\n\u00b6\n\n\nIntroduction\n\u00b6\n\n\nThis document provides an overview of the planned retirement of support for VOMS-Admin\nin the OSG Software Stack.\n\n\nSupport for the VOMS infrastructure has three major components:\n\n\n\n\nVOMS-Admin\n: A web interface for maintaining the list of authorized users in\n    a VO and their various authorizations (group membership, roles, attributes, etc).\n\n\nVOMS-Server\n: A TCP service which signs a cryptographic extension on an X509\n    proxy certificate asserting the authorizations available to the authenticated user.\n\n\nVOMS Client\n: Software for extracting and validating the signed VOMS extension from\n    an X509 proxy.  The validation is meant to be distributed: the VOMS client does not\n    need to contact the VOMS-Admin server.  However, OSG has historically used software\n    such as GUMS or \nedg-mkgridmap\n to cache a list of authorizations from the VOMS-Admin\n    interface, creating a dependency between VOMS client and VOMS-Admin.\n\n\n\n\nVOMS-Admin is a large, complex Java web application.  Over the last\nfew years, upstream support has tailed off - particularly as OSG has been unable\nto update to VOMS-Admin version 3.  As a result, the maintenance burden has largely\nfallen on the OSG Software team.\n\n\nGiven that VOMS-Admin is deeply tied to X509 security infrastructure - and is\nmaintenance-only from OSG Software - there is no path forward to eliminate the use\nof X509 certificates in the web browser, a high-priority goal\n\n\nIn discussions with the OSG community, we have found very few VOs utilize VOMS-Admin\nto manage their VO users.  Instead, the majority use VOMS-Admin to whitelist a pilot\ncertificate: this can be done without a VOMS-Admin endpoint.\n\n\nOSG's plans to retire VOMS-Admin has three major components:\n\n\n\n\n(Sites) Enable distributed validation of VOMS extensions in the VOMS client.\n\n\n(VOs) Migrate VOs that use VOMS only for pilot certificates to direct signing\n  of VOMS proxies.\n\n\n(VOs) Migrate remaining VOs to a central \ncomanage\n instance for managing user\n  authorizations; maintain a plugin to enable direct callouts from VOMS-Server\n  to \ncomanage\n for authorization lookups.\n\n\n\n\nSite Transition Plans\n\u00b6\n\n\nWe will release a configuration of the LCMAPS authorization framework that performs\ndistributed verification of VOMS extensions; this verification eludes the need to\ncontact the VOMS-Admin interface for a list of authorizations.\n\n\nIn 2015/2016, LCMAPS and GUMS were upgraded so GUMS skips the VOMS-Admin lookup when\nLCMAPS asserts the validation was performed.  Hence, when GUMS sites update clients to the\nlatest (April 2017) LCMAPS and HTCondor-CE releases, the callout to VOMS-Admin is no longer\nneeded. \nNote\n: In parallel to the VOMS-Admin transition, OSG Software plans to \nretire GUMS\n.\nThere is no need to complete one transition before the other.\n\n\nSites using \nedg-mkgridmap\n will need to use its replacement, \nlcmaps-plugins-voms\n (this\nprocess is documented \nhere\n).\n\n\nVO Transition Plans\n\u00b6\n\n\nBased on one-to-one discussions, we believe the majority of VOs only use VOMS-Admin to maintain\na list of authorized pilots.  For these VOs, we will help convert invocations of \nvoms-proxy-init\n:\n\n\nvoms-proxy-init -voms hcc:/hcc/Role=pilot\n\n\n\n\n\nto an equivalent call to \nvoms-proxy-fake\n:\n\n\nvoms-proxy-fake -hostcert /etc/grid-security/voms/vomscert.pem \\\n                -hostkey /etc/grid-security/voms/vomskey.pem \\\n                -fqan /hcc/Role=pilot/Capability=NULL \\\n                -voms hcc -uri hcc-voms.unl.edu:15000\n\n\n\n\n\nThe latter command would typically be run on the VO's glideinWMS frontend host, requiring the service certificate\ncurrently on the VOMS-Admin server to be kept on the frontend host.  The frontend's account may also need access\nto the certificate.\n\n\n\n\nInfo\n\n\nSee \nthis documentation\n to\nupdate your GlideinWMS Frontend to use the new proxy generation command.\n\n\n\n\nWe plan to transition more complex VOs - those using VOMS-Admin to track membership in a VO - to \ncomanage\n.  It is\nnot clear there are any such VOs that need support from OSG.  If there are, a hosted version of \ncomanage\n is expected\nto be available in summer 2017 from the CILogon 2.0 project.  If you feel your VO is affected, please contact the\nOSG and we will build a custom timeline.  If there are no such VOs, we will not need to adopt \ncomanage\n for this\nuse case (other uses of \ncomanage\n are expected to proceed regardless).\n\n\nTimeline\n\u00b6\n\n\n\n\nApril 2017 (completed): \nlcmaps-plugins-voms\n shipped and supported by OSG.\n\n\nMay 2017 (completed): \nosg-configure\n and documentation necessary for using \nlcmaps-plugins-voms\n is shipped.\n\n\nJune 2017 (completed): OSG 3.4.0 is released without VOMS-Admin, \nedg-mkgridmap\n, or GUMS.  Sites begin transition\n  to validating VOMS extensions.\n\n\nSummer 2017 (completed): As necessary, VOs are given access to a hosted \ncomanage\n instance.\n\n\nMarch 2017 (completed): First VOs begin to retire VOMS-Admin.\n\n\nMay 2018 (completed): Support is dropped for OSG 3.3 series; no further support for VOMS-Admin or GUMS is provided.",
            "title": "VOMS Admin Retirement"
        },
        {
            "location": "/policy/voms-admin-retire/#voms-admin-retirement",
            "text": "",
            "title": "VOMS-Admin Retirement"
        },
        {
            "location": "/policy/voms-admin-retire/#introduction",
            "text": "This document provides an overview of the planned retirement of support for VOMS-Admin\nin the OSG Software Stack.  Support for the VOMS infrastructure has three major components:   VOMS-Admin : A web interface for maintaining the list of authorized users in\n    a VO and their various authorizations (group membership, roles, attributes, etc).  VOMS-Server : A TCP service which signs a cryptographic extension on an X509\n    proxy certificate asserting the authorizations available to the authenticated user.  VOMS Client : Software for extracting and validating the signed VOMS extension from\n    an X509 proxy.  The validation is meant to be distributed: the VOMS client does not\n    need to contact the VOMS-Admin server.  However, OSG has historically used software\n    such as GUMS or  edg-mkgridmap  to cache a list of authorizations from the VOMS-Admin\n    interface, creating a dependency between VOMS client and VOMS-Admin.   VOMS-Admin is a large, complex Java web application.  Over the last\nfew years, upstream support has tailed off - particularly as OSG has been unable\nto update to VOMS-Admin version 3.  As a result, the maintenance burden has largely\nfallen on the OSG Software team.  Given that VOMS-Admin is deeply tied to X509 security infrastructure - and is\nmaintenance-only from OSG Software - there is no path forward to eliminate the use\nof X509 certificates in the web browser, a high-priority goal  In discussions with the OSG community, we have found very few VOs utilize VOMS-Admin\nto manage their VO users.  Instead, the majority use VOMS-Admin to whitelist a pilot\ncertificate: this can be done without a VOMS-Admin endpoint.  OSG's plans to retire VOMS-Admin has three major components:   (Sites) Enable distributed validation of VOMS extensions in the VOMS client.  (VOs) Migrate VOs that use VOMS only for pilot certificates to direct signing\n  of VOMS proxies.  (VOs) Migrate remaining VOs to a central  comanage  instance for managing user\n  authorizations; maintain a plugin to enable direct callouts from VOMS-Server\n  to  comanage  for authorization lookups.",
            "title": "Introduction"
        },
        {
            "location": "/policy/voms-admin-retire/#site-transition-plans",
            "text": "We will release a configuration of the LCMAPS authorization framework that performs\ndistributed verification of VOMS extensions; this verification eludes the need to\ncontact the VOMS-Admin interface for a list of authorizations.  In 2015/2016, LCMAPS and GUMS were upgraded so GUMS skips the VOMS-Admin lookup when\nLCMAPS asserts the validation was performed.  Hence, when GUMS sites update clients to the\nlatest (April 2017) LCMAPS and HTCondor-CE releases, the callout to VOMS-Admin is no longer\nneeded.  Note : In parallel to the VOMS-Admin transition, OSG Software plans to  retire GUMS .\nThere is no need to complete one transition before the other.  Sites using  edg-mkgridmap  will need to use its replacement,  lcmaps-plugins-voms  (this\nprocess is documented  here ).",
            "title": "Site Transition Plans"
        },
        {
            "location": "/policy/voms-admin-retire/#vo-transition-plans",
            "text": "Based on one-to-one discussions, we believe the majority of VOs only use VOMS-Admin to maintain\na list of authorized pilots.  For these VOs, we will help convert invocations of  voms-proxy-init :  voms-proxy-init -voms hcc:/hcc/Role=pilot  to an equivalent call to  voms-proxy-fake :  voms-proxy-fake -hostcert /etc/grid-security/voms/vomscert.pem \\\n                -hostkey /etc/grid-security/voms/vomskey.pem \\\n                -fqan /hcc/Role=pilot/Capability=NULL \\\n                -voms hcc -uri hcc-voms.unl.edu:15000  The latter command would typically be run on the VO's glideinWMS frontend host, requiring the service certificate\ncurrently on the VOMS-Admin server to be kept on the frontend host.  The frontend's account may also need access\nto the certificate.   Info  See  this documentation  to\nupdate your GlideinWMS Frontend to use the new proxy generation command.   We plan to transition more complex VOs - those using VOMS-Admin to track membership in a VO - to  comanage .  It is\nnot clear there are any such VOs that need support from OSG.  If there are, a hosted version of  comanage  is expected\nto be available in summer 2017 from the CILogon 2.0 project.  If you feel your VO is affected, please contact the\nOSG and we will build a custom timeline.  If there are no such VOs, we will not need to adopt  comanage  for this\nuse case (other uses of  comanage  are expected to proceed regardless).",
            "title": "VO Transition Plans"
        },
        {
            "location": "/policy/voms-admin-retire/#timeline",
            "text": "April 2017 (completed):  lcmaps-plugins-voms  shipped and supported by OSG.  May 2017 (completed):  osg-configure  and documentation necessary for using  lcmaps-plugins-voms  is shipped.  June 2017 (completed): OSG 3.4.0 is released without VOMS-Admin,  edg-mkgridmap , or GUMS.  Sites begin transition\n  to validating VOMS extensions.  Summer 2017 (completed): As necessary, VOs are given access to a hosted  comanage  instance.  March 2017 (completed): First VOs begin to retire VOMS-Admin.  May 2018 (completed): Support is dropped for OSG 3.3 series; no further support for VOMS-Admin or GUMS is provided.",
            "title": "Timeline"
        },
        {
            "location": "/policy/release-series/",
            "text": "OSG Software Release Series Support Policy\n\u00b6\n\n\nThis document describes the OSG policy for managing its software releases. Use this policy to help plan when to perform\nmajor OSG software updates at your site.\n\n\nOSG software releases are organized into \nrelease series\n, with the intent that software updates within a series do\nnot take long to perform, cause significant downtime, or break dependent software.\nNew series can be more disruptive, allowing OSG to add, substantially change, and remove software components.\nReleases are assigned versions, such as \"OSG 3.2.1\", where the first two numbers designate the release series and the\nthird number increments within the series.\nChanges to the first number are infrequent and indicate sweeping changes to the way in which OSG software is\ndistributed.\n\n\nOSG supports at most two concurrent release series, \ncurrent\n and \nprevious\n, where the goal is to begin a new\nrelease series about every 18 months.\nOnce a new series starts, OSG will support the previous series for at least 12 months and will announce its end-of-life\ndate at least 6 months in advance.\nDuring the first 6 months of a series, OSG will endeavor to apply backward-compatible changes to the previous series as\nwell; afterward, OSG will apply only critical bug and security fixes.\nWhen support ends for a release series, it means that OSG no longer updates the software, fixes issues, or troubleshoots\ninstallations for releases within the series.\nThe plan is to maintain interoperability between supported series, but there is no guarantee that unsupported series\nwill continue to function in OSG.\n\n\nFiles for release series older than current or previous will be removed from the OSG software repositories no earlier\nthan when support ends for the previous release.\nFor example, files for OSG 3.2 will be removed no earlier than when support ends for OSG 3.3 in May 2018.\n\n\nOSG Operations will handle deviations from this policy, in consultation with OSG Technology and stakeholders.\n\n\nLife-cycle Dates\n\u00b6\n\n\n\n\n\n\n\n\nRelease Series\n\n\nInitial Release\n\n\nEnd of Regular Support\n\n\nEnd of Critical Bug/Security Support\n\n\n\n\n\n\n\n\n\n\n3.5\n\n\nAugust 2019\n\n\nNot set\n\n\nNot set\n\n\n\n\n\n\n3.4\n\n\nJune 2017\n\n\nFebruary 2020\n\n\nNovember 2020\n\n\n\n\n\n\n3.3\n\n\nAugust 2015\n\n\nDecember 2017\n\n\nMay 2018\n\n\n\n\n\n\n3.2\n\n\nNovember 2013\n\n\nFebruary 2016\n\n\nAugust 2016\n\n\n\n\n\n\n3.1\n\n\nApril 2012\n\n\nOctober 2014\n\n\nApril 2015",
            "title": "Release Series Support"
        },
        {
            "location": "/policy/release-series/#osg-software-release-series-support-policy",
            "text": "This document describes the OSG policy for managing its software releases. Use this policy to help plan when to perform\nmajor OSG software updates at your site.  OSG software releases are organized into  release series , with the intent that software updates within a series do\nnot take long to perform, cause significant downtime, or break dependent software.\nNew series can be more disruptive, allowing OSG to add, substantially change, and remove software components.\nReleases are assigned versions, such as \"OSG 3.2.1\", where the first two numbers designate the release series and the\nthird number increments within the series.\nChanges to the first number are infrequent and indicate sweeping changes to the way in which OSG software is\ndistributed.  OSG supports at most two concurrent release series,  current  and  previous , where the goal is to begin a new\nrelease series about every 18 months.\nOnce a new series starts, OSG will support the previous series for at least 12 months and will announce its end-of-life\ndate at least 6 months in advance.\nDuring the first 6 months of a series, OSG will endeavor to apply backward-compatible changes to the previous series as\nwell; afterward, OSG will apply only critical bug and security fixes.\nWhen support ends for a release series, it means that OSG no longer updates the software, fixes issues, or troubleshoots\ninstallations for releases within the series.\nThe plan is to maintain interoperability between supported series, but there is no guarantee that unsupported series\nwill continue to function in OSG.  Files for release series older than current or previous will be removed from the OSG software repositories no earlier\nthan when support ends for the previous release.\nFor example, files for OSG 3.2 will be removed no earlier than when support ends for OSG 3.3 in May 2018.  OSG Operations will handle deviations from this policy, in consultation with OSG Technology and stakeholders.",
            "title": "OSG Software Release Series Support Policy"
        },
        {
            "location": "/policy/release-series/#life-cycle-dates",
            "text": "Release Series  Initial Release  End of Regular Support  End of Critical Bug/Security Support      3.5  August 2019  Not set  Not set    3.4  June 2017  February 2020  November 2020    3.3  August 2015  December 2017  May 2018    3.2  November 2013  February 2016  August 2016    3.1  April 2012  October 2014  April 2015",
            "title": "Life-cycle Dates"
        },
        {
            "location": "/policy/globus-toolkit/",
            "text": "OSG Support of the Globus Toolkit\n\u00b6\n\n\n6 June 2017\n\n\nMany in the OSG community have heard the news about the \nend of support for the open-source Globus Toolkit\n.\n\n\nWhat does this imply for the OSG Software stack?  Not much: OSG support for the Globus Toolkit (e.g., GridFTP and GSI) will continue for as long as stakeholders need it. Period.\n\n\nNote the OSG Software team provides a support guarantee for all the software in its stack. When a software component reaches end-of-life, the OSG assists its stakeholders in managing the transition to new software to replace or extend those capabilities. This assistance comes in many forms, such as finding an equivalent replacement, adapting code to avoid the dependency, or helping research and develop a transition to new technology.  During such transition periods, OSG takes on traditional maintenance duties (i.e., patching, bug fixes and support) of the end-of-life software.  The OSG is committed to keep the software secure until its stakeholders have successfully transitioned to new software. \n\n\nThis model has been successfully demonstrated throughout the lifetime of OSG, including for example the five year transition period for the BestMan storage resource manager. The Globus Toolkit will not be an exception.  Indeed, OSG has accumulated more than a decade of experience with this software and has often provided patches back to Globus. \n\n\nOver the next weeks and months, we will be in contact with our stakeholder VOs, sites, and software providers to discuss their requirements and timelines with regard to GridFTP and GSI.  \n\n\nPlease reach out to \ngoc@opensciencegrid.org\n with your questions, comments, and concerns.\n\n\nA copy of this statement can be found at \nhttps://www.opensciencegrid.org/technology/policy/globus-toolkit\n.",
            "title": "Globus Toolkit Support"
        },
        {
            "location": "/policy/globus-toolkit/#osg-support-of-the-globus-toolkit",
            "text": "6 June 2017  Many in the OSG community have heard the news about the  end of support for the open-source Globus Toolkit .  What does this imply for the OSG Software stack?  Not much: OSG support for the Globus Toolkit (e.g., GridFTP and GSI) will continue for as long as stakeholders need it. Period.  Note the OSG Software team provides a support guarantee for all the software in its stack. When a software component reaches end-of-life, the OSG assists its stakeholders in managing the transition to new software to replace or extend those capabilities. This assistance comes in many forms, such as finding an equivalent replacement, adapting code to avoid the dependency, or helping research and develop a transition to new technology.  During such transition periods, OSG takes on traditional maintenance duties (i.e., patching, bug fixes and support) of the end-of-life software.  The OSG is committed to keep the software secure until its stakeholders have successfully transitioned to new software.   This model has been successfully demonstrated throughout the lifetime of OSG, including for example the five year transition period for the BestMan storage resource manager. The Globus Toolkit will not be an exception.  Indeed, OSG has accumulated more than a decade of experience with this software and has often provided patches back to Globus.   Over the next weeks and months, we will be in contact with our stakeholder VOs, sites, and software providers to discuss their requirements and timelines with regard to GridFTP and GSI.    Please reach out to  goc@opensciencegrid.org  with your questions, comments, and concerns.  A copy of this statement can be found at  https://www.opensciencegrid.org/technology/policy/globus-toolkit .",
            "title": "OSG Support of the Globus Toolkit"
        },
        {
            "location": "/policy/external-oasis-repos/",
            "text": "Policy for OSG Mirroring of External CVMFS repositories\n\u00b6\n\n\n12 October 2017\n\n\nThis document provides an overview of the policies and security understanding with regards to OSG mirroring of CVMFS\nrepositories of external organizations.  It aims to help external repositories and OSG VOs understand what OSG is\nattempting to achieve with the mirroring service.\nThis is not a service-level agreement but rather a statement of responsibilities.\n\n\n\n\nNote\n\n\nTo actually understand the technical procedure for mirroring a repository, \nsee the following page\n.  This document solely covers the policy aspects.\n\n\n\n\nIntroduction\n\u00b6\n\n\nThe OSG provides a network of CVMFS Stratum-1 servers for mirroring content of externally-managed repositories.  These repositories are often\nhosted by large HEP or physics VOs for the purpose of distributing software for high-throughput computing jobs.  Additionally, OSG provides a\nrepository (\n) for smaller VOs; this is not covered here.\n\n\nOSG will include additional repositories into the content distribution network (CDN) at the request of an OSG-affiliated VO.  These repositories\nare meant to help the OSG-affiliated VO accomplish their domain science.\n\n\nThe goal of this mirroring provides an improved quality-of-service for the VO end-users running at OSG sites.  OSG does not provide support\nfor use of the software in external repositories, but will help end-users contact the VO for help as necessary.\n\n\nOSG Responsibilities\n\u00b6\n\n\n\n\nOSG will provide the Stratum-1 server network according to \nthe OASIS SLA\n\n\nOSG will provide a best-effort mirror of the full contents of the external repo.  We will attempt to provide best-effort integrity of the\n  object contents, but assume users of the Stratum-1 will do further integrity checking.  No SLA is provided covering potential data corruptions.\n\n\nOSG will provide best-effort notification to the mirrored repository in case OSG detects a service outage of the external repo.\n\n\nIn the event of a security incident, the operations group will replace the compromised repository with an empty directory, signed by\nthe key managed by them. This will be done in consultation with the security team or, in the unlikely event they cannot be reached, at the discretion of the Operations Coordinator.\n\n\nOnce the external repository is approved, OSG will distribute the corresponding repository signing keys in a valid whitelist.  The whitelist\n  will be signed by the OSG Stratum-0.  This whitelist attests to the authenticity of the key, but not a statement about repository contents.\n\n\n\n\nVO Responsibilities\n\u00b6\n\n\n\n\nThe individual responsible on behalf of the VO will be registered with the OASIS Manager role in OIM.\n\n\nThe requesting VO should only include targeted repositories they need to support their science.\n\n\nThe VO should understand that in the event of a reported security incident, the contents of this repository may be replaced with an\n  empty directory and signed by the OSG repository key.  Depending on the OSG Security team's evaluation of the severity and urgency\n  of the incident, the blanking may be done immediately without VO notification or after some notification period.\n\n\nIn the case of a security incident, the VO and OSG Security team will need to mutually agree that the incident is resolved before the\n  repository is unblanked.\n\n\nThe VO is ultimately responsible for the contents of the repository.  OSG provides a mirror.\n\n\nIf the external repository is \nnot\n operated by the VO, OSG may work directly with the external repository maintainers.  This is done for\n  ease of operations and may be limited to day-to-day, non-security-related support.\n\n\n\n\nOperational Policies\n\u00b6\n\n\nTo help us provide the best operational setup possible, we have a few additional replication policies:\n\n\n\n\nOSG Operations only hosts the shared \noasis.opensciencegrid.org\n repository; VO-dedicated software respositories\n    (such as \nnova.opensciencegrid.org\n for the NoVA VO) should be operated by the VO.\n\n\nVOs are asked to either run their own repository or utilize the shared repository, but not both.\n\n\nThere is a finite amount of high-performance storage on the CDN.   A minimum of 100 GB per repository is guaranteed.\n    Larger limits may be requested.\n\n\nVOs may ask the OSG to replicate their repositories to the European Grid Infrastructure (EGI); however, this can\n    only be done if the repository name ends in \n.opensciencegrid.org\n.",
            "title": "OASIS Repository Mirroring"
        },
        {
            "location": "/policy/external-oasis-repos/#policy-for-osg-mirroring-of-external-cvmfs-repositories",
            "text": "12 October 2017  This document provides an overview of the policies and security understanding with regards to OSG mirroring of CVMFS\nrepositories of external organizations.  It aims to help external repositories and OSG VOs understand what OSG is\nattempting to achieve with the mirroring service.\nThis is not a service-level agreement but rather a statement of responsibilities.   Note  To actually understand the technical procedure for mirroring a repository,  see the following page .  This document solely covers the policy aspects.",
            "title": "Policy for OSG Mirroring of External CVMFS repositories"
        },
        {
            "location": "/policy/external-oasis-repos/#introduction",
            "text": "The OSG provides a network of CVMFS Stratum-1 servers for mirroring content of externally-managed repositories.  These repositories are often\nhosted by large HEP or physics VOs for the purpose of distributing software for high-throughput computing jobs.  Additionally, OSG provides a\nrepository ( ) for smaller VOs; this is not covered here.  OSG will include additional repositories into the content distribution network (CDN) at the request of an OSG-affiliated VO.  These repositories\nare meant to help the OSG-affiliated VO accomplish their domain science.  The goal of this mirroring provides an improved quality-of-service for the VO end-users running at OSG sites.  OSG does not provide support\nfor use of the software in external repositories, but will help end-users contact the VO for help as necessary.",
            "title": "Introduction"
        },
        {
            "location": "/policy/external-oasis-repos/#osg-responsibilities",
            "text": "OSG will provide the Stratum-1 server network according to  the OASIS SLA  OSG will provide a best-effort mirror of the full contents of the external repo.  We will attempt to provide best-effort integrity of the\n  object contents, but assume users of the Stratum-1 will do further integrity checking.  No SLA is provided covering potential data corruptions.  OSG will provide best-effort notification to the mirrored repository in case OSG detects a service outage of the external repo.  In the event of a security incident, the operations group will replace the compromised repository with an empty directory, signed by\nthe key managed by them. This will be done in consultation with the security team or, in the unlikely event they cannot be reached, at the discretion of the Operations Coordinator.  Once the external repository is approved, OSG will distribute the corresponding repository signing keys in a valid whitelist.  The whitelist\n  will be signed by the OSG Stratum-0.  This whitelist attests to the authenticity of the key, but not a statement about repository contents.",
            "title": "OSG Responsibilities"
        },
        {
            "location": "/policy/external-oasis-repos/#vo-responsibilities",
            "text": "The individual responsible on behalf of the VO will be registered with the OASIS Manager role in OIM.  The requesting VO should only include targeted repositories they need to support their science.  The VO should understand that in the event of a reported security incident, the contents of this repository may be replaced with an\n  empty directory and signed by the OSG repository key.  Depending on the OSG Security team's evaluation of the severity and urgency\n  of the incident, the blanking may be done immediately without VO notification or after some notification period.  In the case of a security incident, the VO and OSG Security team will need to mutually agree that the incident is resolved before the\n  repository is unblanked.  The VO is ultimately responsible for the contents of the repository.  OSG provides a mirror.  If the external repository is  not  operated by the VO, OSG may work directly with the external repository maintainers.  This is done for\n  ease of operations and may be limited to day-to-day, non-security-related support.",
            "title": "VO Responsibilities"
        },
        {
            "location": "/policy/external-oasis-repos/#operational-policies",
            "text": "To help us provide the best operational setup possible, we have a few additional replication policies:   OSG Operations only hosts the shared  oasis.opensciencegrid.org  repository; VO-dedicated software respositories\n    (such as  nova.opensciencegrid.org  for the NoVA VO) should be operated by the VO.  VOs are asked to either run their own repository or utilize the shared repository, but not both.  There is a finite amount of high-performance storage on the CDN.   A minimum of 100 GB per repository is guaranteed.\n    Larger limits may be requested.  VOs may ask the OSG to replicate their repositories to the European Grid Infrastructure (EGI); however, this can\n    only be done if the repository name ends in  .opensciencegrid.org .",
            "title": "Operational Policies"
        },
        {
            "location": "/policy/flexible-release-model/",
            "text": "OSG Software Flexible Release Model\n\u00b6\n\n\nIntroduction\n\u00b6\n\n\nBefore November 2017, the OSG software stack was released on the second Tuesday of each month, except in the case of urgent releases, which were infrequent. This schedule had been in place since early 2013. Since then, conditions within and outside of the Software team have changed, and we have adjusted the release schedule and associated processes.\n\n\nThe previous release model had the recurring problem of a \"release crunch,\" where it was difficult to find the effort required to test large changes before their deadline had passed. Sometimes the lack of timely effort led to software being pushed to the next release (a month later), because there was insufficient testing time.\n\n\nBased on software support tickets, we noticed that many sites follow a local update schedule that is independent of the OSG Release team schedule; some sites upgrade every few months, skipping interim releases, other sites upgrade individual packages as needed. In addition, upstream software developers do not follow our release schedule either, releasing software on their own development timelines. As a result, some site administrators would prefer to have OSG software updates more often, closer to when they become available, rather than tied to a monthly cycle.\n\n\nFor these reasons, we created a new release model.\n\n\nRelease Model\n\u00b6\n\n\nThe OSG Release team releases batches of integrated, tested software on an ad hoc basis, with the process outlined below (changes from the old process are highlighted):\n\n\n\n\n\n\nSoftware and Release Team members develop packages and mark them for testing\n\n\n\n\n\n\nSoftware and Release Team members test the packages, possibly with help from the community\n\n\n\n\n\n\nOnce adequate testing is complete and successful, the Release Manager approves packages for release\n\n\n\n\n\n\nWeekly, the Release Manager evaluates packages that are ready for release; when a sufficient number of important packages are ready\n[1]\n, the Release Manager schedules a release date and announces it. For urgent changes, the Release Manager evaluates the packages as soon as they are tested\n\n\n\n\n\n\nThe Software and Release Team performs pre-release testing, releases the packages, and announces the release\n\n\n\n\n\n\nNote: The release dates of parallel release series (e.g., 3.3 and 3.4) do not have to coincide, as they have in the past.\n\n\n[1] The threshold for \u201csufficient number of important packages\u201d is determined by the Release Manager, with input from the other Technology Area leaders.",
            "title": "Flexible Release Model"
        },
        {
            "location": "/policy/flexible-release-model/#osg-software-flexible-release-model",
            "text": "",
            "title": "OSG Software Flexible Release Model"
        },
        {
            "location": "/policy/flexible-release-model/#introduction",
            "text": "Before November 2017, the OSG software stack was released on the second Tuesday of each month, except in the case of urgent releases, which were infrequent. This schedule had been in place since early 2013. Since then, conditions within and outside of the Software team have changed, and we have adjusted the release schedule and associated processes.  The previous release model had the recurring problem of a \"release crunch,\" where it was difficult to find the effort required to test large changes before their deadline had passed. Sometimes the lack of timely effort led to software being pushed to the next release (a month later), because there was insufficient testing time.  Based on software support tickets, we noticed that many sites follow a local update schedule that is independent of the OSG Release team schedule; some sites upgrade every few months, skipping interim releases, other sites upgrade individual packages as needed. In addition, upstream software developers do not follow our release schedule either, releasing software on their own development timelines. As a result, some site administrators would prefer to have OSG software updates more often, closer to when they become available, rather than tied to a monthly cycle.  For these reasons, we created a new release model.",
            "title": "Introduction"
        },
        {
            "location": "/policy/flexible-release-model/#release-model",
            "text": "The OSG Release team releases batches of integrated, tested software on an ad hoc basis, with the process outlined below (changes from the old process are highlighted):    Software and Release Team members develop packages and mark them for testing    Software and Release Team members test the packages, possibly with help from the community    Once adequate testing is complete and successful, the Release Manager approves packages for release    Weekly, the Release Manager evaluates packages that are ready for release; when a sufficient number of important packages are ready [1] , the Release Manager schedules a release date and announces it. For urgent changes, the Release Manager evaluates the packages as soon as they are tested    The Software and Release Team performs pre-release testing, releases the packages, and announces the release    Note: The release dates of parallel release series (e.g., 3.3 and 3.4) do not have to coincide, as they have in the past.  [1] The threshold for \u201csufficient number of important packages\u201d is determined by the Release Manager, with input from the other Technology Area leaders.",
            "title": "Release Model"
        },
        {
            "location": "/policy/software-release/",
            "text": "Software Release Policy\n\u00b6\n\n\nThis document contains information about the OSG Software Yum repositories and their policies.\nFor details regarding the technical process for an OSG release, see \nthis document\n.\n\n\nYum Repositories\n\u00b6\n\n\nThe Software Team maintains the following Yum repositories:\n\n\n\n\nosg-development\n: This is the \"wild west\", the place where software goes while it is being worked on by the\n    software team.\n\n\nosg-testing\n: This is where software goes when it is ready for wide-spread testing, including upstream release\n    candidates\n\n\nosg-prerelease\n: This is where software goes just before being released, for final verification.\n\n\nosg-rolling\n: This is where software goes before being included in a point release. Intended for end-users.\n\n\nosg-release\n: This is the official, production release of the software stack.\n    This is the main repository for end-users.\n\n\nosg-contrib\n: This is where software goes that is not officially supported by the OSG Software Team,\n    but we provide as a convenience for software our users might find useful.\n\n\n\n\nWe also create a repository per release, called \nosg-release-VERSION\n (such as osg-release-3.0.4).\nThis is intended mostly for testing purposes, though users may occasionally find it useful.\n\n\nOccasionally there may be other repositories for specific short-term purposes.\n\n\nVersion Numbers\n\u00b6\n\n\nThere is a single version number that is used to summarize the contents of the \nosg-release\n repository.\nHaving a single version number is very useful for a variety of reasons, including:\n\n\n\n\nEvery time changes are made to the \nosg-release\n repository, we update the version number and write release notes.\n\n\nWe have a shorthand for referring to the state of the repository; we can talk about specific releases.\n\n\n\n\nHowever, there are important caveats about the version number:\n\n\n\n\nEven if a user says they have installed Version X, it may not be an accurate reflection of what they have installed:\n    they may have chosen to update some of their software from a previous version.\n    To truly understand what they have installed, the entire set of RPMs installed on their computer must be considered.\n\n\nThe version number is only meaningful in the \nosg-release\n repository, though for technical reasons it's present (as\n    an RPM) in other repositories.\n\n\n\n\nThe version number is communicated in two ways:\n\n\n\n\nEvery time a new release is made, the version number is updated.\n    All release notes and communication to users about this release uses the new version number.\n\n\nThere is an \nosg-version\n RPM that reports the version of the release. Major metapackages (osg-ce, osg-client,\n    etc...) depend on this RPM.\n    The RPM itself has the version number in it. It also provide a program that reports the version, and a text file\n    that contains the version number.\n\n\n\n\nThe version number will be of the form X.Y.Z. As of this writing, version numbers are 3.4.Z, where Z indicates a minor\nrevision.\n\n\nProgression of Repositories\n\u00b6\n\n\nThis figure shows the progression of repositories that packages will go through:\n\n\n osg-development -> osg-testing -> osg-prerelease / osg-rolling -> osg-release\n                  \\\n                   -> osg-contrib\n\n\n\n\n\nRelease Policies\n\u00b6\n\n\nAdding packages to osg-development\n\u00b6\n\n\nNew packages will only be added to \nosg-development\n with the permission of the OSG Software Manager.\nUpdates can be done at any time without permission, but developers should be careful if their updates might be\nsignificant, particularly if an update might cause series compatibility issues.\nIn cases where there is uncertainty, discuss it with the Software Manager.\n\n\nMoving packages to osg-testing\n\u00b6\n\n\nA package may be moved from \nosg-development\n to \nosg-testing\n when the individual maintainer of that package decides\nthat it is ready for widespread testing and when approved by the OSG Software Manager.\nApproval is needed because this is when we first make packages available to people outside of the OSG Software Team.\n\n\nMoving packages to osg-prerelease and osg-rolling; Readying the release\n\u00b6\n\n\nWhen we are ready to make a production release, we first move the correct subset of packages from \nosg-testing\n into\n\nosg-prerelease\n and \nosg-rolling\n.\nThis should be done after checking with the OSG Release Manager to verify that it's okay to release the software.\nThe intention of \nosg-prerelease\n is to do a final verification that we have the correct set of packages for release and\nthat they really work together.\nThe intention of \nosg-rolling\n is to make thoroughly tested software available to users before its first point release.\nThis is important because the \nosg-testing\n repository might contain a mix of packages that are ready for release with\npackages that are not ready for release.\nWhen moving packages to \nosg-prerelease\n and \nosg-rolling\n, the team member doing the release will:\n\n\n\n\nUpdate the osg-version RPM to reflect the new version.\n    Push this RPM through \nosg-development\n, \nosg-testing\n, and into \nosg-prerelease\n and \nosg-rolling\n.\n\n\nFind the correct set of packages to push from \nosg-testing\n into \nosg-prerelease\n and \nosg-rolling\n.\n\n\nAt a minimum, run the automated test suite on the contents of \nosg-prerelease\n and \nosg-rolling\n.\n    In cases were more extensive testing is needed, or the test suite doesn't sufficiently cover the testing needs, do\n    specific ad-hoc testing.\n    (If appropriate, consider proposing extensions to the automated test suite.)\n\n\n\n\nWe expect that in most cases, this process of updating and testing the \nosg-prelease\n and \nosg-rolling\n repositories\nwill be less than one day.\nIf there are urgent security updates to release, this process may be shortened.\n\n\nMoving packages to osg-release\n\u00b6\n\n\nWhen the \nosg-prerelease\n repository has been updated and verified, all of the changed software can be moved into the\n\nosg-release\n repository.\nAs part of this move, two important tasks must be done:\n\n\n\n\nRecord the complete set of packages in the new release repository.\n\n\nUpdate the \nRelease Notes\n.\n    Note that each release has a separate page to describe the release, and it's linked from the main page.\n    The individual page lists the changes at a high level (i.e. Updated package X to version Y) and the complete set of\n    RPMs that changed.\n\n\nCreate a ticket on ticket.opensciencegrid.org with a release announcement.\n    Operations will distribute it to the right places.\n\n\n\n\nIn addition, we will make another Koji tag/yum repository called \nosg-release-VERSION\n.\nAll of the latest packages in osg-release will be tagged to be in this repository, and the tag will be locked.\nThis will give us a reproducible way to install any given OSG Software release.\n\n\nMoving packages to osg-release-VERSION\n\u00b6\n\n\nWhen we make a specific release, we copy the osg-release repository to a versioned osg-release-VERSION repository.\nThis allows us to do testing with specific versions and in rare cases allows users to use a specific release.\n\n\nMoving packages to osg-contrib\n\u00b6\n\n\nThe \nosg-contrib\n repository is loosely regulated.\nIn most cases, the team member in charge of the package can decide when a package is updated in \nosg-contrib\n.\nContrib packages should be tested in \nosg-development\n first.\n\n\nTiming of releases\n\u00b6\n\n\nCode freezes happen two business days in advance of the release (normally Friday).\nSpecifically: RPM updates intended to be included in the next release (that is, pushed to the osg-release yum repo) must\nbe in the osg-testing yum repo by noon Central Time two business days in advance of the release.\nThis will allow time for final testing, discussions, reverts, etc.\n\n\nWe will make exceptions for urgent situations; consult with the release manager when needed.\n\n\nCA Certificates and VO Client packages\n\u00b6\n\n\nPackages that contain only data are not part of the usual release cycle.\nCurrently, these are the CA certificate packages and the VO Client packages.\nUpdates to these packages come from the Security Team and Software Team, respectively.\nThey still move through the usual process for release, and the Software and Release Managers decide when these packages\nshould be promoted to the next repository level.\nHowever, the actual releases of these packages do not increment the version number of the software stack.\n\n\nThe release process for data packages is discussed here.",
            "title": "Software Release Policy"
        },
        {
            "location": "/policy/software-release/#software-release-policy",
            "text": "This document contains information about the OSG Software Yum repositories and their policies.\nFor details regarding the technical process for an OSG release, see  this document .",
            "title": "Software Release Policy"
        },
        {
            "location": "/policy/software-release/#yum-repositories",
            "text": "The Software Team maintains the following Yum repositories:   osg-development : This is the \"wild west\", the place where software goes while it is being worked on by the\n    software team.  osg-testing : This is where software goes when it is ready for wide-spread testing, including upstream release\n    candidates  osg-prerelease : This is where software goes just before being released, for final verification.  osg-rolling : This is where software goes before being included in a point release. Intended for end-users.  osg-release : This is the official, production release of the software stack.\n    This is the main repository for end-users.  osg-contrib : This is where software goes that is not officially supported by the OSG Software Team,\n    but we provide as a convenience for software our users might find useful.   We also create a repository per release, called  osg-release-VERSION  (such as osg-release-3.0.4).\nThis is intended mostly for testing purposes, though users may occasionally find it useful.  Occasionally there may be other repositories for specific short-term purposes.",
            "title": "Yum Repositories"
        },
        {
            "location": "/policy/software-release/#version-numbers",
            "text": "There is a single version number that is used to summarize the contents of the  osg-release  repository.\nHaving a single version number is very useful for a variety of reasons, including:   Every time changes are made to the  osg-release  repository, we update the version number and write release notes.  We have a shorthand for referring to the state of the repository; we can talk about specific releases.   However, there are important caveats about the version number:   Even if a user says they have installed Version X, it may not be an accurate reflection of what they have installed:\n    they may have chosen to update some of their software from a previous version.\n    To truly understand what they have installed, the entire set of RPMs installed on their computer must be considered.  The version number is only meaningful in the  osg-release  repository, though for technical reasons it's present (as\n    an RPM) in other repositories.   The version number is communicated in two ways:   Every time a new release is made, the version number is updated.\n    All release notes and communication to users about this release uses the new version number.  There is an  osg-version  RPM that reports the version of the release. Major metapackages (osg-ce, osg-client,\n    etc...) depend on this RPM.\n    The RPM itself has the version number in it. It also provide a program that reports the version, and a text file\n    that contains the version number.   The version number will be of the form X.Y.Z. As of this writing, version numbers are 3.4.Z, where Z indicates a minor\nrevision.",
            "title": "Version Numbers"
        },
        {
            "location": "/policy/software-release/#progression-of-repositories",
            "text": "This figure shows the progression of repositories that packages will go through:   osg-development -> osg-testing -> osg-prerelease / osg-rolling -> osg-release\n                  \\\n                   -> osg-contrib",
            "title": "Progression of Repositories"
        },
        {
            "location": "/policy/software-release/#release-policies",
            "text": "",
            "title": "Release Policies"
        },
        {
            "location": "/policy/software-release/#adding-packages-to-osg-development",
            "text": "New packages will only be added to  osg-development  with the permission of the OSG Software Manager.\nUpdates can be done at any time without permission, but developers should be careful if their updates might be\nsignificant, particularly if an update might cause series compatibility issues.\nIn cases where there is uncertainty, discuss it with the Software Manager.",
            "title": "Adding packages to osg-development"
        },
        {
            "location": "/policy/software-release/#moving-packages-to-osg-testing",
            "text": "A package may be moved from  osg-development  to  osg-testing  when the individual maintainer of that package decides\nthat it is ready for widespread testing and when approved by the OSG Software Manager.\nApproval is needed because this is when we first make packages available to people outside of the OSG Software Team.",
            "title": "Moving packages to osg-testing"
        },
        {
            "location": "/policy/software-release/#moving-packages-to-osg-prerelease-and-osg-rolling-readying-the-release",
            "text": "When we are ready to make a production release, we first move the correct subset of packages from  osg-testing  into osg-prerelease  and  osg-rolling .\nThis should be done after checking with the OSG Release Manager to verify that it's okay to release the software.\nThe intention of  osg-prerelease  is to do a final verification that we have the correct set of packages for release and\nthat they really work together.\nThe intention of  osg-rolling  is to make thoroughly tested software available to users before its first point release.\nThis is important because the  osg-testing  repository might contain a mix of packages that are ready for release with\npackages that are not ready for release.\nWhen moving packages to  osg-prerelease  and  osg-rolling , the team member doing the release will:   Update the osg-version RPM to reflect the new version.\n    Push this RPM through  osg-development ,  osg-testing , and into  osg-prerelease  and  osg-rolling .  Find the correct set of packages to push from  osg-testing  into  osg-prerelease  and  osg-rolling .  At a minimum, run the automated test suite on the contents of  osg-prerelease  and  osg-rolling .\n    In cases were more extensive testing is needed, or the test suite doesn't sufficiently cover the testing needs, do\n    specific ad-hoc testing.\n    (If appropriate, consider proposing extensions to the automated test suite.)   We expect that in most cases, this process of updating and testing the  osg-prelease  and  osg-rolling  repositories\nwill be less than one day.\nIf there are urgent security updates to release, this process may be shortened.",
            "title": "Moving packages to osg-prerelease and osg-rolling; Readying the release"
        },
        {
            "location": "/policy/software-release/#moving-packages-to-osg-release",
            "text": "When the  osg-prerelease  repository has been updated and verified, all of the changed software can be moved into the osg-release  repository.\nAs part of this move, two important tasks must be done:   Record the complete set of packages in the new release repository.  Update the  Release Notes .\n    Note that each release has a separate page to describe the release, and it's linked from the main page.\n    The individual page lists the changes at a high level (i.e. Updated package X to version Y) and the complete set of\n    RPMs that changed.  Create a ticket on ticket.opensciencegrid.org with a release announcement.\n    Operations will distribute it to the right places.   In addition, we will make another Koji tag/yum repository called  osg-release-VERSION .\nAll of the latest packages in osg-release will be tagged to be in this repository, and the tag will be locked.\nThis will give us a reproducible way to install any given OSG Software release.",
            "title": "Moving packages to osg-release"
        },
        {
            "location": "/policy/software-release/#moving-packages-to-osg-release-version",
            "text": "When we make a specific release, we copy the osg-release repository to a versioned osg-release-VERSION repository.\nThis allows us to do testing with specific versions and in rare cases allows users to use a specific release.",
            "title": "Moving packages to osg-release-VERSION"
        },
        {
            "location": "/policy/software-release/#moving-packages-to-osg-contrib",
            "text": "The  osg-contrib  repository is loosely regulated.\nIn most cases, the team member in charge of the package can decide when a package is updated in  osg-contrib .\nContrib packages should be tested in  osg-development  first.",
            "title": "Moving packages to osg-contrib"
        },
        {
            "location": "/policy/software-release/#timing-of-releases",
            "text": "Code freezes happen two business days in advance of the release (normally Friday).\nSpecifically: RPM updates intended to be included in the next release (that is, pushed to the osg-release yum repo) must\nbe in the osg-testing yum repo by noon Central Time two business days in advance of the release.\nThis will allow time for final testing, discussions, reverts, etc.  We will make exceptions for urgent situations; consult with the release manager when needed.",
            "title": "Timing of releases"
        },
        {
            "location": "/policy/software-release/#ca-certificates-and-vo-client-packages",
            "text": "Packages that contain only data are not part of the usual release cycle.\nCurrently, these are the CA certificate packages and the VO Client packages.\nUpdates to these packages come from the Security Team and Software Team, respectively.\nThey still move through the usual process for release, and the Software and Release Managers decide when these packages\nshould be promoted to the next repository level.\nHowever, the actual releases of these packages do not increment the version number of the software stack.  The release process for data packages is discussed here.",
            "title": "CA Certificates and VO Client packages"
        },
        {
            "location": "/policy/container-release/",
            "text": "Container Release Policy\n\u00b6\n\n\n17 April 2019\n\n\nContainer images are an increasingly popular tool for shortening the software development life cycle, allowing for speedy\ndeployment of new software versions or additional instances of a service.\nSelect services in the OSG Software Stack will be distributed as container images to support VOs and sites that are\ninterested in this model.\n\n\nThis document contains policy information for container images distributed by the OSG Software Team.\n\n\nContents and Sources\n\u00b6\n\n\nSimilar to our existing RPM infrastructure, container image sources, build logs, and artifacts will be stored in\npublicly available repositories (e.g. GitHub, Docker Hub) for collaboration and traceability.\nAdditionally, container images distributed by the OSG Software team will be based off of the latest version of a \n\nsupported platform\n with software installed from OS,\nEPEL, and \nOSG release\n Yum repositories with select packages\ninstalled from \nosg-development\n.\n\n\nTags\n\u00b6\n\n\nOSG Software container images will be tagged with at least one of the following tags:\n\n\n\n\n\n\n\n\nTag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfresh\n\n\nImages that build successfully and pass automated tests. Intended for users that need the latest fixes and features.\n\n\n\n\n\n\ntimestamp\n\n\nEach \nfresh\n image  is also tagged with a timestamp reflecting their build date and time. Intended for rollback in case of issues with the current \nfresh\n image.\n\n\n\n\n\n\nstable\n\n\nfresh\n images that pass acceptance testing; approved by the Release Manager. Intended for stable production use.\n\n\n\n\n\n\n\n\nCleanup\n\u00b6\n\n\nImages with only a timestamp tag will be untagged according to the following policy:\n\n\n\n\nWeekly timestamped image tags will be kept for at least three months\n\n\nAfter three months, monthly timestamped image tags will be kept for at least one year\n\n\n\n\nAnnouncements\n\u00b6\n\n\nContainer images that have been tagged as \nstable\n will be noted in the OSG release notes and announcements.",
            "title": "Container Release Policy"
        },
        {
            "location": "/policy/container-release/#container-release-policy",
            "text": "17 April 2019  Container images are an increasingly popular tool for shortening the software development life cycle, allowing for speedy\ndeployment of new software versions or additional instances of a service.\nSelect services in the OSG Software Stack will be distributed as container images to support VOs and sites that are\ninterested in this model.  This document contains policy information for container images distributed by the OSG Software Team.",
            "title": "Container Release Policy"
        },
        {
            "location": "/policy/container-release/#contents-and-sources",
            "text": "Similar to our existing RPM infrastructure, container image sources, build logs, and artifacts will be stored in\npublicly available repositories (e.g. GitHub, Docker Hub) for collaboration and traceability.\nAdditionally, container images distributed by the OSG Software team will be based off of the latest version of a  supported platform  with software installed from OS,\nEPEL, and  OSG release  Yum repositories with select packages\ninstalled from  osg-development .",
            "title": "Contents and Sources"
        },
        {
            "location": "/policy/container-release/#tags",
            "text": "OSG Software container images will be tagged with at least one of the following tags:     Tag  Description      fresh  Images that build successfully and pass automated tests. Intended for users that need the latest fixes and features.    timestamp  Each  fresh  image  is also tagged with a timestamp reflecting their build date and time. Intended for rollback in case of issues with the current  fresh  image.    stable  fresh  images that pass acceptance testing; approved by the Release Manager. Intended for stable production use.",
            "title": "Tags"
        },
        {
            "location": "/policy/container-release/#cleanup",
            "text": "Images with only a timestamp tag will be untagged according to the following policy:   Weekly timestamped image tags will be kept for at least three months  After three months, monthly timestamped image tags will be kept for at least one year",
            "title": "Cleanup"
        },
        {
            "location": "/policy/container-release/#announcements",
            "text": "Container images that have been tagged as  stable  will be noted in the OSG release notes and announcements.",
            "title": "Announcements"
        },
        {
            "location": "/policy/community-testing/",
            "text": "OSG Community Software Testing\n\u00b6\n\n\n8 October 2019\n\n\nThe community of OSG resource providers has a vested interest in the quality and stability of the OSG software stack.\nWe would like to notify our stakeholders of software updates as soon as they are designated as \"Ready for Testing\" by\nthe Software Team.\nDirect engagement with the entire community would allow for feedback from a broader array of interested parties.\nCombined with our \nflexible release model\n, we hope to further improve the turnaround\ntime of new features and bug fixes.\n\n\nImplementation\n\u00b6\n\n\nAfter the OSG Software Team builds and tests a package successfully, it is marked \"Ready for Testing\" and is added to the\nappropriate Yum testing repository:\n\nosg-testing\n and \nosg-upcoming-testing\n for packages targeted for the release and the upcoming release, respectively.\nUpon addition to the relevant testing repository, we intend to notify OSG site administrators that the package, or a\nlogically connected group of packages, is available for testing with a description of changes compared to previously\nreleased versions and provide a forum by which interested users can provide feedback.\nAdditionally, any packages that are considered release candidates by their upstream authors will be noted as such.\n\n\nThe Software and Release team will classify packages as either \n\"major\"\n or \"minor\"; where major\npackages are deemed critical to the functionality of the production grid and all other packages are minor.\nFor major packages, we will notify site administrators as soon as they are eligible for testing;\nminor packages eligible for testing will be collected and announced in a weekly digest.\nAfter users have been notified of changes, minor packages will be marked eligible for release if they have not received\nnegative feedback after 7 calendar days.\nIn addition to the above requirements, major packages must also receive positive feedback and be approved by the Release\nManager.\nIf a package receives negative feedback, the offending package will be removed from the relevant testing repository.\n\n\nMajor Packages\n\u00b6\n\n\nThe following packages are considered critical to the production Open Science Grid:\n\n\n\n\nBLAHP\n\n\nCVMFS\n\n\nFrontier Squid\n\n\nGlideinWMS\n\n\nHDFS\n\n\nHTCondor\n\n\nHTCondor-CE\n\n\nSingularity\n\n\nXCache\n\n\nXRootD\n\n\n\n\nThis list is maintained by the Release Manager with input from OSG stakeholders, the Software Manager, and the\nOperations Manager.\n\n\nExceptions\n\u00b6\n\n\nIf an expedient release is required, the OSG Software Team may forego the community testing policy outlined above.\nCommon exceptions to the policy include releases that contain one or more of the following:\n\n\n\n\nSecurity updates\n\n\nCA or VO data updates\n\n\nUpdates that address installation or upgrade issues\n\n\n\n\nAnnouncement Template\n\u00b6\n\n\nThe following email template is filled out to announce that packages are ready\nfor testing. Sections without packages to be tested should be omitted.\n\n\nSubject: OSG Packages Available for Testing\n\n\n\n\n\nSeveral packages are available for testing for tentative release the\nweek of Month Day.\n\nOSG 3.5 Only:\n-   Major Components\n    -   Major Package n.v.r (Comment, Security, etc.)\n    -   Major Package n.v.r\n-   Minor Components\n    -   Minor Package n.v.r\n    -   Minor Package n.v.r\n\nBoth OSG 3.5 and 3.4:\n-   Major Components\n    -   Major Package n.v.r (Comment, Security, etc.)\n    -   Major Package n.v.r\n-   Minor Components\n    -   Minor Package n.v.r\n    -   Minor Package n.v.r\n\nOSG 3.4 Only:\n-   Major Components\n    -   Major Package n.v.r (Comment, Security, etc.)\n    -   Major Package n.v.r\n-   Minor Components\n    -   Minor Package n.v.r\n    -   Minor Package n.v.r\n\nJIRA Ticket Summary: https://opensciencegrid.atlassian.net/issues/?filter=12355\n\nPlease test this software in a non-production environment.\nSend positive or negative feedback to osg-software@opensciencegrid.org\nBe sure to include details describing your testing platform: (OSG 3.4 vs 3.5)\nand (EL6 vs EL7). If you any questions, you can always contact us at\nhelp@opensciencegrid.org\n\nAs described by our Community Software Testing Policy,\n(https://opensciencegrid.org/technology/policy/community-testing/)\nMajor components of the OSG software stack and need positive feedback and\nthe approval of the release manager before being marked \"Ready for Release\".\n\nFeedback about the community testing process is also desired.\n\n\n\n\n\nVersion History\n\u00b6\n\n\n\n\n2019-10-08\n: Add policy exceptions\n\n\n2019-08-12\n: Add notification frequency details\n\n\n2019-02-20\n: Initial policy",
            "title": "Community Testing"
        },
        {
            "location": "/policy/community-testing/#osg-community-software-testing",
            "text": "8 October 2019  The community of OSG resource providers has a vested interest in the quality and stability of the OSG software stack.\nWe would like to notify our stakeholders of software updates as soon as they are designated as \"Ready for Testing\" by\nthe Software Team.\nDirect engagement with the entire community would allow for feedback from a broader array of interested parties.\nCombined with our  flexible release model , we hope to further improve the turnaround\ntime of new features and bug fixes.",
            "title": "OSG Community Software Testing"
        },
        {
            "location": "/policy/community-testing/#implementation",
            "text": "After the OSG Software Team builds and tests a package successfully, it is marked \"Ready for Testing\" and is added to the\nappropriate Yum testing repository: osg-testing  and  osg-upcoming-testing  for packages targeted for the release and the upcoming release, respectively.\nUpon addition to the relevant testing repository, we intend to notify OSG site administrators that the package, or a\nlogically connected group of packages, is available for testing with a description of changes compared to previously\nreleased versions and provide a forum by which interested users can provide feedback.\nAdditionally, any packages that are considered release candidates by their upstream authors will be noted as such.  The Software and Release team will classify packages as either  \"major\"  or \"minor\"; where major\npackages are deemed critical to the functionality of the production grid and all other packages are minor.\nFor major packages, we will notify site administrators as soon as they are eligible for testing;\nminor packages eligible for testing will be collected and announced in a weekly digest.\nAfter users have been notified of changes, minor packages will be marked eligible for release if they have not received\nnegative feedback after 7 calendar days.\nIn addition to the above requirements, major packages must also receive positive feedback and be approved by the Release\nManager.\nIf a package receives negative feedback, the offending package will be removed from the relevant testing repository.",
            "title": "Implementation"
        },
        {
            "location": "/policy/community-testing/#major-packages",
            "text": "The following packages are considered critical to the production Open Science Grid:   BLAHP  CVMFS  Frontier Squid  GlideinWMS  HDFS  HTCondor  HTCondor-CE  Singularity  XCache  XRootD   This list is maintained by the Release Manager with input from OSG stakeholders, the Software Manager, and the\nOperations Manager.",
            "title": "Major Packages"
        },
        {
            "location": "/policy/community-testing/#exceptions",
            "text": "If an expedient release is required, the OSG Software Team may forego the community testing policy outlined above.\nCommon exceptions to the policy include releases that contain one or more of the following:   Security updates  CA or VO data updates  Updates that address installation or upgrade issues",
            "title": "Exceptions"
        },
        {
            "location": "/policy/community-testing/#announcement-template",
            "text": "The following email template is filled out to announce that packages are ready\nfor testing. Sections without packages to be tested should be omitted.  Subject: OSG Packages Available for Testing  Several packages are available for testing for tentative release the\nweek of Month Day.\n\nOSG 3.5 Only:\n-   Major Components\n    -   Major Package n.v.r (Comment, Security, etc.)\n    -   Major Package n.v.r\n-   Minor Components\n    -   Minor Package n.v.r\n    -   Minor Package n.v.r\n\nBoth OSG 3.5 and 3.4:\n-   Major Components\n    -   Major Package n.v.r (Comment, Security, etc.)\n    -   Major Package n.v.r\n-   Minor Components\n    -   Minor Package n.v.r\n    -   Minor Package n.v.r\n\nOSG 3.4 Only:\n-   Major Components\n    -   Major Package n.v.r (Comment, Security, etc.)\n    -   Major Package n.v.r\n-   Minor Components\n    -   Minor Package n.v.r\n    -   Minor Package n.v.r\n\nJIRA Ticket Summary: https://opensciencegrid.atlassian.net/issues/?filter=12355\n\nPlease test this software in a non-production environment.\nSend positive or negative feedback to osg-software@opensciencegrid.org\nBe sure to include details describing your testing platform: (OSG 3.4 vs 3.5)\nand (EL6 vs EL7). If you any questions, you can always contact us at\nhelp@opensciencegrid.org\n\nAs described by our Community Software Testing Policy,\n(https://opensciencegrid.org/technology/policy/community-testing/)\nMajor components of the OSG software stack and need positive feedback and\nthe approval of the release manager before being marked \"Ready for Release\".\n\nFeedback about the community testing process is also desired.",
            "title": "Announcement Template"
        },
        {
            "location": "/policy/community-testing/#version-history",
            "text": "2019-10-08 : Add policy exceptions  2019-08-12 : Add notification frequency details  2019-02-20 : Initial policy",
            "title": "Version History"
        },
        {
            "location": "/documentation/writing-documentation/",
            "text": "Writing OSG Documentation\n\u00b6\n\n\nMany OSG pages are written in \nmarkdown\n, built using\n\nMkDocs\n, and served via \nGitHub Pages\n.\nTo \ncontribute content\n, submit a pull request to the relevant github repository:\n\n\n\n\nSite administrator documentation\n\n\nInternal Technology Area documentation\n.\n\n\nNetworking documentation\n\n\nSecurity documentation\n\n\nOperations documentation\n\n\nProduction meeting notes\n\n\nManagement pages\n\n\nOutreach pages\n\n\nUser School 2017 pages\n\n\nUser School 2018 pages\n\n\n\n\n\n\n\n\nThis document contains instructions, recommendations, and guidelines for writing OSG content.\n\n\nContributing Content\n\u00b6\n\n\nTo contribute minor content changes (e.g., fixing typos, changing a couple of sentences), we recommend using the\n\nGitHub web interface\n to submit a pull request.\n\n\nTo contribute major content changes to one of the above OSG areas, make sure you and the machine you'll be working on\nmeet the following requirements:\n\n\n\n\nHave a \nGithub account\n\n\nInstallations of the following tools and languages:\n\n\ngit\n\n\nPython\n\n\npip\n (usually comes by default with Python 2 >= 2.7.9 or Python 3 >= 3.4)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nOn macOS, the OS-distributed Python does not come with pip.\nRun the following to install it:\n\n\n$\n sudo easy_install pip\n\n\n\n\n\npip will be installed in \n/usr/local/bin/\n, so you will need \n/usr/local/bin\n in your PATH.\n\n\n\n\nPreparing the git repository\n\u00b6\n\n\nBefore making any content changes, you will need to prepare a local git clone and set up a Python virtual environment:\n\n\n\n\nFork and clone\n the GitHub repository that you'd like to contribute to\n\n\ncd\n into the directory containing the local clone of your Github fork\n\n\n\n\nRun the following command to update the contents of the \nci\n directory:\n\n\n$\n git submodule update --init --recursive\n\n\n\n\n\n\n\n\n\nAdd the upstream Github repository as a \nremote\n.\n   For example, if you are working on the User School 2018 pages:\n\n\n$\n git remote add upstream https://github.com/opensciencegrid/user-school-2018\n\n\n\n\n\n\n\n\n\nInstall the \nvirtualenv\n package:\n\n\n$\n pip install --user virtualenv\n\n\n\n\n\n\n\n\n\nSet up your Python virtual environment:\n\n\n$\n virtualenv env\n\n$\n env/bin/pip install -r ci/pip-requirements.txt\n\n\n\n\n\n\n\n\n\nPreviewing the pages\n\u00b6\n\n\nTo preview the pages, start a MkDocs development server.\nThe development server will automatically detect any content changes and make them viewable in your browser.\n\n\n\n\n\n\ncd\n into the directory containing the local clone of your GitHub fork\n\n\n\n\n\n\nStart a MkDocs development server to preview your changes:\n\n\n$\n \nPYTHONPATH\n=\nsrc env/bin/mkdocs serve\n\n\n\n\n\nTo preview your changes visit \nlocalhost:8000\n in the browser of your choice.\nThe server can be stopped with \nCtrl-C\n.\n\n\n\n\n\n\nMaking content changes\n\u00b6\n\n\nTo contribute content to the OSG, follow these steps to submit a pull request with your desired changes:\n\n\n\n\ncd\n into the directory containing the local clone of your Github fork\n\n\n\n\nCreate a branch based on a branch from the \nupstream\n repository:\n\n\n$\n git fetch --all\n\n$\n git checkout -b <BRANCH NAME> upstream/<UPSTREAM BRANCH NAME>\n\n\n\n\n\nReplace \n<BRANCH NAME>\n with a name of your choice and \n<UPSTREAM BRANCH NAME>\n with a branch name from the\n\nupstream\n repository.\nFor example, instructors for the 2018 User School should use the \nmaterials\n branch:\n\n\n$\n git checkout -b example_branch_name upstream/materials\n\n\n\n\n\nIf you do not know which \nupstream\n branch to use, pick \nmaster\n.\n\n\n\n\n\n\nMake your changes in the \ndocs/\n directory of your local clone, following the \nstyle guide\n:\n\n\n\n\nIf you are making changes to an existing page:\n\n\nOpen \nmkdocs.yml\n and find the location of the file relative to the \ndocs/\n directory\n\n\nMake your changes to that file and move onto the next step\n\n\n\n\n\n\nIf you are contributing a new page:\n\n\nName the page. Page file names should be lowercase, \n-\n delimited, and concise but descriptive,\n   e.g. \nmarkdown-migration.md\n or \ncutting-release.md\n\n\nPlace the page in the relevant sub-folder of the \ndocs/\n directory.\n   If you are unsure of the appropriate location, note that in the description of the pull request.\n\n\nAdd the document to the \npages:\n section of \nmkdocs.yml\n in \ntitle case\n,\n   e.g. \n- Migrating Documents to Markdown: 'software/markdown-migration.md'\n\n\nIf you are writing site administrator documentation, following the \nsuggested document layout\n\n\n\n\n\n\n\n\n\n\n\n\nIf you haven't already, start a Mkdocs development server to \npreview your changes\n.\n\n\n\n\n\n\nContinue making changes until you are satisfied with the preview, then stage your changes in git:\n\n\n$\n git add <YOUR FILE> <YOUR 2nd FILE>...<YOUR Nth FILE>\n\n\n\n\n\nWhere \n<YOUR * FILE>\n is any file that contains changes that you'd wish to make.\nIf you are adding a new page, one of the files should be \nmkdocs.yml\n.\n\n\n\n\n\n\nCommit your changes and push them to your Github fork:\n\n\n$\n git commit -m \n\"<DESCRIPTIVE COMMIT MESSAGE>\"\n\n\n$\n git push origin\n\n\n\n\n\nWhere \n<DESCRIPTIVE COMMIT MESSAGE>\n is a meaningful short text that identifies the changes applied, it is a good\npractice, to concatenate the ticket number associated e.g. \"Removing color macros (SOFTWARE-3739)\"\n\n\n\n\n\n\nFrom your Github fork, \nsubmit a pull request\n\n\n\n\n\n\nDeploying content to the ITB (advanced)\n\u00b6\n\n\nIf you are a member of the OSG software and release team, you can preview large changes to the\n\nITB docs\n or \nITB technology\n\nby pushing a branch that starts with an \nitb.\n prefix to the \nopensciencegrid/docs\n repo.\nFor example:\n\n\n$\n git remote add upstream https://github.com/opensciencegrid/docs.git\n\n$\n git checkout new_docs\n\n$\n git push upstream new_docs:itb.new_docs\n\n\n\n\n\n\n\nNote\n\n\nSince there is only one ITB docs area, simultaneous new commits to different \nitb.*\n branches will overwrite each other's changes. To re-deploy your changes, find your \nTravis-CI build\n and restart it \nBUT\n coordinate with the author of the other commits to avoid conflicts.\n\n\n\n\nDocument Layout\n\u00b6\n\n\nThis section contains suggested layouts of externally-facing, \nsite administrator documentation\n.\nThe introduction is the only layout requirement for documents except for installation guides.\n\n\nIntroductions\n\u00b6\n\n\nAll documents should start with an introduction that explains \nwhat\n the document contains, \nwhat\n the product does,\nand \nwhy\n someone may want to use it.\nIn the past, document introductions were included in \nAbout this...\n sections due to the layout of the table of contents.\nSince the table of contents is included in the sidebar this is unnecessary and introduction content should go directly\nbelow the title heading without any second-level headings.\n\n\nThe \nHTCondor-CE installation guide\n\nis an example that meet all of the above criteria.\n\n\nInstallation guides\n\u00b6\n\n\nIn addition to the introduction above, installation documents should have the following sections:\n\n\n\n\nBefore Starting:\n This section should contain information for any prepatory work that the site administrator should\n  do or consider before proceeding with the installation\n  (\nexample\n).\n\n\nInstallation:\n Procedural instructions that tell the user how to install the software\n  (\nexample\n)\n\n\nValidation:\n How does the user make sure their installation is functional?\n\n\nHelp:\n Often just a link to the relevant \nhelp document\n as well\n  as contact information for specific support groups, if applicable.\n\n\n\n\nOptionally, the following sections should be included as necessary.\n\n\n\n\nOverview:\n if the introduction becomes large and unwieldy, extract the details of \nwhat\n the product does into an\n  overview section\n\n\nConfiguration:\n required configuration steps (\nexample\n)\n  as well as a sub-section for optional configurations.\n  For long optional configuration sections, consider creating alist of contents at the top of the sub-section\n  (\nexample\n).\n\n\nTroubleshooting:\n common issues that users encounter and their fixes\n\n\nReference:\n Details about configuration and log files, unix users, certificates, networking, links to relevant\n  upstream documentation, etc.\n  (\nexample\n)\n\n\n\n\nIf any of the sections become too large, consider separating them out and linking to the new documents\n(\nexample\n).\n\n\nTips for Writing Procedural Instructions\n\u00b6\n\n\n\n\n\n\nTitle the procedure with the user goal, usually starting with a gerund; e.g.:\n\n\nInstalling the Frobnosticator\n\n\n\n\n\n\nNumber all steps (as opposed to using bullets)\n\n\n\n\n\n\nList steps in order in which they are performed\n\n\n\n\n\n\nEach step should begin with a single-line instruction in plain English, in command form; e.g.:\n\n\n\n\nMake sure that the Frobnosticator configuration file is world-writable\n\n\n\n\n\n\n\n\nIf the means of carrying out the instruction is unclear or complex, include clarification, ideally in the form of a\n  working example; e.g.:\n  \nchmod a+x /usr/share/frobnosticator/frob.conf\n\n\n\n\n\n\nPut clarifying information in separate paragraphs within the step\n\n\n\n\n\n\nPut critical information about the \nwhole\n procedure in one or more paragraphs before the numbered steps\n\n\n\n\n\n\nPut supplemental information about the \nwhole\n procedure in one or more paragraphs after the numbered steps\n\n\n\n\n\n\nAvoid pronouns when writing technical articles or documentation e.g., \ninstall foo\n rather than \ninstall it\n.\n\n\n\n\n\n\nAvoid superfluous statements like \nyou will want\n, \nyou want\n, \nyou should\n e.g., \ninstall foo\n rather than\n  \nyou will want to install foo\n.",
            "title": "Writing Documentation"
        },
        {
            "location": "/documentation/writing-documentation/#writing-osg-documentation",
            "text": "Many OSG pages are written in  markdown , built using MkDocs , and served via  GitHub Pages .\nTo  contribute content , submit a pull request to the relevant github repository:   Site administrator documentation  Internal Technology Area documentation .  Networking documentation  Security documentation  Operations documentation  Production meeting notes  Management pages  Outreach pages  User School 2017 pages  User School 2018 pages     This document contains instructions, recommendations, and guidelines for writing OSG content.",
            "title": "Writing OSG Documentation"
        },
        {
            "location": "/documentation/writing-documentation/#contributing-content",
            "text": "To contribute minor content changes (e.g., fixing typos, changing a couple of sentences), we recommend using the GitHub web interface  to submit a pull request.  To contribute major content changes to one of the above OSG areas, make sure you and the machine you'll be working on\nmeet the following requirements:   Have a  Github account  Installations of the following tools and languages:  git  Python  pip  (usually comes by default with Python 2 >= 2.7.9 or Python 3 >= 3.4)      Note  On macOS, the OS-distributed Python does not come with pip.\nRun the following to install it:  $  sudo easy_install pip  pip will be installed in  /usr/local/bin/ , so you will need  /usr/local/bin  in your PATH.",
            "title": "Contributing Content"
        },
        {
            "location": "/documentation/writing-documentation/#preparing-the-git-repository",
            "text": "Before making any content changes, you will need to prepare a local git clone and set up a Python virtual environment:   Fork and clone  the GitHub repository that you'd like to contribute to  cd  into the directory containing the local clone of your Github fork   Run the following command to update the contents of the  ci  directory:  $  git submodule update --init --recursive    Add the upstream Github repository as a  remote .\n   For example, if you are working on the User School 2018 pages:  $  git remote add upstream https://github.com/opensciencegrid/user-school-2018    Install the  virtualenv  package:  $  pip install --user virtualenv    Set up your Python virtual environment:  $  virtualenv env $  env/bin/pip install -r ci/pip-requirements.txt",
            "title": "Preparing the git repository"
        },
        {
            "location": "/documentation/writing-documentation/#previewing-the-pages",
            "text": "To preview the pages, start a MkDocs development server.\nThe development server will automatically detect any content changes and make them viewable in your browser.    cd  into the directory containing the local clone of your GitHub fork    Start a MkDocs development server to preview your changes:  $   PYTHONPATH = src env/bin/mkdocs serve  To preview your changes visit  localhost:8000  in the browser of your choice.\nThe server can be stopped with  Ctrl-C .",
            "title": "Previewing the pages"
        },
        {
            "location": "/documentation/writing-documentation/#making-content-changes",
            "text": "To contribute content to the OSG, follow these steps to submit a pull request with your desired changes:   cd  into the directory containing the local clone of your Github fork   Create a branch based on a branch from the  upstream  repository:  $  git fetch --all $  git checkout -b <BRANCH NAME> upstream/<UPSTREAM BRANCH NAME>  Replace  <BRANCH NAME>  with a name of your choice and  <UPSTREAM BRANCH NAME>  with a branch name from the upstream  repository.\nFor example, instructors for the 2018 User School should use the  materials  branch:  $  git checkout -b example_branch_name upstream/materials  If you do not know which  upstream  branch to use, pick  master .    Make your changes in the  docs/  directory of your local clone, following the  style guide :   If you are making changes to an existing page:  Open  mkdocs.yml  and find the location of the file relative to the  docs/  directory  Make your changes to that file and move onto the next step    If you are contributing a new page:  Name the page. Page file names should be lowercase,  -  delimited, and concise but descriptive,\n   e.g.  markdown-migration.md  or  cutting-release.md  Place the page in the relevant sub-folder of the  docs/  directory.\n   If you are unsure of the appropriate location, note that in the description of the pull request.  Add the document to the  pages:  section of  mkdocs.yml  in  title case ,\n   e.g.  - Migrating Documents to Markdown: 'software/markdown-migration.md'  If you are writing site administrator documentation, following the  suggested document layout       If you haven't already, start a Mkdocs development server to  preview your changes .    Continue making changes until you are satisfied with the preview, then stage your changes in git:  $  git add <YOUR FILE> <YOUR 2nd FILE>...<YOUR Nth FILE>  Where  <YOUR * FILE>  is any file that contains changes that you'd wish to make.\nIf you are adding a new page, one of the files should be  mkdocs.yml .    Commit your changes and push them to your Github fork:  $  git commit -m  \"<DESCRIPTIVE COMMIT MESSAGE>\"  $  git push origin  Where  <DESCRIPTIVE COMMIT MESSAGE>  is a meaningful short text that identifies the changes applied, it is a good\npractice, to concatenate the ticket number associated e.g. \"Removing color macros (SOFTWARE-3739)\"    From your Github fork,  submit a pull request",
            "title": "Making content changes"
        },
        {
            "location": "/documentation/writing-documentation/#deploying-content-to-the-itb-advanced",
            "text": "If you are a member of the OSG software and release team, you can preview large changes to the ITB docs  or  ITB technology \nby pushing a branch that starts with an  itb.  prefix to the  opensciencegrid/docs  repo.\nFor example:  $  git remote add upstream https://github.com/opensciencegrid/docs.git $  git checkout new_docs $  git push upstream new_docs:itb.new_docs   Note  Since there is only one ITB docs area, simultaneous new commits to different  itb.*  branches will overwrite each other's changes. To re-deploy your changes, find your  Travis-CI build  and restart it  BUT  coordinate with the author of the other commits to avoid conflicts.",
            "title": "Deploying content to the ITB (advanced)"
        },
        {
            "location": "/documentation/writing-documentation/#document-layout",
            "text": "This section contains suggested layouts of externally-facing,  site administrator documentation .\nThe introduction is the only layout requirement for documents except for installation guides.",
            "title": "Document Layout"
        },
        {
            "location": "/documentation/writing-documentation/#introductions",
            "text": "All documents should start with an introduction that explains  what  the document contains,  what  the product does,\nand  why  someone may want to use it.\nIn the past, document introductions were included in  About this...  sections due to the layout of the table of contents.\nSince the table of contents is included in the sidebar this is unnecessary and introduction content should go directly\nbelow the title heading without any second-level headings.  The  HTCondor-CE installation guide \nis an example that meet all of the above criteria.",
            "title": "Introductions"
        },
        {
            "location": "/documentation/writing-documentation/#installation-guides",
            "text": "In addition to the introduction above, installation documents should have the following sections:   Before Starting:  This section should contain information for any prepatory work that the site administrator should\n  do or consider before proceeding with the installation\n  ( example ).  Installation:  Procedural instructions that tell the user how to install the software\n  ( example )  Validation:  How does the user make sure their installation is functional?  Help:  Often just a link to the relevant  help document  as well\n  as contact information for specific support groups, if applicable.   Optionally, the following sections should be included as necessary.   Overview:  if the introduction becomes large and unwieldy, extract the details of  what  the product does into an\n  overview section  Configuration:  required configuration steps ( example )\n  as well as a sub-section for optional configurations.\n  For long optional configuration sections, consider creating alist of contents at the top of the sub-section\n  ( example ).  Troubleshooting:  common issues that users encounter and their fixes  Reference:  Details about configuration and log files, unix users, certificates, networking, links to relevant\n  upstream documentation, etc.\n  ( example )   If any of the sections become too large, consider separating them out and linking to the new documents\n( example ).",
            "title": "Installation guides"
        },
        {
            "location": "/documentation/writing-documentation/#tips-for-writing-procedural-instructions",
            "text": "Title the procedure with the user goal, usually starting with a gerund; e.g.:  Installing the Frobnosticator    Number all steps (as opposed to using bullets)    List steps in order in which they are performed    Each step should begin with a single-line instruction in plain English, in command form; e.g.:   Make sure that the Frobnosticator configuration file is world-writable     If the means of carrying out the instruction is unclear or complex, include clarification, ideally in the form of a\n  working example; e.g.:\n   chmod a+x /usr/share/frobnosticator/frob.conf    Put clarifying information in separate paragraphs within the step    Put critical information about the  whole  procedure in one or more paragraphs before the numbered steps    Put supplemental information about the  whole  procedure in one or more paragraphs after the numbered steps    Avoid pronouns when writing technical articles or documentation e.g.,  install foo  rather than  install it .    Avoid superfluous statements like  you will want ,  you want ,  you should  e.g.,  install foo  rather than\n   you will want to install foo .",
            "title": "Tips for Writing Procedural Instructions"
        },
        {
            "location": "/documentation/reviewing-documentation/",
            "text": "Review OSG Software Documentation\n\u00b6\n\n\nTo maintain quality documentation, we must regularly review our documentation for clarity and correctness. We differentiate between two types of reviews, content and editorial, which you can think of as for correctness and clarity, respectively. If you are reviewing a document as part of the release process, perform a content review.\n\n\nAfter completing a review, update the appropriate columns in the \ndocument tracking spreadsheet\n. Speak to Brian Lin for write access.\n\n\nContent Review\n\u00b6\n\n\nContent reviews are for validating the correctness of technical steps and details. To perform a content review, follow the instructions of the document to a tee as if you were an OSG neophyte. Things to note and/or fix:\n\n\n\n\nAfter completing the instructions in the document:\n\n\nDoes the document inform you how to use the product?\n\n\nDoes the document tell you how to verify that the product is functioning?\n\n\nDoes the product work?\n\n\n\n\n\n\nIncorrect or out of date instructions\n\n\nSteps that may be particularly conducive to software or default configuration as a solution\n\n\nLack of clarity or any other confusion you may have\n\n\n\n\nEditorial Review\n\u00b6\n\n\nEditorial reviews are for ensuring docs meet our \nstyle\n and \nlayout\n guidelines; improving readability; and proofing spelling, grammar, and punctuation.",
            "title": "Reviewing Documentation"
        },
        {
            "location": "/documentation/reviewing-documentation/#review-osg-software-documentation",
            "text": "To maintain quality documentation, we must regularly review our documentation for clarity and correctness. We differentiate between two types of reviews, content and editorial, which you can think of as for correctness and clarity, respectively. If you are reviewing a document as part of the release process, perform a content review.  After completing a review, update the appropriate columns in the  document tracking spreadsheet . Speak to Brian Lin for write access.",
            "title": "Review OSG Software Documentation"
        },
        {
            "location": "/documentation/reviewing-documentation/#content-review",
            "text": "Content reviews are for validating the correctness of technical steps and details. To perform a content review, follow the instructions of the document to a tee as if you were an OSG neophyte. Things to note and/or fix:   After completing the instructions in the document:  Does the document inform you how to use the product?  Does the document tell you how to verify that the product is functioning?  Does the product work?    Incorrect or out of date instructions  Steps that may be particularly conducive to software or default configuration as a solution  Lack of clarity or any other confusion you may have",
            "title": "Content Review"
        },
        {
            "location": "/documentation/reviewing-documentation/#editorial-review",
            "text": "Editorial reviews are for ensuring docs meet our  style  and  layout  guidelines; improving readability; and proofing spelling, grammar, and punctuation.",
            "title": "Editorial Review"
        },
        {
            "location": "/documentation/style-guide/",
            "text": "Markdown Style Guide\n\u00b6\n\n\nThis document contains markdown conventions that are used in OSG Software documentation.\n\n\nMeta\n\u00b6\n\n\n\n\nRun a spellchecker to catch any obvious spelling mistakes.\n\n\nUse official capitalizations when referring to titles (i.e., HTTPS, HTCondor)\n\n\nWherever possible, prose should be limited to 120 characters wide but do not break links up between lines.\n  In addition, using one line for each sentence is recommended since it makes update diffs easier to review.\n\n\n\n\nHeadings\n\u00b6\n\n\nUse the following conventions for headings:\n\n\n\n\nThe title should be the only level 1 heading\n\n\nLevel 1 headings should use the \n====\n format\n\n\nLevel 2 headings should use the \n----\n format\n\n\nUse Title Case for level 1 and level 2 headings. Only capitalize the first word for all other headings.\n\n\nOther heading levels should use the appropriate number of \n#\n\n\nGo no deeper than of level 5 headings\n\n\nSpin-off a new document or re-organize the existing document if you find that you regularly need level 5 headings.\n\n\n\n\nLinks\n\u00b6\n\n\n\n\nAvoid document relative links\n\n\nDocument-relative links to other pages have changed in MkDocs 1.0.0 in a backwards-incompatible way.\nPlease convert any document-relative links to site-relative links before updating the \ndoc-ci-scripts\n submodule.\n\n\n\n\n\n\nLinks to internal pages should not have the \n.md\n extension\n\n\nUse site-relative (\n/software/development-process\n) instead of document-relative (\n../software/development-process\n)\n  links.\n  This will allow us to easily search for links and move documents around in the future.\n\n\nLinks to the area's homepage (e.g. https://opensciencegrid.org/technology/) need to be of the form \n[link text](/)\n\n\n\n\nSection links\n\u00b6\n\n\nTo link sections within a page, lowercase the entire section name and replace spaces with dashes. If there are multiple\nsections with the same name you can link the subsequent sections by appending \n_N\n where \nN\n is the section's ordinal\nnumber minus one, e.g. append \n_1\n for the second section. For example, if you have three sections named \"Optional\nConfiguration\", link them like so:\n\n\n[1st section](#optional-configuration)\n[2nd section](#optional-configuration_1)\n[3rd section](#optional-configuration_2)\n\n\n\n\n\nCommand blocks and file snippets\n\u00b6\n\n\nCommand blocks and file snippets outside of lists should be wrapped in three back-ticks (```) followed by an optional\ncode highlighting format:\n\n\n```console\n# stuff\n```\n\n\n\n\n\nCommand blocks and file snippets inside of a list should use the appropriate number of spaces before three\ncolons followed by an optional code highlighting format:\n\n\n#\n stuff\n\n\n\n\n\nSee the \nlists section\n for details on properly formatting command blocks within a list.\n\n\nWe use the \nPygments\n highlighting library for syntax; it knows about 100 different languages.\nThe Pygments website contains a live renderer if you want to see how your text will come out.  Please use the \nconsole\n\nlanguage for shell sessions.\n\n\nRoot and user prompts\n\u00b6\n\n\nWhen specifying instructions for the command-line, indicate to users whether the commands can be run as root \n(\nroot@host #\n) or as an unprivileged user (\nuser@host $\n).\n\n\nFor example:\n\n\nroot@host #\n useradd -m osguser\n\nroot@host #\n su - osguser\n\nuser@host $\n whoami\n\nosguser\n\n\n\n\n\n\nIt can provide helpful context to use a more specific hostname in the prompt than \nhost\n.\nFor example, if you're writing a doc for setting up a Storage Element and a command is run as root on the SE, use \nroot@se #\n.\nOr if you're testing the SE from the client side and the command is run as a normal user on a client, use \nuser@client $\n.\n\n\nHighlighting user input\n\u00b6\n\n\nUse descriptive, all-caps text wrapped in angle brackets to to highlight areas that users would have to insert text\nspecific to their site, e.g. \n<REMOTE SSH HOSTNAME>\n.\nThe same text should be cited verbatim in surrounding prose with further explanation with examples of appropriate values.\nFor additional visual highlighting,\nuse \nhl_lines=\"N\"\n,\nwhere \nN\n can indicate multiple line numbers:\n\n\n```console hl_lines=\"1 3\"\n\n\nroot@condor-ce #\n yum install htcondor-ce\n\n#\n this is a comment\n\nroot@condor-ce #\n condor_ce_trace -d <CE HOSTNAME>\n\n````\n\n\n\n\n\n\nSimilarly, you may also specify \n:::console hl_lines=\"N\"\n for indented command blocks, replacing \nconsole\n with any\nlanguage supported by \nPygments\n.\nThe above block is rendered below:\n\n\nroot@condor-ce #\n yum install htcondor-ce\n\n#\n this is a comment\n\nroot@condor-ce #\n condor_ce_trace -d <CE HOSTNAME>\n\n\n\n\n\nLists\n\u00b6\n\n\nWhen constructing lists, use the following guidelines:\n\n\n\n\nUse \n1.\n for each item in a numbered list\n\n\nTo make sure the contents of code blocks, file snippets, and subsequent paragraphs are indented properly, use the\n  following formatting:\n\n\nFor code blocks or file snippets, add an empty line after any regular text, then insert \n(N+1)*4\n spaces at the\n  beginning of each line, where N is the level of the item in the list. To apply code highlighting, start the code\n  block with \n:::<FORMAT>\n; see \nthis page\n for\n  details, including possible highlighting formats.  For an example of formatting a code section inside a list, see\n  \nthe release series document\n.\n\n\nFor additional text (i.e. after a code block), insert \nN*4\n spaces at the beginning of each line, where N is the\n  level of the item in the list.\n\n\n\n\n\n\n\n\nFor example:\n\n\n1. Foo\n    - Bar\n\n            :::console\n            COMMAND\n            BLOCK\n        text associated with Bar\n\n    text associated with Foo\n\n1. Baz\n\n        FILE\n        SNIPPET\n\n\n\n\n\nThere are 12 spaces and 8 spaces in front of the command block and text associated with \nBar\n, respectively; 4 spaces in\nfront of the text associated with \nFoo\n; and 8 spaces in front of the file snippet associated with \nBaz\n.  The above\nblock is rendered below:\n\n\n\n\n\n\nFoo\n\n\n\n\nBar\nCOMMAND\n\n\nBLOCK\n\n\n\n\n\n\ntext associated with Bar\n\n\n\n\n\n\ntext associated with Foo\n\n\n\n\n\n\nBaz\n\n\nFILE\nSNIPPET\n\n\n\n\n\n\n\n\n\nNotes\n\u00b6\n\n\nTo catch the user's attention for important items or pitfalls, we used \n%NOTE%\n TWiki macros, these can be replaced with\nadmonition-style notes and warnings:\n\n\n!!! note\n    things to note\n\n\n\n\n\nor\n\n\n!!! warning\n    if a user doesn't do this thing, bad stuff will happen\n\n\n\n\n\nThe above blocks are rendered below as an example.\n\n\n\n\nNote\n\n\nthings to note\n\n\n\n\nand\n\n\n\n\nWarning\n\n\nif a user doesn't do this thing, bad stuff will happen\n\n\n\n\nFor a full list of admonition styles, see the documentation\n\nhere\n.",
            "title": "Markdown Style Guide"
        },
        {
            "location": "/documentation/style-guide/#markdown-style-guide",
            "text": "This document contains markdown conventions that are used in OSG Software documentation.",
            "title": "Markdown Style Guide"
        },
        {
            "location": "/documentation/style-guide/#meta",
            "text": "Run a spellchecker to catch any obvious spelling mistakes.  Use official capitalizations when referring to titles (i.e., HTTPS, HTCondor)  Wherever possible, prose should be limited to 120 characters wide but do not break links up between lines.\n  In addition, using one line for each sentence is recommended since it makes update diffs easier to review.",
            "title": "Meta"
        },
        {
            "location": "/documentation/style-guide/#headings",
            "text": "Use the following conventions for headings:   The title should be the only level 1 heading  Level 1 headings should use the  ====  format  Level 2 headings should use the  ----  format  Use Title Case for level 1 and level 2 headings. Only capitalize the first word for all other headings.  Other heading levels should use the appropriate number of  #  Go no deeper than of level 5 headings  Spin-off a new document or re-organize the existing document if you find that you regularly need level 5 headings.",
            "title": "Headings"
        },
        {
            "location": "/documentation/style-guide/#links",
            "text": "Avoid document relative links  Document-relative links to other pages have changed in MkDocs 1.0.0 in a backwards-incompatible way.\nPlease convert any document-relative links to site-relative links before updating the  doc-ci-scripts  submodule.    Links to internal pages should not have the  .md  extension  Use site-relative ( /software/development-process ) instead of document-relative ( ../software/development-process )\n  links.\n  This will allow us to easily search for links and move documents around in the future.  Links to the area's homepage (e.g. https://opensciencegrid.org/technology/) need to be of the form  [link text](/)",
            "title": "Links"
        },
        {
            "location": "/documentation/style-guide/#section-links",
            "text": "To link sections within a page, lowercase the entire section name and replace spaces with dashes. If there are multiple\nsections with the same name you can link the subsequent sections by appending  _N  where  N  is the section's ordinal\nnumber minus one, e.g. append  _1  for the second section. For example, if you have three sections named \"Optional\nConfiguration\", link them like so:  [1st section](#optional-configuration)\n[2nd section](#optional-configuration_1)\n[3rd section](#optional-configuration_2)",
            "title": "Section links"
        },
        {
            "location": "/documentation/style-guide/#command-blocks-and-file-snippets",
            "text": "Command blocks and file snippets outside of lists should be wrapped in three back-ticks (```) followed by an optional\ncode highlighting format:  ```console\n# stuff\n```  Command blocks and file snippets inside of a list should use the appropriate number of spaces before three\ncolons followed by an optional code highlighting format:  #  stuff  See the  lists section  for details on properly formatting command blocks within a list.  We use the  Pygments  highlighting library for syntax; it knows about 100 different languages.\nThe Pygments website contains a live renderer if you want to see how your text will come out.  Please use the  console \nlanguage for shell sessions.",
            "title": "Command blocks and file snippets"
        },
        {
            "location": "/documentation/style-guide/#root-and-user-prompts",
            "text": "When specifying instructions for the command-line, indicate to users whether the commands can be run as root \n( root@host # ) or as an unprivileged user ( user@host $ ).  For example:  root@host #  useradd -m osguser root@host #  su - osguser user@host $  whoami osguser   It can provide helpful context to use a more specific hostname in the prompt than  host .\nFor example, if you're writing a doc for setting up a Storage Element and a command is run as root on the SE, use  root@se # .\nOr if you're testing the SE from the client side and the command is run as a normal user on a client, use  user@client $ .",
            "title": "Root and user prompts"
        },
        {
            "location": "/documentation/style-guide/#highlighting-user-input",
            "text": "Use descriptive, all-caps text wrapped in angle brackets to to highlight areas that users would have to insert text\nspecific to their site, e.g.  <REMOTE SSH HOSTNAME> .\nThe same text should be cited verbatim in surrounding prose with further explanation with examples of appropriate values.\nFor additional visual highlighting,\nuse  hl_lines=\"N\" ,\nwhere  N  can indicate multiple line numbers:  ```console hl_lines=\"1 3\"  root@condor-ce #  yum install htcondor-ce #  this is a comment root@condor-ce #  condor_ce_trace -d <CE HOSTNAME> ````   Similarly, you may also specify  :::console hl_lines=\"N\"  for indented command blocks, replacing  console  with any\nlanguage supported by  Pygments .\nThe above block is rendered below:  root@condor-ce #  yum install htcondor-ce #  this is a comment root@condor-ce #  condor_ce_trace -d <CE HOSTNAME>",
            "title": "Highlighting user input"
        },
        {
            "location": "/documentation/style-guide/#lists",
            "text": "When constructing lists, use the following guidelines:   Use  1.  for each item in a numbered list  To make sure the contents of code blocks, file snippets, and subsequent paragraphs are indented properly, use the\n  following formatting:  For code blocks or file snippets, add an empty line after any regular text, then insert  (N+1)*4  spaces at the\n  beginning of each line, where N is the level of the item in the list. To apply code highlighting, start the code\n  block with  :::<FORMAT> ; see  this page  for\n  details, including possible highlighting formats.  For an example of formatting a code section inside a list, see\n   the release series document .  For additional text (i.e. after a code block), insert  N*4  spaces at the beginning of each line, where N is the\n  level of the item in the list.     For example:  1. Foo\n    - Bar\n\n            :::console\n            COMMAND\n            BLOCK\n        text associated with Bar\n\n    text associated with Foo\n\n1. Baz\n\n        FILE\n        SNIPPET  There are 12 spaces and 8 spaces in front of the command block and text associated with  Bar , respectively; 4 spaces in\nfront of the text associated with  Foo ; and 8 spaces in front of the file snippet associated with  Baz .  The above\nblock is rendered below:    Foo   Bar COMMAND  BLOCK   text associated with Bar    text associated with Foo    Baz  FILE\nSNIPPET",
            "title": "Lists"
        },
        {
            "location": "/documentation/style-guide/#notes",
            "text": "To catch the user's attention for important items or pitfalls, we used  %NOTE%  TWiki macros, these can be replaced with\nadmonition-style notes and warnings:  !!! note\n    things to note  or  !!! warning\n    if a user doesn't do this thing, bad stuff will happen  The above blocks are rendered below as an example.   Note  things to note   and   Warning  if a user doesn't do this thing, bad stuff will happen   For a full list of admonition styles, see the documentation here .",
            "title": "Notes"
        },
        {
            "location": "/documentation/new-doc-area/",
            "text": "Creating a New Area\n\u00b6\n\n\nThis document contains instructions for creating a new top-level OSG website via \nGitHub Pages\n\nand deploying it automatically with \nTravis-CI\n.\nThis document assumes that you are an administrator of the \nopensciencegrid\n GitHub organization.\nBefore starting, make sure that you have the \ngit\n and \ngem\n tools installed.\n\n\n\n\n\n\nCreate a new repository in the \nopensciencegrid organization\n\n   (referred to as \n<REPO NAME>\n in the rest of this document)\n\n\n\n\nCheck the box marked \nInitialize this repository with a README\n\n\n\n\n\n\n\n\nIdentify the repository as using mkdocs:\n\n\n\n\nOn the repository home page (i.e., \nhttps://github.com/opensciencegrid/<REPO NAME>\n), click the \u201cManage topics\u201d\n   link\n\n\nSearch for \nmkdocs\n and select \nmkdocs\n\n\nClick the \u201cDone\u201d button\n\n\n\n\n\n\n\n\nClone the repository and \ncd\n into the directory:\n\n\ngit clone https://github.com/opensciencegrid/<REPO NAME>.git\ncd <REPO NAME>\n\n\n\n\n\n\n\n\n\nCreate a \ngh-pages\n branch in the GitHub repository:\n\n\ngit push origin master:gh-pages\n\n\n\n\n\n\n\n\n\nUpdate the contents of \nREADME.md\n and populate the \nLICENSE\n file with a\n   \nCreative Commons Attribution 4.0 license\n:\n\n\nwget https://creativecommons.org/licenses/by/4.0/legalcode.txt > LICENSE\n\n\n\n\n\n\n\n\n\nCreate and encrypt the repository deploy key\n\n\n\n\n\n\nGenerate the repository deploy key:\n\n\nssh-keygen -t rsa -b 4096 -C \"help@opensciencegrid.org\" -f deploy-key -N ''\n\n\n\n\n\n\n\n\n\nInstall the \ntravis\n gem:\n\n\ngem install travis\n\n\n\n\n\n\n\n\n\nLogin using your GitHub credentials:\n\n\ntravis login\n\n\n\n\n\n\n\n\n\nEnable the repository in Travis:\n\n\ntravis enable opensciencegrid/<REPO NAME>\n\n\n\n\n\n\n\n\n\nEncrypt the deploy key:\n\n\ntravis encrypt-file deploy-key\n\n\n\n\n\n\n\n\n\nStage and commit your files:\n\n\ngit add LICENSE README.md deploy-key.enc\ngit commit -m \"Prepare the repository for Travis-CI deployment\"\n\n\n\n\n\n\n\nDanger\n\n\nDo NOT commit the unencrypted \ndeploy-key\n!\n\n\n\n\n\n\n\n\nAdd the contents of \ndeploy-key.pub\n to your repository's list of\n   \ndeploy keys\n.\n   Make sure to check \nAllow write access\n.\n\n\n\n\n\n\n\n\n\n\nFollow \nthese instructions\n to add\n   the \ndoc-ci-scripts\n sub-module\n\n\n\n\n\n\nCreate \nmkdocs.yml\n containing the following:\n\n\nsite_name: <TITLE OF YOUR SITE>\nsite_url: https://opensciencegrid.org/<REPO NAME>\nrepo_name: https://github.com/opensciencegrid/<REPO NAME>\n\npages:\n  - Home: 'index.md'\n\nmarkdown_extensions:\n  - admonition\n  - codehilite:\n      guess_lang: False\n  - toc:\n      permalink: True\n\n\n\n\n\n\n\n\n\nCreate a \ndocs\n directory containing an \nindex.md\n that will be your home page.\n\n\n\n\n\n\nStage and commit these changes:\n\n\ngit add mkdocs.yml docs/index.md\ngit commit -m \"Staging initial web page contents\"\n\n\n\n\n\n\n\n\n\nPush local changes to the GitHub repository:\n\n\ngit push origin master\n\n\n\n\n\nYour documents should be shortly available at \nhttps://www.opensciencegrid.org/<REPO NAME>\n\n\n\n\n\n\nCreating an ITB Area\n\u00b6\n\n\nThis section describes creating an ITB repository for a documentation area created in the \nprevious section\n\n\n\n\n\n\nCreate a new repository in the \nopensciencegrid organization\n and name it \n<REPO NAME>-itb\n.\n   For example, an ITB area for the \ndocs\n repository has a repository name of \ndocs-itb\n.\n   The ITB repository will be referred to as \n<ITB REPO NAME>\n in the rest of this document.\n\n\n\n\nCheck the box marked \nInitialize this repository with a README\n\n\nOnce created, add the \nmkdocs\n topic by clicking on the \"Add topics\" button\n\n\n\n\n\n\n\n\nClone the repository and \ncd\n into the directory:\n\n\ngit clone git@github.com:opensciencegrid/<ITB REPO NAME>\ncd <ITB REPO NAME>\n\n\n\n\n\n\n\n\n\nCreate a \ngh-pages\n branch in the GitHub repository:\n\n\ngit push origin master:gh-pages\n\n\n\n\n\n\n\n\n\nUpdate the contents of \nREADME.md\n\n\n\n\n\n\nIn the non-ITB repository, create and encrypt the ITB repository deploy key\n\n\n\n\n\n\ncd\n into the non-ITB repository and generate the ITB deploy key\n\n\ncd <REPO NAME>\nssh-keygen -t rsa -b 4096 -C \"help@opensciencegrid.org\" -f deploy-itb\n\n\n\n\n\n\n\n\n\nInstall the \ntravis\n gem:\n\n\ngem install travis\n\n\n\n\n\n\n\n\n\nEncrypt the deploy key:\n\n\ntravis encrypt-file deploy-itb\n\n\n\n\n\n\n\n\n\nUpdate \n.travis.env\n with the appropriate ITB values\n\n\n\n\n\n\nAdd and commit your files:\n\n\ngit add .travis.env deploy-itb.enc\ngit commit -m \"Add ITB deployment\"\n\n\n\n\n\n\n\nDanger\n\n\nDo NOT commit the unencrypted \ndeploy-itb\n!\n\n\n\n\n\n\n\n\n\n\n\n\nAdd \ndeploy-itb.pub\n to the \nITB\n repository's list of \ndeploy keys\n.\n   Make sure to check \nAllow write access\n.\n\n\n\n\n\n\nStill in the non-ITB repository, push your local changes to the GitHub repository\n\n\ngit push origin master\n\n\n\n\n\nYour documents should be shortly available at \nhttps://www.opensciencegrid.org/<REPO NAME>",
            "title": "Creating a New Area"
        },
        {
            "location": "/documentation/new-doc-area/#creating-a-new-area",
            "text": "This document contains instructions for creating a new top-level OSG website via  GitHub Pages \nand deploying it automatically with  Travis-CI .\nThis document assumes that you are an administrator of the  opensciencegrid  GitHub organization.\nBefore starting, make sure that you have the  git  and  gem  tools installed.    Create a new repository in the  opensciencegrid organization \n   (referred to as  <REPO NAME>  in the rest of this document)   Check the box marked  Initialize this repository with a README     Identify the repository as using mkdocs:   On the repository home page (i.e.,  https://github.com/opensciencegrid/<REPO NAME> ), click the \u201cManage topics\u201d\n   link  Search for  mkdocs  and select  mkdocs  Click the \u201cDone\u201d button     Clone the repository and  cd  into the directory:  git clone https://github.com/opensciencegrid/<REPO NAME>.git\ncd <REPO NAME>    Create a  gh-pages  branch in the GitHub repository:  git push origin master:gh-pages    Update the contents of  README.md  and populate the  LICENSE  file with a\n    Creative Commons Attribution 4.0 license :  wget https://creativecommons.org/licenses/by/4.0/legalcode.txt > LICENSE    Create and encrypt the repository deploy key    Generate the repository deploy key:  ssh-keygen -t rsa -b 4096 -C \"help@opensciencegrid.org\" -f deploy-key -N ''    Install the  travis  gem:  gem install travis    Login using your GitHub credentials:  travis login    Enable the repository in Travis:  travis enable opensciencegrid/<REPO NAME>    Encrypt the deploy key:  travis encrypt-file deploy-key    Stage and commit your files:  git add LICENSE README.md deploy-key.enc\ngit commit -m \"Prepare the repository for Travis-CI deployment\"   Danger  Do NOT commit the unencrypted  deploy-key !     Add the contents of  deploy-key.pub  to your repository's list of\n    deploy keys .\n   Make sure to check  Allow write access .      Follow  these instructions  to add\n   the  doc-ci-scripts  sub-module    Create  mkdocs.yml  containing the following:  site_name: <TITLE OF YOUR SITE>\nsite_url: https://opensciencegrid.org/<REPO NAME>\nrepo_name: https://github.com/opensciencegrid/<REPO NAME>\n\npages:\n  - Home: 'index.md'\n\nmarkdown_extensions:\n  - admonition\n  - codehilite:\n      guess_lang: False\n  - toc:\n      permalink: True    Create a  docs  directory containing an  index.md  that will be your home page.    Stage and commit these changes:  git add mkdocs.yml docs/index.md\ngit commit -m \"Staging initial web page contents\"    Push local changes to the GitHub repository:  git push origin master  Your documents should be shortly available at  https://www.opensciencegrid.org/<REPO NAME>",
            "title": "Creating a New Area"
        },
        {
            "location": "/documentation/new-doc-area/#creating-an-itb-area",
            "text": "This section describes creating an ITB repository for a documentation area created in the  previous section    Create a new repository in the  opensciencegrid organization  and name it  <REPO NAME>-itb .\n   For example, an ITB area for the  docs  repository has a repository name of  docs-itb .\n   The ITB repository will be referred to as  <ITB REPO NAME>  in the rest of this document.   Check the box marked  Initialize this repository with a README  Once created, add the  mkdocs  topic by clicking on the \"Add topics\" button     Clone the repository and  cd  into the directory:  git clone git@github.com:opensciencegrid/<ITB REPO NAME>\ncd <ITB REPO NAME>    Create a  gh-pages  branch in the GitHub repository:  git push origin master:gh-pages    Update the contents of  README.md    In the non-ITB repository, create and encrypt the ITB repository deploy key    cd  into the non-ITB repository and generate the ITB deploy key  cd <REPO NAME>\nssh-keygen -t rsa -b 4096 -C \"help@opensciencegrid.org\" -f deploy-itb    Install the  travis  gem:  gem install travis    Encrypt the deploy key:  travis encrypt-file deploy-itb    Update  .travis.env  with the appropriate ITB values    Add and commit your files:  git add .travis.env deploy-itb.enc\ngit commit -m \"Add ITB deployment\"   Danger  Do NOT commit the unencrypted  deploy-itb !       Add  deploy-itb.pub  to the  ITB  repository's list of  deploy keys .\n   Make sure to check  Allow write access .    Still in the non-ITB repository, push your local changes to the GitHub repository  git push origin master  Your documents should be shortly available at  https://www.opensciencegrid.org/<REPO NAME>",
            "title": "Creating an ITB Area"
        },
        {
            "location": "/projects/sha2-support/",
            "text": "SHA-2 Compliance\n\u00b6\n\n\nWhen a certificate authority signs a certificate, it uses one of several possible hash algorithms. \nHistorically, the most popular algorithms were MD5 (now retired due to security issues) and the SHA-1 family.\nSHA-1 certificates are being phased out due to perceived weaknesses \u2014 as of February 2017, a practical attack for generating collisions was demonstrated by \nGoogle researchers\n.\n These days, the preferred hash algorithm family is SHA-2.\n\n\nThe certificate authorities (CAs), which issue host and user certificates used widely in the OSG, defaulted to SHA-2-based certificates on 1 October 2013; all sites will need to make sure that their software supports certificates using the SHA-2 algorithms. All supported OSG releases support SHA-2.\n\n\nThe table below denotes indicates the minimum releases necessary to support SHA-2 certificates.\n\n\n\n\n\n\n\n\nComponent\n\n\nVersion\n\n\nIn Release\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nBeStMan 2\n\n\nbestman2-2.3.0-9.osg\n\n\n3.1.13\n\n\nSHA-2 support; also see jGlobus, below\n\n\n\n\n\n\ndCache SRM client\n\n\ndcache-srmclient-2.2.11.1-2.osg\n\n\n3.1.22\n\n\nMajor update includes SHA-2 support\n\n\n\n\n\n\nGlobus GRAM\n\n\nglobus-gram-job-manager-13.45-1.2.osg, globus-gram-job-manager-condor-1.0-13.1.osg, globus-gram-job-manager-pbs-1.6-1.1.osg\n\n\n3.1.9\n\n\nCritical bug fixes (not SHA-2 specific)\n\n\n\n\n\n\nGUMS\n\n\ngums-1.3.18.009-15.2.osg\n\n\n3.1.13\n\n\nSwitched to jGlobus 2 with SHA-2 support; also see jGlobus, below\n\n\n\n\n\n\njGlobus (for BeStMan 2)\n\n\njglobus-2.0.5-3.osg\n\n\n3.1.18\n\n\nFixed CRL refresh bug (not SHA-2 specific)\n\n\n\n\n\n\nVOMS\n\n\nvoms-2.0.8-1.5.osg\n\n\n3.1.17\n\n\nSHA-2 fix for voms-proxy-init\n\n\n\n\n\n\n\n\nIf a component does not appear in the above table, it already has SHA-2 support.",
            "title": "SHA-2 Support"
        },
        {
            "location": "/projects/sha2-support/#sha-2-compliance",
            "text": "When a certificate authority signs a certificate, it uses one of several possible hash algorithms. \nHistorically, the most popular algorithms were MD5 (now retired due to security issues) and the SHA-1 family.\nSHA-1 certificates are being phased out due to perceived weaknesses \u2014 as of February 2017, a practical attack for generating collisions was demonstrated by  Google researchers .\n These days, the preferred hash algorithm family is SHA-2.  The certificate authorities (CAs), which issue host and user certificates used widely in the OSG, defaulted to SHA-2-based certificates on 1 October 2013; all sites will need to make sure that their software supports certificates using the SHA-2 algorithms. All supported OSG releases support SHA-2.  The table below denotes indicates the minimum releases necessary to support SHA-2 certificates.     Component  Version  In Release  Notes      BeStMan 2  bestman2-2.3.0-9.osg  3.1.13  SHA-2 support; also see jGlobus, below    dCache SRM client  dcache-srmclient-2.2.11.1-2.osg  3.1.22  Major update includes SHA-2 support    Globus GRAM  globus-gram-job-manager-13.45-1.2.osg, globus-gram-job-manager-condor-1.0-13.1.osg, globus-gram-job-manager-pbs-1.6-1.1.osg  3.1.9  Critical bug fixes (not SHA-2 specific)    GUMS  gums-1.3.18.009-15.2.osg  3.1.13  Switched to jGlobus 2 with SHA-2 support; also see jGlobus, below    jGlobus (for BeStMan 2)  jglobus-2.0.5-3.osg  3.1.18  Fixed CRL refresh bug (not SHA-2 specific)    VOMS  voms-2.0.8-1.5.osg  3.1.17  SHA-2 fix for voms-proxy-init     If a component does not appear in the above table, it already has SHA-2 support.",
            "title": "SHA-2 Compliance"
        },
        {
            "location": "/documentation/markdown-migration/",
            "text": "Migrating to Markdown\n\u00b6\n\n\nAs part of the TWiki retirement (the read-only target date of Oct 1, 2017, with a shutdown date in 2018), we will need to convert the OSG Software and Release3 docs from TWiki syntax to \nMarkdown\n. The following document outlines the conversion process and conventions.\n\n\nChoosing the git repository\n\u00b6\n\n\nFirst you will need to choose which git repoository you will be working with:\n\n\n\n\n\n\n\n\nIf you are converting a document from...\n\n\nUse this github repository...\n\n\n\n\n\n\n\n\n\n\nSoftwareTeam\n\n\ntechnology\n\n\n\n\n\n\nRelease3\n\n\ndocs\n\n\n\n\n\n\n\n\nOnce you've chosen the target repository for your document, move onto the next section and pick your conversion method.\n\n\nAutomatic TWiki conversion\n\u00b6\n\n\n\n\nNote\n\n\nIf you are only archiving the documents, skip to this \nsection\n.\n\n\n\n\nChoose one of the following methods for converting TWiki documents:\n\n\n\n\nUsing our own \ndocker conversion image\n (recommended)\n\n\nDirectly using pandoc and mkdocs \non your own machine\n\n\n\n\nUsing docker\n\u00b6\n\n\nThe twiki-converter docker image can be used to preview the document tree via a \nmkdocs\n development server, archive TWiki documents, and convert documents to Markdown via \npandoc\n. The image is available on \nosghost\n, otherwise, it is availble on \ndockerhub\n.\n\n\nuser@host $\n docker pull opensciencegrid/docker-twiki-converter\n\n\n\n\n\nRequirements\n\u00b6\n\n\nTo perform a document migration using docker, you will need the following tools and accounts:\n\n\n\n\nFork\n and \nclone\n the repository that you chose in the \nabove section\n\n\nA host with a running docker service\n\n\nsudo\n or membership in the \ndocker\n group\n\n\n\n\nIf you cannot install the above tools locally, they are available on \nosghost\n. Speak with Brian L for access.\n\n\nPreparing the git repository\n\u00b6\n\n\n\n\ncd\n into your local git repository\n\n\n\n\nAdd \nopensciencegrid/technology\n as the upstream remote repository for merging upstream changes:\n\n\nuser@host $\n git remote add upstream https://www.github.com/opensciencegrid/technology.git\n\n\n\n\n\n\n\n\n\nCreate a branch for the document you plan to convert:\n\n\nuser@host $\n git branch <BRANCH NAME> master\n\n\n\n\n\nReplace \n<BRANCH NAME>\n with a name of your choice\n\n\n\n\n\n\nChange to the branch you just created\n\n\nuser@host $\n git checkout <BRANCH NAME>\n\n\n\n\n\nReplace \n<BRANCH NAME>\n with the name you chose in the step above\n\n\n\n\n\n\nPreviewing the document tree\n\u00b6\n\n\nWhen starting a twiki-converter docker container, it expects your local github repository to be mounted in \n/source\n so that any changes made to the repository are reflected in the mkdocs development server. To start a docker container based off of the twiki-converter docker image:\n\n\n\n\n\n\nCreate a container from the image with the following command:\n\n\nuser@host $\n docker run -d -v <PATH TO LOCAL GITHUB REPO>:/source -p \n8000\n opensciencegrid/docker-twiki-converter\n\n\n\n\n\nChange \n<PATH TO LOCAL GITHUB REPO>\n for the directory where you have cloned the repo. The above command should return the container ID, which will be used in subsequent commands.\n\n\n\n\nNote\n\n\nIf the docker container exits immediately, remove the \n-d\n option for details. If you see permission denied errors, you may need to disable SELinux or put it in permissive mode.\n\n\n\n\n\n\n\n\nTo find the port that your development server is listening on, use the container ID (you should only need the first few chars of the ID) returned from the previous command:\n\n\nuser@host $\n docker port <CONTAINER ID>\n\n\n\n\n\nChange \n<CONTAINER ID>\n for the value returned by the execution of the previous command\n\n\n\n\n\n\nAccess the development server in your browser via \nhttp://osghost.chtc.wisc.edu:<PORT>\n or \nlocalhost:<PORT>\n for containers run on \nosghost\n or locally, respectively. \nosghost\n has a restrictive firewall so if you have issues accessing your container from outside of the UW-Madison campus, use an SSH tunnel to map the \nosghost\n port to a local port.\n\n\n\n\n\n\nConverting documents\n\u00b6\n\n\nThe docker image contains a convenience script, \nconvert-twiki\n for saving archives and converting them to Markdown. To run the script in a running container, run the following command:\n\n\nuser@host $\n docker \nexec\n <CONTAINER ID> convert-twiki <TWIKI URL>\n\n\n\n\n\nWhere \n<CONTAINER ID>\n is the docker container ID and \n<TWIKI URL>\n is the link to the TWiki document that you want to convert, e.g. https://twiki.opensciencegrid.org/bin/view/SoftwareTeam/SoftwareDevelopmentProcess . This will result in an archive of the twiki doc, \narchive/SoftwareDevelopmentProcess\n, in your local repo and a converted copy, \nSoftwareDevelopmentProcess.md\n, placed into the root of your local github repository.  If the twiki url is for a specific revision of the document, a \n.rNN\n will be included in the output filenames.\n\n\n\n\nWarning\n\n\nIf the above command does not complete quickly, it means that Pandoc is having an issue with a specific section of the document. See \nTroubleshooting conversion\n for next steps.\n\n\n\n\nTo see the converted document in your browser:\n\n\n\n\nRename, move the converted document into a folder in \ndocs/\n.\n\n\nDocument file names should be lowercase, \n-\n delimited, and descriptive but concise, e.g. \nmarkdown-migration.md\n or \ncutting-release.md\n\n\nIt's not important to get the name/location correct on the first try as this can be discussed in the pull request\n\n\n\n\n\n\nsudo chown\n the archived and converted documents to be owned by you\n\n\nAdd the document to the \npages:\n section of \nmkdocs.yml\n in \ntitle case\n, e.g. \n- Migrating Documents to Markdown: 'software/markdown-migration.md'\n\n\nRefresh the document tree in your browser\n\n\n\n\nOnce you can view the converted document in your browser, move onto the \nnext section\n\n\nTroubleshooting conversion\n\u00b6\n\n\nPandoc sometimes has issues converting documents and requires manual intervention by removing whichever section is causing issues in the conversion.\n\n\n\n\nCopy the archive of the document into the root of your git repository\n\n\n\n\nKill the process in the docker container:\n\n\nuser@host $\n docker \nexec\n <CONTAINER ID> pkill -9 pandoc\n\n\n\n\n\nWhere \n<CONTAINER ID>\n is the docker container ID\n\n\n\n\n\n\nRemove a section from the copy of the archive to find the problematic section (recommendation: use a binary search strategy)\n\n\n\n\n\n\nRun pandoc manually:\n\n\nuser@host $\n docker \nexec\n <CONTAINER ID> pandoc -f twiki -t markdown_github <ARCHIVE COPY> > <MARKDOWN FILE>\n\n\n\n\n\nWhere \n<CONTAINER ID>\n is the docker container ID, \n<ARCHIVE COPY>\n is the the file you copied in the first step\nand \n<MARKDOWN FILE>\n is the resulting \n.md\n file\n\n\n\n\n\n\nRepeat steps 2-4 until you've narrowed down the problematic section\n\n\n\n\nManually convert the offending section\n\n\n\n\nConversion without Docker\n\u00b6\n\n\nIf you've already used the \ndocker method\n, skip to the section about \ncompleting the conversion\n. \n\n\nRequirements\n\u00b6\n\n\nThis method requires the following:\n\n\n\n\nFork\n and \nclone\n the repository that you chose in the \nabove section\n\n\npandoc (> 1.16)\n\n\nmkdocs\n\n\nMarkdownHighlight\n\n\npygments\n\n\n\n\nPreparing the git repository\n\u00b6\n\n\n\n\ncd\n into your local git repository\n\n\n\n\nAdd \nopensciencegrid/technology\n as the upstream remote repository for merging upstream changes:\n\n\nuser@host $\n git remote add upstream https://www.github.com/opensciencegrid/technology.git\n\n\n\n\n\n\n\n\n\nCreate a branch for the document you plan to convert:\n\n\nuser@host $\n git branch <BRANCH NAME> master\n\n\n\n\n\nReplace \n<BRANCH NAME>\n with a name of your choice\n5. Change to the branch you just created\n\n\nuser@host $\n git checkout <BRANCH NAME>\n\n\n\n\n\nReplace \n<BRANCH NAME>\n with the name you chose in the step above\n\n\nArchiving the TWiki document\n\u00b6\n\n\n\n\n\n\nFollow the instructions for \narchival\n then continue to the next section to convert the document with pandoc.\n\n\nInitial conversion with Pandoc\n\u00b6\n\n\nPandoc\n is a tool that's useful for automated conversion of markdown languages. \nOnce installed\n (alternatively, run pandoc \nvia docker\n), run the following command to convert TWiki to Markdown:\n\n\n$\n pandoc -f twiki -t markdown_github <TWIKI FILE> > <MARKDOWN FILE>\n\n\n\n\n\nWhere \n<TWIKI FILE>\n is the path to initial document in raw TWiki and \n<MARKDOWN FILE>\n is the path to the resulting document in GitHub Markdown.\n\n\n\n\nNote\n\n\nIf you don't see output from the above command quickly, it means that Pandoc is having an issue with a specific section of the document. Stop the command (or docker container), find and temporarily remove the offending section, convert the remainder of the document with Pandoc, and manually convert the offending section.\n\n\n\n\nPreviewing your document(s) with Mkdocs\n\u00b6\n\n\nMkdocs\n has a development mode that can be used to preview documents as you work on them and is available via package manager or \npip\n. \nOnce installed\n, add your document(s) to the \npages\n section of \nmkdocs.yml\n and launch the mkdocs server with the following command from the dir containing \nmkdocs.yml\n:\n\n\n$\n \nPYTHONPATH\n=\nsrc/ mkdocs serve\n\n\n\n\n\nAccess the server at \nhttp://127.0.0.1:8000\n and navigate to the document you're working on. It's useful to open the original TWiki doc in an adjacent tab or window to quickly compare the two.\n\n\nCompleting the conversion\n\u00b6\n\n\nManual review of the automatically converted documents are required since the automatic conversion process isn't perfect. This section contains a list of problems commonly encountered in automatically converted documents.\n\n\nVisit the \nstyle guide\n to ensure that the document meets all style guidelines.\n\n\nArchiving Documents\n\u00b6\n\n\nIf the document is slated for archival (check if it says \"yes\" in the  \"archived\" column of the spreadsheet), just download the document to the \narchive\n folder of your local git repository:\n\n\nuser@host $\n \ncd\n technology/\n\nuser@host $\n curl \n'<TWIKI URL>?raw=text'\n \n|\n iconv -f windows-1252 > archive/<TWIKI TITLE>\n\n\n\n\n\nWhere \n<TWIKI URL>\n is the link to the TWiki document that you want to download and \n<TWIKI TITLE>\n is the name that will receive the archived file\nFor example:\n\n\nuser@host $\n \ncd\n technology\n\nuser@host $\n curl \n'https://twiki.opensciencegrid.org/bin/view/Documentation/Release3/SHA2Compliance?raw=text'\n \n|\n iconv -f windows-1252 > archive/SHA2Compliance\n\n\n\n\n\nAfter downloading the document, continue onto the next section to walk through pull request submission.\n\n\nSubmitting the pull request\n\u00b6\n\n\n\n\n\n\nStage the archived raw TWiki (as well as the converted Markdown document(s) and \nmkdocs.yml\n if you are converting the document):\n\n\nuser@host $\n git add mkdocs.yml archive/<TWIKI ARCHIVE> <PATH TO CONVERTED DOC>\n\n\n\n\n\nWhere \n<TWIKI ARCHIVE>\n is the name of the archived document and \n<PATH TO CONVERTED DOC>\n is the path to the \n.md\n\nfile\n\n\n\n\n\n\nCommit and push your changes to your GitHub repo:\n\n\nuser@host $\n git commit -m \n\"<COMMIT MSG>\"\n\n\nuser@host $\n git push origin <BRANCH NAME>\n\n\n\n\n\nChange \n<COMMIT MSG>\n for a meaningful text that describes the conversion done and \n<BRANCH NAME>\n with the name\nchosen in the 3rd step of the \nPreparing the git repository\n section\n\n\n\n\n\n\nOpen your browser and navigate to your GitHub fork\n\n\n\n\n\n\nSubmit a pull request containing with the following body:\n\n\n<LINK TO TWIKI DOCUMENT>\n\n- [ ] Enter date into \"Migrated\" column of google sheet\n\n\n\n\n\nAn example of \n<LINK TO TWIKI DOCUMENT>\n is: https://twiki.opensciencegrid.org/bin/view/SoftwareTeam/SoftwareDevelopmentProcess\n\n\n\n\n\n\nIf you are migrating a document, also add this task:\n\n\n- [ ] Add migration header to TWiki document\n\n\n\n\n\n\n\n\n\nIf you are archiving a document, add this task:\n\n\n- [ ] Move TWiki document to the trash\n\n\n\n\n\n\n\n\n\n\n\n\n\nSee an example pull request \nhere\n.\n\n\nAfter the pull request\n\u00b6\n\n\nAfter the pull request is merged, replace the contents of TWiki document with the div if you're migrating the document, linking to the location of the migrated document:\n\n\n<div style=\"border: 1px solid black; margin: 1em 0; padding: 1em; background-color: #FFDDDD; font-weight: 600;\">\nThis document has been migrated to !GitHub (<LINK TO GITHUB DOCUMENT>). If you wish to see the old TWiki document, use the TWiki history below.\n\nBackground:\n\nAt the end of year (2017), the TWiki will be retired in favor of !GitHub. You can find the various TWiki webs and their new !GitHub locations listed below:\n\n   * Release3: https://www.opensciencegrid.org/docs ([[https://github.com/opensciencegrid/docs/tree/master/archive][archive]])\n   * !SoftwareTeam: https://www.opensciencegrid.org/technology ([[https://github.com/opensciencegrid/technology/tree/master/archive][archive]])\n</div>\n\n\n\n\n\nIf you are archiving a document, move it to the trash instead. Once the document has been updated or trashed, add the date to the spreadsheet and go back to your pull request and mark your tasks as complete. For example, if you completed the migration of a document:\n\n\n- [X] Enter date into \"Migrated\" column of google sheet\n- [X] Add migration div to TWiki document\n\n\n\n\n\nCurrently, we do not recommend changing backlinks (links on other twiki pages that refer to the Twiki page you are migrating) to point at the new GitHub URL.  This is to provide a simple reminder to users that the migration will occur, and also is likely low priority regardless as all pages will eventually migrate to GitHub.  This advice may change in the future as we gain experience with this transition.\n\n\nReviewing pull requests\n\u00b6\n\n\nTo review pull requests, \ncd\n into the dir containing your git repository and check out the requester's branch, which the twiki-converter container should automatically notice. Here's an example checking out Brian's \ncut-sw-release\n branch of the technology repository:\n\n\n#\n Add the requester\n's repo as a remote if you haven'\nt already\n\nuser@host $\n git remote add blin https://www.github.com/brianhlin/technology.git\n\nuser@host $\n git fetch --all\n\nuser@host $\n git checkout blin/cut-sw-release\n\n\n\n\n\nRefresh your browser and navigate to the document in the request.",
            "title": "Migrating Documents to Markdown"
        },
        {
            "location": "/documentation/markdown-migration/#migrating-to-markdown",
            "text": "As part of the TWiki retirement (the read-only target date of Oct 1, 2017, with a shutdown date in 2018), we will need to convert the OSG Software and Release3 docs from TWiki syntax to  Markdown . The following document outlines the conversion process and conventions.",
            "title": "Migrating to Markdown"
        },
        {
            "location": "/documentation/markdown-migration/#choosing-the-git-repository",
            "text": "First you will need to choose which git repoository you will be working with:     If you are converting a document from...  Use this github repository...      SoftwareTeam  technology    Release3  docs     Once you've chosen the target repository for your document, move onto the next section and pick your conversion method.",
            "title": "Choosing the git repository"
        },
        {
            "location": "/documentation/markdown-migration/#automatic-twiki-conversion",
            "text": "Note  If you are only archiving the documents, skip to this  section .   Choose one of the following methods for converting TWiki documents:   Using our own  docker conversion image  (recommended)  Directly using pandoc and mkdocs  on your own machine",
            "title": "Automatic TWiki conversion"
        },
        {
            "location": "/documentation/markdown-migration/#using-docker",
            "text": "The twiki-converter docker image can be used to preview the document tree via a  mkdocs  development server, archive TWiki documents, and convert documents to Markdown via  pandoc . The image is available on  osghost , otherwise, it is availble on  dockerhub .  user@host $  docker pull opensciencegrid/docker-twiki-converter",
            "title": "Using docker"
        },
        {
            "location": "/documentation/markdown-migration/#requirements",
            "text": "To perform a document migration using docker, you will need the following tools and accounts:   Fork  and  clone  the repository that you chose in the  above section  A host with a running docker service  sudo  or membership in the  docker  group   If you cannot install the above tools locally, they are available on  osghost . Speak with Brian L for access.",
            "title": "Requirements"
        },
        {
            "location": "/documentation/markdown-migration/#preparing-the-git-repository",
            "text": "cd  into your local git repository   Add  opensciencegrid/technology  as the upstream remote repository for merging upstream changes:  user@host $  git remote add upstream https://www.github.com/opensciencegrid/technology.git    Create a branch for the document you plan to convert:  user@host $  git branch <BRANCH NAME> master  Replace  <BRANCH NAME>  with a name of your choice    Change to the branch you just created  user@host $  git checkout <BRANCH NAME>  Replace  <BRANCH NAME>  with the name you chose in the step above",
            "title": "Preparing the git repository"
        },
        {
            "location": "/documentation/markdown-migration/#previewing-the-document-tree",
            "text": "When starting a twiki-converter docker container, it expects your local github repository to be mounted in  /source  so that any changes made to the repository are reflected in the mkdocs development server. To start a docker container based off of the twiki-converter docker image:    Create a container from the image with the following command:  user@host $  docker run -d -v <PATH TO LOCAL GITHUB REPO>:/source -p  8000  opensciencegrid/docker-twiki-converter  Change  <PATH TO LOCAL GITHUB REPO>  for the directory where you have cloned the repo. The above command should return the container ID, which will be used in subsequent commands.   Note  If the docker container exits immediately, remove the  -d  option for details. If you see permission denied errors, you may need to disable SELinux or put it in permissive mode.     To find the port that your development server is listening on, use the container ID (you should only need the first few chars of the ID) returned from the previous command:  user@host $  docker port <CONTAINER ID>  Change  <CONTAINER ID>  for the value returned by the execution of the previous command    Access the development server in your browser via  http://osghost.chtc.wisc.edu:<PORT>  or  localhost:<PORT>  for containers run on  osghost  or locally, respectively.  osghost  has a restrictive firewall so if you have issues accessing your container from outside of the UW-Madison campus, use an SSH tunnel to map the  osghost  port to a local port.",
            "title": "Previewing the document tree"
        },
        {
            "location": "/documentation/markdown-migration/#converting-documents",
            "text": "The docker image contains a convenience script,  convert-twiki  for saving archives and converting them to Markdown. To run the script in a running container, run the following command:  user@host $  docker  exec  <CONTAINER ID> convert-twiki <TWIKI URL>  Where  <CONTAINER ID>  is the docker container ID and  <TWIKI URL>  is the link to the TWiki document that you want to convert, e.g. https://twiki.opensciencegrid.org/bin/view/SoftwareTeam/SoftwareDevelopmentProcess . This will result in an archive of the twiki doc,  archive/SoftwareDevelopmentProcess , in your local repo and a converted copy,  SoftwareDevelopmentProcess.md , placed into the root of your local github repository.  If the twiki url is for a specific revision of the document, a  .rNN  will be included in the output filenames.   Warning  If the above command does not complete quickly, it means that Pandoc is having an issue with a specific section of the document. See  Troubleshooting conversion  for next steps.   To see the converted document in your browser:   Rename, move the converted document into a folder in  docs/ .  Document file names should be lowercase,  -  delimited, and descriptive but concise, e.g.  markdown-migration.md  or  cutting-release.md  It's not important to get the name/location correct on the first try as this can be discussed in the pull request    sudo chown  the archived and converted documents to be owned by you  Add the document to the  pages:  section of  mkdocs.yml  in  title case , e.g.  - Migrating Documents to Markdown: 'software/markdown-migration.md'  Refresh the document tree in your browser   Once you can view the converted document in your browser, move onto the  next section",
            "title": "Converting documents"
        },
        {
            "location": "/documentation/markdown-migration/#troubleshooting-conversion",
            "text": "Pandoc sometimes has issues converting documents and requires manual intervention by removing whichever section is causing issues in the conversion.   Copy the archive of the document into the root of your git repository   Kill the process in the docker container:  user@host $  docker  exec  <CONTAINER ID> pkill -9 pandoc  Where  <CONTAINER ID>  is the docker container ID    Remove a section from the copy of the archive to find the problematic section (recommendation: use a binary search strategy)    Run pandoc manually:  user@host $  docker  exec  <CONTAINER ID> pandoc -f twiki -t markdown_github <ARCHIVE COPY> > <MARKDOWN FILE>  Where  <CONTAINER ID>  is the docker container ID,  <ARCHIVE COPY>  is the the file you copied in the first step\nand  <MARKDOWN FILE>  is the resulting  .md  file    Repeat steps 2-4 until you've narrowed down the problematic section   Manually convert the offending section",
            "title": "Troubleshooting conversion"
        },
        {
            "location": "/documentation/markdown-migration/#conversion-without-docker",
            "text": "If you've already used the  docker method , skip to the section about  completing the conversion .",
            "title": "Conversion without Docker"
        },
        {
            "location": "/documentation/markdown-migration/#requirements_1",
            "text": "This method requires the following:   Fork  and  clone  the repository that you chose in the  above section  pandoc (> 1.16)  mkdocs  MarkdownHighlight  pygments",
            "title": "Requirements"
        },
        {
            "location": "/documentation/markdown-migration/#preparing-the-git-repository_1",
            "text": "cd  into your local git repository   Add  opensciencegrid/technology  as the upstream remote repository for merging upstream changes:  user@host $  git remote add upstream https://www.github.com/opensciencegrid/technology.git    Create a branch for the document you plan to convert:  user@host $  git branch <BRANCH NAME> master  Replace  <BRANCH NAME>  with a name of your choice\n5. Change to the branch you just created  user@host $  git checkout <BRANCH NAME>  Replace  <BRANCH NAME>  with the name you chose in the step above",
            "title": "Preparing the git repository"
        },
        {
            "location": "/documentation/markdown-migration/#archiving-the-twiki-document",
            "text": "Follow the instructions for  archival  then continue to the next section to convert the document with pandoc.",
            "title": "Archiving the TWiki document"
        },
        {
            "location": "/documentation/markdown-migration/#initial-conversion-with-pandoc",
            "text": "Pandoc  is a tool that's useful for automated conversion of markdown languages.  Once installed  (alternatively, run pandoc  via docker ), run the following command to convert TWiki to Markdown:  $  pandoc -f twiki -t markdown_github <TWIKI FILE> > <MARKDOWN FILE>  Where  <TWIKI FILE>  is the path to initial document in raw TWiki and  <MARKDOWN FILE>  is the path to the resulting document in GitHub Markdown.   Note  If you don't see output from the above command quickly, it means that Pandoc is having an issue with a specific section of the document. Stop the command (or docker container), find and temporarily remove the offending section, convert the remainder of the document with Pandoc, and manually convert the offending section.",
            "title": "Initial conversion with Pandoc"
        },
        {
            "location": "/documentation/markdown-migration/#previewing-your-documents-with-mkdocs",
            "text": "Mkdocs  has a development mode that can be used to preview documents as you work on them and is available via package manager or  pip .  Once installed , add your document(s) to the  pages  section of  mkdocs.yml  and launch the mkdocs server with the following command from the dir containing  mkdocs.yml :  $   PYTHONPATH = src/ mkdocs serve  Access the server at  http://127.0.0.1:8000  and navigate to the document you're working on. It's useful to open the original TWiki doc in an adjacent tab or window to quickly compare the two.",
            "title": "Previewing your document(s) with Mkdocs"
        },
        {
            "location": "/documentation/markdown-migration/#completing-the-conversion",
            "text": "Manual review of the automatically converted documents are required since the automatic conversion process isn't perfect. This section contains a list of problems commonly encountered in automatically converted documents.  Visit the  style guide  to ensure that the document meets all style guidelines.",
            "title": "Completing the conversion"
        },
        {
            "location": "/documentation/markdown-migration/#archiving-documents",
            "text": "If the document is slated for archival (check if it says \"yes\" in the  \"archived\" column of the spreadsheet), just download the document to the  archive  folder of your local git repository:  user@host $   cd  technology/ user@host $  curl  '<TWIKI URL>?raw=text'   |  iconv -f windows-1252 > archive/<TWIKI TITLE>  Where  <TWIKI URL>  is the link to the TWiki document that you want to download and  <TWIKI TITLE>  is the name that will receive the archived file\nFor example:  user@host $   cd  technology user@host $  curl  'https://twiki.opensciencegrid.org/bin/view/Documentation/Release3/SHA2Compliance?raw=text'   |  iconv -f windows-1252 > archive/SHA2Compliance  After downloading the document, continue onto the next section to walk through pull request submission.",
            "title": "Archiving Documents"
        },
        {
            "location": "/documentation/markdown-migration/#submitting-the-pull-request",
            "text": "Stage the archived raw TWiki (as well as the converted Markdown document(s) and  mkdocs.yml  if you are converting the document):  user@host $  git add mkdocs.yml archive/<TWIKI ARCHIVE> <PATH TO CONVERTED DOC>  Where  <TWIKI ARCHIVE>  is the name of the archived document and  <PATH TO CONVERTED DOC>  is the path to the  .md \nfile    Commit and push your changes to your GitHub repo:  user@host $  git commit -m  \"<COMMIT MSG>\"  user@host $  git push origin <BRANCH NAME>  Change  <COMMIT MSG>  for a meaningful text that describes the conversion done and  <BRANCH NAME>  with the name\nchosen in the 3rd step of the  Preparing the git repository  section    Open your browser and navigate to your GitHub fork    Submit a pull request containing with the following body:  <LINK TO TWIKI DOCUMENT>\n\n- [ ] Enter date into \"Migrated\" column of google sheet  An example of  <LINK TO TWIKI DOCUMENT>  is: https://twiki.opensciencegrid.org/bin/view/SoftwareTeam/SoftwareDevelopmentProcess    If you are migrating a document, also add this task:  - [ ] Add migration header to TWiki document    If you are archiving a document, add this task:  - [ ] Move TWiki document to the trash      See an example pull request  here .",
            "title": "Submitting the pull request"
        },
        {
            "location": "/documentation/markdown-migration/#after-the-pull-request",
            "text": "After the pull request is merged, replace the contents of TWiki document with the div if you're migrating the document, linking to the location of the migrated document:  <div style=\"border: 1px solid black; margin: 1em 0; padding: 1em; background-color: #FFDDDD; font-weight: 600;\">\nThis document has been migrated to !GitHub (<LINK TO GITHUB DOCUMENT>). If you wish to see the old TWiki document, use the TWiki history below.\n\nBackground:\n\nAt the end of year (2017), the TWiki will be retired in favor of !GitHub. You can find the various TWiki webs and their new !GitHub locations listed below:\n\n   * Release3: https://www.opensciencegrid.org/docs ([[https://github.com/opensciencegrid/docs/tree/master/archive][archive]])\n   * !SoftwareTeam: https://www.opensciencegrid.org/technology ([[https://github.com/opensciencegrid/technology/tree/master/archive][archive]])\n</div>  If you are archiving a document, move it to the trash instead. Once the document has been updated or trashed, add the date to the spreadsheet and go back to your pull request and mark your tasks as complete. For example, if you completed the migration of a document:  - [X] Enter date into \"Migrated\" column of google sheet\n- [X] Add migration div to TWiki document  Currently, we do not recommend changing backlinks (links on other twiki pages that refer to the Twiki page you are migrating) to point at the new GitHub URL.  This is to provide a simple reminder to users that the migration will occur, and also is likely low priority regardless as all pages will eventually migrate to GitHub.  This advice may change in the future as we gain experience with this transition.",
            "title": "After the pull request"
        },
        {
            "location": "/documentation/markdown-migration/#reviewing-pull-requests",
            "text": "To review pull requests,  cd  into the dir containing your git repository and check out the requester's branch, which the twiki-converter container should automatically notice. Here's an example checking out Brian's  cut-sw-release  branch of the technology repository:  #  Add the requester 's repo as a remote if you haven' t already user@host $  git remote add blin https://www.github.com/brianhlin/technology.git user@host $  git fetch --all user@host $  git checkout blin/cut-sw-release  Refresh your browser and navigate to the document in the request.",
            "title": "Reviewing pull requests"
        },
        {
            "location": "/meetings/2019/TechArea20191202/",
            "text": "OSG Technology Area Meeting,  2 December 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n Brian, Derek, Diego, Edgar, Marco Mambelli, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nMarian OOO today\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: TimT\n\n\nNext week: Diego\n\n\n7 (-3) open FreshDesk tickets\n\n\n0 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n158\n\n\n-1\n\n\nOpen\n\n\n\n\n\n\n36\n\n\n-3\n\n\nIn Progress\n\n\n\n\n\n\n8\n\n\n-2\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.7/3.4.41  \n\n\nAI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)\n\n\nAI (Carl): Investigate xrootd-standalone EL6 failures\n\n\nAI (Carl): gsi-openssh: move OSG changes to separate package (SOFTWARE-3915)\n\n\nAI (Carl, Derek): Malformed classad in history file causes gratia probe to silently fail (SOFTWARE-3877)\n\n\nAI (Brian): Write HTCondor-CE 4.1.0 and 3.4.0 documentation (SOFTWARE-3861, SOFTWARE-3862)\n\n\n\n\n\n\nAI (Diego): Replace smart quotes and dashes in osg-notify (SOFTWARE-3893)\n\n\nAI (Carl): Compare HTCondor/HTCondor-CE probe output from history records on itb-ce2 (SOFTWARE-3873)\n\n\nAI (Brian): Rewrite software support (\nhttps://opensciencegrid.org/technology/policy/software-support/\n) documentation\n\n\nAI (Brian): Hosted CE container/chart bug fixes\n\n\nAI (Brian): Working on serving HTML results from osg-sw-submit web server\n\n\n\n\nDiscussion\n\u00b6\n\n\nITB factory has been updated to GlideinWMS 3.6.1. Edgar will update the LIGO frontend and Marco will discuss updating with Fermi frontend admins.\n\n\nSupport Update\n\u00b6\n\n\nStashCache (Derek): A few issues were brought up by the research facilitation team regarding StashCache stability. Derek believes that this means we need to rethink our negative cache and port design.\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.40\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.6\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-4\n\n\n0\n\n\n-1\n\n\n0\n\n\n-5\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-1\n\n\n0\n\n\n-4\n\n\n0\n\n\n-1\n\n\n0\n\n\n-6\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-1\n\n\n0\n\n\n-4\n\n\n0\n\n\n-3\n\n\n0\n\n\n-8\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n5\n\n\n+3\n\n\n1\n\n\n+0\n\n\n6\n\n\n+3\n\n\nReady for Release\n\n\n\n\n\n\n0\n\n\n-2\n\n\n5\n\n\n-9\n\n\n1\n\n\n-5\n\n\n6\n\n\n-16\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Release  \n\n\n3.5.6  \n\n\nosg-release 3.5-3\n\n\n\n\n\n\nBoth  \n\n\nXCache 1.2\n\n\nCCTools 7.0.21\n\n\n\n\n\n\n3.4.40  \n\n\nosg-release 3.4-9\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.41\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.7\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n5\n\n\n+0\n\n\n1\n\n\n+0\n\n\n6\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n1\n\n\n+0\n\n\n3\n\n\n+0\n\n\n2\n\n\n+0\n\n\n6\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n1\n\n\n+0\n\n\n4\n\n\n+0\n\n\n3\n\n\n+0\n\n\n8\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n2\n\n\n+0\n\n\n12\n\n\n+0\n\n\n6\n\n\n+0\n\n\n20\n\n\n+0\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing  \n\n\n3.5.7  \n\n\nHTCondor-CE 4.1.0\n\n\nUpcoming: HTCondor 8.9.4\n\n\n\n\n\n\nBoth  \n\n\nGlideinWMS 3.6.1\n\n\nHTCondor 8.8.6\n\n\nHTCondor CE - non-OSG method for modifying job environment\n\n\n\n\n\n\n3.4.41  \n\n\nHTCondor-CE 3.4.0\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\n3.5.7  \n\n\nNothing yet\n\n\n\n\n\n\nBoth  \n\n\nNothing yet\n\n\n\n\n\n\n3.4.41  \n\n\nNothing yet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nWe should announce new 'fresh' containers in the community testing announcements\n\n\nAI (Brian): Let security know about new stable Frontier Squid container\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nUpdate of GRACC ES, which may require some development changes.  GRACC ES update is still ongoing.\n\n\nWait for Marian to update.\n\n\n\n\n\n\nGithub actions are cool.\n\n\nModifying scitokens-cpp build process to use github actions.  Possibly applicable for others.  Reusable components!\n\n\n\n\n\n\n(Derek) scitokens-cpp update - Make release.\n\n\n(overdue) Simple validation of xrootd-monitoring-collector passed.  \n\n\nData collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.\n\n\n\n\n\n\n(in progress) Development on perfsonar tape-backup flow with John.\n\n\nWorking with UChicago\n\n\n\n\n\n\n(in progress) XRootD development for TCP stats.\n\n\n\n\nDiscussion\n\u00b6\n\n\nDerek will give a short presentation on GitHub actions after next week's meeting",
            "title": "December, 2 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#osg-technology-area-meeting-2-december-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  Brian, Derek, Diego, Edgar, Marco Mambelli, Mat, TimT",
            "title": "OSG Technology Area Meeting,  2 December 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#announcements",
            "text": "Marian OOO today",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#triage-duty",
            "text": "This week: TimT  Next week: Diego  7 (-3) open FreshDesk tickets  0 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#jira",
            "text": "# of tickets  \u0394  State      158  -1  Open    36  -3  In Progress    8  -2  Ready for Testing    0  -1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#osg-software-team",
            "text": "OSG 3.5.7/3.4.41    AI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)  AI (Carl): Investigate xrootd-standalone EL6 failures  AI (Carl): gsi-openssh: move OSG changes to separate package (SOFTWARE-3915)  AI (Carl, Derek): Malformed classad in history file causes gratia probe to silently fail (SOFTWARE-3877)  AI (Brian): Write HTCondor-CE 4.1.0 and 3.4.0 documentation (SOFTWARE-3861, SOFTWARE-3862)    AI (Diego): Replace smart quotes and dashes in osg-notify (SOFTWARE-3893)  AI (Carl): Compare HTCondor/HTCondor-CE probe output from history records on itb-ce2 (SOFTWARE-3873)  AI (Brian): Rewrite software support ( https://opensciencegrid.org/technology/policy/software-support/ ) documentation  AI (Brian): Hosted CE container/chart bug fixes  AI (Brian): Working on serving HTML results from osg-sw-submit web server",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#discussion",
            "text": "ITB factory has been updated to GlideinWMS 3.6.1. Edgar will update the LIGO frontend and Marco will discuss updating with Fermi frontend admins.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#support-update",
            "text": "StashCache (Derek): A few issues were brought up by the research facilitation team regarding StashCache stability. Derek believes that this means we need to rethink our negative cache and port design.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#osg-release-team",
            "text": "3.4.40  \u0394  Both  \u0394  3.5.6  \u0394  Total  \u0394  Status      0  +0  0  -4  0  -1  0  -5  Open    0  -1  0  -4  0  -1  0  -6  In Progress    0  -1  0  -4  0  -3  0  -8  Ready for Testing    0  +0  5  +3  1  +0  6  +3  Ready for Release    0  -2  5  -9  1  -5  6  -16  Total      Software    Ready for Release    3.5.6    osg-release 3.5-3    Both    XCache 1.2  CCTools 7.0.21    3.4.40    osg-release 3.4-9        Data    Nothing    Operations    Nothing    Contrib    Nothing        3.4.41  \u0394  Both  \u0394  3.5.7  \u0394  Total  \u0394  Status      0  +0  5  +0  1  +0  6  +0  Open    1  +0  3  +0  2  +0  6  +0  In Progress    1  +0  4  +0  3  +0  8  +0  Ready for Testing    0  +0  0  +0  0  +0  0  +0  Ready for Release    2  +0  12  +0  6  +0  20  +0  Total      Software    Ready for Testing    3.5.7    HTCondor-CE 4.1.0  Upcoming: HTCondor 8.9.4    Both    GlideinWMS 3.6.1  HTCondor 8.8.6  HTCondor CE - non-OSG method for modifying job environment    3.4.41    HTCondor-CE 3.4.0      Ready for Release    3.5.7    Nothing yet    Both    Nothing yet    3.4.41    Nothing yet        Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#discussion_1",
            "text": "We should announce new 'fresh' containers in the community testing announcements  AI (Brian): Let security know about new stable Frontier Squid container",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#osg-investigations-team",
            "text": "Update of GRACC ES, which may require some development changes.  GRACC ES update is still ongoing.  Wait for Marian to update.    Github actions are cool.  Modifying scitokens-cpp build process to use github actions.  Possibly applicable for others.  Reusable components!    (Derek) scitokens-cpp update - Make release.  (overdue) Simple validation of xrootd-monitoring-collector passed.    Data collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.    (in progress) Development on perfsonar tape-backup flow with John.  Working with UChicago    (in progress) XRootD development for TCP stats.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20191202/#discussion_2",
            "text": "Derek will give a short presentation on GitHub actions after next week's meeting",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191125/",
            "text": "OSG Technology Area Meeting, 25 November 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Diego, Edgar, Marco Mambelli, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nMarian OOO this week\n\n\nEveryone OOO Friday except maybe Carl, Brian\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: BrianL\n\n\nNext week: TimT\n\n\n10 (-5) open FreshDesk tickets\n\n\n0 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n159\n\n\n-4\n\n\nOpen\n\n\n\n\n\n\n39\n\n\n+5\n\n\nIn Progress\n\n\n\n\n\n\n10\n\n\n+3\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.7/3.4.41\n\n\nAI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)\n\n\nAI (Carl, Derek): Malformed classad in history file causes gratia probe to silently fail (SOFTWARE-3877)\n\n\nAI (Carl): gsi-openssh: move OSG changes to separate package (SOFTWARE-3915)\n\n\nAI (Diego): Build XRootD 5.0.0 RC1 (SOFTWARE-3923)\n\n\nAI (Brian): Write HTCondor-CE 4.1.0 and 3.4.0 documentation (SOFTWARE-3861, SOFTWARE-3862)\n\n\n\n\n\n\nAI (Mat): remote worker node setup for Hosted CE container (SOFTWARE-3903, SOFTWARE-3905)\n\n\nAI (Diego): Replace smart quotes and dashes in osg-notify (SOFTWARE-3893)\n\n\nAI (Carl): Compare HTCondor/HTCondor-CE probe output from history records on itb-ce2 (SOFTWARE-3873)\n\n\nosg-sw-submit: Working on serving HTML results from local web server\n\n\n\n\nDiscussion\n\u00b6\n\n\nGlideinWMS developer testing completed this morning\n\n\nSupport Update\n\u00b6\n\n\nNone this week  \n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.40\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.6\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n4\n\n\n+0\n\n\n1\n\n\n+0\n\n\n5\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n1\n\n\n+0\n\n\n4\n\n\n+0\n\n\n1\n\n\n+0\n\n\n6\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n1\n\n\n+0\n\n\n4\n\n\n+0\n\n\n3\n\n\n+0\n\n\n8\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n2\n\n\n+0\n\n\n1\n\n\n+0\n\n\n3\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n2\n\n\n+0\n\n\n14\n\n\n+0\n\n\n6\n\n\n+0\n\n\n22\n\n\n+0\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing\n\n\n3.5.6\n\n\nHTCondor-CE 4.1.0\n\n\n\n\n\n\nBoth\n\n\nXCache 1.2\n\n\n\n\n\n\n3.4.40\n\n\nHTCondor-CE 3.4.0\n\n\n\n\n\n\n\n\n\n\nReady for Release\n\n\n3.5.6\n\n\nosg-release 3.5-3\n\n\n\n\n\n\nBoth\n\n\nCCTools 7.0.21\n\n\n\n\n\n\n3.4.40\n\n\nosg-release 3.4-9\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nUpdate of GRACC ES, which may require some development changes.  GRACC ES update is still ongoing.\n\n\nGithub actions are cool.\n\n\n(Derek) scitokens-cpp update - Make release.\n\n\n(overdue) Simple validation of xrootd-monitoring-collector passed.  \n\n\nData collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.\n\n\n\n\n\n\n(in progress) Development on perfsonar tape-backup flow with John.\n\n\n(in progress) XRootD development for TCP stats.\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week",
            "title": "November, 25 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#osg-technology-area-meeting-25-november-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Diego, Edgar, Marco Mambelli, Mat, TimT",
            "title": "OSG Technology Area Meeting, 25 November 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#announcements",
            "text": "Marian OOO this week  Everyone OOO Friday except maybe Carl, Brian",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#triage-duty",
            "text": "This week: BrianL  Next week: TimT  10 (-5) open FreshDesk tickets  0 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#jira",
            "text": "# of tickets  \u0394  State      159  -4  Open    39  +5  In Progress    10  +3  Ready for Testing    1  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#osg-software-team",
            "text": "OSG 3.5.7/3.4.41  AI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)  AI (Carl, Derek): Malformed classad in history file causes gratia probe to silently fail (SOFTWARE-3877)  AI (Carl): gsi-openssh: move OSG changes to separate package (SOFTWARE-3915)  AI (Diego): Build XRootD 5.0.0 RC1 (SOFTWARE-3923)  AI (Brian): Write HTCondor-CE 4.1.0 and 3.4.0 documentation (SOFTWARE-3861, SOFTWARE-3862)    AI (Mat): remote worker node setup for Hosted CE container (SOFTWARE-3903, SOFTWARE-3905)  AI (Diego): Replace smart quotes and dashes in osg-notify (SOFTWARE-3893)  AI (Carl): Compare HTCondor/HTCondor-CE probe output from history records on itb-ce2 (SOFTWARE-3873)  osg-sw-submit: Working on serving HTML results from local web server",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#discussion",
            "text": "GlideinWMS developer testing completed this morning",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#support-update",
            "text": "None this week",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#osg-release-team",
            "text": "3.4.40  \u0394  Both  \u0394  3.5.6  \u0394  Total  \u0394  Status      0  +0  4  +0  1  +0  5  +0  Open    1  +0  4  +0  1  +0  6  +0  In Progress    1  +0  4  +0  3  +0  8  +0  Ready for Testing    0  +0  2  +0  1  +0  3  +0  Ready for Release    2  +0  14  +0  6  +0  22  +0  Total      Software    Ready for Testing  3.5.6  HTCondor-CE 4.1.0    Both  XCache 1.2    3.4.40  HTCondor-CE 3.4.0      Ready for Release  3.5.6  osg-release 3.5-3    Both  CCTools 7.0.21    3.4.40  osg-release 3.4-9        Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#osg-investigations-team",
            "text": "Update of GRACC ES, which may require some development changes.  GRACC ES update is still ongoing.  Github actions are cool.  (Derek) scitokens-cpp update - Make release.  (overdue) Simple validation of xrootd-monitoring-collector passed.    Data collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.    (in progress) Development on perfsonar tape-backup flow with John.  (in progress) XRootD development for TCP stats.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20191125/#discussion_2",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191118/",
            "text": "OSG Technology Area Meeting, 18 November 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n Brian, Carl, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nBrianL out tomorrow, 11/19  \n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Carl\n\n\nNext week: BrianL\n\n\n15 (+1) open FreshDesk tickets\n\n\n0 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n163\n\n\n+9\n\n\nOpen\n\n\n\n\n\n\n34\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n7\n\n\n+1\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n-6\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.6/3.4.40  \n\n\nAI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)\n\n\nAI (Carl): Kick off VMU tests for osg-xrootd-standalone and CCTools (SOFTWARE-3587, SOFTWARE-3883)\n\n\nAI (Carl): Release HTCondor 8.8.6 (SOFTWARE-3890)\n\n\nAI (Diego): Release HTCondor 8.9.4\n\n\n\n\n\n\nAI (Diego): Replace smart quotes and dashes in osg-notify (SOFTWARE-3893)\n\n\nAI (Carl): Add multi-user Hosted-CE support (SOFTWARE-3847)\n\n\nAI (Carl): Compare HTCondor/HTCondor-CE probe output from history records on itb-ce2 (SOFTWARE-3873)\n\n\nDoc focus this Thursdy, 11/21, 1:30pm CST\n\n\nTransition from osghost to osg-sw-submit for nightlies are waiting on new HTTP service from CHTC infrastructure\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nEdgar had a meeting with the LIGO folks last week:\n\n\nSites accidentally got both HTCondor-CE from the CHTC Yum repositories.\n    As we move all of the OSG specifics to the OSG CE metapackage, this should be a reasonable installation setup.\n\n\nLIGO depends on Edgar's RSV probe but we no longer support RSV. They need an alternative solution for 3.5.\n\n\nThey're interested in another training, similar to the one Edgar/Christina gave them a few years ago, in Wisconsin somewhere.\n    Unfortunately, the week they're planning on meeting is during the OSG All Hands.\n\n\n\n\n\n\nAI (BrianL): Create GlideinWMS 3.6.1 ticket\n\n\n\n\nSupport Update\n\u00b6\n\n\nNone this week  \n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.39\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.5\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-1\n\n\n0\n\n\n+0\n\n\n0\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-5\n\n\n0\n\n\n+0\n\n\n0\n\n\n-5\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+0\n\n\n11\n\n\n+6\n\n\n0\n\n\n+0\n\n\n12\n\n\n+6\n\n\nReady for Release\n\n\n\n\n\n\n1\n\n\n+0\n\n\n11\n\n\n+0\n\n\n0\n\n\n+0\n\n\n12\n\n\n+0\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\n3.5.5  \n\n\nNothing\n\n\n\n\n\n\nBoth  \n\n\nfrontier-squid 4.9-1.1\n\n\nBLAHP 1.18.45\n\n\nXRootD 4.11.0\n\n\nscitokens-cpp 0.3.5\n\n\nscitokens-credmon 0.4-2\n\n\n\n\n\n\n3.4.39  \n\n\nSingularity 3.4.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.40\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.6\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-1\n\n\n0\n\n\n+0\n\n\n0\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-5\n\n\n0\n\n\n+0\n\n\n0\n\n\n-5\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+0\n\n\n11\n\n\n+6\n\n\n0\n\n\n+0\n\n\n12\n\n\n+6\n\n\nReady for Release\n\n\n\n\n\n\n1\n\n\n+0\n\n\n11\n\n\n+0\n\n\n0\n\n\n+0\n\n\n12\n\n\n+0\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\n3.5.6  \n\n\nHTCondor-CE 4.1.0\n\n\nosg-release 3.5-3\n\n\n\n\n\n\nBoth  \n\n\nXCache 1.2\n\n\nCC*Tools 7.0.21\n\n\n\n\n\n\n3.4.40  \n\n\nHTCondor-CE 3.4.0\n\n\nosg-release 3.4-9\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nosg-notify\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nWorking with Brian (and Frank?) on GRACC changes.  \n\n\nHigher priority this week, need to get it done.\n\n\n\n\n\n\nUpdate of GRACC ES, which may require some development changes.  Hopefully updating... this week?\n\n\nDONE\n NSF science bucket metadata for GRACC development.  \n\n\nDONE\n Need to discuss with the RCF team about field of science updates\n\n\nDONE\n Add science bucket on a dashboard (on payload screen, but can be added to more)\n\n\n\n\n\n\nDevelopment of scitokens-cpp for WLCG compatibility and testing framework.  Expect a new release in ~week or so.\n\n\nSimple validation of xrootd-monitoring-collector passed.  \n\n\nData collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.\n\n\n\n\n\n\nDevelopment on perfsonar tape-backup flow with John.\n\n\nXRootD development for TCP stats.\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week",
            "title": "November, 18 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#osg-technology-area-meeting-18-november-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  Brian, Carl, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 18 November 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#announcements",
            "text": "BrianL out tomorrow, 11/19",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#triage-duty",
            "text": "This week: Carl  Next week: BrianL  15 (+1) open FreshDesk tickets  0 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#jira",
            "text": "# of tickets  \u0394  State      163  +9  Open    34  -2  In Progress    7  +1  Ready for Testing    1  -6  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#osg-software-team",
            "text": "OSG 3.5.6/3.4.40    AI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)  AI (Carl): Kick off VMU tests for osg-xrootd-standalone and CCTools (SOFTWARE-3587, SOFTWARE-3883)  AI (Carl): Release HTCondor 8.8.6 (SOFTWARE-3890)  AI (Diego): Release HTCondor 8.9.4    AI (Diego): Replace smart quotes and dashes in osg-notify (SOFTWARE-3893)  AI (Carl): Add multi-user Hosted-CE support (SOFTWARE-3847)  AI (Carl): Compare HTCondor/HTCondor-CE probe output from history records on itb-ce2 (SOFTWARE-3873)  Doc focus this Thursdy, 11/21, 1:30pm CST  Transition from osghost to osg-sw-submit for nightlies are waiting on new HTTP service from CHTC infrastructure",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#discussion",
            "text": "Edgar had a meeting with the LIGO folks last week:  Sites accidentally got both HTCondor-CE from the CHTC Yum repositories.\n    As we move all of the OSG specifics to the OSG CE metapackage, this should be a reasonable installation setup.  LIGO depends on Edgar's RSV probe but we no longer support RSV. They need an alternative solution for 3.5.  They're interested in another training, similar to the one Edgar/Christina gave them a few years ago, in Wisconsin somewhere.\n    Unfortunately, the week they're planning on meeting is during the OSG All Hands.    AI (BrianL): Create GlideinWMS 3.6.1 ticket",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#support-update",
            "text": "None this week",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#osg-release-team",
            "text": "3.4.39  \u0394  Both  \u0394  3.5.5  \u0394  Total  \u0394  Status      0  +0  0  +0  0  +0  0  +0  Open    0  +0  0  -1  0  +0  0  -1  In Progress    0  +0  0  -5  0  +0  0  -5  Ready for Testing    1  +0  11  +6  0  +0  12  +6  Ready for Release    1  +0  11  +0  0  +0  12  +0  Total      Software    3.5.5    Nothing    Both    frontier-squid 4.9-1.1  BLAHP 1.18.45  XRootD 4.11.0  scitokens-cpp 0.3.5  scitokens-credmon 0.4-2    3.4.39    Singularity 3.4.2          3.4.40  \u0394  Both  \u0394  3.5.6  \u0394  Total  \u0394  Status      0  +0  0  +0  0  +0  0  +0  Open    0  +0  0  -1  0  +0  0  -1  In Progress    0  +0  0  -5  0  +0  0  -5  Ready for Testing    1  +0  11  +6  0  +0  12  +6  Ready for Release    1  +0  11  +0  0  +0  12  +0  Total      Software    3.5.6    HTCondor-CE 4.1.0  osg-release 3.5-3    Both    XCache 1.2  CC*Tools 7.0.21    3.4.40    HTCondor-CE 3.4.0  osg-release 3.4-9      Data    Nothing    Operations    osg-notify    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#osg-investigations-team",
            "text": "Working with Brian (and Frank?) on GRACC changes.    Higher priority this week, need to get it done.    Update of GRACC ES, which may require some development changes.  Hopefully updating... this week?  DONE  NSF science bucket metadata for GRACC development.    DONE  Need to discuss with the RCF team about field of science updates  DONE  Add science bucket on a dashboard (on payload screen, but can be added to more)    Development of scitokens-cpp for WLCG compatibility and testing framework.  Expect a new release in ~week or so.  Simple validation of xrootd-monitoring-collector passed.    Data collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.    Development on perfsonar tape-backup flow with John.  XRootD development for TCP stats.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20191118/#discussion_2",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191111/",
            "text": "OSG Technology Area Meeting, 11 November 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Marco Mambelli, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nMarian OOO today\n\n\nUCSD off for Veteran's Day\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Edgar\n\n\nNext week: Carl\n\n\n14 (+2) open FreshDesk tickets\n\n\n0 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n154\n\n\n+1\n\n\nOpen\n\n\n\n\n\n\n36\n\n\n+6\n\n\nIn Progress\n\n\n\n\n\n\n6\n\n\n-6\n\n\nReady for Testing\n\n\n\n\n\n\n7\n\n\n+7\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.6/3.4.40\n\n\nAI (Carl): Add schedd cron configuration for the HTCondor-CE gratia probe (SOFTWARE-3830)\n\n\nAI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)\n\n\nAI (BrianL): Release HTCondor-CE 3.2.3 and 4.0.2 (SOFTWARE-3862, SOFTWARE-3861)\n\n\n\n\n\n\nAI (Mat): Add multi-user Hosted-CE support (SOFTWARE-3847)\n\n\nAI (Carl): Compare HTCondor/HTCondor-CE probe output from history records on itb-ce2 (SOFTWARE-3873)\n\n\nUW Madison + UChicago + Utah Container Hackathon dates 11/13 + 11/14 (\nhttps://indico.fnal.gov/event/22296/\n)\n\n\nDoc focus pushed back to 11/21\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nNightly/developer VMU tests are functional again after issues with the CHTC pool last week\n\n\nAI (BrianL): We decided to add epel-testing to our nightlies to catch potential issues with EPEL updates before they're released\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nCyVerse (Carl, Mat): upgrade issues were resolved by setting Yum priorities for HTCondor's repositories so that they're better than the OSG repositories. Upstream ticket has been made so that this becomes standard.\n\n\nPIC/CIEMAT (BrianL): Job route order in 8.8/8.9 is hash table order instead of config order. Tested a fix for stable from the HTCondor team\n\n\nUniversity of Washington (BrianL): Discussed rejoining as an OSG site via Hosted CE. They need to sort outgoing network access on the WNs first.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.39\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.5\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-1\n\n\n0\n\n\n-1\n\n\n0\n\n\n-1\n\n\n0\n\n\n-3\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n1\n\n\n-4\n\n\n0\n\n\n-2\n\n\n1\n\n\n-6\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-1\n\n\n5\n\n\n+1\n\n\n0\n\n\n+0\n\n\n5\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+1\n\n\n5\n\n\n+0\n\n\n0\n\n\n+0\n\n\n6\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n1\n\n\n-1\n\n\n11\n\n\n-4\n\n\n0\n\n\n-3\n\n\n12\n\n\n-8\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing  \n\n\n3.5.5  \n\n\nNothing\n\n\n\n\n\n\nBoth  \n\n\nfrontier-squid 4.9-1.1\n\n\nXRootD 4.11.0\n\n\nscitokens-cpp 0.3.5\n\n\nscitokens-credmon 0.4-2\n\n\n\n\n\n\n3.4.39  \n\n\nSingularity 3.4.2\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nBoth  \n\n\nBLAHP 1.18.45\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nosg-notify\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nSimple validation of xrootd-monitoring-collector passed.  \n\n\nData collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.\n\n\n\n\n\n\nWorking with Brian (and Frank?) on GRACC changes.\n\n\nHigher priority this week, need to get it done.\n\n\n\n\n\n\nUpdate of GRACC ES, which may require some development changes.  Hopefully updating this week.\n\n\nDONE\n NSF science bucket metadata for GRACC development.  \n\n\nDONE\n Need to discuss with the RCF team about field of science updates\n\n\nTODO\n Add science bucket on a dashboard\n\n\n\n\n\n\nEmergency development for scitokens-cpp.  Thanks Mat for the RPM.\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week",
            "title": "November, 11 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#osg-technology-area-meeting-11-november-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Marco Mambelli, Mat, TimT",
            "title": "OSG Technology Area Meeting, 11 November 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#announcements",
            "text": "Marian OOO today  UCSD off for Veteran's Day",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#triage-duty",
            "text": "This week: Edgar  Next week: Carl  14 (+2) open FreshDesk tickets  0 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#jira",
            "text": "# of tickets  \u0394  State      154  +1  Open    36  +6  In Progress    6  -6  Ready for Testing    7  +7  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#osg-software-team",
            "text": "OSG 3.5.6/3.4.40  AI (Carl): Add schedd cron configuration for the HTCondor-CE gratia probe (SOFTWARE-3830)  AI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)  AI (BrianL): Release HTCondor-CE 3.2.3 and 4.0.2 (SOFTWARE-3862, SOFTWARE-3861)    AI (Mat): Add multi-user Hosted-CE support (SOFTWARE-3847)  AI (Carl): Compare HTCondor/HTCondor-CE probe output from history records on itb-ce2 (SOFTWARE-3873)  UW Madison + UChicago + Utah Container Hackathon dates 11/13 + 11/14 ( https://indico.fnal.gov/event/22296/ )  Doc focus pushed back to 11/21",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#discussion",
            "text": "Nightly/developer VMU tests are functional again after issues with the CHTC pool last week  AI (BrianL): We decided to add epel-testing to our nightlies to catch potential issues with EPEL updates before they're released",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#support-update",
            "text": "CyVerse (Carl, Mat): upgrade issues were resolved by setting Yum priorities for HTCondor's repositories so that they're better than the OSG repositories. Upstream ticket has been made so that this becomes standard.  PIC/CIEMAT (BrianL): Job route order in 8.8/8.9 is hash table order instead of config order. Tested a fix for stable from the HTCondor team  University of Washington (BrianL): Discussed rejoining as an OSG site via Hosted CE. They need to sort outgoing network access on the WNs first.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#osg-release-team",
            "text": "3.4.39  \u0394  Both  \u0394  3.5.5  \u0394  Total  \u0394  Status      0  -1  0  -1  0  -1  0  -3  Open    0  +0  1  -4  0  -2  1  -6  In Progress    0  -1  5  +1  0  +0  5  +0  Ready for Testing    1  +1  5  +0  0  +0  6  +1  Ready for Release    1  -1  11  -4  0  -3  12  -8  Total      Software    Ready for Testing    3.5.5    Nothing    Both    frontier-squid 4.9-1.1  XRootD 4.11.0  scitokens-cpp 0.3.5  scitokens-credmon 0.4-2    3.4.39    Singularity 3.4.2      Ready for Release    Both    BLAHP 1.18.45        Data    Nothing    Operations    osg-notify    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#osg-investigations-team",
            "text": "Simple validation of xrootd-monitoring-collector passed.    Data collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.    Working with Brian (and Frank?) on GRACC changes.  Higher priority this week, need to get it done.    Update of GRACC ES, which may require some development changes.  Hopefully updating this week.  DONE  NSF science bucket metadata for GRACC development.    DONE  Need to discuss with the RCF team about field of science updates  TODO  Add science bucket on a dashboard    Emergency development for scitokens-cpp.  Thanks Mat for the RPM.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20191111/#discussion_2",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191104/",
            "text": "OSG Technology Area Meeting,  4 November 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Diego, Edgar, Marco Mambelli, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nMarian OOO 28 Oct - 8 Nov\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: Edgar\n\n\n12 (+1) open FreshDesk tickets\n\n\n0 (-1) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n153\n\n\n-2\n\n\nOpen\n\n\n\n\n\n\n30\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n12\n\n\n+5\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.5/3.4.39  \n\n\nAI (Carl, Tim): Produce blahp release notes\n\n\nAI (Carl): Add schedd cron configuration for the HTCondor-CE gratia probe (SOFTWARE-3830)\n\n\nAI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)\n\n\nAI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810, SOFTWARE-3875)\n\n\nAI (BrianL): Release HTCondor-CE 3.2.3 and 4.0.2 (SOFTWARE-3862, SOFTWARE-3861)\n\n\n\n\n\n\nAI (Mat): Add multi-user Hosted-CE support (SOFTWARE-3847)\n\n\nAI (Carl): Transition an HTCondor site to using the HTCondor-CE probe (SOFTWARE-3873)\n\n\nAI (BrianL, Diego): Get access to osg-sw-submit and Freshdesk\n\n\nUW Madison + UChicago + Utah Container Hackathon dates 11/13 + 11/14 (\nhttps://indico.fnal.gov/event/22296/\n)\n\n\n11/14 doc focus delayed\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nMarco is expecting to release a GlideinWMS 3.6.1 RC today\n\n\nOSG security defaults in HTCondor 8.8 for OSG 3.5 are overriding GlideinWMS security defaults. Marco will send an email to the list to discuss config naming conventions.\n\n\nAI (BrianL): We decided to add epel-testing to our nightlies to catch potential issues with EPEL updates before they're released\n\n\nEdgar mentioned that the osg-sw-base container image is really useful and that we should advertise it more widely\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nCERN (BrianL): There's a bug in HTCondor 8.8/8.9 where remote submits set the \"Owner\" attribute, which prevents job submission if they're mapped to a different owner on the remote host. Will be fixed in the next HTCondor versions. Can be worked around by setting \n+Owner = undefined\n in the submit file.\n\n\nFNAL (Mat): Steve Timm requested that we disable some cyphers in VOMS\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.39\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.5\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n1\n\n\n-1\n\n\n1\n\n\n-2\n\n\n1\n\n\n+0\n\n\n3\n\n\n-3\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n5\n\n\n-2\n\n\n2\n\n\n+0\n\n\n7\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n1\n\n\n+1\n\n\n4\n\n\n-1\n\n\n0\n\n\n+0\n\n\n5\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n5\n\n\n+5\n\n\n0\n\n\n+0\n\n\n5\n\n\n+5\n\n\nReady for Release\n\n\n\n\n\n\n2\n\n\n+0\n\n\n15\n\n\n+0\n\n\n3\n\n\n+0\n\n\n20\n\n\n+0\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing  \n\n\n3.5.5  \n\n\nNothing\n\n\n\n\n\n\nBoth  \n\n\nXRootD 4.11.0\n\n\nscitokens-credmon 0.4-2\n\n\n\n\n\n\n3.4.39  \n\n\nSingularity 3.4.2\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nBoth  \n\n\nBLAHP 1.18.45\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nosg-notify\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week",
            "title": "November, 4 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191104/#osg-technology-area-meeting-4-november-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Diego, Edgar, Marco Mambelli, Mat, TimT",
            "title": "OSG Technology Area Meeting,  4 November 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191104/#announcements",
            "text": "Marian OOO 28 Oct - 8 Nov",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20191104/#triage-duty",
            "text": "This week: Mat  Next week: Edgar  12 (+1) open FreshDesk tickets  0 (-1) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20191104/#jira",
            "text": "# of tickets  \u0394  State      153  -2  Open    30  -2  In Progress    12  +5  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20191104/#osg-software-team",
            "text": "OSG 3.5.5/3.4.39    AI (Carl, Tim): Produce blahp release notes  AI (Carl): Add schedd cron configuration for the HTCondor-CE gratia probe (SOFTWARE-3830)  AI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)  AI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810, SOFTWARE-3875)  AI (BrianL): Release HTCondor-CE 3.2.3 and 4.0.2 (SOFTWARE-3862, SOFTWARE-3861)    AI (Mat): Add multi-user Hosted-CE support (SOFTWARE-3847)  AI (Carl): Transition an HTCondor site to using the HTCondor-CE probe (SOFTWARE-3873)  AI (BrianL, Diego): Get access to osg-sw-submit and Freshdesk  UW Madison + UChicago + Utah Container Hackathon dates 11/13 + 11/14 ( https://indico.fnal.gov/event/22296/ )  11/14 doc focus delayed",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20191104/#discussion",
            "text": "Marco is expecting to release a GlideinWMS 3.6.1 RC today  OSG security defaults in HTCondor 8.8 for OSG 3.5 are overriding GlideinWMS security defaults. Marco will send an email to the list to discuss config naming conventions.  AI (BrianL): We decided to add epel-testing to our nightlies to catch potential issues with EPEL updates before they're released  Edgar mentioned that the osg-sw-base container image is really useful and that we should advertise it more widely",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191104/#support-update",
            "text": "CERN (BrianL): There's a bug in HTCondor 8.8/8.9 where remote submits set the \"Owner\" attribute, which prevents job submission if they're mapped to a different owner on the remote host. Will be fixed in the next HTCondor versions. Can be worked around by setting  +Owner = undefined  in the submit file.  FNAL (Mat): Steve Timm requested that we disable some cyphers in VOMS",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20191104/#osg-release-team",
            "text": "3.4.39  \u0394  Both  \u0394  3.5.5  \u0394  Total  \u0394  Status      1  -1  1  -2  1  +0  3  -3  Open    0  +0  5  -2  2  +0  7  -2  In Progress    1  +1  4  -1  0  +0  5  +0  Ready for Testing    0  +0  5  +5  0  +0  5  +5  Ready for Release    2  +0  15  +0  3  +0  20  +0  Total      Software    Ready for Testing    3.5.5    Nothing    Both    XRootD 4.11.0  scitokens-credmon 0.4-2    3.4.39    Singularity 3.4.2      Ready for Release    Both    BLAHP 1.18.45        Data    Nothing    Operations    osg-notify    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20191104/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191028/",
            "text": "OSG Technology Area Meeting, 28 October 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Diego, Edgar, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nMarian OOO 28 Oct - 8 Nov\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: TimT\n\n\nNext week: Mat\n\n\n11 (+0) open FreshDesk tickets\n\n\n1 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n155\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n32\n\n\n+2\n\n\nIn Progress\n\n\n\n\n\n\n7\n\n\n-3\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.5/3.4.39  \n\n\nAI (Carl, Tim): Produce blahp release notes\n\n\nAI (Carl): Release XRootD 4.11.0+ and plugins (SOFTWARE-3830)\n\n\nAI (Carl): Add schedd cron configuration for the HTCondor-CE gratia probe (SOFTWARE-3830)\n\n\nAI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)\n\n\nAI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810, SOFTWARE-3875)\n\n\nAI (BrianL): Release HTCondor-CE 3.2.3 and 4.0.2 (SOFTWARE-3862, SOFTWARE-3861)\n\n\nAI (Mat): Package scitokens-credmon (SOFTWARE-3711)\n\n\n\n\n\n\nAI (Mat, devops): Avoid duplicate WN tarball generation for multiple users (SOFTWARE-3484)\n\n\nAI (Carl): Submit DockerHub promotion/cleanup scripts to release-tools (SOFTWARE-3843, SOFTWARE-3844)\n\n\nAI (Carl): Transition an HTCondor site to using the HTCondor-CE probe (SOFTWARE-3873)\n\n\nAI (BrianL, Diego): Get access to osg-sw-submit and Freshdesk\n\n\nUW Madison + UChicago + Utah Hackathon dates 11/13 + 11/14\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (BrianL): We decided to add epel-testing to our nightlies to catch potential issues with EPEL updates before they're released\n\n\nAI (BrianL): Fix typo in SPF record for osg-sw-submit\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBNL (Derek): Belle II had disabled their Gratia probes but after re-enabling them the historical records were not still picked up. Still investigating.\n\n\nUCSD (Edgar): had been assisting a user with their environment on a local submit host but we think it would be a good idea to have them sign up with OSG Connect.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.38\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.4\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-6\n\n\n0\n\n\n-1\n\n\n0\n\n\n-7\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n4\n\n\n+4\n\n\n1\n\n\n+1\n\n\n5\n\n\n+5\n\n\nReady for Release\n\n\n\n\n\n\n0\n\n\n+0\n\n\n4\n\n\n-2\n\n\n1\n\n\n+0\n\n\n5\n\n\n-2\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\n3.5.4  \n\n\nHTCondor 8.8.5-1.7\n\n\n\n\n\n\nBoth  \n\n\nstashcache client 5.5.0\n\n\n\n\n\n\n3.4.38  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nIGTF 1.102\n\n\nVO Package v97 - Add JLab CLAS12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.39\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.5\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n2\n\n\n+2\n\n\n3\n\n\n+3\n\n\n1\n\n\n+1\n\n\n6\n\n\n+6\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n7\n\n\n+7\n\n\n2\n\n\n+2\n\n\n9\n\n\n+9\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n+0\n\n\n5\n\n\n+5\n\n\n0\n\n\n+0\n\n\n5\n\n\n+5\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n2\n\n\n+2\n\n\n15\n\n\n+15\n\n\n3\n\n\n+3\n\n\n20\n\n\n+20\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing  \n\n\n3.5.5  \n\n\nNothing\n\n\n\n\n\n\nBoth  \n\n\nBLAHP 1.18.45\n\n\n\n\n\n\n3.4.39  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nosg-notify\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nWe receive feedback from community testing emails infrequently but tend to still have to contact specific people for testing\n\n\nBrian Lin proposed adding the ATLAS and CMS Tier-2 email lists to perhaps get stake holders to encourage admins to do some testing\n\n\n\n\n\n\n\n\nOSG Investigations\n\u00b6\n\n\n\n\nSimple validation of xrootd-monitoring-collector passed.  \n\n\nData collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.\n\n\n\n\n\n\nWorking with Brian (and Frank?) on GRACC changes.\n\n\nUpdate of GRACC ES, which may require some development changes.  Hopefully updating this week.\n\n\nDONE\n NSF science bucket metadata for GRACC development.  \n\n\nTODO\n Need to discuss with the RCF team about field of science updates\n\n\nTODO\n Add science bucket on a dashboard\n\n\n\n\n\n\nHelping osg-connect with SciTokens installation across submit hosts (Thanks mat for the RPM)\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week",
            "title": "October, 28 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#osg-technology-area-meeting-28-october-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Diego, Edgar, Mat, TimT",
            "title": "OSG Technology Area Meeting, 28 October 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#announcements",
            "text": "Marian OOO 28 Oct - 8 Nov",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#triage-duty",
            "text": "This week: TimT  Next week: Mat  11 (+0) open FreshDesk tickets  1 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#jira",
            "text": "# of tickets  \u0394  State      155  +0  Open    32  +2  In Progress    7  -3  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#osg-software-team",
            "text": "OSG 3.5.5/3.4.39    AI (Carl, Tim): Produce blahp release notes  AI (Carl): Release XRootD 4.11.0+ and plugins (SOFTWARE-3830)  AI (Carl): Add schedd cron configuration for the HTCondor-CE gratia probe (SOFTWARE-3830)  AI (Mat): Drop or upstream OSG-specific Globus patches (SOFTWARE-2996)  AI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810, SOFTWARE-3875)  AI (BrianL): Release HTCondor-CE 3.2.3 and 4.0.2 (SOFTWARE-3862, SOFTWARE-3861)  AI (Mat): Package scitokens-credmon (SOFTWARE-3711)    AI (Mat, devops): Avoid duplicate WN tarball generation for multiple users (SOFTWARE-3484)  AI (Carl): Submit DockerHub promotion/cleanup scripts to release-tools (SOFTWARE-3843, SOFTWARE-3844)  AI (Carl): Transition an HTCondor site to using the HTCondor-CE probe (SOFTWARE-3873)  AI (BrianL, Diego): Get access to osg-sw-submit and Freshdesk  UW Madison + UChicago + Utah Hackathon dates 11/13 + 11/14",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#discussion",
            "text": "AI (BrianL): We decided to add epel-testing to our nightlies to catch potential issues with EPEL updates before they're released  AI (BrianL): Fix typo in SPF record for osg-sw-submit",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#support-update",
            "text": "BNL (Derek): Belle II had disabled their Gratia probes but after re-enabling them the historical records were not still picked up. Still investigating.  UCSD (Edgar): had been assisting a user with their environment on a local submit host but we think it would be a good idea to have them sign up with OSG Connect.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#osg-release-team",
            "text": "3.4.38  \u0394  Both  \u0394  3.5.4  \u0394  Total  \u0394  Status      0  +0  0  +0  0  +0  0  +0  Open    0  +0  0  +0  0  +0  0  +0  In Progress    0  +0  0  -6  0  -1  0  -7  Ready for Testing    0  +0  4  +4  1  +1  5  +5  Ready for Release    0  +0  4  -2  1  +0  5  -2  Total      Software    3.5.4    HTCondor 8.8.5-1.7    Both    stashcache client 5.5.0    3.4.38    Nothing      Data    IGTF 1.102  VO Package v97 - Add JLab CLAS12        3.4.39  \u0394  Both  \u0394  3.5.5  \u0394  Total  \u0394  Status      2  +2  3  +3  1  +1  6  +6  Open    0  +0  7  +7  2  +2  9  +9  In Progress    0  +0  5  +5  0  +0  5  +5  Ready for Testing    0  +0  0  +0  0  +0  0  +0  Ready for Release    2  +2  15  +15  3  +3  20  +20  Total      Software    Ready for Testing    3.5.5    Nothing    Both    BLAHP 1.18.45    3.4.39    Nothing      Ready for Release    Nothing      Data    Nothing    Operations    osg-notify    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#discussion_1",
            "text": "We receive feedback from community testing emails infrequently but tend to still have to contact specific people for testing  Brian Lin proposed adding the ATLAS and CMS Tier-2 email lists to perhaps get stake holders to encourage admins to do some testing",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#osg-investigations",
            "text": "Simple validation of xrootd-monitoring-collector passed.    Data collected for production validation, now to correlate the 2 sources, collector and remote xrootd server.  Difficult step.    Working with Brian (and Frank?) on GRACC changes.  Update of GRACC ES, which may require some development changes.  Hopefully updating this week.  DONE  NSF science bucket metadata for GRACC development.    TODO  Need to discuss with the RCF team about field of science updates  TODO  Add science bucket on a dashboard    Helping osg-connect with SciTokens installation across submit hosts (Thanks mat for the RPM)",
            "title": "OSG Investigations"
        },
        {
            "location": "/meetings/2019/TechArea20191028/#discussion_2",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191021/",
            "text": "OSG Technology Area Meeting, 21 October 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nBrianL OOO 24 Oct - 25 Oct\n\n\nDiego OOO 17 Oct - 24 Oct\n\n\nMarian OOO 28 Oct - 8 Nov\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Edgar\n\n\nNext week: TimT\n\n\n11 (-1) open FreshDesk tickets\n\n\n1 (-1) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n155\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n30\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n10\n\n\n-10\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.4/3.4.38  \n\n\nAI (Carl): 3.4 -> 3.5 HTCondor upgrades broken due to difference in CREAM support (SOFTWARE-3869)\n\n\n\n\n\n\nOSG 3.5.5/3.4.39  \n\n\nAI (Carl): Release XRootD 4.11.0+ and plugins (SOFTWARE-3830)\n\n\nAI (BrianL): Release HTCondor-CE 3.2.3 and 4.0.2 (SOFTWARE-3862, SOFTWARE-3861)\n\n\nAI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810)\n\n\nAI (Mat): Avoid duplicate WN tarball generation for multiple users (SOFTWARE-3484)\n\n\nAI (Mat): Package scitokens-credmon (SOFTWARE-3711)\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nWe decided to add epel-testing to our nightlies to catch potential issues with EPEL updates before they're released\n\n\nSupport Update\n\u00b6\n\n\nNone this week\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.37\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.3\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-1\n\n\n0\n\n\n-15\n\n\n0\n\n\n-1\n\n\n0\n\n\n-17\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-9\n\n\n0\n\n\n-1\n\n\n0\n\n\n-10\n\n\nIn Progress\n\n\n\n\n\n\n5\n\n\n-5\n\n\n0\n\n\n-11\n\n\n0\n\n\n-3\n\n\n0\n\n\n-19\n\n\nReady for Testing\n\n\n\n\n\n\n5\n\n\n+5\n\n\n11\n\n\n+11\n\n\n2\n\n\n+2\n\n\n18\n\n\n+18\n\n\nReady for Release\n\n\n\n\n\n\n5\n\n\n-1\n\n\n11\n\n\n-24\n\n\n2\n\n\n-3\n\n\n18\n\n\n-28\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\n3.5.2  \n\n\nHTCondor 8.8.5\n\n\nosg-configure 3.1.0\n\n\nUpcoming: HTCondor 8.9.3\n\n\n\n\n\n\nBoth  \n\n\nGlideinWMS 3.6\n\n\nXRootD 4.10.1\n\n\nscitokens-cpp 0.3.4\n\n\noidc-agent 3.2.6\n\n\ngratia-probe 1.20.11\n\n\n\n\n\n\n3.4.36  \n\n\nHTCondor 8.8.5\n\n\nosg-configure 2.5.0\n\n\nkoji 1.11.1-1.2\n\n\nosg-build 1.15.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.38\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.4\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n+0\n\n\n6\n\n\n+0\n\n\n1\n\n\n+0\n\n\n7\n\n\n+7\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n0\n\n\n+0\n\n\n6\n\n\n+0\n\n\n1\n\n\n+0\n\n\n7\n\n\n+7\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing  \n\n\n3.5.2  \n\n\nHTCondor 8.8.5-1.7\n\n\n\n\n\n\nBoth  \n\n\nBLAHP 1.18.45\n\n\nstashcache client 5.5.0\n\n\n\n\n\n\n3.4.36  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nIGTF 1.102\n\n\nVO Package v97 - Add JLab Clas12\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Email Susan to discuss CA certificate packaging responsibilities\n\n\nWe receive feedback from community testing emails infrequently but tend to still have to contact specific people for testing\n\n\nOur release cadence is very frequent with the new community testing policy and this seems to be pushing us toward a rolling release for the next release series\n\n\nTo minimize maintenance effort, we would need something like an automated RSS feed for released packages\n\n\nIt would be nice to have a better interface for testing feedback like what Bodhi has for Fedora\n\n\n\n\n\n\n\n\nOSG Investigations\n\u00b6\n\n\n\n\nSimple validation of xrootd-monitoring-collector passed.  \n\n\nWorking now with Bockjoo on production validation.  Step 1 is making a public test collector\n\n\n\n\n\n\nWorking with Brian (and Frank?) on GRACC changes.\n\n\nUpdate of GRACC ES, which may require some development changes.  Hopefully updating this week.\n\n\nDONE\n NSF science bucket metadata for GRACC development.\n\n\nNeed to discuss with the RCF team about field of science updates\n\n\n\n\n\n\nAttended the RCF meeting to view the new osg-connect user management interface.  \nneat\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week",
            "title": "October, 21 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#osg-technology-area-meeting-21-october-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Mat, TimT",
            "title": "OSG Technology Area Meeting, 21 October 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#announcements",
            "text": "BrianL OOO 24 Oct - 25 Oct  Diego OOO 17 Oct - 24 Oct  Marian OOO 28 Oct - 8 Nov",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#triage-duty",
            "text": "This week: Edgar  Next week: TimT  11 (-1) open FreshDesk tickets  1 (-1) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#jira",
            "text": "# of tickets  \u0394  State      155  +0  Open    30  -2  In Progress    10  -10  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#osg-software-team",
            "text": "OSG 3.5.4/3.4.38    AI (Carl): 3.4 -> 3.5 HTCondor upgrades broken due to difference in CREAM support (SOFTWARE-3869)    OSG 3.5.5/3.4.39    AI (Carl): Release XRootD 4.11.0+ and plugins (SOFTWARE-3830)  AI (BrianL): Release HTCondor-CE 3.2.3 and 4.0.2 (SOFTWARE-3862, SOFTWARE-3861)  AI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810)  AI (Mat): Avoid duplicate WN tarball generation for multiple users (SOFTWARE-3484)  AI (Mat): Package scitokens-credmon (SOFTWARE-3711)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#discussion",
            "text": "We decided to add epel-testing to our nightlies to catch potential issues with EPEL updates before they're released",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#support-update",
            "text": "None this week",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#osg-release-team",
            "text": "3.4.37  \u0394  Both  \u0394  3.5.3  \u0394  Total  \u0394  Status      0  -1  0  -15  0  -1  0  -17  Open    0  +0  0  -9  0  -1  0  -10  In Progress    5  -5  0  -11  0  -3  0  -19  Ready for Testing    5  +5  11  +11  2  +2  18  +18  Ready for Release    5  -1  11  -24  2  -3  18  -28  Total      Software    3.5.2    HTCondor 8.8.5  osg-configure 3.1.0  Upcoming: HTCondor 8.9.3    Both    GlideinWMS 3.6  XRootD 4.10.1  scitokens-cpp 0.3.4  oidc-agent 3.2.6  gratia-probe 1.20.11    3.4.36    HTCondor 8.8.5  osg-configure 2.5.0  koji 1.11.1-1.2  osg-build 1.15.1          3.4.38  \u0394  Both  \u0394  3.5.4  \u0394  Total  \u0394  Status      0  +0  0  +0  0  +0  0  +0  Open    0  +0  0  +0  0  +0  0  +0  In Progress    0  +0  6  +0  1  +0  7  +7  Ready for Testing    0  +0  0  +0  0  +0  0  +0  Ready for Release    0  +0  6  +0  1  +0  7  +7  Total      Software    Ready for Testing    3.5.2    HTCondor 8.8.5-1.7    Both    BLAHP 1.18.45  stashcache client 5.5.0    3.4.36    Nothing      Ready for Release    Nothing      Data    IGTF 1.102  VO Package v97 - Add JLab Clas12    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#discussion_1",
            "text": "AI (TimT): Email Susan to discuss CA certificate packaging responsibilities  We receive feedback from community testing emails infrequently but tend to still have to contact specific people for testing  Our release cadence is very frequent with the new community testing policy and this seems to be pushing us toward a rolling release for the next release series  To minimize maintenance effort, we would need something like an automated RSS feed for released packages  It would be nice to have a better interface for testing feedback like what Bodhi has for Fedora",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#osg-investigations",
            "text": "Simple validation of xrootd-monitoring-collector passed.    Working now with Bockjoo on production validation.  Step 1 is making a public test collector    Working with Brian (and Frank?) on GRACC changes.  Update of GRACC ES, which may require some development changes.  Hopefully updating this week.  DONE  NSF science bucket metadata for GRACC development.  Need to discuss with the RCF team about field of science updates    Attended the RCF meeting to view the new osg-connect user management interface.   neat",
            "title": "OSG Investigations"
        },
        {
            "location": "/meetings/2019/TechArea20191021/#discussion_2",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191014/",
            "text": "OSG Technology Area Meeting, 14 October 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Diego, Marian, Mat, TimT  \n\n\nAnnouncements\n\u00b6\n\n\n\n\nEdgar is at HEPiX\n\n\nDiego OOO 17 Oct - 24 Oct\n\n\nMarian OOO 28 Oct - 8 Nov\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: Edgar\n\n\n12 (-8) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n155\n\n\n-10\n\n\nOpen\n\n\n\n\n\n\n32\n\n\n+3\n\n\nIn Progress\n\n\n\n\n\n\n20\n\n\n-3\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.3/3.4.37  \n\n\nAI (Carl): Investigate slurm/pbs blahp errors (SOFTWARE-3824)\n\n\nAI (Diego): Enable checksum verification in xrootd-hdfs (SOFTWARE-3803)\n\n\nAI (Diego): Update osg-release to use koji.opensciencegrid.org (SOFTWARE-3863)\n\n\nAI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810)\n\n\n\n\n\n\nAI (Mat): Add multi-user support to Hosted CEs (SOFTWARE-3847)\n\n\nAI (BrianL): Troubleshoot itb-ce2 with SciTokens\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nSupport Update\n\u00b6\n\n\n\n\nCaltech (Carl): Some HDFS yum warnings upon upgrade that appear to be due to the local site configuration\n\n\nCMS (Marian, John): workarounds in place for SAM test failures with ongoing discussion for a complete solution in GGUS.\n\n\nBrown (Marian): Marian will update the support ticket with status updates\n\n\nOASIS (Derek): There was an issue with the CVMFS/Singularity sync due to an attempt to transition to Python 3\n\n\nUFL (BrianL): assisted with HTCondor-CE upgrade and remote condor query authentication failures\n\n\nUFL (Derek): Working with Bockjoo to validate XRootD accounting sent to the OSG collector\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.36\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.2\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-1\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n-1\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-3\n\n\n0\n\n\n+0\n\n\n0\n\n\n-3\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-3\n\n\n0\n\n\n-7\n\n\n0\n\n\n-9\n\n\n0\n\n\n-19\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+2\n\n\n5\n\n\n+5\n\n\n6\n\n\n+6\n\n\n13\n\n\n+13\n\n\nReady for Release\n\n\n\n\n\n\n2\n\n\n-2\n\n\n5\n\n\n-5\n\n\n6\n\n\n-3\n\n\n13\n\n\n-10\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware\n\n\n3.5.2\n\n\nosg-ce 3.5-2\n\n\nHTCondor CE 4.0.1\n\n\n\n\n\n\nBoth\n\n\nCVMFS 2.6.3\n\n\nFrontier Squid 4.8-2.1\n\n\nhosted-ce-tools 0.4\n\n\ncctools 7.0.18\n\n\n\n\n\n\n3.4.36\n\n\nlcmaps 1.6.6-1.9\n\n\n\n\n\n\n\n\n\n\nData\n\n\nLHCb VO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.37\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.3\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n1\n\n\n+1\n\n\n15\n\n\n+15\n\n\n1\n\n\n+1\n\n\n17\n\n\n+17\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n9\n\n\n+9\n\n\n1\n\n\n+1\n\n\n10\n\n\n+10\n\n\nIn Progress\n\n\n\n\n\n\n5\n\n\n+5\n\n\n11\n\n\n+11\n\n\n3\n\n\n+3\n\n\n19\n\n\n+19\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n6\n\n\n+6\n\n\n35\n\n\n+35\n\n\n5\n\n\n+5\n\n\n46\n\n\n+46\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing  \n\n\n3.5.2\n\n\nHTCondor 8.8.5\n\n\nosg-configure 3.1.0\n\n\nUpcoming: HTCondor 8.9.3\n\n\n\n\n\n\nBoth  \n\n\nGlideinWMS 3.6\n\n\nXRootD 4.10.1\n\n\nscitokens-cpp 0.3.4\n\n\noidc-agent 3.2.6\n\n\nstashcache client 5.5.0\n\n\ngratia-probe 1.20.11\n\n\n\n\n\n\n3.4.36\n\n\nHTCondor 8.8.5\n\n\nosg-configure 2.5.0\n\n\nkoji 1.11.1-1.2\n\n\nosg-build 1.15.1\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nIGTF 1.102\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nDecided that sending the weekly email on Thursday is fine for the \"Ready for Testing\" announcements.\n\n\nOSG Investigations\n\u00b6\n\n\n\n\nSimple validation of xrootd-monitoring-collector passed.  \n\n\nWorking now with Bockjoo on production validation.  Step 1 is making a public test collector\n\n\nWorking with Brian (and Frank?) on GRACC changes.\n\n\n\n\n\n\nUpdate of GRACC ES, which may require some development changes.  Hopefully updating this week.\n\n\ncvmfs-singularity-sync development for for python3 update.\n\n\nNSF science bucket metadata for GRACC development this week.\n\n\n\n\nDiscussion\n\u00b6\n\n\nDerek will try to tackle the FoS -> NSF bucket mapping for the GRACC this week, or contact BrianL for delegation",
            "title": "October, 14 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#osg-technology-area-meeting-14-october-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Diego, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 14 October 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#announcements",
            "text": "Edgar is at HEPiX  Diego OOO 17 Oct - 24 Oct  Marian OOO 28 Oct - 8 Nov",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#triage-duty",
            "text": "This week: Mat  Next week: Edgar  12 (-8) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#jira",
            "text": "# of tickets  \u0394  State      155  -10  Open    32  +3  In Progress    20  -3  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#osg-software-team",
            "text": "OSG 3.5.3/3.4.37    AI (Carl): Investigate slurm/pbs blahp errors (SOFTWARE-3824)  AI (Diego): Enable checksum verification in xrootd-hdfs (SOFTWARE-3803)  AI (Diego): Update osg-release to use koji.opensciencegrid.org (SOFTWARE-3863)  AI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810)    AI (Mat): Add multi-user support to Hosted CEs (SOFTWARE-3847)  AI (BrianL): Troubleshoot itb-ce2 with SciTokens",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#discussion",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#support-update",
            "text": "Caltech (Carl): Some HDFS yum warnings upon upgrade that appear to be due to the local site configuration  CMS (Marian, John): workarounds in place for SAM test failures with ongoing discussion for a complete solution in GGUS.  Brown (Marian): Marian will update the support ticket with status updates  OASIS (Derek): There was an issue with the CVMFS/Singularity sync due to an attempt to transition to Python 3  UFL (BrianL): assisted with HTCondor-CE upgrade and remote condor query authentication failures  UFL (Derek): Working with Bockjoo to validate XRootD accounting sent to the OSG collector",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#osg-release-team",
            "text": "3.4.36  \u0394  Both  \u0394  3.5.2  \u0394  Total  \u0394  Status      0  -1  0  +0  0  +0  0  -1  Open    0  +0  0  -3  0  +0  0  -3  In Progress    0  -3  0  -7  0  -9  0  -19  Ready for Testing    2  +2  5  +5  6  +6  13  +13  Ready for Release    2  -2  5  -5  6  -3  13  -10  Total      Software  3.5.2  osg-ce 3.5-2  HTCondor CE 4.0.1    Both  CVMFS 2.6.3  Frontier Squid 4.8-2.1  hosted-ce-tools 0.4  cctools 7.0.18    3.4.36  lcmaps 1.6.6-1.9      Data  LHCb VO        3.4.37  \u0394  Both  \u0394  3.5.3  \u0394  Total  \u0394  Status      1  +1  15  +15  1  +1  17  +17  Open    0  +0  9  +9  1  +1  10  +10  In Progress    5  +5  11  +11  3  +3  19  +19  Ready for Testing    0  +0  0  +0  0  +0  0  +0  Ready for Release    6  +6  35  +35  5  +5  46  +46  Total      Software    Ready for Testing    3.5.2  HTCondor 8.8.5  osg-configure 3.1.0  Upcoming: HTCondor 8.9.3    Both    GlideinWMS 3.6  XRootD 4.10.1  scitokens-cpp 0.3.4  oidc-agent 3.2.6  stashcache client 5.5.0  gratia-probe 1.20.11    3.4.36  HTCondor 8.8.5  osg-configure 2.5.0  koji 1.11.1-1.2  osg-build 1.15.1      Ready for Release    Nothing      Data    IGTF 1.102    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#discussion_1",
            "text": "Decided that sending the weekly email on Thursday is fine for the \"Ready for Testing\" announcements.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#osg-investigations",
            "text": "Simple validation of xrootd-monitoring-collector passed.    Working now with Bockjoo on production validation.  Step 1 is making a public test collector  Working with Brian (and Frank?) on GRACC changes.    Update of GRACC ES, which may require some development changes.  Hopefully updating this week.  cvmfs-singularity-sync development for for python3 update.  NSF science bucket metadata for GRACC development this week.",
            "title": "OSG Investigations"
        },
        {
            "location": "/meetings/2019/TechArea20191014/#discussion_2",
            "text": "Derek will try to tackle the FoS -> NSF bucket mapping for the GRACC this week, or contact BrianL for delegation",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191007/",
            "text": "OSG Technology Area Meeting,  7 October 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Derek, Marian, Marco Mambelli, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Carl\n\n\nNext week: Edgar\n\n\n20 (+2) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n165\n\n\n+3\n\n\nOpen\n\n\n\n\n\n\n29\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n23\n\n\n+7\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.2/3.4.36  \n\n\nKick off VMU tests for stashcache-client\n\n\nscitokens-cpp needs developer testing\n\n\nAI (Mat): Kick off clean installs for Singularity 3.4.1\n\n\nAI (BrianL): Write upgrade instructions for HTCondor-CE 4.0.1\n\n\n\n\n\n\nOSG 3.5.3/3.4.37  \n\n\nAI (Carl): New blahp! (SOFTWARE-3824)\n\n\nAI (Carl): New Gratia probe (SOFTWARE-3737)\n\n\nAI (Diego): Package oidc-agent (SOFTWARE-3820)\n\n\nAI (Diego): Enable checksum verification in xrootd-hdfs (SOFTWARE-3803)\n\n\nAI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810)\n\n\n\n\n\n\nAI (Mat): Add multi-user support to Hosted CEs (SOFTWARE-3847)\n\n\nNext doc focus this Thursday Oct 10 at 1:30pm\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (Carl): Add htcondor/BLAH to the GitHub backup script\n\n\nAI (BrianL): Archive the OSG BLAH repository with pointers to the unified htcondor/BLAH fork\n\n\nAI (TimT): Disable AFS/GitHub sync for htcondor/BLAH\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nCMS (Marian, John): troubleshooting SAM test failures resulted in a few XRootD pull requests. There is also an ongoing network investigation since these failures are affecting multiple US-CMS T2 sites.\n\n\nBrown (Marian): Provided some \nsite.xml\n configuration that the admin needs to apply\n\n\nCaltech (Carl): Some HDFS yum warnings upon upgrade that appear to be due to the local site configuration\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.36\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.2\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n1\n\n\n+1\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n1\n\n\n+1\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n3\n\n\n-2\n\n\n0\n\n\n+0\n\n\n3\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n3\n\n\n+1\n\n\n7\n\n\n+2\n\n\n9\n\n\n+1\n\n\n19\n\n\n+4\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n4\n\n\n+2\n\n\n10\n\n\n+0\n\n\n9\n\n\n+1\n\n\n23\n\n\n+3\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing  \n\n\n3.4.36  \n\n\nHTCondor 8.8.5\n\n\nlcmaps 1.6.6-1.9\n\n\nosg-configure 2.5.0\n\n\n\n\n\n\nBoth  \n\n\nCVMFS 2.6.3\n\n\nFrontier Squid 4.8-2.1\n\n\nhosted-ce-tools 0.4\n\n\ncctools 7.0.18\n\n\nGlideinWMS 3.6\n\n\n\n\n\n\n3.5.2\n\n\nosg-ce 3.5-2\n\n\nHTCondor CE 4.0.1\n\n\nHTCondor 8.8.5\n\n\nosg-configure 3.1.0\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nLHCb VO\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week\n\n\nOSG Investigations\n\u00b6\n\n\n\n\nSimple validation of xrootd-monitoring-collector passed.\n\n\nWorking now with Bockjoo on production validation.  Step 1 is making a public test collector\n\n\n\n\n\n\nWorking with Brian (and Frank?) on GRACC changes.\n\n\nUpdate of GRACC ES, which may require some development changes.\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week",
            "title": "October, 7 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#osg-technology-area-meeting-7-october-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Derek, Marian, Marco Mambelli, Mat, TimT",
            "title": "OSG Technology Area Meeting,  7 October 2019"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#announcements",
            "text": "",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#triage-duty",
            "text": "This week: Carl  Next week: Edgar  20 (+2) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#jira",
            "text": "# of tickets  \u0394  State      165  +3  Open    29  -1  In Progress    23  +7  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#osg-software-team",
            "text": "OSG 3.5.2/3.4.36    Kick off VMU tests for stashcache-client  scitokens-cpp needs developer testing  AI (Mat): Kick off clean installs for Singularity 3.4.1  AI (BrianL): Write upgrade instructions for HTCondor-CE 4.0.1    OSG 3.5.3/3.4.37    AI (Carl): New blahp! (SOFTWARE-3824)  AI (Carl): New Gratia probe (SOFTWARE-3737)  AI (Diego): Package oidc-agent (SOFTWARE-3820)  AI (Diego): Enable checksum verification in xrootd-hdfs (SOFTWARE-3803)  AI (Edgar): Investigate auth StashCache issue (SOFTWARE-3810)    AI (Mat): Add multi-user support to Hosted CEs (SOFTWARE-3847)  Next doc focus this Thursday Oct 10 at 1:30pm",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#discussion",
            "text": "AI (Carl): Add htcondor/BLAH to the GitHub backup script  AI (BrianL): Archive the OSG BLAH repository with pointers to the unified htcondor/BLAH fork  AI (TimT): Disable AFS/GitHub sync for htcondor/BLAH",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#support-update",
            "text": "CMS (Marian, John): troubleshooting SAM test failures resulted in a few XRootD pull requests. There is also an ongoing network investigation since these failures are affecting multiple US-CMS T2 sites.  Brown (Marian): Provided some  site.xml  configuration that the admin needs to apply  Caltech (Carl): Some HDFS yum warnings upon upgrade that appear to be due to the local site configuration",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#osg-release-team",
            "text": "3.4.36  \u0394  Both  \u0394  3.5.2  \u0394  Total  \u0394  Status      1  +1  0  +0  0  +0  1  +1  Open    0  +0  3  -2  0  +0  3  -2  In Progress    3  +1  7  +2  9  +1  19  +4  Ready for Testing    0  +0  0  +0  0  +0  0  +0  Ready for Release    4  +2  10  +0  9  +1  23  +3  Total      Software    Ready for Testing    3.4.36    HTCondor 8.8.5  lcmaps 1.6.6-1.9  osg-configure 2.5.0    Both    CVMFS 2.6.3  Frontier Squid 4.8-2.1  hosted-ce-tools 0.4  cctools 7.0.18  GlideinWMS 3.6    3.5.2  osg-ce 3.5-2  HTCondor CE 4.0.1  HTCondor 8.8.5  osg-configure 3.1.0      Ready for Release    Nothing      Data    LHCb VO    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#osg-investigations",
            "text": "Simple validation of xrootd-monitoring-collector passed.  Working now with Bockjoo on production validation.  Step 1 is making a public test collector    Working with Brian (and Frank?) on GRACC changes.  Update of GRACC ES, which may require some development changes.",
            "title": "OSG Investigations"
        },
        {
            "location": "/meetings/2019/TechArea20191007/#discussion_2",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190930/",
            "text": "OSG Technology Area Meeting, 30 September 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Diego, Edgar, Marco Mambelli, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: BrianL\n\n\nNext week: Carl\n\n\n18 (+3) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n162\n\n\n-2\n\n\nOpen\n\n\n\n\n\n\n30\n\n\n+1\n\n\nIn Progress\n\n\n\n\n\n\n16\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nXRootD 4.10.1 was released this morning\n\n\nRelatively few deadlines this month so we'll use our time to pay down some technical debt  \n\n\nComplete sustainable hosted CE project\n\n\nSpin up the new OSG submit host for VMU tests\n\n\n\n\n\n\nNext doc focus Oct 10\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nNew \"unified\" blahp in the upstream HTCondor punted to 8.9.5 due to build difficulties\n\n\nAI (BrianL): Run VMU tests for GlideinWMS 3.6\n\n\nAI (BrianL): Archive the OSG BLAH repository with pointers to the unified htcondor/BLAH fork\n\n\nAI (Carl): Add htcondor/BLAH to the GitHub backup script\n\n\nAI (TimT): Disable AFS/GitHub sync for htcondor/BLAH\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBrown (Marian): Provided some \nsite.xml\n configuration that the admin needs to apply\n\n\nCaltech (Carl): Some HDFS yum warnings upon upgrade that appear to be due to the local site configuration\n\n\nFNAL (Mat): Gave Steve Timm a patch that hardcodes VOMS server to accept TLS > v1. We don't think we can apply this patch across the board.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.36\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.2\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-26\n\n\n0\n\n\n-2\n\n\n0\n\n\n-28\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-1\n\n\n5\n\n\n-1\n\n\n0\n\n\n+0\n\n\n5\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n+0\n\n\n5\n\n\n+0\n\n\n8\n\n\n+0\n\n\n15\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n3\n\n\n+3\n\n\n37\n\n\n+37\n\n\n10\n\n\n+10\n\n\n20\n\n\n-30\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing  \n\n\n3.4.36  \n\n\nHTCondor 8.8.5\n\n\n\n\n\n\nBoth  \n\n\nCVMFS 2.6.3\n\n\nFrontier Squid 4.8-2.1\n\n\nhosted-ce-tools 0.4\n\n\n\n\n\n\n3.5.1  \n\n\nosg-ce 3.5-2\n\n\nHTCondor CE 4.0.1\n\n\nHTCondor 8.8.5\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week\n\n\nOSG Investigations\n\u00b6\n\n\n\n\nIgor has made some progress on deploying XCaches in Azure, Amazon\n\n\nEdgar met with Caltech folks to discuss CMS XCache usage and deployment. They decided that they will deploy k8s pods for SoCal\n\n\n\n\nDiscussion\n\u00b6\n\n\nEdgar mentioned some issues with the submit host setup, including that it's too OSG VO specific and that there is an HTCondor bug that requires a workaround implementation for all UC host certificates",
            "title": "September, 30 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#osg-technology-area-meeting-30-september-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Diego, Edgar, Marco Mambelli, Mat, TimT",
            "title": "OSG Technology Area Meeting, 30 September 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#announcements",
            "text": "",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#triage-duty",
            "text": "This week: BrianL  Next week: Carl  18 (+3) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#jira",
            "text": "# of tickets  \u0394  State      162  -2  Open    30  +1  In Progress    16  +0  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#osg-software-team",
            "text": "XRootD 4.10.1 was released this morning  Relatively few deadlines this month so we'll use our time to pay down some technical debt    Complete sustainable hosted CE project  Spin up the new OSG submit host for VMU tests    Next doc focus Oct 10",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#discussion",
            "text": "New \"unified\" blahp in the upstream HTCondor punted to 8.9.5 due to build difficulties  AI (BrianL): Run VMU tests for GlideinWMS 3.6  AI (BrianL): Archive the OSG BLAH repository with pointers to the unified htcondor/BLAH fork  AI (Carl): Add htcondor/BLAH to the GitHub backup script  AI (TimT): Disable AFS/GitHub sync for htcondor/BLAH",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#support-update",
            "text": "Brown (Marian): Provided some  site.xml  configuration that the admin needs to apply  Caltech (Carl): Some HDFS yum warnings upon upgrade that appear to be due to the local site configuration  FNAL (Mat): Gave Steve Timm a patch that hardcodes VOMS server to accept TLS > v1. We don't think we can apply this patch across the board.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#osg-release-team",
            "text": "3.4.36  \u0394  Both  \u0394  3.5.2  \u0394  Total  \u0394  Status      0  +0  0  -26  0  -2  0  -28  Open    0  -1  5  -1  0  +0  5  -2  In Progress    2  +0  5  +0  8  +0  15  +0  Ready for Testing    0  +0  0  +0  0  +0  0  +0  Ready for Release    3  +3  37  +37  10  +10  20  -30  Total      Software    Ready for Testing    3.4.36    HTCondor 8.8.5    Both    CVMFS 2.6.3  Frontier Squid 4.8-2.1  hosted-ce-tools 0.4    3.5.1    osg-ce 3.5-2  HTCondor CE 4.0.1  HTCondor 8.8.5      Ready for Release    Nothing      Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#osg-investigations",
            "text": "Igor has made some progress on deploying XCaches in Azure, Amazon  Edgar met with Caltech folks to discuss CMS XCache usage and deployment. They decided that they will deploy k8s pods for SoCal",
            "title": "OSG Investigations"
        },
        {
            "location": "/meetings/2019/TechArea20190930/#discussion_2",
            "text": "Edgar mentioned some issues with the submit host setup, including that it's too OSG VO specific and that there is an HTCondor bug that requires a workaround implementation for all UC host certificates",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190923/",
            "text": "OSG Technology Area Meeting, 23 September 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n Mat, Carl, Derek, Edgar, Marian, Marco Mambelli, TimT\n\n\n\nAnnouncements\n\u00b6\n\n\n\n\nCC* Workshop Sep 23-25. Tasks for/from this workshop are very high priority!\n\n\nBrianL OOO today, at HTCondor Week Europe Sep 24-27\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: BrianL\n\n\n15 (+1) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n164\n\n\n+9\n\n\nOpen\n\n\n\n\n\n\n29\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n16\n\n\n+4\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.4.36/3.5.2\n\n\nAI (Diego): Apply bosco override patch to HTCondor 8.8.5 in OSG 3.4 (SOFTWARE-3816)\n\n\nAI (Diego): Release stashcache-client (SOFTWARE-3799)\n\n\n\n\n\n\nAI (Carl): Replace HTCondor blahp external with the \"OSG version\" in the HTCondor 8.9 series\n\n\nAI (Carl): Issues with Gratia 1.2.10 need to be fixed (SOFTWARE-3737)\n\n\nAI (Edgar): Test the latest Stash Cache image (SOFTWARE-3810)\n\n\n\n\nDiscussion\n\u00b6\n\n\nSupport Update\n\u00b6\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.35\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.1\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-2\n\n\n0\n\n\n-1\n\n\n0\n\n\n-3\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-1\n\n\n0\n\n\n-5\n\n\n0\n\n\n-1\n\n\n0\n\n\n-7\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-2\n\n\n0\n\n\n-2\n\n\n0\n\n\n-6\n\n\n0\n\n\n-10\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+1\n\n\n1\n\n\n+1\n\n\n0\n\n\n+0\n\n\n3\n\n\n+2\n\n\nReady for Release\n\n\n\n\n\n\n2\n\n\n-2\n\n\n1\n\n\n-8\n\n\n0\n\n\n-8\n\n\n3\n\n\n-18\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nReleased - High Priority\n\n\nMyProxy, GSI-OpenSSH, Globus GridFTP Server: rebuild without globus-usage\n\n\nSingularity 3.4.0\n\n\nGlideinWMS 3.4.6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.36\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.2\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n26\n\n\n+26\n\n\n2\n\n\n+2\n\n\n28\n\n\n+28\n\n\nOpen\n\n\n\n\n\n\n1\n\n\n+1\n\n\n6\n\n\n+6\n\n\n0\n\n\n+0\n\n\n7\n\n\n+7\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n+2\n\n\n5\n\n\n+5\n\n\n8\n\n\n+8\n\n\n15\n\n\n+15\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n3\n\n\n+3\n\n\n37\n\n\n+37\n\n\n10\n\n\n+10\n\n\n50\n\n\n+50\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware\n\n\nReady for Testing\n\n\n3.4.36\n\n\nHTCondor 8.8.5\n\n\n\n\n\n\nBoth\n\n\nCVMFS 2.6.3\n\n\nFrontier Squid 4.8-2.1\n\n\nhosted-ce-tools 0.4\n\n\n\n\n\n\n3.5.1\n\n\nosg-ce 3.5-2\n\n\nHTCondor CE 4.0.1\n\n\nHTCondor 8.8.5\n\n\n\n\n\n\n\n\n\n\nReady for Release\n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData\n\n\nNothing\n\n\n\n\n\n\nOperations\n\n\nNothing\n\n\n\n\n\n\nContrib\n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nCMS requested some changes to xrootd monitoring.  Changes are made and deployed... But need debugging.\n\n\nWill begin validation of the xrootd monitoring collector.\n\n\nHTCondor-CE gratia probe deployed for several weeks at Nebraska successfully.  Will coordinate with external site to use it (probably Florida).\n\n\nSAND display for CC* workshop: \nhttps://display.sand-ci.org/\n\n\nGRACC development is upcoming for NSF Field of Science improvements.\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nGRACC Taskforce\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "September, 23 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#osg-technology-area-meeting-23-september-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  Mat, Carl, Derek, Edgar, Marian, Marco Mambelli, TimT",
            "title": "OSG Technology Area Meeting, 23 September 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#announcements",
            "text": "CC* Workshop Sep 23-25. Tasks for/from this workshop are very high priority!  BrianL OOO today, at HTCondor Week Europe Sep 24-27",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#triage-duty",
            "text": "This week: Mat  Next week: BrianL  15 (+1) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#jira",
            "text": "# of tickets  \u0394  State      164  +9  Open    29  -1  In Progress    16  +4  Ready for Testing    0  -1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#osg-software-team",
            "text": "OSG 3.4.36/3.5.2  AI (Diego): Apply bosco override patch to HTCondor 8.8.5 in OSG 3.4 (SOFTWARE-3816)  AI (Diego): Release stashcache-client (SOFTWARE-3799)    AI (Carl): Replace HTCondor blahp external with the \"OSG version\" in the HTCondor 8.9 series  AI (Carl): Issues with Gratia 1.2.10 need to be fixed (SOFTWARE-3737)  AI (Edgar): Test the latest Stash Cache image (SOFTWARE-3810)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#discussion",
            "text": "",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#support-update",
            "text": "",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#osg-release-team",
            "text": "3.4.35  \u0394  Both  \u0394  3.5.1  \u0394  Total  \u0394  Status      0  +0  0  -2  0  -1  0  -3  Open    0  -1  0  -5  0  -1  0  -7  In Progress    0  -2  0  -2  0  -6  0  -10  Ready for Testing    2  +1  1  +1  0  +0  3  +2  Ready for Release    2  -2  1  -8  0  -8  3  -18  Total      Released - High Priority  MyProxy, GSI-OpenSSH, Globus GridFTP Server: rebuild without globus-usage  Singularity 3.4.0  GlideinWMS 3.4.6        3.4.36  \u0394  Both  \u0394  3.5.2  \u0394  Total  \u0394  Status      0  +0  26  +26  2  +2  28  +28  Open    1  +1  6  +6  0  +0  7  +7  In Progress    2  +2  5  +5  8  +8  15  +15  Ready for Testing    0  +0  0  +0  0  +0  0  +0  Ready for Release    3  +3  37  +37  10  +10  50  +50  Total      Software  Ready for Testing  3.4.36  HTCondor 8.8.5    Both  CVMFS 2.6.3  Frontier Squid 4.8-2.1  hosted-ce-tools 0.4    3.5.1  osg-ce 3.5-2  HTCondor CE 4.0.1  HTCondor 8.8.5      Ready for Release  Nothing      Data  Nothing    Operations  Nothing    Contrib  Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#osg-investigations-team",
            "text": "CMS requested some changes to xrootd monitoring.  Changes are made and deployed... But need debugging.  Will begin validation of the xrootd monitoring collector.  HTCondor-CE gratia probe deployed for several weeks at Nebraska successfully.  Will coordinate with external site to use it (probably Florida).  SAND display for CC* workshop:  https://display.sand-ci.org/  GRACC development is upcoming for NSF Field of Science improvements.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  GRACC Taskforce",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190923/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190916/",
            "text": "OSG Technology Area Meeting, 16 September 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Diego, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nCC* Workshop Sep 23-25. Tasks for/from this workshop are very high priority!\n\n\nBrianL OOO Sep 17-23, HTCondor Week Europe Sep 24-27\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Edgar\n\n\nNext week: Mat\n\n\n14 (+0) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n155\n\n\n-3\n\n\nOpen\n\n\n\n\n\n\n30\n\n\n+2\n\n\nIn Progress\n\n\n\n\n\n\n12\n\n\n+6\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nPlease review the next triage rotation starting Sep 30\n\n\nOSG 3.4.35/3.5.1  \n\n\nAI (Diego): Apply bosco override patch to HTCondor 8.8.5 in OSG 3.4 (SOFTWARE-3816)\n\n\nAI (Diego): Release stashcache-client (SOFTWARE-3799)\n\n\nAI (Mat): Add support for bosco\ncluster\n override in osg-configure v2 (SOFTWARE-3818)\n\n\n\n\n\n\nAI (Mat): Coordinate with Marco, Jeff, and Judith for the Hosted CE git repo and config management\n\n\nAI (Carl): Replace HTCondor blahp external with the \"OSG version\" in the HTCondor 8.9 series\n\n\nAI (Carl): Issues with Gratia 1.2.10 need to be fixed (SOFTWARE-3737)\n\n\nAI (Edgar): Test the latest Stash Cache image (SOFTWARE-3810)\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nMarco intends to release GlideinWMS 3.5.1 today so that we can test it in OSG 3.4 and 3.5\n\n\nWe discussed the short-term plan if we find an issue with the latest Bosco tarballs:\n\n\nIf it's an issue with the compiled code, the tarball needs to be rebuilt\n\n\nIf it's an issue with the scripts, Operations will maintain patches\n\n\n\n\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBrown (Marian): They're still working on setting their \nstorage.xml\n properly to join CMS AAA\n\n\nCNAF (Edgar): Troubleshooting authorization failures for authenticated Stash Cache\n\n\nCyVerse (Carl): Running into issues with 32-bit depsolving on upgrade\n\n\nHarvard Medical School (Mat): They can actually get user accounts from Harvard so they don't need to use the OpenID-issued certs\n\n\nLHCb (Derek, Carl): LHCb pilot records show up as \nother_egee\n but the raw record doesn't contain this anywhere\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.35\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.1\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n2\n\n\n-20\n\n\n1\n\n\n-2\n\n\n3\n\n\n-22\n\n\nOpen\n\n\n\n\n\n\n1\n\n\n+1\n\n\n5\n\n\n+1\n\n\n1\n\n\n-2\n\n\n7\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n-1\n\n\n2\n\n\n+2\n\n\n6\n\n\n+6\n\n\n10\n\n\n+7\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+1\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n1\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n4\n\n\n+1\n\n\n9\n\n\n-17\n\n\n8\n\n\n+2\n\n\n21\n\n\n-14\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware  \n\n\nReady for Testing  \n\n\n3.4.35\n\n\nGlideinWMS 3.4.6\n\n\nHTCondor 8.8.4\n\n\n\n\n\n\nBoth  \n\n\nCVMFS 2.6.3\n\n\n\n\n\n\n3.5.1  \n\n\nosg-ce 3.5-2\n\n\nHTCondor CE 4.0.0\n\n\nHTCondor 8.8.5\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\n3.4.35\n\n\nSingularity 3.3.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nCMS requested some changes to xrootd monitoring.  Changes are made and deployed... But need debugging.\n\n\nIRIS-HEP meeting went well.\n\n\nWill begin validation of the xrootd monitoring collector.\n\n\nHTCondor-CE gratia probe deployed for several weeks at Nebraska successfully.  Will coordinate with external site to use it (probably Florida).\n\n\nWorked with operations to shorten stashcache negative cache duration.\n\n\nSAND display for CC* workshop: \nhttps://display.sand-ci.org/\n\n\nGRACC development is upcoming for NSF Field of Science improvements.\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nGRACC Taskforce\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "September, 16 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#osg-technology-area-meeting-16-september-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Diego, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 16 September 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#announcements",
            "text": "CC* Workshop Sep 23-25. Tasks for/from this workshop are very high priority!  BrianL OOO Sep 17-23, HTCondor Week Europe Sep 24-27",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#triage-duty",
            "text": "This week: Edgar  Next week: Mat  14 (+0) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#jira",
            "text": "# of tickets  \u0394  State      155  -3  Open    30  +2  In Progress    12  +6  Ready for Testing    1  +1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#osg-software-team",
            "text": "Please review the next triage rotation starting Sep 30  OSG 3.4.35/3.5.1    AI (Diego): Apply bosco override patch to HTCondor 8.8.5 in OSG 3.4 (SOFTWARE-3816)  AI (Diego): Release stashcache-client (SOFTWARE-3799)  AI (Mat): Add support for bosco cluster  override in osg-configure v2 (SOFTWARE-3818)    AI (Mat): Coordinate with Marco, Jeff, and Judith for the Hosted CE git repo and config management  AI (Carl): Replace HTCondor blahp external with the \"OSG version\" in the HTCondor 8.9 series  AI (Carl): Issues with Gratia 1.2.10 need to be fixed (SOFTWARE-3737)  AI (Edgar): Test the latest Stash Cache image (SOFTWARE-3810)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#discussion",
            "text": "Marco intends to release GlideinWMS 3.5.1 today so that we can test it in OSG 3.4 and 3.5  We discussed the short-term plan if we find an issue with the latest Bosco tarballs:  If it's an issue with the compiled code, the tarball needs to be rebuilt  If it's an issue with the scripts, Operations will maintain patches",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#support-update",
            "text": "Brown (Marian): They're still working on setting their  storage.xml  properly to join CMS AAA  CNAF (Edgar): Troubleshooting authorization failures for authenticated Stash Cache  CyVerse (Carl): Running into issues with 32-bit depsolving on upgrade  Harvard Medical School (Mat): They can actually get user accounts from Harvard so they don't need to use the OpenID-issued certs  LHCb (Derek, Carl): LHCb pilot records show up as  other_egee  but the raw record doesn't contain this anywhere",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#osg-release-team",
            "text": "3.4.35  \u0394  Both  \u0394  3.5.1  \u0394  Total  \u0394  Status      0  +0  2  -20  1  -2  3  -22  Open    1  +1  5  +1  1  -2  7  +0  In Progress    2  -1  2  +2  6  +6  10  +7  Ready for Testing    1  +1  0  +0  0  +0  1  +1  Ready for Release    4  +1  9  -17  8  +2  21  -14  Total      Software    Ready for Testing    3.4.35  GlideinWMS 3.4.6  HTCondor 8.8.4    Both    CVMFS 2.6.3    3.5.1    osg-ce 3.5-2  HTCondor CE 4.0.0  HTCondor 8.8.5      Ready for Release    3.4.35  Singularity 3.3.0        Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#osg-investigations-team",
            "text": "CMS requested some changes to xrootd monitoring.  Changes are made and deployed... But need debugging.  IRIS-HEP meeting went well.  Will begin validation of the xrootd monitoring collector.  HTCondor-CE gratia probe deployed for several weeks at Nebraska successfully.  Will coordinate with external site to use it (probably Florida).  Worked with operations to shorten stashcache negative cache duration.  SAND display for CC* workshop:  https://display.sand-ci.org/  GRACC development is upcoming for NSF Field of Science improvements.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  GRACC Taskforce",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190916/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190909/",
            "text": "OSG Technology Area Meeting,  9 September 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Diego, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nGDB meeting this Wednesday at FNAL\n\n\nIRIS-HEP planning meeting this Thurs/Fri at FNAL\n\n\nCC* Workshop Sep 23-25. Tasks for/from this workshop are very high priority!\n\n\nBrianL OOO Sep 17-23, HTCondor Week Europe Sep 24-27\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: TimT\n\n\nNext week: Edgar\n\n\n14 (+6) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n158\n\n\n+5\n\n\nOpen\n\n\n\n\n\n\n28\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n6\n\n\n+3\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5.1  \n\n\nAI (BrianL): HTCondor-CE 4.0.0! Featuring SciTokens support, disabling job retries, config reorganization.\n\n\nAI (Diego): Release HTCondor 8.8.5 that pulls down the newest Bosco tarballs\n\n\n\n\n\n\nAI (Mat): Coordinate with Marco, Jeff, and Judith for the Hosted CE git repo and config management\n\n\nAI (Carl): Replace HTCondor blahp external with the \"OSG version\" in the HTCondor 8.9 series\n\n\nAI (Carl): Issues with Gratia 1.2.10 need to be fixed\n\n\nAI (Edgar): Test the latest Stash Cache image\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nSupport Update\n\u00b6\n\n\n\n\nHarvard Medical School (Mat): Need OASIS access but can only get OpenID-issued user certificates.\n    It was suggested that Mat contact the Security Team and Dave Dykstra about allowing OpenID certs on OASIS.\n\n\nMWT2 (Brian): Pilot jobs removed en masse due to an issue with their HTCondor pool and ATLAS policy to not restart pilot jobs\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.35\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.1\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n22\n\n\n+22\n\n\n3\n\n\n+3\n\n\n25\n\n\n+25\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n4\n\n\n+4\n\n\n3\n\n\n+3\n\n\n7\n\n\n+7\n\n\nIn Progress\n\n\n\n\n\n\n3\n\n\n+3\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n3\n\n\n+3\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n3\n\n\n+3\n\n\n26\n\n\n+26\n\n\n6\n\n\n+6\n\n\n35\n\n\n+35\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nSoftware\n\n\nReady for Testing  \n\n\n3.4.35\n\n\nGlideinWMS 3.4.6\n\n\nHTCondor 8.8.4\n\n\nSingularity 3.3.0\n\n\n\n\n\n\nBoth\n\n\nNothing\n\n\n\n\n\n\n3.5.2\n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nReady for Testing\n\n\nrepo-update-cadist: Don't verify MD5 checksum (SHA256 Only)\n\n\n\n\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.34\n\n\n\u0394\n\n\nBoth\n\n\n\u0394\n\n\n3.5.0\n\n\n\u0394\n\n\nTotal\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-15\n\n\n0\n\n\n+0\n\n\n0\n\n\n-15\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n+0\n\n\n0\n\n\n-11\n\n\n0\n\n\n+0\n\n\n0\n\n\n-11\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-1\n\n\n0\n\n\n-9\n\n\n0\n\n\n+0\n\n\n0\n\n\n-10\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+1\n\n\n20\n\n\n+19\n\n\n20\n\n\n+20\n\n\n41\n\n\n+40\n\n\nReady for Release\n\n\n\n\n\n\n1\n\n\n+0\n\n\n20\n\n\n-16\n\n\n20\n\n\n+20\n\n\n41\n\n\n+4\n\n\nTotal\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nWe discussed the timeline of releasing packages based on the community testing policy and agreed that if we get HTCondor-CE into testing this week, we should be able to release it next week\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nCMS requested some changes to xrootd monitoring.  Spurred many other changes which are just finishing up.\n\n\nThe entire Investigations Team will be attending the IRIS-HEP meeting\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nGRACC Taskforce\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "September, 9 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#osg-technology-area-meeting-9-september-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Diego, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting,  9 September 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#announcements",
            "text": "GDB meeting this Wednesday at FNAL  IRIS-HEP planning meeting this Thurs/Fri at FNAL  CC* Workshop Sep 23-25. Tasks for/from this workshop are very high priority!  BrianL OOO Sep 17-23, HTCondor Week Europe Sep 24-27",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#triage-duty",
            "text": "This week: TimT  Next week: Edgar  14 (+6) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#jira",
            "text": "# of tickets  \u0394  State      158  +5  Open    28  -1  In Progress    6  +3  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#osg-software-team",
            "text": "OSG 3.5.1    AI (BrianL): HTCondor-CE 4.0.0! Featuring SciTokens support, disabling job retries, config reorganization.  AI (Diego): Release HTCondor 8.8.5 that pulls down the newest Bosco tarballs    AI (Mat): Coordinate with Marco, Jeff, and Judith for the Hosted CE git repo and config management  AI (Carl): Replace HTCondor blahp external with the \"OSG version\" in the HTCondor 8.9 series  AI (Carl): Issues with Gratia 1.2.10 need to be fixed  AI (Edgar): Test the latest Stash Cache image",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#discussion",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#support-update",
            "text": "Harvard Medical School (Mat): Need OASIS access but can only get OpenID-issued user certificates.\n    It was suggested that Mat contact the Security Team and Dave Dykstra about allowing OpenID certs on OASIS.  MWT2 (Brian): Pilot jobs removed en masse due to an issue with their HTCondor pool and ATLAS policy to not restart pilot jobs",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#osg-release-team",
            "text": "3.4.35  \u0394  Both  \u0394  3.5.1  \u0394  Total  \u0394  Status      0  +0  22  +22  3  +3  25  +25  Open    0  +0  4  +4  3  +3  7  +7  In Progress    3  +3  0  +0  0  +0  3  +3  Ready for Testing    0  +0  0  +0  0  +0  0  +0  Ready for Release    3  +3  26  +26  6  +6  35  +35  Total      Software  Ready for Testing    3.4.35  GlideinWMS 3.4.6  HTCondor 8.8.4  Singularity 3.3.0    Both  Nothing    3.5.2  Nothing      Ready for Release    Nothing      Data    Nothing    Operations    Ready for Testing  repo-update-cadist: Don't verify MD5 checksum (SHA256 Only)      Contrib    Nothing        3.4.34  \u0394  Both  \u0394  3.5.0  \u0394  Total  \u0394  Status      0  +0  0  -15  0  +0  0  -15  Open    0  +0  0  -11  0  +0  0  -11  In Progress    0  -1  0  -9  0  +0  0  -10  Ready for Testing    1  +1  20  +19  20  +20  41  +40  Ready for Release    1  +0  20  -16  20  +20  41  +4  Total",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#discussion_1",
            "text": "We discussed the timeline of releasing packages based on the community testing policy and agreed that if we get HTCondor-CE into testing this week, we should be able to release it next week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#osg-investigations-team",
            "text": "CMS requested some changes to xrootd monitoring.  Spurred many other changes which are just finishing up.  The entire Investigations Team will be attending the IRIS-HEP meeting",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  GRACC Taskforce",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190909/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190826/",
            "text": "OSG Technology Area Meeting, 26 August 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Derek, Diego, Mat\n\n\nAnnouncements\n\u00b6\n\n\n\n\nNext week's meeting (9/2) canceled for Labor Day\n\n\nIRIS-HEP retreat September 12, 13: block your calendars\n\n\nCarl OOO, returning 8/29\n\n\nEdgar OOO, returning 9/3\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: BrianL\n\n\nNext week: Carl\n\n\n8 (+3) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n153\n\n\n-6\n\n\nOpen\n\n\n\n\n\n\n42\n\n\n-3\n\n\nIn Progress\n\n\n\n\n\n\n20\n\n\n+7\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.4.34  \n\n\nDiego found issues with buiding stashcache-client\n\n\nAI (BrianL): Release XCache 1.1, build, and test\n\n\n\n\n\n\nOSG 3.5  \n\n\nPackage list: \nhttps://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit#gid=566881086\n\n\nPerform packaging work in the \nosg-3.5\n and \ndevops\n SVN branches\n\n\n3.5.0 will ship without HTCondor-CE or GlideinWMS: new major versions will be targeted for OSG 3.5.1+\n\n\nAI (Mat): Build HTCondor 8.8 with default \nDAEMON_LIST\n and pool password (SOFTWARE-3795);\n\n\nAI (Diego): Test osg-configure 3.0.0\n\n\nAI (BrianL): Investigate OSG 3.5 test failures (Slurm configuration)\n\n\nAI (BrianL): Document manual 3.5 upgrade instructions (SOFTWARE-3799)\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nDiego will update the stashcache-client spec to use upstream's setup.py\n\n\nSupport Update\n\u00b6\n\n\n\n\nINFN (Mat): Assisting with StashCache installation issues (mismatched FQAN, missing dependencies)\n\n\nMilwaukee (Derek): Moving LIGO containers to the OSG CVMFS repo\n\n\nOklahoma (BrianL): Issues with logrotate and XRootD on hosts that share the same configuration/OS\n\n\nSyracuse (Mat, Edgar): larger GLOW test jobs succeeded but users from the OSG VO ran into similar problems\n\n\nGGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; still need to create the ticket for load-balanced GridFTP + Let's Encrypt document\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nCMS requested some changes to xrootd monitoring.  Spurred many other changes which are just finishing up.\n\n\nWorking with operations on new, better monitoring of CVMFS exporters.  LIGO failed undetected for a while.  Now fixed, but need better alerting on what ended up being a \"WARNING\" that should have been a failure.\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nGRACC Taskforce\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "August, 26 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#osg-technology-area-meeting-26-august-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Derek, Diego, Mat",
            "title": "OSG Technology Area Meeting, 26 August 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#announcements",
            "text": "Next week's meeting (9/2) canceled for Labor Day  IRIS-HEP retreat September 12, 13: block your calendars  Carl OOO, returning 8/29  Edgar OOO, returning 9/3",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#triage-duty",
            "text": "This week: BrianL  Next week: Carl  8 (+3) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#jira",
            "text": "# of tickets  \u0394  State      153  -6  Open    42  -3  In Progress    20  +7  Ready for Testing    2  +1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#osg-software-team",
            "text": "OSG 3.4.34    Diego found issues with buiding stashcache-client  AI (BrianL): Release XCache 1.1, build, and test    OSG 3.5    Package list:  https://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit#gid=566881086  Perform packaging work in the  osg-3.5  and  devops  SVN branches  3.5.0 will ship without HTCondor-CE or GlideinWMS: new major versions will be targeted for OSG 3.5.1+  AI (Mat): Build HTCondor 8.8 with default  DAEMON_LIST  and pool password (SOFTWARE-3795);  AI (Diego): Test osg-configure 3.0.0  AI (BrianL): Investigate OSG 3.5 test failures (Slurm configuration)  AI (BrianL): Document manual 3.5 upgrade instructions (SOFTWARE-3799)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#discussion",
            "text": "Diego will update the stashcache-client spec to use upstream's setup.py",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#support-update",
            "text": "INFN (Mat): Assisting with StashCache installation issues (mismatched FQAN, missing dependencies)  Milwaukee (Derek): Moving LIGO containers to the OSG CVMFS repo  Oklahoma (BrianL): Issues with logrotate and XRootD on hosts that share the same configuration/OS  Syracuse (Mat, Edgar): larger GLOW test jobs succeeded but users from the OSG VO ran into similar problems  GGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; still need to create the ticket for load-balanced GridFTP + Let's Encrypt document",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#osg-investigations-team",
            "text": "CMS requested some changes to xrootd monitoring.  Spurred many other changes which are just finishing up.  Working with operations on new, better monitoring of CVMFS exporters.  LIGO failed undetected for a while.  Now fixed, but need better alerting on what ended up being a \"WARNING\" that should have been a failure.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  GRACC Taskforce",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190826/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190819/",
            "text": "OSG Technology Area Meeting, 19 August 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Diego, Marco Mambelli, Marian, Matyas\n\n\nAnnouncements\n\u00b6\n\n\n\n\nHTCondor Fun day this Friday\n\n\nIRIS-HEP retreat September 12, 13: block your calendars\n\n\nTimT OOO, returning 8/26\n\n\nCarl OOO, returning 8/29\n\n\nEdgar OOO, returning 9/2\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: TimT\n\n\n5 (-2) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n159\n\n\n+3\n\n\nOpen\n\n\n\n\n\n\n45\n\n\n+2\n\n\nIn Progress\n\n\n\n\n\n\n13\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.4.34  \n\n\nAI (Brian): Stash Origin changes; osg-xrootd support\n\n\nAI (Mat): Ping Marco to test osg-configure changes\n\n\n\n\n\n\nOSG 3.5  \n\n\nPackage list: \nhttps://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit#gid=566881086\n\n\nPerform packaging work in the \nosg-3.5\n and \ndevops\n SVN branches\n\n\nAI (Mat): Remove GUMS and gLexec references from LCMAPS (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3776\n)\n\n\nAI (BrianL): Investigate OSG 3.5 test failures (slurm config, condor 8.6 -> 8.8 upgrades, GridFTP + HDFS failures)\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nWe decided to punt on the new GPG keys (SOFTWARE-3275) for OSG 3.4.34/3.5.0\n\n\nHTCondor yum upgrade failures are due to dropping CREAM support in OSG 3.5 and we hope to find packaging solution\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBrown (Marian): working on XRootD issue (AAA CMS problems); still in progress\n\n\nSyracuse (Mat, Edgar): initial test jobs succeeded, submitting larger test jobs for further validation\n\n\nPurdue (Edgar): CMS XCache mostly set up (2 caches, 1 redirector) and just need to open the firewall for the last verification tests\n\n\nGGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; still need to create the ticket for load-balanced GridFTP + Let's Encrypt document\n\n\nVanderbilt (Marian): answered XRootD questions about how to track down misbehaving users\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\nNo updates this week\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6",
            "title": "August, 19 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#osg-technology-area-meeting-19-august-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Diego, Marco Mambelli, Marian, Matyas",
            "title": "OSG Technology Area Meeting, 19 August 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#announcements",
            "text": "HTCondor Fun day this Friday  IRIS-HEP retreat September 12, 13: block your calendars  TimT OOO, returning 8/26  Carl OOO, returning 8/29  Edgar OOO, returning 9/2",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#triage-duty",
            "text": "This week: Mat  Next week: TimT  5 (-2) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#jira",
            "text": "# of tickets  \u0394  State      159  +3  Open    45  +2  In Progress    13  +0  Ready for Testing    1  +1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#osg-software-team",
            "text": "OSG 3.4.34    AI (Brian): Stash Origin changes; osg-xrootd support  AI (Mat): Ping Marco to test osg-configure changes    OSG 3.5    Package list:  https://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit#gid=566881086  Perform packaging work in the  osg-3.5  and  devops  SVN branches  AI (Mat): Remove GUMS and gLexec references from LCMAPS ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3776 )  AI (BrianL): Investigate OSG 3.5 test failures (slurm config, condor 8.6 -> 8.8 upgrades, GridFTP + HDFS failures)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#discussion",
            "text": "We decided to punt on the new GPG keys (SOFTWARE-3275) for OSG 3.4.34/3.5.0  HTCondor yum upgrade failures are due to dropping CREAM support in OSG 3.5 and we hope to find packaging solution",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#support-update",
            "text": "Brown (Marian): working on XRootD issue (AAA CMS problems); still in progress  Syracuse (Mat, Edgar): initial test jobs succeeded, submitting larger test jobs for further validation  Purdue (Edgar): CMS XCache mostly set up (2 caches, 1 redirector) and just need to open the firewall for the last verification tests  GGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; still need to create the ticket for load-balanced GridFTP + Let's Encrypt document  Vanderbilt (Marian): answered XRootD questions about how to track down misbehaving users",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#osg-investigations-team",
            "text": "No updates this week",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190819/#discussions",
            "text": "",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190812/",
            "text": "OSG Technology Area Meeting, 12 August 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Diego, Edgar, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nIRIS-HEP retreat September 12, 13: block your calendars\n\n\nTimT OOO starting tomorrow, returning 8/26\n\n\nCarl OOO starting next week, returning 8/29\n\n\nEdgar OOO starting next week, returning 9/2\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Carl\n\n\nNext week: Mat\n\n\n7 (-3) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n156\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n43\n\n\n+4\n\n\nIn Progress\n\n\n\n\n\n\n13\n\n\n-2\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.4.34  \n\n\nAI (Brian): Stash Origin changes; osg-xrootd support; xrootd-lcmaps fixes\n\n\nAI (Carl): Support new MySQL versions in the Slurm Gratia probes; UFL kicked back to us\n\n\n\n\n\n\nOSG 3.5  \n\n\nPackage list: \nhttps://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit#gid=566881086\n\n\nPerform packaging work in the \nosg-3.5\n SVN branch\n\n\nAI (Carl): Build \"devops\" and \"contrib\" packages (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3291\n)\n\n\nAI (Mat, Diego): Remove GUMS and gLexec references from LCMAPS (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3776\n)\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (BrianL): Follow-up with BrianB about HTCondor 8.8 release plans in OSG 3.5\n\n\nAI (BrianL, Mat): Discuss osg-promote routes for goc/devops repos\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBrown (Marian): working on XRootD issue (AAA CMS problems); still in progress\n\n\nBrown (Mat, Edgar): helped with Squid/CE topology registrations\n\n\nPurdue (Edgar): CMS XCache mostly set up (2 caches, 1 redirector) and just need to open the firewall for the last verification tests\n\n\nGGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; still need to create the ticket for load-balanced GridFTP + Let's Encrypt document\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.34\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n15\n\n\n+4\n\n\nOpen\n\n\n\n\n\n\n11\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n10\n\n\n-3\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n37\n\n\n+0\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.34  \n\n\nReady for Testing  \n\n\nSingularity 3.3.0\n\n\nGlideinWMS 3.5\n\n\nmyproxy 6.2.4\n\n\nosg-configure 2.4.0\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): send community testing announcement template for review to technology-team mailing list (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3755\n)\n\n\nAI (BrianL): Update community testing policy to note that critical packages will be announced immediately and non-critical packages in weekly digests\n\n\nAI (TimT): Madison ITB nodes need to be rebuilt. itb-ce2 and itb-submit will be upgraded to CentOS 7. itb-ce1 remains at SL6.\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nInstalled the CMS XCache docker image into production at UCSD\n\n\nUpdate the OASIS hosts to use the new CVMFS configuration repo (\nhttps://github.com/cvmfs-contrib/config-repo\n)\n\n\nWorking on testing BLAHP systemcpu time.\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "August, 12 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#osg-technology-area-meeting-12-august-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Diego, Edgar, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 12 August 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#announcements",
            "text": "IRIS-HEP retreat September 12, 13: block your calendars  TimT OOO starting tomorrow, returning 8/26  Carl OOO starting next week, returning 8/29  Edgar OOO starting next week, returning 9/2",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#triage-duty",
            "text": "This week: Carl  Next week: Mat  7 (-3) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#jira",
            "text": "# of tickets  \u0394  State      156  +0  Open    43  +4  In Progress    13  -2  Ready for Testing    0  +1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#osg-software-team",
            "text": "OSG 3.4.34    AI (Brian): Stash Origin changes; osg-xrootd support; xrootd-lcmaps fixes  AI (Carl): Support new MySQL versions in the Slurm Gratia probes; UFL kicked back to us    OSG 3.5    Package list:  https://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit#gid=566881086  Perform packaging work in the  osg-3.5  SVN branch  AI (Carl): Build \"devops\" and \"contrib\" packages ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3291 )  AI (Mat, Diego): Remove GUMS and gLexec references from LCMAPS ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3776 )",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#discussion",
            "text": "AI (BrianL): Follow-up with BrianB about HTCondor 8.8 release plans in OSG 3.5  AI (BrianL, Mat): Discuss osg-promote routes for goc/devops repos",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#support-update",
            "text": "Brown (Marian): working on XRootD issue (AAA CMS problems); still in progress  Brown (Mat, Edgar): helped with Squid/CE topology registrations  Purdue (Edgar): CMS XCache mostly set up (2 caches, 1 redirector) and just need to open the firewall for the last verification tests  GGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; still need to create the ticket for load-balanced GridFTP + Let's Encrypt document",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#osg-release-team",
            "text": "3.4.34  \u0394  Status      15  +4  Open    11  -2  In Progress    10  -3  Ready for Testing    1  +1  Ready for Release    37  +0  Total      OSG 3.4.34    Ready for Testing    Singularity 3.3.0  GlideinWMS 3.5  myproxy 6.2.4  osg-configure 2.4.0    Ready for Release    Nothing      Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#discussion_1",
            "text": "AI (TimT): send community testing announcement template for review to technology-team mailing list ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3755 )  AI (BrianL): Update community testing policy to note that critical packages will be announced immediately and non-critical packages in weekly digests  AI (TimT): Madison ITB nodes need to be rebuilt. itb-ce2 and itb-submit will be upgraded to CentOS 7. itb-ce1 remains at SL6.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#osg-investigations-team",
            "text": "Installed the CMS XCache docker image into production at UCSD  Update the OASIS hosts to use the new CVMFS configuration repo ( https://github.com/cvmfs-contrib/config-repo )  Working on testing BLAHP systemcpu time.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190812/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190805/",
            "text": "OSG Technology Area Meeting,  5 August 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Diego, Derek, Edgar, Marian, Mat, Tim\n\n\nAnnouncements\n\u00b6\n\n\n\n\nBrianL OOO Wed-Fri\n\n\nTimT OOO Thu-Fri\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Edgar\n\n\nNext week: Carl\n\n\n10 (+4) open FreshDesk tickets\n\n\n2 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n156\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n39\n\n\n+1\n\n\nIn Progress\n\n\n\n\n\n\n15\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.4.34  \n\n\nAI (Brian): Stash Origin changes; osg-xrootd support\n\n\nAI (Carl): Support new MySQL versions in the Slurm Gratia probes; UFL kicked back to us\n\n\n\n\n\n\nOSG 3.5  \n\n\nPackage list: \nhttps://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit#gid=566881086\n\n\nPerform packaging work in the \nosg-3.5\n SVN branch\n\n\nAI (Carl): Prepare the \"devops\" repository (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3291\n)\n\n\nAI (Mat, Diego): Remove GUMS and gLexec references from LCMAPS (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3776\n)\n\n\nAI (Diego): build HTCondor 8.9.2 into upcoming with SciTokens support\n\n\n\n\n\n\nAI (Edgar): Add chkconfig lines to \ngwms-renew-proxies\n (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3758\n)\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (BrianL): Add Diego to VMU mailing list and start introducing him to the VMU test suite [DONE]\n\n\nAI (BrianL): Review Gratia tickets and let Carl know if he can move forward with building the RPM [DONE]\n\n\nNow that we're depending on more EPEL packaging, we should add \nepel-testing\n to the nightlies so that we can catch compatability issues early on.\n    This discussion was precipitated by the recent GlideinWMS/Singularity issues and it was noted that we should also have GlideinWMS integration testing.\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBrown (Marian): working on XRootD issue (AAA CMS problems); still in progress\n\n\nCLAS12 (Edgar): starting to support them through the GlueX VO; already registered as a project\n\n\nCNAF (Edgar, Mat): StashCache authfile generation broken due to an their hostname being different from what's registered in topology; workaround doesn't appear to work and requires more investigation\n\n\nGGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; still need to create the load-balanced GridFTP + Let's Encrypt document\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.34\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n11\n\n\n+11\n\n\nOpen\n\n\n\n\n\n\n13\n\n\n+13\n\n\nIn Progress\n\n\n\n\n\n\n13\n\n\n+13\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n37\n\n\n+37\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.34\n\n\nReady for Testing  \n\n\nSingularity 3.3.0\n\n\nGlideinWMS 3.5\n\n\nmyproxy 6.2.4\n\n\nosg-configure 2.4.0\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.33\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-13\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-10\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-15\n\n\nReady for Testing\n\n\n\n\n\n\n5\n\n\n+5\n\n\nReady for Release\n\n\n\n\n\n\n5\n\n\n-33\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.33\n\n\nFrontier Squid 4.8\n\n\nXRootD 4.10.0 and plugins\n\n\ncvmfs-x509-helper 2.0\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): write template for community testing announcements (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3755\n)\n\n\nAI (TimT): Madison ITB nodes need to be rebuilt. itb-ce2 and itb-submit will be upgraded to CentOS 7. itb-ce1 remains at SL6.\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\n\n\nStashCache paper presentation at PEARC. Official citation of StashCache is now:\n\n\nDerek Weitzel, Marian Zvada, Ilija Vukotic, Rob Gardner, Brian Bockelman, Mats Rynge, Edgar Fajardo Hernandez, Brian Lin, and M\u00e1ty\u00e1s Selmeci. 2019. StashCache: A Distributed Caching Federation for the Open Science Grid. In Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning) (PEARC '19). ACM, New York, NY, USA, Article 58, 7 pages. DOI: https://doi.org/10.1145/3332186.3332212\n\n\n\n\n\n\n\n\n\nPresented OSG + SciTokens work @ PEARC.\n\n\n\n\nEmergency modification of SciTokens credmon, multi-threading and signal handling is hard!  Give up and use processes!\n\n\nWorking on testing BLAHP systemcpu time.\n\n\nMoving 100G testing to starlight network.\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\n\n\nAI (Edgar): Address CMS XCache auth ticket (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3774\n) [DONE]\n\n\nAI (BrianL): Build an XCache 1.1 RPM pre-release containing ATLAS/CMS RPMs so that Edgar can build the CMS XCache container [DONE]",
            "title": "August, 5 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#osg-technology-area-meeting-5-august-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Diego, Derek, Edgar, Marian, Mat, Tim",
            "title": "OSG Technology Area Meeting,  5 August 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#announcements",
            "text": "BrianL OOO Wed-Fri  TimT OOO Thu-Fri",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#triage-duty",
            "text": "This week: Edgar  Next week: Carl  10 (+4) open FreshDesk tickets  2 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#jira",
            "text": "# of tickets  \u0394  State      156  +0  Open    39  +1  In Progress    15  +0  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#osg-software-team",
            "text": "OSG 3.4.34    AI (Brian): Stash Origin changes; osg-xrootd support  AI (Carl): Support new MySQL versions in the Slurm Gratia probes; UFL kicked back to us    OSG 3.5    Package list:  https://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit#gid=566881086  Perform packaging work in the  osg-3.5  SVN branch  AI (Carl): Prepare the \"devops\" repository ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3291 )  AI (Mat, Diego): Remove GUMS and gLexec references from LCMAPS ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3776 )  AI (Diego): build HTCondor 8.9.2 into upcoming with SciTokens support    AI (Edgar): Add chkconfig lines to  gwms-renew-proxies  ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3758 )",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#discussion",
            "text": "AI (BrianL): Add Diego to VMU mailing list and start introducing him to the VMU test suite [DONE]  AI (BrianL): Review Gratia tickets and let Carl know if he can move forward with building the RPM [DONE]  Now that we're depending on more EPEL packaging, we should add  epel-testing  to the nightlies so that we can catch compatability issues early on.\n    This discussion was precipitated by the recent GlideinWMS/Singularity issues and it was noted that we should also have GlideinWMS integration testing.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#support-update",
            "text": "Brown (Marian): working on XRootD issue (AAA CMS problems); still in progress  CLAS12 (Edgar): starting to support them through the GlueX VO; already registered as a project  CNAF (Edgar, Mat): StashCache authfile generation broken due to an their hostname being different from what's registered in topology; workaround doesn't appear to work and requires more investigation  GGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; still need to create the load-balanced GridFTP + Let's Encrypt document",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#osg-release-team",
            "text": "3.4.34  \u0394  Status      11  +11  Open    13  +13  In Progress    13  +13  Ready for Testing    0  +0  Ready for Release    37  +37  Total      OSG 3.4.34  Ready for Testing    Singularity 3.3.0  GlideinWMS 3.5  myproxy 6.2.4  osg-configure 2.4.0    Ready for Release    Nothing      Data    Nothing    Operations    Nothing    Contrib    Nothing        3.4.33  \u0394  Status      0  -13  Open    0  -10  In Progress    0  -15  Ready for Testing    5  +5  Ready for Release    5  -33  Total      OSG 3.4.33  Frontier Squid 4.8  XRootD 4.10.0 and plugins  cvmfs-x509-helper 2.0",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#discussion_1",
            "text": "AI (TimT): write template for community testing announcements ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3755 )  AI (TimT): Madison ITB nodes need to be rebuilt. itb-ce2 and itb-submit will be upgraded to CentOS 7. itb-ce1 remains at SL6.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#osg-investigations-team",
            "text": "StashCache paper presentation at PEARC. Official citation of StashCache is now:  Derek Weitzel, Marian Zvada, Ilija Vukotic, Rob Gardner, Brian Bockelman, Mats Rynge, Edgar Fajardo Hernandez, Brian Lin, and M\u00e1ty\u00e1s Selmeci. 2019. StashCache: A Distributed Caching Federation for the Open Science Grid. In Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning) (PEARC '19). ACM, New York, NY, USA, Article 58, 7 pages. DOI: https://doi.org/10.1145/3332186.3332212    Presented OSG + SciTokens work @ PEARC.   Emergency modification of SciTokens credmon, multi-threading and signal handling is hard!  Give up and use processes!  Working on testing BLAHP systemcpu time.  Moving 100G testing to starlight network.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190805/#discussions",
            "text": "AI (Edgar): Address CMS XCache auth ticket ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3774 ) [DONE]  AI (BrianL): Build an XCache 1.1 RPM pre-release containing ATLAS/CMS RPMs so that Edgar can build the CMS XCache container [DONE]",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190729/",
            "text": "OSG Technology Area Meeting, 29 July 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Diego, Edgar, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nDerek at PEARC\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: TimT\n\n\nNext week: Edgar\n\n\n6 (-4) open FreshDesk tickets\n\n\n2 (-1) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n156\n\n\n-4\n\n\nOpen\n\n\n\n\n\n\n38\n\n\n+8\n\n\nIn Progress\n\n\n\n\n\n\n15\n\n\n-5\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.4.33  \n\n\nAcross the board failures with xrootd-lcmaps-1.7.2-1 needs investigation (\nhttp://vdt.cs.wisc.edu/tests/20190726-1559/results.html\n)\n\n\nAI (Brian): Stash Origin changes; osg-xrootd support\n\n\nAI (Carl): Support new MySQL versions in the Slurm Gratia probes\n\n\n\n\n\n\nOSG 3.5  \n\n\nAI (Carl): Start preparing the OSG 3.5 repositories (\nhttps://opensciencegrid.org/technology/release/new-release-series/\n).\n\n    Take notes so that we can generalize the document moving forward.\n\n\nAI (Mat): Upstream OSG GCT patches so we can drop GCT packages from OSG 3.5\n\n\n\n\n\n\nAI (Edgar): Add chkconfig lines to \ngwms-renew-proxies\n (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3758\n)\n\n\nNew documentation explaining the Topology resource retirement process:\n\n\nhttps://opensciencegrid.org//operations/services/topology-contacts-data/#retiring-resources\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (BrianL): Add Diego to VMU mailing list and start introducing him to the VMU test suite\n\n\nAI (BrianL): Review Gratia tickets and let Carl know if he can move forward with building the RPM\n\n\nThere was some discussion about whether it's a good idea to continue removing resources from Topology. Namely if there are resources that are revived after being retired, there can be a discontinuity in records if the resource is revived under a different site and resource name. There are technical solutions (using \ngit log -S\n to search through commit history) and process solutions that we can develop to address this potential problem.\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBrown (Marian): working on XRootD issue (AAA CMS problems); still in progress\n\n\nGGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; resulting in JIRA doc tickets\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.33\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n13\n\n\n+13\n\n\nOpen\n\n\n\n\n\n\n10\n\n\n+10\n\n\nIn Progress\n\n\n\n\n\n\n15\n\n\n+15\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n1\n\n\n+1\n\n\nClosed\n\n\n\n\n\n\n39\n\n\n+39\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.32  \n\n\nReady for Testing  \n\n\nGlideinWMS 3.5\n\n\nFrontier Squid 4.8\n\n\nmyproxy 6.2.4\n\n\ngratia-probe 1.20.9\n\n\nosg-configure 2.4.0\n\n\nXRootD 4.10.0 and plugins\n\n\nscitokens-cpp\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.32\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-5\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-6\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-17\n\n\nReady for Testing\n\n\n\n\n\n\n5\n\n\n+4\n\n\nReady for Release\n\n\n\n\n\n\n5\n\n\n-24\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.32\n\n\nReady for Release\n\n\nFrontier Squid 4.4-2.1\n\n\nSingularity 3.2.1-1.1\n\n\nVO Package v94\n\n\nHTCondor 8.8.4\n\n\nglite-lbjp-common-gsoap-plugin\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nAI (TimT): write template for community testing announcements (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3755\n)\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nDerek is at PEARC presenting StashCache work\n\n\nPresented accounting task force status and last week's OSG AC meeting\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\n\n\nAI (Edgar): Address CMS XCache auth ticket (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3774\n)\n\n\nAI (BrianL): Build an XCache 1.1 RPM pre-release containing ATLAS/CMS RPMs so that Edgar can build the CMS XCache container# OSG Technology Area Meeting, 29 July 2019",
            "title": "July 29, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#osg-technology-area-meeting-29-july-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Diego, Edgar, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 29 July 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#announcements",
            "text": "Derek at PEARC",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#triage-duty",
            "text": "This week: TimT  Next week: Edgar  6 (-4) open FreshDesk tickets  2 (-1) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#jira",
            "text": "# of tickets  \u0394  State      156  -4  Open    38  +8  In Progress    15  -5  Ready for Testing    0  -1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#osg-software-team",
            "text": "OSG 3.4.33    Across the board failures with xrootd-lcmaps-1.7.2-1 needs investigation ( http://vdt.cs.wisc.edu/tests/20190726-1559/results.html )  AI (Brian): Stash Origin changes; osg-xrootd support  AI (Carl): Support new MySQL versions in the Slurm Gratia probes    OSG 3.5    AI (Carl): Start preparing the OSG 3.5 repositories ( https://opensciencegrid.org/technology/release/new-release-series/ ). \n    Take notes so that we can generalize the document moving forward.  AI (Mat): Upstream OSG GCT patches so we can drop GCT packages from OSG 3.5    AI (Edgar): Add chkconfig lines to  gwms-renew-proxies  ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3758 )  New documentation explaining the Topology resource retirement process:  https://opensciencegrid.org//operations/services/topology-contacts-data/#retiring-resources",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#discussion",
            "text": "AI (BrianL): Add Diego to VMU mailing list and start introducing him to the VMU test suite  AI (BrianL): Review Gratia tickets and let Carl know if he can move forward with building the RPM  There was some discussion about whether it's a good idea to continue removing resources from Topology. Namely if there are resources that are revived after being retired, there can be a discontinuity in records if the resource is revived under a different site and resource name. There are technical solutions (using  git log -S  to search through commit history) and process solutions that we can develop to address this potential problem.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#support-update",
            "text": "Brown (Marian): working on XRootD issue (AAA CMS problems); still in progress  GGUS ticket w/ Doug Johnson about using Let's Encrypt with LVS; resulting in JIRA doc tickets",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#osg-release-team",
            "text": "3.4.33  \u0394  Status      13  +13  Open    10  +10  In Progress    15  +15  Ready for Testing    0  +0  Ready for Release    1  +1  Closed    39  +39  Total      OSG 3.4.32    Ready for Testing    GlideinWMS 3.5  Frontier Squid 4.8  myproxy 6.2.4  gratia-probe 1.20.9  osg-configure 2.4.0  XRootD 4.10.0 and plugins  scitokens-cpp    Ready for Release    Nothing      Data    Nothing    Operations    Nothing    Contrib    Nothing        3.4.32  \u0394  Status      0  -5  Open    0  -6  In Progress    0  -17  Ready for Testing    5  +4  Ready for Release    5  -24  Total      OSG 3.4.32  Ready for Release  Frontier Squid 4.4-2.1  Singularity 3.2.1-1.1  VO Package v94  HTCondor 8.8.4  glite-lbjp-common-gsoap-plugin",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#discussion_1",
            "text": "AI (TimT): write template for community testing announcements ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3755 )",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#osg-investigations-team",
            "text": "Derek is at PEARC presenting StashCache work  Presented accounting task force status and last week's OSG AC meeting",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190729/#discussions",
            "text": "AI (Edgar): Address CMS XCache auth ticket ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3774 )  AI (BrianL): Build an XCache 1.1 RPM pre-release containing ATLAS/CMS RPMs so that Edgar can build the CMS XCache container# OSG Technology Area Meeting, 29 July 2019",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190722/",
            "text": "OSG Technology Area Meeting, 22 July 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat\n\n\nAnnouncements\n\u00b6\n\n\n\n\nGitHub currently has issues, you may run into 500 errors\n\n\nZhenzhou's (UW-Madison student) last day was last Friday\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: BrianL\n\n\nNext week: TimT\n\n\n10 (+1) open FreshDesk tickets\n\n\n3 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n160\n\n\n-1\n\n\nOpen\n\n\n\n\n\n\n30\n\n\n+4\n\n\nIn Progress\n\n\n\n\n\n\n20\n\n\n+1\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.4.32  \n\n\nAI (Brian): Complete CMS XCache; other XCache 1.1 changes; osg-xrootd\n\n\nAI (Carl): Support Slurm v19 schema change; SWT2 Slurm v18 testing?\n\n\n\n\n\n\nOSG 3.5  \n\n\nAI (Carl): Start preparing the OSG 3.5 repositories (\nhttps://opensciencegrid.org/technology/release/new-release-series/\n).\n    Take notes so that we can generalize the document moving forward.\n\n\nAI (Mat): Upstream OSG GCT patches so we can drop GCT packages from OSG 3.5\n\n\nAI (Diego): Remove group tags from spec files (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3547\n)\n\n\n\n\n\n\nAI (Mat): Waiting on Benedikt to verify access to the GLOW origin server, onboard another test user with CHTC RCFs\n\n\nAI (Edgar): Add chkconfig lines to \ngwms-renew-proxies\n (\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3758\n)\n\n\nNext doc focus this Thursday, July 25 (1:30-5:30pm CDT)\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (BrianL): Create epic for OSG 3.5\n\n\nAI (Edgar): Create GlideinWMS branch off of v3_4\n\n\nAI (BrianL): Talk to Diego about doc focus expectations\n\n\nThere were some compat issues between 3.5 factories and 3.4.2 frontends. Solved with a frontend upgrade to 3.4.5.\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBrown (Marian): working on XRootD issue (AAA CMS problems); still in progress\n\n\nGGUS ticket w/ Doug Johnson about using Let's Encrypt  \n\n\nproblems with using LVS\n\n\nneed doc improvements\n\n\n\n\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.32\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n5\n\n\n-7\n\n\nOpen\n\n\n\n\n\n\n6\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n17\n\n\n+9\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n29\n\n\n+1\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.32  \n\n\nReady for Testing  \n\n\ngratia-probe 1.20.9\n\n\ncctools 7.0.14\n\n\nmyproxy 6.2.4\n\n\nsingularity 3.2.1-1.1\n\n\nosg-configure 2.4.0\n\n\nosg-oasis 13\n\n\nscitokens-cpp\n\n\nGlideinWMS 3.5\n\n\nxrootd 4.10.0 and plugins\n\n\ncondor 8.8.4\n\n\n\n\n\n\nReady for Release  \n\n\ncvmfs-x509-helper 2.0\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nWe would like to get HTCondor 8.8 into mainline but the default auth removes \nDAEMON_LIST\n so it could break current installations of HTCondor  \n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nHTCondor-CE Gratia probe installed and running at Nebraska slurm. Records look ok.  Need to perform a \"checklist\" of attributes to make sure we are correct.  \n\n\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3748\n\n\nFound we are not collecting system time.\n\n\n\n\n\n\nCMS asked for application specific attributes to be added to the XRootD Detailed Monitoring Collector.\n\n\nGRACC accounting taskforce - Tasking!!!  See meeting on Wed.\n\n\nNetworking wants a tool to \"go back in time\".\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "July 22, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#osg-technology-area-meeting-22-july-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat",
            "title": "OSG Technology Area Meeting, 22 July 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#announcements",
            "text": "GitHub currently has issues, you may run into 500 errors  Zhenzhou's (UW-Madison student) last day was last Friday",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#triage-duty",
            "text": "This week: BrianL  Next week: TimT  10 (+1) open FreshDesk tickets  3 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#jira",
            "text": "# of tickets  \u0394  State      160  -1  Open    30  +4  In Progress    20  +1  Ready for Testing    1  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#osg-software-team",
            "text": "OSG 3.4.32    AI (Brian): Complete CMS XCache; other XCache 1.1 changes; osg-xrootd  AI (Carl): Support Slurm v19 schema change; SWT2 Slurm v18 testing?    OSG 3.5    AI (Carl): Start preparing the OSG 3.5 repositories ( https://opensciencegrid.org/technology/release/new-release-series/ ).\n    Take notes so that we can generalize the document moving forward.  AI (Mat): Upstream OSG GCT patches so we can drop GCT packages from OSG 3.5  AI (Diego): Remove group tags from spec files ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3547 )    AI (Mat): Waiting on Benedikt to verify access to the GLOW origin server, onboard another test user with CHTC RCFs  AI (Edgar): Add chkconfig lines to  gwms-renew-proxies  ( https://opensciencegrid.atlassian.net/browse/SOFTWARE-3758 )  Next doc focus this Thursday, July 25 (1:30-5:30pm CDT)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#discussion",
            "text": "AI (BrianL): Create epic for OSG 3.5  AI (Edgar): Create GlideinWMS branch off of v3_4  AI (BrianL): Talk to Diego about doc focus expectations  There were some compat issues between 3.5 factories and 3.4.2 frontends. Solved with a frontend upgrade to 3.4.5.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#support-update",
            "text": "Brown (Marian): working on XRootD issue (AAA CMS problems); still in progress  GGUS ticket w/ Doug Johnson about using Let's Encrypt    problems with using LVS  need doc improvements",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#osg-release-team",
            "text": "3.4.32  \u0394  Status      5  -7  Open    6  -2  In Progress    17  +9  Ready for Testing    1  +1  Ready for Release    29  +1  Total      OSG 3.4.32    Ready for Testing    gratia-probe 1.20.9  cctools 7.0.14  myproxy 6.2.4  singularity 3.2.1-1.1  osg-configure 2.4.0  osg-oasis 13  scitokens-cpp  GlideinWMS 3.5  xrootd 4.10.0 and plugins  condor 8.8.4    Ready for Release    cvmfs-x509-helper 2.0      Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#discussion_1",
            "text": "We would like to get HTCondor 8.8 into mainline but the default auth removes  DAEMON_LIST  so it could break current installations of HTCondor",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#osg-investigations-team",
            "text": "HTCondor-CE Gratia probe installed and running at Nebraska slurm. Records look ok.  Need to perform a \"checklist\" of attributes to make sure we are correct.    https://opensciencegrid.atlassian.net/browse/SOFTWARE-3748  Found we are not collecting system time.    CMS asked for application specific attributes to be added to the XRootD Detailed Monitoring Collector.  GRACC accounting taskforce - Tasking!!!  See meeting on Wed.  Networking wants a tool to \"go back in time\".",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190722/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190708/",
            "text": "OSG Technology Area Meeting,  8 July 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nOSG User School next week (July 15-19)\n\n\nBrianL OOO Friday afternoon\n\n\nTimT OOO July 11-15\n\n\nMat OOO July 15-17\n\n\nCanceling next week's meeting; next meeting July 22\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: Edgar\n\n\n9 (+1) open FreshDesk tickets\n\n\n3 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n155\n\n\n+1\n\n\nOpen\n\n\n\n\n\n\n28\n\n\n+1\n\n\nIn Progress\n\n\n\n\n\n\n9\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.4.32  \n\n\nAI (Mat): Build osg-configure\n\n\nAI (Brian): Complete XCache re-organization (\nhttps://github.com/opensciencegrid/xcache/pull/63\n)\n\n\nAI (Carl): Support Slurm v19 schema change; ask Bockjoo to test Slurm v18 support\n\n\n\n\n\n\nAI (Mat): Waiting on Benedikt to verify access to the GLOW origin server\n\n\nNext doc focus July 25 (1:30-5:30pm CDT)\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nMake OS version support lnaguage stronger; add warnings to XRootD/CVMFS about not supporting < 7.5\n\n\nMarco Mambelli will contact Marco Mascheroni to update the CERN GlideinWMS factory to OSG 3.5 for acceptance testing\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBrown (Marian): working on XRootD issue (AAA CMS problems); still in progress\n\n\nMIT (Carl, Edgar): XRootD LCMAPS issue solved by updating from CentOS 7.3 -> 7.5\n\n\nGGUS ticket w/ Doug Johnson about using Let's Encrypt\n\n\nproblems with using LVS\n\n\nneed doc improvements\n\n\n\n\n\n\nUCSD (Edgar): Setting up a Comet CE to also serve CMS in addition to LIGO/IceCube\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.32\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n12\n\n\n+3\n\n\nOpen\n\n\n\n\n\n\n8\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n8\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n28\n\n\n+3\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.32  \n\n\nReady for Testing  \n\n\ngratia-probe 1.20.9\n\n\ncctools 7.0.14\n\n\ncvmfs-x509-helper 2.0\n\n\nscitokens-cpp\n\n\nGlideinWMS 3.5\n\n\nxrootd 4.10\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nWe would like to get HTCondor 8.8 into mainline but the default auth removes \nDAEMON_LIST\n so it could break current\ninstallations of HTCondor\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\ncvmfs-authz-helper (cvmfs-x509-helper) - Testing continues\n\n\nHTCondor-CE Gratia probe installed and running at Nebraska slurm. Records look ok.  Need to perform a \"checklist\" of attributes to make sure we are correct.\n\n\nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3748\n\n\n\n\n\n\nCMS asked for application specific attributes to be added to the XRootD Detailed Monitoring Collector.\n\n\nGRACC accounting taskforce - Tasking!!!\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "July 8, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#osg-technology-area-meeting-8-july-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting,  8 July 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#announcements",
            "text": "OSG User School next week (July 15-19)  BrianL OOO Friday afternoon  TimT OOO July 11-15  Mat OOO July 15-17  Canceling next week's meeting; next meeting July 22",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#triage-duty",
            "text": "This week: Mat  Next week: Edgar  9 (+1) open FreshDesk tickets  3 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#jira",
            "text": "# of tickets  \u0394  State      155  +1  Open    28  +1  In Progress    9  +0  Ready for Testing    0  -1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#osg-software-team",
            "text": "OSG 3.4.32    AI (Mat): Build osg-configure  AI (Brian): Complete XCache re-organization ( https://github.com/opensciencegrid/xcache/pull/63 )  AI (Carl): Support Slurm v19 schema change; ask Bockjoo to test Slurm v18 support    AI (Mat): Waiting on Benedikt to verify access to the GLOW origin server  Next doc focus July 25 (1:30-5:30pm CDT)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#discussion",
            "text": "Make OS version support lnaguage stronger; add warnings to XRootD/CVMFS about not supporting < 7.5  Marco Mambelli will contact Marco Mascheroni to update the CERN GlideinWMS factory to OSG 3.5 for acceptance testing",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#support-update",
            "text": "Brown (Marian): working on XRootD issue (AAA CMS problems); still in progress  MIT (Carl, Edgar): XRootD LCMAPS issue solved by updating from CentOS 7.3 -> 7.5  GGUS ticket w/ Doug Johnson about using Let's Encrypt  problems with using LVS  need doc improvements    UCSD (Edgar): Setting up a Comet CE to also serve CMS in addition to LIGO/IceCube",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#osg-release-team",
            "text": "3.4.32  \u0394  Status      12  +3  Open    8  +0  In Progress    8  +0  Ready for Testing    0  +0  Ready for Release    28  +3  Total      OSG 3.4.32    Ready for Testing    gratia-probe 1.20.9  cctools 7.0.14  cvmfs-x509-helper 2.0  scitokens-cpp  GlideinWMS 3.5  xrootd 4.10    Ready for Release    Nothing      Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#discussion_1",
            "text": "We would like to get HTCondor 8.8 into mainline but the default auth removes  DAEMON_LIST  so it could break current\ninstallations of HTCondor",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#osg-investigations-team",
            "text": "cvmfs-authz-helper (cvmfs-x509-helper) - Testing continues  HTCondor-CE Gratia probe installed and running at Nebraska slurm. Records look ok.  Need to perform a \"checklist\" of attributes to make sure we are correct.  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3748    CMS asked for application specific attributes to be added to the XRootD Detailed Monitoring Collector.  GRACC accounting taskforce - Tasking!!!",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190708/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190701/",
            "text": "OSG Technology Area Meeting, 1 July 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n TimT, Mat, Carl, Marian, Diego, Edgar, Derek\n\n\nAnnouncements\n\u00b6\n\n\nBrianL on vacation; back July 5.\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: TimT\n\n\nNext week: Mat\n\n\n8 (+3) open FreshDesk tickets\n\n\n3 (+2) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n154\n\n\n0\n\n\nOpen\n\n\n\n\n\n\n27\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n9\n\n\n+1\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nHosted-CE:\n\n\nInitial script for managing WN software/data from the CE host; tested by operations, now needs some tweaks and putting it in a cron job\n\n\nAI (Mat): Make release of osg-configure\n\n\n\n\n\n\nAI (Mat): Mat verified /icecube accessible via stashcp, cvmfs;\n        waiting on Benedikt to try it out\n\n\nNext doc focus July 25 (1:30-5:30pm CDT)\n\n\n\n\nDiscussion\n\u00b6\n\n\nSupport Update\n\u00b6\n\n\n\n\nMarian working on Brown xrootd issue (AAA CMS problems); still in progress\n\n\nEdgar looking into xrootd with MIT issue (xrootd doesn't start due to 'missing' library issue.  Edgar unable to reproduce\n\n\nGGUS ticket w/ Doug Johnson about using Let's Encrypt\n\n\nproblems with using LVS\n\n\nneed doc improvements\n\n\n\n\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.32\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n9\n\n\n-2\n\n\nOpen\n\n\n\n\n\n\n8\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n8\n\n\n+2\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n25\n\n\n+0\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.32  \n\n\nReady for Testing  \n\n\ngratia-probe 1.20.9\n\n\ncctools 7.0.14\n\n\ncvmfs-x509-helper 2.0\n\n\nscitokens-cpp\n\n\nGlideinWMS 3.5\n\n\nxrootd 4.10\n\n\n\n\n\n\nReady for Release\n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nIGTF 1.101\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nDONE: Adapting LIGO style cvmfs + singularity. Deployed and working.\n\n\nBug in cleanup is causing it to fail now though...\n\n\n\n\n\n\ncvmfs-authz-helper (cvmfs-x509-helper) - Tagged and built.\n\n\nSLURM Gratia probe installed and running at Nebraska slurm.  Now need factory to submit jobs to the cluster.\n\n\nGRACC accounting taskforce - Tasking!!!\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "July 1, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#osg-technology-area-meeting-1-july-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  TimT, Mat, Carl, Marian, Diego, Edgar, Derek",
            "title": "OSG Technology Area Meeting, 1 July 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#announcements",
            "text": "BrianL on vacation; back July 5.",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#triage-duty",
            "text": "This week: TimT  Next week: Mat  8 (+3) open FreshDesk tickets  3 (+2) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#jira",
            "text": "# of tickets  \u0394  State      154  0  Open    27  -1  In Progress    9  +1  Ready for Testing    1  +1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#osg-software-team",
            "text": "Hosted-CE:  Initial script for managing WN software/data from the CE host; tested by operations, now needs some tweaks and putting it in a cron job  AI (Mat): Make release of osg-configure    AI (Mat): Mat verified /icecube accessible via stashcp, cvmfs;\n        waiting on Benedikt to try it out  Next doc focus July 25 (1:30-5:30pm CDT)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#discussion",
            "text": "",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#support-update",
            "text": "Marian working on Brown xrootd issue (AAA CMS problems); still in progress  Edgar looking into xrootd with MIT issue (xrootd doesn't start due to 'missing' library issue.  Edgar unable to reproduce  GGUS ticket w/ Doug Johnson about using Let's Encrypt  problems with using LVS  need doc improvements",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#osg-release-team",
            "text": "3.4.32  \u0394  Status      9  -2  Open    8  +0  In Progress    8  +2  Ready for Testing    0  +0  Ready for Release    25  +0  Total      OSG 3.4.32    Ready for Testing    gratia-probe 1.20.9  cctools 7.0.14  cvmfs-x509-helper 2.0  scitokens-cpp  GlideinWMS 3.5  xrootd 4.10    Ready for Release  Nothing      Data    IGTF 1.101    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#osg-investigations-team",
            "text": "DONE: Adapting LIGO style cvmfs + singularity. Deployed and working.  Bug in cleanup is causing it to fail now though...    cvmfs-authz-helper (cvmfs-x509-helper) - Tagged and built.  SLURM Gratia probe installed and running at Nebraska slurm.  Now need factory to submit jobs to the cluster.  GRACC accounting taskforce - Tasking!!!",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190701/#discussions_1",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190624/",
            "text": "OSG Technology Area Meeting, 24 June 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n Marian, TimT, Diego, Mat, Carl, Derek, Marco Mambelli\n\n\nAnnouncements\n\u00b6\n\n\nBrianL at NYU this week, and vacation the following week. Returning July 5.\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Carl\n\n\nNext week: TimT\n\n\n5 (+1) open FreshDesk tickets\n\n\n1 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n154\n\n\n-1\n\n\nOpen\n\n\n\n\n\n\n28\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n8\n\n\n+3\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nHosted-CE:\n\n\nInitial script for managing WN software/data from the CE host in the Operation team's hands\n\n\nAI (Mat): Make release of osg-configure\n\n\n\n\n\n\nBlahp unification (Carl): Changed direction: building standalone instead of external;\n    builds now, want to add a few changes (like reverting to old config file paths).\n    TimT: that works along with Condor's new strategy of not using externals and always using proper builds.\n\n\nAI (Mat): Mat verified /icecube accessible via stashcp, cvmfs;\n        waiting on Benedikt to try it out\n\n\nMadison ITB fixed (was broken due to a pool password misconfiguration)\n\n\nNext doc focus July 25 (1:30-5:30pm CDT)\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nosg-notify script updated to allow skipping DNS check; Diego tested\n\n\nglideinwms 3.5 needs to get promoted to testing\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nNeed to discuss with CalTech and CMS their desire to set up a new SC origin\n\n\nBockjoo running into issues with Slurm probe w/ Slurm v19; he made a tweak to the SQL so that it worked for him.  Maybe we can merge his change.\n  In the long run, want people to use the HTCondor-CE probe only\n\n\nWaiting for Patrick from SWT2 to test Slurm probe w/ fix for v18\n\n\nNeed to fix WI submit host to report GLOW usage\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.32\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n11\n\n\n+3\n\n\nOpen\n\n\n\n\n\n\n8\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n6\n\n\n+2\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n25\n\n\n+3\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.32  \n\n\nReady for Testing  \n\n\ngratia-probe 1.20.9\n\n\ncctools 7.0.14\n\n\ncvmfs-x509-helper 2.0\n\n\nscitokens-cpp\n\n\n\n\n\n\nReady for Release\n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nIGTF 1.101\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nAccounting audit is complete with Fred. Report sent out to Operations team, will send further along as needed.\n\n\nDONE: Adapting LIGO style cvmfs + singularity. Deployed and working.\n\n\ncvmfs-authz-helper (cvmfs-x509-helper) - Derek ran out of time to tag / build.\n\n\nXRootD Workshop went well.  Not many questions\u2026\n\n\nSAND meeting this week.  I\u2019m sure there will be action items from this.\n\n\nSLURM Gratia probe replacement has become urgent, will be done this week.\n\n\nGRACC accounting taskforce - Tasking!!!\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "June 24, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#osg-technology-area-meeting-24-june-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  Marian, TimT, Diego, Mat, Carl, Derek, Marco Mambelli",
            "title": "OSG Technology Area Meeting, 24 June 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#announcements",
            "text": "BrianL at NYU this week, and vacation the following week. Returning July 5.",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#triage-duty",
            "text": "This week: Carl  Next week: TimT  5 (+1) open FreshDesk tickets  1 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#jira",
            "text": "# of tickets  \u0394  State      154  -1  Open    28  -1  In Progress    8  +3  Ready for Testing    0  0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#osg-software-team",
            "text": "Hosted-CE:  Initial script for managing WN software/data from the CE host in the Operation team's hands  AI (Mat): Make release of osg-configure    Blahp unification (Carl): Changed direction: building standalone instead of external;\n    builds now, want to add a few changes (like reverting to old config file paths).\n    TimT: that works along with Condor's new strategy of not using externals and always using proper builds.  AI (Mat): Mat verified /icecube accessible via stashcp, cvmfs;\n        waiting on Benedikt to try it out  Madison ITB fixed (was broken due to a pool password misconfiguration)  Next doc focus July 25 (1:30-5:30pm CDT)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#discussion",
            "text": "osg-notify script updated to allow skipping DNS check; Diego tested  glideinwms 3.5 needs to get promoted to testing",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#support-update",
            "text": "Need to discuss with CalTech and CMS their desire to set up a new SC origin  Bockjoo running into issues with Slurm probe w/ Slurm v19; he made a tweak to the SQL so that it worked for him.  Maybe we can merge his change.\n  In the long run, want people to use the HTCondor-CE probe only  Waiting for Patrick from SWT2 to test Slurm probe w/ fix for v18  Need to fix WI submit host to report GLOW usage",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#osg-release-team",
            "text": "3.4.32  \u0394  Status      11  +3  Open    8  -2  In Progress    6  +2  Ready for Testing    0  +0  Ready for Release    25  +3  Total      OSG 3.4.32    Ready for Testing    gratia-probe 1.20.9  cctools 7.0.14  cvmfs-x509-helper 2.0  scitokens-cpp    Ready for Release  Nothing      Data    IGTF 1.101    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#osg-investigations-team",
            "text": "Accounting audit is complete with Fred. Report sent out to Operations team, will send further along as needed.  DONE: Adapting LIGO style cvmfs + singularity. Deployed and working.  cvmfs-authz-helper (cvmfs-x509-helper) - Derek ran out of time to tag / build.  XRootD Workshop went well.  Not many questions\u2026  SAND meeting this week.  I\u2019m sure there will be action items from this.  SLURM Gratia probe replacement has become urgent, will be done this week.  GRACC accounting taskforce - Tasking!!!",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190624/#discussions_1",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190617/",
            "text": "OSG Technology Area Meeting, 17 June 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nBrianL at UChicago Wednesday, NYU next week, and vacation the following week. Returning July 5.  \n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: BrianL\n\n\nNext week: Carl\n\n\n4 (+2) open FreshDesk tickets\n\n\n1 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n155\n\n\n-1\n\n\nOpen\n\n\n\n\n\n\n29\n\n\n+3\n\n\nIn Progress\n\n\n\n\n\n\n5\n\n\n-3\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-2\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nXCache:  \n\n\nAI (BrianL): Get ATLAS/CMS XCache RPM packaging in this week\n\n\nAI (BrianL): Add XCache integration tests to the container CI\n\n\n\n\n\n\nHosted-CE:  \n\n\nInitial script for managing WN software/data from the CE host in the Operation team's hands\n\n\nAI (Mat): execute remote host management plan\n\n\n\n\n\n\nBlahp unification: Still working through HTCondor build issues.\n\n\nAI (Derek): Review Gratia probe PRs (\nhttps://github.com/opensciencegrid/gratia-probe/pulls\n)\n\n\nAI (Mat): Waiting on Benedikt to verify access to the GLOW origin server\n\n\nAI( BrianL, TimT): Madison ITB currently broken due to a pool password misconfiguration\n\n\nNext doc focus July 25 (1:30-5:30pm CDT)\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nEdgar is also working on setting up a GlideinWMS frontend for BNL.\n    This may be a Kubernetes setup or just a regular old VM.\n\n\nDue to commas in some certificate DNs (looking at you, UCSD) this breaks the ability to run \ncondor_off\n from GlideinWMS frontends against pilot startds.\n    Marco has potential fixes involving using \ncondor_mapfile\n instead of \nGSI_DAEMON_NAME\n.\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nGLOW (BrianL): Some user jobs are being held in IIT startd's with the message \"missing http plugin\"\n\n\nLet's Encrypt (Mat): A site asked for Let's Encrypt instructions for EL6. We don't have Let's Encrypt instructions for EL6 we know how to do this, it just needs to be documented\n\n\nSWT2 (Carl): We've got a Gratia probe pull request in for a Slurm v18 fix; we're also investigating a strange dependency on the OSG user-vo-map that shouldn't be there anymore\n\n\nSyracuse (BrianL): troubleshooting why their condor pool negotiator isn't matching their whole node jobs. Working with the Flightworthy team.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.32\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n8\n\n\n+8\n\n\nOpen\n\n\n\n\n\n\n10\n\n\n+10\n\n\nIn Progress\n\n\n\n\n\n\n4\n\n\n+4\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n22\n\n\n+22\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.32  \n\n\nReady for Testing  \n\n\ncctools 7.0.14\n\n\nXRootD 4.10.0-rc1\n\n\nxrootd-scitokens 1.0.0\n\n\nscitokens-cpp\n\n\n\n\n\n\nReady for Release\n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.31\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-7\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-6\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-7\n\n\nReady for Testing\n\n\n\n\n\n\n7\n\n\n+5\n\n\nReady for Release\n\n\n\n\n\n\n7\n\n\n-15\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.31  \n\n\nPunted to 3.4.32\n\n\ncctools 7.0.13\n\n\nXRootD 4.10.0-rc1\n\n\nxrootd-scitokens 1.0.0\n\n\nscitokens-cpp\n\n\n\n\n\n\nReleased\n\n\nSingularity 3.2.1\n\n\nGlideinWMS proxy renewal (for Xenon)\n\n\nHTCondor 8.6 patch python packaging to match EPEL\n\n\nUpcoming: HTCondor 8.8.3\n\n\nVO Package v93\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email [IN PROGRESS]\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nAccounting audit is complete with Fred. Report sent out to Operations team, will send further along as needed.\n\n\nDONE: Adapting LIGO style cvmfs + singularity. Deployed and working.\n\n\ncvmfs-authz-helper (cvmfs-x509-helper) - Derek ran out of time to tag / build.\n\n\nXRootD Workshop went well.  Not many questions\u2026\n\n\nSAND meeting this week.  I\u2019m sure there will be action items from this.\n\n\nSLURM Gratia probe replacement has become urgent, will be done this week.\n\n\nGRACC accounting taskforce - Tasking!!!\n\n\n\n\nBackburner\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "June 17, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#osg-technology-area-meeting-17-june-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 17 June 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#announcements",
            "text": "BrianL at UChicago Wednesday, NYU next week, and vacation the following week. Returning July 5.",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#triage-duty",
            "text": "This week: BrianL  Next week: Carl  4 (+2) open FreshDesk tickets  1 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#jira",
            "text": "# of tickets  \u0394  State      155  -1  Open    29  +3  In Progress    5  -3  Ready for Testing    0  -2  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#osg-software-team",
            "text": "XCache:    AI (BrianL): Get ATLAS/CMS XCache RPM packaging in this week  AI (BrianL): Add XCache integration tests to the container CI    Hosted-CE:    Initial script for managing WN software/data from the CE host in the Operation team's hands  AI (Mat): execute remote host management plan    Blahp unification: Still working through HTCondor build issues.  AI (Derek): Review Gratia probe PRs ( https://github.com/opensciencegrid/gratia-probe/pulls )  AI (Mat): Waiting on Benedikt to verify access to the GLOW origin server  AI( BrianL, TimT): Madison ITB currently broken due to a pool password misconfiguration  Next doc focus July 25 (1:30-5:30pm CDT)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#discussion",
            "text": "Edgar is also working on setting up a GlideinWMS frontend for BNL.\n    This may be a Kubernetes setup or just a regular old VM.  Due to commas in some certificate DNs (looking at you, UCSD) this breaks the ability to run  condor_off  from GlideinWMS frontends against pilot startds.\n    Marco has potential fixes involving using  condor_mapfile  instead of  GSI_DAEMON_NAME .",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#support-update",
            "text": "GLOW (BrianL): Some user jobs are being held in IIT startd's with the message \"missing http plugin\"  Let's Encrypt (Mat): A site asked for Let's Encrypt instructions for EL6. We don't have Let's Encrypt instructions for EL6 we know how to do this, it just needs to be documented  SWT2 (Carl): We've got a Gratia probe pull request in for a Slurm v18 fix; we're also investigating a strange dependency on the OSG user-vo-map that shouldn't be there anymore  Syracuse (BrianL): troubleshooting why their condor pool negotiator isn't matching their whole node jobs. Working with the Flightworthy team.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#osg-release-team",
            "text": "3.4.32  \u0394  Status      8  +8  Open    10  +10  In Progress    4  +4  Ready for Testing    0  +0  Ready for Release    22  +22  Total      OSG 3.4.32    Ready for Testing    cctools 7.0.14  XRootD 4.10.0-rc1  xrootd-scitokens 1.0.0  scitokens-cpp    Ready for Release  Nothing      Data    Nothing    Operations    Nothing    Contrib    Nothing        3.4.31  \u0394  Status      0  -7  Open    0  -6  In Progress    0  -7  Ready for Testing    7  +5  Ready for Release    7  -15  Total      OSG 3.4.31    Punted to 3.4.32  cctools 7.0.13  XRootD 4.10.0-rc1  xrootd-scitokens 1.0.0  scitokens-cpp    Released  Singularity 3.2.1  GlideinWMS proxy renewal (for Xenon)  HTCondor 8.6 patch python packaging to match EPEL  Upcoming: HTCondor 8.8.3  VO Package v93",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#discussion_1",
            "text": "AI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email [IN PROGRESS]",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#osg-investigations-team",
            "text": "Accounting audit is complete with Fred. Report sent out to Operations team, will send further along as needed.  DONE: Adapting LIGO style cvmfs + singularity. Deployed and working.  cvmfs-authz-helper (cvmfs-x509-helper) - Derek ran out of time to tag / build.  XRootD Workshop went well.  Not many questions\u2026  SAND meeting this week.  I\u2019m sure there will be action items from this.  SLURM Gratia probe replacement has become urgent, will be done this week.  GRACC accounting taskforce - Tasking!!!",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#backburner",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)",
            "title": "Backburner"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190617/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190610/",
            "text": "OSG Technology Area Meeting, 10 June 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Diego, Edgar, Marco Mambelli, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nBrianL OOO Friday\n\n\nDerek OOO Wed - Fri\n\n\nMat OOO Tuesday PM\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: TimT\n\n\nNext week: BrianL\n\n\n2 (+0) open FreshDesk tickets\n\n\n1 (+1) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n156\n\n\n+2\n\n\nOpen\n\n\n\n\n\n\n26\n\n\n+1\n\n\nIn Progress\n\n\n\n\n\n\n8\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+2\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5 packages reviewed: \nhttps://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit?usp=sharing\n\n\nXCache:  \n\n\nAI (BrianL): Get ATLAS/CMS XCache RPM packaging in this week\n\n\nAI (BrianL): Add XCache integration tests to the container CI\n\n\nAI (BrianL, Marian): Put together slides for the XRootD container/packaging/monitoring presentation\n\n\n\n\n\n\nHosted-CE:  \n\n\nInitial script for managing WN software/data from the CE host in the Operation team's hands\n\n\nAI (Mat): elaborate on plans to manage remote submission host patches/config from a central host\n\n\n\n\n\n\nBlahp unification: CHTC git repo and mirroring to GitHub complete. Working through HTCondor build issues.\n\n\nAI (Derek): Review Gratia probe PRs (\nhttps://github.com/opensciencegrid/gratia-probe/pulls\n)\n\n\nAI (Mat): Give IceCube access to the GLOW origin\n\n\nMadison ITB CE host certificates will be updated this week\n\n\nGlideinWMS 3.5.0 has been released upstream and there are some important upgrade instructions that Marco has noted. It's also still fully compatible with HTCondor 8.6 and older frontend/factory versions.\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (BrianL): Talk to FNAL, factory folks about OSG 3.4 support lifetime (due to dropping EL6 support in OSG 3.5)\n\n\nAI (Edgar, Mat): ITB submit host request certificate, investigate how glidein3 is monitoring it\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nATLAS (Derek): Accounting audit continues.  Still editing with Fred.\n\n\nCMS (Edgar): Told CMS sites that they can use Let's Encrypt certs for their CEs but there are issues. The CERN factory doesn't have LE CAs installed but we control the host so we can install them. Pilot jobs are running ok but SAM tests and PHEDeX transfers are failing. Vanderbilt is paying DigiCert per host certificate, which may be a potential alternative to InCommon and Let's Encrypt.\n\n\nGLOW (BrianL): Some user jobs are being held in IIT startd's with the message \"missing http plugin\"\n\n\nSWT2 (Carl): We've got a Gratia probe pull request in for a Slurm v18 fix; we're also investigating a strange dependency on the OSG user-vo-map that shouldn't be there anymore\n\n\nSyracuse (BrianL): troubleshooting why their condor pool negotiator isn't matching their whole node jobs\n\n\nOSG User Support (Derek): Virtually attending meeting in Chicago.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.31\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n7\n\n\n-3\n\n\nOpen\n\n\n\n\n\n\n6\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n7\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+2\n\n\nReady for Release\n\n\n\n\n\n\n22\n\n\n-2\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.31  \n\n\nReady for Testing  \n\n\ncctools 7.0.13\n\n\nXRootD 4.10.0-rc1\n\n\nxrootd-scitokens 1.0.0\n\n\nscitokens-cpp\n\n\nGlideinWMS proxy renewal (for Xenon)\n\n\nUpcoming: HTCondor 8.8.3\n\n\n\n\n\n\nReady for Release\n\n\nSingularity 3.2.1\n\n\nHTCondor 8.6 patch python packaging to match EPEL\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nVO Package v93\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email [IN PROGRESS]\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\nAccounting audit is continuing in collaboration with ATLAS.  Editing final report.\n\n\nAdapting LIGO style cvmfs + singularity.  Ready for testing.\n\n\ncvmfs-authz-helper (cvmfs-x509-helper) should be built this week.  will ask osg-software for help.\n\n\nXRootD Workshop this week.\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "June 10, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#osg-technology-area-meeting-10-june-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Diego, Edgar, Marco Mambelli, Mat, TimT",
            "title": "OSG Technology Area Meeting, 10 June 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#announcements",
            "text": "BrianL OOO Friday  Derek OOO Wed - Fri  Mat OOO Tuesday PM",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#triage-duty",
            "text": "This week: TimT  Next week: BrianL  2 (+0) open FreshDesk tickets  1 (+1) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#jira",
            "text": "# of tickets  \u0394  State      156  +2  Open    26  +1  In Progress    8  +0  Ready for Testing    2  +2  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#osg-software-team",
            "text": "OSG 3.5 packages reviewed:  https://docs.google.com/spreadsheets/d/1WNk8F5XRQSJw3mwTFejJBLNbrQptdUxpWpZ0UEu-4MI/edit?usp=sharing  XCache:    AI (BrianL): Get ATLAS/CMS XCache RPM packaging in this week  AI (BrianL): Add XCache integration tests to the container CI  AI (BrianL, Marian): Put together slides for the XRootD container/packaging/monitoring presentation    Hosted-CE:    Initial script for managing WN software/data from the CE host in the Operation team's hands  AI (Mat): elaborate on plans to manage remote submission host patches/config from a central host    Blahp unification: CHTC git repo and mirroring to GitHub complete. Working through HTCondor build issues.  AI (Derek): Review Gratia probe PRs ( https://github.com/opensciencegrid/gratia-probe/pulls )  AI (Mat): Give IceCube access to the GLOW origin  Madison ITB CE host certificates will be updated this week  GlideinWMS 3.5.0 has been released upstream and there are some important upgrade instructions that Marco has noted. It's also still fully compatible with HTCondor 8.6 and older frontend/factory versions.",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#discussion",
            "text": "AI (BrianL): Talk to FNAL, factory folks about OSG 3.4 support lifetime (due to dropping EL6 support in OSG 3.5)  AI (Edgar, Mat): ITB submit host request certificate, investigate how glidein3 is monitoring it",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#support-update",
            "text": "ATLAS (Derek): Accounting audit continues.  Still editing with Fred.  CMS (Edgar): Told CMS sites that they can use Let's Encrypt certs for their CEs but there are issues. The CERN factory doesn't have LE CAs installed but we control the host so we can install them. Pilot jobs are running ok but SAM tests and PHEDeX transfers are failing. Vanderbilt is paying DigiCert per host certificate, which may be a potential alternative to InCommon and Let's Encrypt.  GLOW (BrianL): Some user jobs are being held in IIT startd's with the message \"missing http plugin\"  SWT2 (Carl): We've got a Gratia probe pull request in for a Slurm v18 fix; we're also investigating a strange dependency on the OSG user-vo-map that shouldn't be there anymore  Syracuse (BrianL): troubleshooting why their condor pool negotiator isn't matching their whole node jobs  OSG User Support (Derek): Virtually attending meeting in Chicago.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#osg-release-team",
            "text": "3.4.31  \u0394  Status      7  -3  Open    6  -1  In Progress    7  +0  Ready for Testing    2  +2  Ready for Release    22  -2  Total      OSG 3.4.31    Ready for Testing    cctools 7.0.13  XRootD 4.10.0-rc1  xrootd-scitokens 1.0.0  scitokens-cpp  GlideinWMS proxy renewal (for Xenon)  Upcoming: HTCondor 8.8.3    Ready for Release  Singularity 3.2.1  HTCondor 8.6 patch python packaging to match EPEL      Data    VO Package v93    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#discussion_1",
            "text": "AI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email [IN PROGRESS]",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#osg-investigations-team",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)  Accounting audit is continuing in collaboration with ATLAS.  Editing final report.  Adapting LIGO style cvmfs + singularity.  Ready for testing.  cvmfs-authz-helper (cvmfs-x509-helper) should be built this week.  will ask osg-software for help.  XRootD Workshop this week.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190610/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190603/",
            "text": "OSG Technology Area Meeting,  3 June 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Edgar, Derek, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nMat at FNAL Thursday, 6/6, to discuss Modularity with the Scientific Linux team\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: TimT\n\n\n2 (-2) open FreshDesk tickets\n\n\n0 (-1) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n154\n\n\n-5\n\n\nOpen\n\n\n\n\n\n\n25\n\n\n+4\n\n\nIn Progress\n\n\n\n\n\n\n8\n\n\n+1\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5 planning to start this week: \nhttps://opensciencegrid.atlassian.net/issues/?jql=labels%20%3D%203.5.0\n\n\nXCache:  \n\n\nAI (BrianL, Edgar): Get ATLAS/CMS XCache RPM packaging in this week\n\n\nAI (BrianL): Add XCache integration tests to the container CI\n\n\n\n\n\n\nHosted-CE:  \n\n\nInitial script for managing WN software/data from the CE host in the Operation team's hands\n\n\nAI (Mat): send email to Ops and UChicago admins to discuss design of managing CE configuration from a central host\n\n\n\n\n\n\nAI (Mat): Give IceCube access to the GLOW origin\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (BrianL): Investigate missing OSG VMU test results, potentially due to local Gluster issues\n\n\nAI (BrianL): Create ticket for IceCube/GLOW origin VO work\n\n\nAI (BrianL): Talk to FNAL, factory folks about OSG 3.4 support lifetime (due to dropping EL6 support in OSG 3.5)\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nATLAS (Derek): Accounting audit continues.\n\n\nCMS (Edgar): Told CMS sites that they can use Let's Encrypt certs for their CEs but there are issues. The CERN factory doesn't have LE CAs installed but we control the host so we can install them. Pilot jobs are running ok but SAM tests and PHEDeX transfers are failing. Vanderbilt is paying DigiCert per host certificate, which may be a potential alternative to InCommon and Let's Encrypt.\n\n\nSyracuse (BrianL): troubleshooting issues with factory ops about the OSG VO's inability to fully utilize their idle cores\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.31\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n10\n\n\n+1\n\n\nOpen\n\n\n\n\n\n\n7\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n7\n\n\n+1\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n24\n\n\n+2\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.31\n\n\nReady for Testing  \n\n\nSingularity 3.2.1\n\n\ncctools 7.0.13\n\n\nHTCondor 8.6 patch python packaging to match EPEL\n\n\nXRootD 4.10.0-rc1\n\n\nxrootd-scitokens 1.0.0\n\n\nscitokens-cpp\n\n\nUpcoming: HTCondor 8.8.3\n\n\n\n\n\n\n\n\n\n\nData\n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email [IN PROGRESS]\n\n\nTimT and Mat are working on getting IGTF CA certificate announcements to the osg-sw-notices [DONE]\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nWorking with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)\n\n\nAccounting audit is continuing in collaboration with ATLAS.  Pretty much done on our end.  Accounting portal appears updated.  PDF's look wrong.  They will not be updated, but they look wrong even for the previous bad data.\n\n\nAdapting LIGO style cvmfs + singularity.  Ready for testing.\n\n\n(DONE) Creating cvmfs + scitokens repo to start testing scitokens enabled stashcache.\n\n\ncvmfs-authz-helper (cvmfs-x509-helper) will be built this week.  Pending pull request to fix issues discovered through testing.\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "June 3, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#osg-technology-area-meeting-3-june-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Edgar, Derek, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting,  3 June 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#announcements",
            "text": "Mat at FNAL Thursday, 6/6, to discuss Modularity with the Scientific Linux team",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#triage-duty",
            "text": "This week: Mat  Next week: TimT  2 (-2) open FreshDesk tickets  0 (-1) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#jira",
            "text": "# of tickets  \u0394  State      154  -5  Open    25  +4  In Progress    8  +1  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#osg-software-team",
            "text": "OSG 3.5 planning to start this week:  https://opensciencegrid.atlassian.net/issues/?jql=labels%20%3D%203.5.0  XCache:    AI (BrianL, Edgar): Get ATLAS/CMS XCache RPM packaging in this week  AI (BrianL): Add XCache integration tests to the container CI    Hosted-CE:    Initial script for managing WN software/data from the CE host in the Operation team's hands  AI (Mat): send email to Ops and UChicago admins to discuss design of managing CE configuration from a central host    AI (Mat): Give IceCube access to the GLOW origin",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#discussion",
            "text": "AI (BrianL): Investigate missing OSG VMU test results, potentially due to local Gluster issues  AI (BrianL): Create ticket for IceCube/GLOW origin VO work  AI (BrianL): Talk to FNAL, factory folks about OSG 3.4 support lifetime (due to dropping EL6 support in OSG 3.5)",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#support-update",
            "text": "ATLAS (Derek): Accounting audit continues.  CMS (Edgar): Told CMS sites that they can use Let's Encrypt certs for their CEs but there are issues. The CERN factory doesn't have LE CAs installed but we control the host so we can install them. Pilot jobs are running ok but SAM tests and PHEDeX transfers are failing. Vanderbilt is paying DigiCert per host certificate, which may be a potential alternative to InCommon and Let's Encrypt.  Syracuse (BrianL): troubleshooting issues with factory ops about the OSG VO's inability to fully utilize their idle cores",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#osg-release-team",
            "text": "3.4.31  \u0394  Status      10  +1  Open    7  +0  In Progress    7  +1  Ready for Testing    0  +0  Ready for Release    24  +2  Total      OSG 3.4.31  Ready for Testing    Singularity 3.2.1  cctools 7.0.13  HTCondor 8.6 patch python packaging to match EPEL  XRootD 4.10.0-rc1  xrootd-scitokens 1.0.0  scitokens-cpp  Upcoming: HTCondor 8.8.3      Data  Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#discussion_1",
            "text": "AI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email [IN PROGRESS]  TimT and Mat are working on getting IGTF CA certificate announcements to the osg-sw-notices [DONE]",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#osg-investigations-team",
            "text": "Working with operations investigating OAuth with co-manage.  Waiting on co-manage (Wisconsin?!?!)  Accounting audit is continuing in collaboration with ATLAS.  Pretty much done on our end.  Accounting portal appears updated.  PDF's look wrong.  They will not be updated, but they look wrong even for the previous bad data.  Adapting LIGO style cvmfs + singularity.  Ready for testing.  (DONE) Creating cvmfs + scitokens repo to start testing scitokens enabled stashcache.  cvmfs-authz-helper (cvmfs-x509-helper) will be built this week.  Pending pull request to fix issues discovered through testing.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190603/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190528/",
            "text": "OSG Technology Area Meeting, 28 May 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Diego, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nBrianL OOO this Friday, 5/31\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Edgar\n\n\nNext week: Mat\n\n\n4 (-0) open FreshDesk tickets\n\n\n1 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n159\n\n\n+1\n\n\nOpen\n\n\n\n\n\n\n21\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n7\n\n\n+2\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nOSG 3.5 planning to start this week: \nhttps://opensciencegrid.atlassian.net/issues/?jql=labels%20%3D%203.5.0\n\n\nHosted-CE:  \n\n\nInitial script for managing WN software/data from the CE host in the Operation team's hands\n\n\nAI (Mat): send email to Ops and UChicago admins to discuss design of managing CE configuration from a central host\n\n\n\n\n\n\nBlahp unification: CHTC git repo and mirroring to GitHub complete. Working through HTCondor build issues.\n\n\nAI (Mat): IceCube is interested in using the GLOW origin\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (BrianL): Talk to FNAL, factory folks about OSG 3.4 support lifetime (due to dropping EL6 support in OSG 3.5)\n\n\nAI (TimT): Send expiration warning emails for OSG CA host certs\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nATLAS (Derek): Update multiple sites in the WLCG accounting portal (NET2 and OU): \nhttps://ggus.eu/index.php?mode=ticket_info&ticket_id=141350\n\n\nSyracuse (BrianL): troubleshooting issues with factory ops about the OSG VO's inability to fully utilize their idle cores\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.31\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n9\n\n\n+9\n\n\nOpen\n\n\n\n\n\n\n7\n\n\n+7\n\n\nIn Progress\n\n\n\n\n\n\n6\n\n\n+6\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n22\n\n\n+22\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.31 - This Week\n\n\nReady for Testing  \n\n\nSingularity 3.2.0 (may wait for 3.2.1)\n\n\ncctools 7.0.13\n\n\nHTCondor 8.6 patch python packaging to match EPEL\n\n\nXRootD 4.10.0-rc1\n\n\nxrootd-scitokens 1.0.0\n\n\nscitokens-cpp\n\n\n\n\n\n\n\n\n\n\nData - This week\n\n\nIGTF 1.99\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.30\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-10\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-10\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-5\n\n\nReady for Testing\n\n\n\n\n\n\n15\n\n\n+15\n\n\nReady for Release\n\n\n\n\n\n\n15\n\n\n-10\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.30 - Two weeks ago\n\n\nSingularity security release (new)\n\n\nBLAHP 1.18.41 (new)\n\n\nxrootd-voms-plugin 0.6.0\n\n\nosg-se-hadoop for EL6\n\n\nosg-pki-tools 3.3.0 (new)\n\n\nosg-test 3.0.0\n\n\n\n\n\n\nData - Fold into 3.4.30 release\n\n\nVO Package v91\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email\n\n\nNo real kickers for a software release this week\n\n\nWe'd like to get nanoHUB VO client updates into this week's data release\n\n\nTimT and Mat are working on getting IGTF CA certificate announcements to the osg-sw-notices\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nWorking with Operations on monitoring.  Added Hosted-CE's monitoring.  Continuing to refine.  Way too noisy.  Need to fix alerts.\n\n\nAlso working with operations investigating OAuth with co-manage.\n\n\nAccounting audit is continuing in collaboration with ATLAS.  Pretty much done on our end.  Accounting portal appears updated.\n\n\nAdapting LIGO style cvmfs + singularity.  Ready for testing.\n\n\nCreating cvmfs + scitokens repo to start testing scitokens enabled stashcache.\n\n\nFactory monitoring to GRACC.\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "May 28, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#osg-technology-area-meeting-28-may-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Diego, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 28 May 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#announcements",
            "text": "BrianL OOO this Friday, 5/31",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#triage-duty",
            "text": "This week: Edgar  Next week: Mat  4 (-0) open FreshDesk tickets  1 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#jira",
            "text": "# of tickets  \u0394  State      159  +1  Open    21  -1  In Progress    7  +2  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#osg-software-team",
            "text": "OSG 3.5 planning to start this week:  https://opensciencegrid.atlassian.net/issues/?jql=labels%20%3D%203.5.0  Hosted-CE:    Initial script for managing WN software/data from the CE host in the Operation team's hands  AI (Mat): send email to Ops and UChicago admins to discuss design of managing CE configuration from a central host    Blahp unification: CHTC git repo and mirroring to GitHub complete. Working through HTCondor build issues.  AI (Mat): IceCube is interested in using the GLOW origin",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#discussion",
            "text": "AI (BrianL): Talk to FNAL, factory folks about OSG 3.4 support lifetime (due to dropping EL6 support in OSG 3.5)  AI (TimT): Send expiration warning emails for OSG CA host certs",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#support-update",
            "text": "ATLAS (Derek): Update multiple sites in the WLCG accounting portal (NET2 and OU):  https://ggus.eu/index.php?mode=ticket_info&ticket_id=141350  Syracuse (BrianL): troubleshooting issues with factory ops about the OSG VO's inability to fully utilize their idle cores",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#osg-release-team",
            "text": "3.4.31  \u0394  Status      9  +9  Open    7  +7  In Progress    6  +6  Ready for Testing    0  +0  Ready for Release    22  +22  Total      OSG 3.4.31 - This Week  Ready for Testing    Singularity 3.2.0 (may wait for 3.2.1)  cctools 7.0.13  HTCondor 8.6 patch python packaging to match EPEL  XRootD 4.10.0-rc1  xrootd-scitokens 1.0.0  scitokens-cpp      Data - This week  IGTF 1.99    Operations    Nothing    Contrib    Nothing        3.4.30  \u0394  Status      0  -10  Open    0  -10  In Progress    0  -5  Ready for Testing    15  +15  Ready for Release    15  -10  Total      OSG 3.4.30 - Two weeks ago  Singularity security release (new)  BLAHP 1.18.41 (new)  xrootd-voms-plugin 0.6.0  osg-se-hadoop for EL6  osg-pki-tools 3.3.0 (new)  osg-test 3.0.0    Data - Fold into 3.4.30 release  VO Package v91",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#discussion_1",
            "text": "AI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email  No real kickers for a software release this week  We'd like to get nanoHUB VO client updates into this week's data release  TimT and Mat are working on getting IGTF CA certificate announcements to the osg-sw-notices",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#osg-investigations-team",
            "text": "Working with Operations on monitoring.  Added Hosted-CE's monitoring.  Continuing to refine.  Way too noisy.  Need to fix alerts.  Also working with operations investigating OAuth with co-manage.  Accounting audit is continuing in collaboration with ATLAS.  Pretty much done on our end.  Accounting portal appears updated.  Adapting LIGO style cvmfs + singularity.  Ready for testing.  Creating cvmfs + scitokens repo to start testing scitokens enabled stashcache.  Factory monitoring to GRACC.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190528/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190513/",
            "text": "OSG Technology Area Meeting, 13 May 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT, Zhenzhou\n\n\nAnnouncements\n\u00b6\n\n\n\n\nNext meeting 5/28 (due to HTCondor Week and Memorial Day)\n\n\nZhenzhou, our new student, starts Topology work today\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: BrianL\n\n\nNext week: Carl\n\n\n4 (-2) open FreshDesk tickets\n\n\n1 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n161\n\n\n-1\n\n\nOpen\n\n\n\n\n\n\n24\n\n\n-3\n\n\nIn Progress\n\n\n\n\n\n\n7\n\n\n+4\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nXRootD 4.10.0 RC 1 released so we need to turn a build around\n\n\nRHEL 8 has been released; unsure about the timeline for CentOS 8\n\n\nStable stash-cache image has been tagged\n\n\nHosted-CE improvements:  \n\n\nAdd ability to manage WN software/data from the CE host\n\n\nImprove operational flexibility by managing submit host configuration from the CE\n\n\n\n\n\n\nInternal OSG Site installation exercise on 5/24 at 9am CDT\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nWhat are the limits on the RHEL developer license? TimT said unlimited VMs on a single host\n\n\nDiscussion about GLOW stash cache/origin on k8s\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nNET2 (Carl): Continuing work on the custom SGE probe to fix missing accounting records\n\n\nPurdue (Marco): privileged singularity is not accepting signals even after dropping privs.\n    Suggested solution is to use unprivileged singularity.\n\n\nSuperMIC (Edgar): Troubleshooting issues with CVMFS\n\n\nSWT2 (BrianL): the blahp does not refresh proxies after 24h on WNs and this has bitten ATLAS.\n    Have a fix that worked for SWT2 included in a new build.\n\n\nUCSD (Diego): Troubleshooting issues with using chirp within Singularity containers.\n    Jaime has suggested using the python client.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.30\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n10\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n10\n\n\n+1\n\n\nIn Progress\n\n\n\n\n\n\n5\n\n\n+3\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n25\n\n\n+4\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.30 - This Week  \n\n\nReady for Testing  \n\n\nxrootd-voms-plugin 0.6.0\n\n\nosg-se-hadoop for EL6\n\n\nosg-test 3.0.0\n\n\n\n\n\n\n\n\n\n\nData - Fold into 3.4.30 release\n\n\nVO Package v91\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email\n\n\nPatched BLAHP expected to drive out release this week\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nWorking with Operations on monitoring.  Added Hosted-CE's monitoring.  Continuing to refine.\n\n\nAlso working with operations investigating OAuth with co-manage.\n\n\nAccounting audit is continuing in collaboration with ATLAS.  Pretty much done.\n\n\nUpdates in perfsonar format caused data pipeline to fail.  Some emergency development performed.\n\n\nStashCache PEARC paper officially accepted, very good reviews.\n\n\nWorried about APEL accounting blackbox.\n\n\nAdapting LIGO style cvmfs + singularity.\n\n\nFactory monitoring to GRACC.\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "May 13, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#osg-technology-area-meeting-13-may-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Derek, Diego, Edgar, Marco Mambelli, Marian, Mat, TimT, Zhenzhou",
            "title": "OSG Technology Area Meeting, 13 May 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#announcements",
            "text": "Next meeting 5/28 (due to HTCondor Week and Memorial Day)  Zhenzhou, our new student, starts Topology work today",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#triage-duty",
            "text": "This week: BrianL  Next week: Carl  4 (-2) open FreshDesk tickets  1 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#jira",
            "text": "# of tickets  \u0394  State      161  -1  Open    24  -3  In Progress    7  +4  Ready for Testing    0  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#osg-software-team",
            "text": "XRootD 4.10.0 RC 1 released so we need to turn a build around  RHEL 8 has been released; unsure about the timeline for CentOS 8  Stable stash-cache image has been tagged  Hosted-CE improvements:    Add ability to manage WN software/data from the CE host  Improve operational flexibility by managing submit host configuration from the CE    Internal OSG Site installation exercise on 5/24 at 9am CDT",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#discussion",
            "text": "What are the limits on the RHEL developer license? TimT said unlimited VMs on a single host  Discussion about GLOW stash cache/origin on k8s",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#support-update",
            "text": "NET2 (Carl): Continuing work on the custom SGE probe to fix missing accounting records  Purdue (Marco): privileged singularity is not accepting signals even after dropping privs.\n    Suggested solution is to use unprivileged singularity.  SuperMIC (Edgar): Troubleshooting issues with CVMFS  SWT2 (BrianL): the blahp does not refresh proxies after 24h on WNs and this has bitten ATLAS.\n    Have a fix that worked for SWT2 included in a new build.  UCSD (Diego): Troubleshooting issues with using chirp within Singularity containers.\n    Jaime has suggested using the python client.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#osg-release-team",
            "text": "3.4.30  \u0394  Status      10  +0  Open    10  +1  In Progress    5  +3  Ready for Testing    0  +0  Ready for Release    25  +4  Total      OSG 3.4.30 - This Week    Ready for Testing    xrootd-voms-plugin 0.6.0  osg-se-hadoop for EL6  osg-test 3.0.0      Data - Fold into 3.4.30 release  VO Package v91    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#discussion_1",
            "text": "AI (TimT): Take over osg-sites mailing list for community testing, populate it with Topology admin contacts, and write an introductory email  Patched BLAHP expected to drive out release this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#osg-investigations-team",
            "text": "Working with Operations on monitoring.  Added Hosted-CE's monitoring.  Continuing to refine.  Also working with operations investigating OAuth with co-manage.  Accounting audit is continuing in collaboration with ATLAS.  Pretty much done.  Updates in perfsonar format caused data pipeline to fail.  Some emergency development performed.  StashCache PEARC paper officially accepted, very good reviews.  Worried about APEL accounting blackbox.  Adapting LIGO style cvmfs + singularity.  Factory monitoring to GRACC.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190513/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190506/",
            "text": "OSG Technology Area Meeting,  6 May 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Edgar, Marian, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nMat out for vacation today\n\n\nOSG VO infrastructure undergoing maintenance today\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: TimT\n\n\nNext week: BrianL\n\n\n6 (-3) open FreshDesk tickets\n\n\n1 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n162\n\n\n-3\n\n\nOpen\n\n\n\n\n\n\n27\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n3\n\n\n-7\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-4\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nNeed to transtion services from ingwe to moria, e.g. SVN backup\n\n\nInternal OSG Site installation exercise on 5/24 at 9am CDT\n\n\nHosted-CE improvements:  \n\n\nAdd ability to manage WN software/data from the CE host\n\n\nImprove operational flexibility by managing submit host configuration from the CE\n\n\n\n\n\n\nExpect Singularity 3 to be moved from upcoming to release\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nSupport Update\n\u00b6\n\n\n\n\nNET2 (Carl): Continuing work on the custom SGE probe to fix missing accounting records\n\n\nSWT2 (BrianL): the blahp does not refresh proxies after 24h on WNs and this has bitten ATLAS.\n\n    Have a fix that works in testing but doesn't seem to work for SWT2.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.30\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n10\n\n\n+10\n\n\nOpen\n\n\n\n\n\n\n9\n\n\n+9\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n+2\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n21\n\n\n+21\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.30 - This Week\n\n\nReady for Testing  \n\n\nxrootd-voms-plugin 0.6.0\n\n\nosg-se-hadoop for EL6\n\n\n\n\n\n\n\n\n\n\nData - Tomorrow\n\n\nVO Package v90\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.29\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-11\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-10\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-10\n\n\nReady for Testing\n\n\n\n\n\n\n18\n\n\n+14\n\n\nReady for Release\n\n\n\n\n\n\n18\n\n\n-17\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.29 - Last Week\n\n\nStashCache/XCache (13 tickets)\n\n\nMyProxy using GCT\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Request a mailing list for community testing, populate it with Topology admin contacts, and write an introductory email\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nWorking with Operations on monitoring.  Added Hosted-CE's monitoring.  Continuing to refine.\n\n\nAccounting audit is continuing in collaboration with ATLAS.\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "May 6, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#osg-technology-area-meeting-6-may-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Edgar, Marian, TimT",
            "title": "OSG Technology Area Meeting,  6 May 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#announcements",
            "text": "Mat out for vacation today  OSG VO infrastructure undergoing maintenance today",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#triage-duty",
            "text": "This week: TimT  Next week: BrianL  6 (-3) open FreshDesk tickets  1 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#jira",
            "text": "# of tickets  \u0394  State      162  -3  Open    27  -2  In Progress    3  -7  Ready for Testing    0  -4  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#osg-software-team",
            "text": "Need to transtion services from ingwe to moria, e.g. SVN backup  Internal OSG Site installation exercise on 5/24 at 9am CDT  Hosted-CE improvements:    Add ability to manage WN software/data from the CE host  Improve operational flexibility by managing submit host configuration from the CE    Expect Singularity 3 to be moved from upcoming to release",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#discussion",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#support-update",
            "text": "NET2 (Carl): Continuing work on the custom SGE probe to fix missing accounting records  SWT2 (BrianL): the blahp does not refresh proxies after 24h on WNs and this has bitten ATLAS. \n    Have a fix that works in testing but doesn't seem to work for SWT2.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#osg-release-team",
            "text": "3.4.30  \u0394  Status      10  +10  Open    9  +9  In Progress    2  +2  Ready for Testing    0  +0  Ready for Release    21  +21  Total      OSG 3.4.30 - This Week  Ready for Testing    xrootd-voms-plugin 0.6.0  osg-se-hadoop for EL6      Data - Tomorrow  VO Package v90    Operations    Nothing    Contrib    Nothing        3.4.29  \u0394  Status      0  -11  Open    0  -10  In Progress    0  -10  Ready for Testing    18  +14  Ready for Release    18  -17  Total      OSG 3.4.29 - Last Week  StashCache/XCache (13 tickets)  MyProxy using GCT",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#discussion_1",
            "text": "AI (TimT): Request a mailing list for community testing, populate it with Topology admin contacts, and write an introductory email",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#osg-investigations-team",
            "text": "Working with Operations on monitoring.  Added Hosted-CE's monitoring.  Continuing to refine.  Accounting audit is continuing in collaboration with ATLAS.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190506/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190429/",
            "text": "OSG Technology Area Meeting, 29 April 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n Mat, Edgar, Derek, Tim T, Diego Davila, Marian\n\n\nAnnouncements\n\u00b6\n\n\n\n\nBrian Lin out until Thursday\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: Tim T\n\n\n6 (+3) open FreshDesk tickets\n\n\n1 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n165\n\n\n+1\n\n\nOpen\n\n\n\n\n\n\n29\n\n\n+3\n\n\nIn Progress\n\n\n\n\n\n\n10\n\n\n-2\n\n\nReady for Testing\n\n\n\n\n\n\n4\n\n\n-3\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\nWork in progress:\n\n\n\n\nStashCache/XCache testing\n\n\nHosted-CE updater script and OSG-Configure tweaks\n\n\nBugfix for worker node proxy renewal\n\n\nXCache startup script ordering (will be in XCache 1.0.4)\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nTesting XCache 1.0.4 not urgent; Marian can keep testing 1.0.3\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\n(Mat) helped FIU upgrade 3.3 to 3.4; found condor packaging bug in the meantime\n\n\n(Derek) GlueX installation of data origin.  Now made a networking ticket for slow download speeds.\n\n\n(Derek) APEL numbers added to Purdue and MWT2 clusters.  Following up with Caltech now.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.29\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n11\n\n\n+11\n\n\nOpen\n\n\n\n\n\n\n10\n\n\n+10\n\n\nIn Progress\n\n\n\n\n\n\n10\n\n\n+10\n\n\nReady for Testing\n\n\n\n\n\n\n4\n\n\n+4\n\n\nReady for Release\n\n\n\n\n\n\n35\n\n\n+35\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.29 - This Week\n\n\nReady for Testing\n\n\nStashCache/XCache (13 tickets)\n\n\nMyProxy using GCT\n\n\n\n\n\n\n\n\n\n\nData\n\n\nIGTF 1.98\n\n\n\n\n\n\nOperations\n\n\nNothing\n\n\n\n\n\n\nContrib\n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.28\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-3\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-12\n\n\nReady for Testing\n\n\n\n\n\n\n8\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n8\n\n\n-14\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.28 - Last Week\n\n\nReady for Release\n\n\nXRootD 4.9.1\n\n\nGlideinWMS 3.4.5\n\n\nosg-flock 1.1: flock host DN\n\n\nVO Package v89\n\n\nUpcoming: HTCondor 8.8.2\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (Marian, John T): Should be able to test XCache by noon Wed\n\n\nAI (TimT): Request a mailing list for community testing, populate it with Topology admin contacts, and write an introductory email\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nWorking with Operations on monitoring.\n\n\nAdded collectors this week\n\n\nWorking on hosted-ce's now.  Can we get read-only?\n\n\n\n\n\n\nAccounting audit is continuing in collaboration with ATLAS.\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "April 29, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#osg-technology-area-meeting-29-april-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  Mat, Edgar, Derek, Tim T, Diego Davila, Marian",
            "title": "OSG Technology Area Meeting, 29 April 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#announcements",
            "text": "Brian Lin out until Thursday",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#triage-duty",
            "text": "This week: Mat  Next week: Tim T  6 (+3) open FreshDesk tickets  1 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#jira",
            "text": "# of tickets  \u0394  State      165  +1  Open    29  +3  In Progress    10  -2  Ready for Testing    4  -3  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#osg-software-team",
            "text": "Work in progress:   StashCache/XCache testing  Hosted-CE updater script and OSG-Configure tweaks  Bugfix for worker node proxy renewal  XCache startup script ordering (will be in XCache 1.0.4)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#discussion",
            "text": "Testing XCache 1.0.4 not urgent; Marian can keep testing 1.0.3",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#support-update",
            "text": "(Mat) helped FIU upgrade 3.3 to 3.4; found condor packaging bug in the meantime  (Derek) GlueX installation of data origin.  Now made a networking ticket for slow download speeds.  (Derek) APEL numbers added to Purdue and MWT2 clusters.  Following up with Caltech now.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#osg-release-team",
            "text": "3.4.29  \u0394  Status      11  +11  Open    10  +10  In Progress    10  +10  Ready for Testing    4  +4  Ready for Release    35  +35  Total      OSG 3.4.29 - This Week  Ready for Testing  StashCache/XCache (13 tickets)  MyProxy using GCT      Data  IGTF 1.98    Operations  Nothing    Contrib  Nothing        3.4.28  \u0394  Status      0  +0  Open    0  -3  In Progress    0  -12  Ready for Testing    8  +1  Ready for Release    8  -14  Total      OSG 3.4.28 - Last Week  Ready for Release  XRootD 4.9.1  GlideinWMS 3.4.5  osg-flock 1.1: flock host DN  VO Package v89  Upcoming: HTCondor 8.8.2",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#discussion_1",
            "text": "AI (Marian, John T): Should be able to test XCache by noon Wed  AI (TimT): Request a mailing list for community testing, populate it with Topology admin contacts, and write an introductory email",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#osg-investigations-team",
            "text": "Working with Operations on monitoring.  Added collectors this week  Working on hosted-ce's now.  Can we get read-only?    Accounting audit is continuing in collaboration with ATLAS.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  On pause.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190429/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190422/",
            "text": "OSG Technology Area Meeting, 22 April 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Edgar, Marian, TimT\n\n\nAnnouncements\n\u00b6\n\n\nBrianL out next week 4/29 - 5/1\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Edgar\n\n\nNext week: Mat\n\n\n9 (+1) open FreshDesk tickets\n\n\n1 (+0) open GGUS ticket\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n164\n\n\n-7\n\n\nOpen\n\n\n\n\n\n\n26\n\n\n-3\n\n\nIn Progress\n\n\n\n\n\n\n12\n\n\n-5\n\n\nReady for Testing\n\n\n\n\n\n\n7\n\n\n+7\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nNew GLOW VO certificate?\n\n\nTPC tests have been failing since 4/12 (\nhttp://vdt.cs.wisc.edu/tests/20190412-0423/results.html\n)\n\n\nBlahp updates  \n\n\nMerging relevant HTCondor patches\n\n\nAI (Carl): Use the \"new\" condor env format\n\n\nAI (BrianL): Proxies on WNs fail to renew\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (Carl): will request GLOW certificate\n\n\nAI (Edgar): will look into XRootD TPC tests failing, BrianL will create a ticket\n\n\nAI (BrianL): Review the status of doc tickets labeled for 3.4.28\n\n\nAI (BrianL): Add Diego to the software mailing list and JIRA\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nCMS (Marian): XRootD SAM tests are segfaulting for some sites.\n    Still investigating xrootd-python and xrootd-client.\n\n\nLIGO (Edgar): are interested in opportunistic GPU usage.\n    They're configured to use PRP GPUs and we're working on getting them access to QB2E and CalTech GPUs.\n\n\nNET2 (Carl, Derek): They had an issue similar to Florida but they have all of their accounting records from SGE.\n    This means that we can run a probe locally, \"faking\" any local configuration, and send records off to the GRACC.\n\n\nSWT2 (BrianL): the blahp does not refresh proxies after 24h on WNs and this has bitten ATLAS.\n    Investigating potential fixes.\n\n\nUFL (Carl, Derek): Records have been sent to APEL and now the WLCG needs to regenerate the reports. Out of OSG hands now.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.28\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n3\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n12\n\n\n-5\n\n\nReady for Testing\n\n\n\n\n\n\n7\n\n\n+7\n\n\nReady for Release\n\n\n\n\n\n\n0\n\n\n+0\n\n\nClosed\n\n\n\n\n\n\n22\n\n\n+2\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.28 - This Week\n\n\nReady for Testing\n\n\nXRootD 4.9.1\n\n\nStashCache/XCache (13 tickets)\n\n\nMyProxy using GCT\n\n\nGlideinWMS 3.4.5\n\n\n\n\n\n\nReady for Release\n\n\nosg-flock 1.1: flock host DN\n\n\nUpcoming: HTCondor 8.8.2\n\n\n\n\n\n\n\n\n\n\nData\n\n\nNothing\n\n\n\n\n\n\nOperations\n\n\nNothing\n\n\n\n\n\n\nContrib\n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (Marian, John T): Should be able to test XCache by noon Wed\n\n\nAI (Edgar): Help Diego test GlideinWMS 3.4.5\n\n\nAI (TimT): Request a mailing list for community testing, populate it with Topology admin contacts, and write an introductory email\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nXRootD workshop will be held in France in 6-8 weeks\n\n\nSome resources in topology don't have an APEL normalization factor set in topology, causing issues with APEL numbers.\n\n    We have opened tickets with the relevant site admins.\n\n\nAccounting audit is beginning in collaboration with ATLAS.\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nI would like the investigations team to make a thrust helping Ops with monitoring.  Lots of issues with things that are failing.  And who is watching the watchers (GRACC alert email wasn't being sent... watch the watchers)?\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska, next week.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "April 22, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#osg-technology-area-meeting-22-april-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Edgar, Marian, TimT",
            "title": "OSG Technology Area Meeting, 22 April 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#announcements",
            "text": "BrianL out next week 4/29 - 5/1",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#triage-duty",
            "text": "This week: Edgar  Next week: Mat  9 (+1) open FreshDesk tickets  1 (+0) open GGUS ticket",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#jira",
            "text": "# of tickets  \u0394  State      164  -7  Open    26  -3  In Progress    12  -5  Ready for Testing    7  +7  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#osg-software-team",
            "text": "New GLOW VO certificate?  TPC tests have been failing since 4/12 ( http://vdt.cs.wisc.edu/tests/20190412-0423/results.html )  Blahp updates    Merging relevant HTCondor patches  AI (Carl): Use the \"new\" condor env format  AI (BrianL): Proxies on WNs fail to renew",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#discussion",
            "text": "AI (Carl): will request GLOW certificate  AI (Edgar): will look into XRootD TPC tests failing, BrianL will create a ticket  AI (BrianL): Review the status of doc tickets labeled for 3.4.28  AI (BrianL): Add Diego to the software mailing list and JIRA",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#support-update",
            "text": "CMS (Marian): XRootD SAM tests are segfaulting for some sites.\n    Still investigating xrootd-python and xrootd-client.  LIGO (Edgar): are interested in opportunistic GPU usage.\n    They're configured to use PRP GPUs and we're working on getting them access to QB2E and CalTech GPUs.  NET2 (Carl, Derek): They had an issue similar to Florida but they have all of their accounting records from SGE.\n    This means that we can run a probe locally, \"faking\" any local configuration, and send records off to the GRACC.  SWT2 (BrianL): the blahp does not refresh proxies after 24h on WNs and this has bitten ATLAS.\n    Investigating potential fixes.  UFL (Carl, Derek): Records have been sent to APEL and now the WLCG needs to regenerate the reports. Out of OSG hands now.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#osg-release-team",
            "text": "3.4.28  \u0394  Status      0  +0  Open    3  +0  In Progress    12  -5  Ready for Testing    7  +7  Ready for Release    0  +0  Closed    22  +2  Total      OSG 3.4.28 - This Week  Ready for Testing  XRootD 4.9.1  StashCache/XCache (13 tickets)  MyProxy using GCT  GlideinWMS 3.4.5    Ready for Release  osg-flock 1.1: flock host DN  Upcoming: HTCondor 8.8.2      Data  Nothing    Operations  Nothing    Contrib  Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#discussion_1",
            "text": "AI (Marian, John T): Should be able to test XCache by noon Wed  AI (Edgar): Help Diego test GlideinWMS 3.4.5  AI (TimT): Request a mailing list for community testing, populate it with Topology admin contacts, and write an introductory email",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#osg-investigations-team",
            "text": "XRootD workshop will be held in France in 6-8 weeks  Some resources in topology don't have an APEL normalization factor set in topology, causing issues with APEL numbers. \n    We have opened tickets with the relevant site admins.  Accounting audit is beginning in collaboration with ATLAS.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#future",
            "text": "I would like the investigations team to make a thrust helping Ops with monitoring.  Lots of issues with things that are failing.  And who is watching the watchers (GRACC alert email wasn't being sent... watch the watchers)?  Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska, next week.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190422/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190415/",
            "text": "OSG Technology Area Meeting, 15 April 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Edgar, Marco, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Carl\n\n\nNext week: Edgar\n\n\n8 (-4) open FreshDesk tickets\n\n\n1 (+1) open GGUS tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n171\n\n\n-2\n\n\nOpen\n\n\n\n\n\n\n29\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n17\n\n\n-2\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-4\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nVO client  \n\n\nNeed to release update to voms1.fnal.gov tomorrow\n\n\nWould be nice to include updated GLOW VO cert data but not required\n\n\n\n\n\n\n3.4.29  \n\n\nIs HTCondor 8.8 ready to be moved into release?\n\n\nXCache 1.1  \n\n\ncmsd fix\n\n\nATLAS/CMS binary packages\n\n\nosg-xrootd metapackage\n\n\n\n\n\n\nHosted-CE improvements  \n\n\nosg-configure fixes\n\n\nWN client updating service on the CE\n\n\n\n\n\n\n\n\n\n\nDoc Focus 2019-04-18 1:30pm CDT\n\n\nDefault Python containers in Travis-CI will from 2.7 -> 3.6 tomorrow\n\n\nlibrary and ingwe will be retired and replaced by moria.cs.wisc.edu\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nLeave 8.8 in upcoming because of the empty daemon list may affect central managers that also run a submit host and as an execute node\n\n\nMarco expects to release a GlideinWMS 3.4.5 bug-fix by the end of this week\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nAGLT2 (BrianL): They're using \n/tmp\n for their \nOSG_WN_TMP\n and HTCondor execute directories and this is causing issues since HTCondor and user jobs fight for space.\n\n    Recommended that they move EXECUTE off of \n/tmp\n, clean \n/tmp\n periodically, and look into Docker universe jobs or cgroups.\n\n\nGlueX (Edgar): Their GlideinWMS pool is fixed; the admin updated the cert but not the key so HTCondor couldn't obtain its necessary credentials.\n\n\nLIGO (Edgar): Interested in using GPUs, we're looking to find opportunistic resources\n\n\nSWT2 (BrianL): the blahp does not appear to be refreshing proxies after 24h on WNs and this has bitten ATLAS.\n\n    Trying to determine if this is a configuration issue or a bug.\n\n\nUFL (Carl, Derek): The Jan-Feb records have been uploaded to the GRACC but we still need to resend the records to APEL.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.28\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n3\n\n\n+3\n\n\nIn Progress\n\n\n\n\n\n\n17\n\n\n+17\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n0\n\n\n+0\n\n\nClosed\n\n\n\n\n\n\n20\n\n\n+20\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.28 - Tomorrow\n\n\nReady for Testing  \n\n\nXRootD 4.9.1\n\n\nStashCache/XCache (13 tickets)\n\n\nMyProxy using GCT\n\n\nosg-flock 1.1: flock host DN\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNew DN for OSG VO?\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.27\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-2\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-5\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-19\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-4\n\n\nReady for Release\n\n\n\n\n\n\n13\n\n\n+13\n\n\nClosed\n\n\n\n\n\n\n13\n\n\n-17\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.27 - Last week\n\n\nRelease\n\n\nGridFTP using GCT\n\n\nHTCondor CE 3.2.2\n\n\nCVMFS 2.6.0\n\n\nkoji 1.11.1-1.1\n\n\nosg-pki-tools 3.2.2\n\n\ncctools 7.0.11\n\n\nosg-build 1.14.2\n\n\nUpcoming: Singularity 3.1.1\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nWe promote approximately 180 packages to testing over the year. That works out to roughly 3 packages every 4 working days.\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nDerek is busy preparing for a presentation at UNL about using the OSG as a research platform\n\n\nXRootD workshop will be held in France in 6-8 weeks\n\n\nSome resources in topology don't have an APEL normalization factor set in topology, causing issues with APEL numbers.\n    We have opened tickets with the relevant site admins.\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska, next week.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "April 15, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#osg-technology-area-meeting-15-april-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Edgar, Marco, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 15 April 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#announcements",
            "text": "",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#triage-duty",
            "text": "This week: Carl  Next week: Edgar  8 (-4) open FreshDesk tickets  1 (+1) open GGUS tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#jira",
            "text": "# of tickets  \u0394  State      171  -2  Open    29  -2  In Progress    17  -2  Ready for Testing    0  -4  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#osg-software-team",
            "text": "VO client    Need to release update to voms1.fnal.gov tomorrow  Would be nice to include updated GLOW VO cert data but not required    3.4.29    Is HTCondor 8.8 ready to be moved into release?  XCache 1.1    cmsd fix  ATLAS/CMS binary packages  osg-xrootd metapackage    Hosted-CE improvements    osg-configure fixes  WN client updating service on the CE      Doc Focus 2019-04-18 1:30pm CDT  Default Python containers in Travis-CI will from 2.7 -> 3.6 tomorrow  library and ingwe will be retired and replaced by moria.cs.wisc.edu",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#discussion",
            "text": "Leave 8.8 in upcoming because of the empty daemon list may affect central managers that also run a submit host and as an execute node  Marco expects to release a GlideinWMS 3.4.5 bug-fix by the end of this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#support-update",
            "text": "AGLT2 (BrianL): They're using  /tmp  for their  OSG_WN_TMP  and HTCondor execute directories and this is causing issues since HTCondor and user jobs fight for space. \n    Recommended that they move EXECUTE off of  /tmp , clean  /tmp  periodically, and look into Docker universe jobs or cgroups.  GlueX (Edgar): Their GlideinWMS pool is fixed; the admin updated the cert but not the key so HTCondor couldn't obtain its necessary credentials.  LIGO (Edgar): Interested in using GPUs, we're looking to find opportunistic resources  SWT2 (BrianL): the blahp does not appear to be refreshing proxies after 24h on WNs and this has bitten ATLAS. \n    Trying to determine if this is a configuration issue or a bug.  UFL (Carl, Derek): The Jan-Feb records have been uploaded to the GRACC but we still need to resend the records to APEL.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#osg-release-team",
            "text": "3.4.28  \u0394  Status      0  +0  Open    3  +3  In Progress    17  +17  Ready for Testing    0  +0  Ready for Release    0  +0  Closed    20  +20  Total      OSG 3.4.28 - Tomorrow  Ready for Testing    XRootD 4.9.1  StashCache/XCache (13 tickets)  MyProxy using GCT  osg-flock 1.1: flock host DN    Ready for Release    Nothing      Data    New DN for OSG VO?    Operations    Nothing    Contrib    Nothing        3.4.27  \u0394  Status      0  -2  Open    0  -5  In Progress    0  -19  Ready for Testing    0  -4  Ready for Release    13  +13  Closed    13  -17  Total      OSG 3.4.27 - Last week  Release  GridFTP using GCT  HTCondor CE 3.2.2  CVMFS 2.6.0  koji 1.11.1-1.1  osg-pki-tools 3.2.2  cctools 7.0.11  osg-build 1.14.2  Upcoming: Singularity 3.1.1",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#discussion_1",
            "text": "We promote approximately 180 packages to testing over the year. That works out to roughly 3 packages every 4 working days.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#osg-investigations-team",
            "text": "Derek is busy preparing for a presentation at UNL about using the OSG as a research platform  XRootD workshop will be held in France in 6-8 weeks  Some resources in topology don't have an APEL normalization factor set in topology, causing issues with APEL numbers.\n    We have opened tickets with the relevant site admins.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska, next week.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190415/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190408/",
            "text": "OSG Technology Area Meeting,  8 April 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Edgar, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: BrianL\n\n\nNext week: Carl\n\n\n12 (+1) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n173\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n31\n\n\n+3\n\n\nIn Progress\n\n\n\n\n\n\n19\n\n\n-7\n\n\nReady for Testing\n\n\n\n\n\n\n4\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nVMU tests will be moved from osghost to a VM residing on osghost (osg-sw-submit)\n\n\nlibrary and ingwe will be retired and replaced by moria.cs.wisc.edu\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nGridFTP packages are tested but MyProxy packages have not been\n\n\nXRootD 4.9.1 has been released and needs to be promoted to testing\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nGLOW (Carl): Sent in the request to UW DoIT for the new VO certificate\n\n\nGlueX (Edgar): Due to some certificate changes at the UConn frontend collector GlueX resources are unavailable to the frontends.\n    They aren't completely dead in the water, though, since they are flocking to the OSG pool.\n\n\nNotre Dame (Derek, Edgar): some extensive network usage going back to Wisconsin so they've banned the GLOW VO.\n    Currently being investigated.\n\n\nUFL (Carl, Derek): We've provided Bockjoo a custom package to fix his missing accounting data from Jan/Feb.\n    There may be some complications because they have a temporary\n\n\nUConn (Mat, Derek): setting up a StashCache origin is getting complicated to fetch from their local dCache.\n    Their XRootD-dCache is reporting to the OSG redirector (Freshdesk 8513)\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.27\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n2\n\n\n+1\n\n\nOpen\n\n\n\n\n\n\n5\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n19\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n4\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n0\n\n\n+0\n\n\nClosed\n\n\n\n\n\n\n30\n\n\n+1\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.27 - This week\n\n\nReady for Testing  \n\n\nStashCache/XCache (13 tickets)\n\n\nHTCondor CE 3.2.2\n\n\nMyProxy using GCT\n\n\ncctools 7.0.11\n\n\n\n\n\n\nReady for Release  \n\n\nGridFTP using GCT\n\n\nCVMFS 2.6.0\n\n\nkoji 1.11.1-1.1\n\n\nosg-pki-tools 3.2.1\n\n\n\n\n\n\n\n\n\n\nData\n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Determine the number of times we've promoted packages to testing to see if we need a new mailing list for the community testing announcements\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nMoving forward with new SciTokens setup at OSG-Connect.  Need to coordinate switchover.  Daily poking of osg-connect team.  Admittidely, they seem un-motivated.  Will motivate with... snacks?\n\n\nDerek's current status: In bunker, writing.\n\n\nInvestigating check\nmk\n probe that will check the status of hosted-ce's.  Direct query of glideinwms factory seems dubious.\n\n\n\n\nFuture\n\u00b6\n\n\n\n\nLots of GRACC questions: \nhttps://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska, next week.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "April 8, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#osg-technology-area-meeting-8-april-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Edgar, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting,  8 April 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#announcements",
            "text": "",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#triage-duty",
            "text": "This week: BrianL  Next week: Carl  12 (+1) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#jira",
            "text": "# of tickets  \u0394  State      173  +0  Open    31  +3  In Progress    19  -7  Ready for Testing    4  +1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#osg-software-team",
            "text": "VMU tests will be moved from osghost to a VM residing on osghost (osg-sw-submit)  library and ingwe will be retired and replaced by moria.cs.wisc.edu",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#discussion",
            "text": "GridFTP packages are tested but MyProxy packages have not been  XRootD 4.9.1 has been released and needs to be promoted to testing",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#support-update",
            "text": "GLOW (Carl): Sent in the request to UW DoIT for the new VO certificate  GlueX (Edgar): Due to some certificate changes at the UConn frontend collector GlueX resources are unavailable to the frontends.\n    They aren't completely dead in the water, though, since they are flocking to the OSG pool.  Notre Dame (Derek, Edgar): some extensive network usage going back to Wisconsin so they've banned the GLOW VO.\n    Currently being investigated.  UFL (Carl, Derek): We've provided Bockjoo a custom package to fix his missing accounting data from Jan/Feb.\n    There may be some complications because they have a temporary  UConn (Mat, Derek): setting up a StashCache origin is getting complicated to fetch from their local dCache.\n    Their XRootD-dCache is reporting to the OSG redirector (Freshdesk 8513)",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#osg-release-team",
            "text": "3.4.27  \u0394  Status      2  +1  Open    5  -1  In Progress    19  +0  Ready for Testing    4  +1  Ready for Release    0  +0  Closed    30  +1  Total      OSG 3.4.27 - This week  Ready for Testing    StashCache/XCache (13 tickets)  HTCondor CE 3.2.2  MyProxy using GCT  cctools 7.0.11    Ready for Release    GridFTP using GCT  CVMFS 2.6.0  koji 1.11.1-1.1  osg-pki-tools 3.2.1      Data  Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#discussion_1",
            "text": "AI (TimT): Determine the number of times we've promoted packages to testing to see if we need a new mailing list for the community testing announcements",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#osg-investigations-team",
            "text": "Moving forward with new SciTokens setup at OSG-Connect.  Need to coordinate switchover.  Daily poking of osg-connect team.  Admittidely, they seem un-motivated.  Will motivate with... snacks?  Derek's current status: In bunker, writing.  Investigating check mk  probe that will check the status of hosted-ce's.  Direct query of glideinwms factory seems dubious.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#future",
            "text": "Lots of GRACC questions:  https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska, next week.",
            "title": "Future"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190408/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190401/",
            "text": "OSG Technology Area Meeting, 1 April 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n Carl, Derek, Edgar, Mat, Tim\n\n\nAnnouncements\n\u00b6\n\n\n\n\nBrianL OOO 3/28 - 4/5 (ISGC Taiwan, vacation)\n\n\nTimT OOO 4/3 - 4/5 (Vacation)\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: ? (need to make new triage schedule?)\n\n\n11 (+7) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n173\n\n\n+3\n\n\nOpen\n\n\n\n\n\n\n28\n\n\n+0\n\n\nIn Progress\n\n\n\n\n\n\n26\n\n\n+10\n\n\nReady for Testing\n\n\n\n\n\n\n3\n\n\n+3\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.27\n\n\nOSG-Build 1.14.2+ needs promotion (SOFTWARE-3622)\n\n\nXCache documentation updates need review (multiple)\n\n\nGlideinWMS 3.4.3 maybe?\n\n\nCCTools 7.0.11 maybe? (Carl)\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nEdgar may be able to take GlideinWMS ticket but might have found another bug\n  so needs to do some patching?  Will check to see if the new version fixes the\n  bug.\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nCarl still working on Florida accounting issue; hopes to be done later this week\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.27\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n1\n\n\n-13\n\n\nOpen\n\n\n\n\n\n\n6\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n19\n\n\n+3\n\n\nReady for Testing\n\n\n\n\n\n\n3\n\n\n+3\n\n\nReady for Release\n\n\n\n\n\n\n0\n\n\n+0\n\n\nClosed\n\n\n\n\n\n\n29\n\n\n-8\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.27\n\n\nReady for Testing  \n\n\nGlobus Packages using GCT\n\n\nStashCache/XCache (13 tickets)\n\n\nHTCondor CE 3.2.2\n\n\n\n\n\n\nReady for Release  \n\n\nCVMFS 2.6.0\n\n\nkoji 1.11.1-1.1\n\n\n\n\n\n\n\n\n\n\nData - Tomorrow\n\n\nIGTF 1.97\n\n\nVO Package v87\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Determine the number of times we've promoted packages to testing to see if we need a new mailing list for the community testing announcements\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nLots of GRACC questions: https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642\n\n\nMoving forward with new SciTokens setup at OSG-Connect.  Need to coordinate switchover.\n\n\nDerek is disappearing into a bunker to write paper.\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska, next week.\n\n\nInvestigating check_mk probe that will check the status of hosted-ce's.  Direct query of glideinwms factory seems dubious.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "April 1, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#osg-technology-area-meeting-1-april-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  Carl, Derek, Edgar, Mat, Tim",
            "title": "OSG Technology Area Meeting, 1 April 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#announcements",
            "text": "BrianL OOO 3/28 - 4/5 (ISGC Taiwan, vacation)  TimT OOO 4/3 - 4/5 (Vacation)",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#triage-duty",
            "text": "This week: Mat  Next week: ? (need to make new triage schedule?)  11 (+7) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#jira",
            "text": "# of tickets  \u0394  State      173  +3  Open    28  +0  In Progress    26  +10  Ready for Testing    3  +3  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#osg-software-team",
            "text": "3.4.27  OSG-Build 1.14.2+ needs promotion (SOFTWARE-3622)  XCache documentation updates need review (multiple)  GlideinWMS 3.4.3 maybe?  CCTools 7.0.11 maybe? (Carl)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#discussion",
            "text": "Edgar may be able to take GlideinWMS ticket but might have found another bug\n  so needs to do some patching?  Will check to see if the new version fixes the\n  bug.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#support-update",
            "text": "Carl still working on Florida accounting issue; hopes to be done later this week",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#osg-release-team",
            "text": "3.4.27  \u0394  Status      1  -13  Open    6  -1  In Progress    19  +3  Ready for Testing    3  +3  Ready for Release    0  +0  Closed    29  -8  Total      OSG 3.4.27  Ready for Testing    Globus Packages using GCT  StashCache/XCache (13 tickets)  HTCondor CE 3.2.2    Ready for Release    CVMFS 2.6.0  koji 1.11.1-1.1      Data - Tomorrow  IGTF 1.97  VO Package v87    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#discussion_1",
            "text": "AI (TimT): Determine the number of times we've promoted packages to testing to see if we need a new mailing list for the community testing announcements",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#osg-investigations-team",
            "text": "Lots of GRACC questions: https://opensciencegrid.atlassian.net/browse/SOFTWARE-3642  Moving forward with new SciTokens setup at OSG-Connect.  Need to coordinate switchover.  Derek is disappearing into a bunker to write paper.  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska, next week.  Investigating check_mk probe that will check the status of hosted-ce's.  Direct query of glideinwms factory seems dubious.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190401/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190325/",
            "text": "OSG Technology Area Meeting, 25 March 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Derek, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nHEPiX this week at UCSD\n\n\nBrianL OOO 3/28 - 4/5 (ISGC Taiwan, vacation)\n\n\nIRIS-HEP topical meeting about CDNs at 11:30am CDT\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: TimT\n\n\nNext week: Mat\n\n\n4 (+0) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n170\n\n\n+2\n\n\nOpen\n\n\n\n\n\n\n28\n\n\n-12\n\n\nIn Progress\n\n\n\n\n\n\n16\n\n\n+13\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.27  \n\n\nAI (Mat): request promotion for XRootD pre-pre-release\n\n\nAI (Mat): osg-build-1.14.2+ (SOFTWARE-3622)\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (Mat): Needs to look into osg-build test failures before tagging/building osg-build\n\n\nAI (TimT): Kick off condor pre-release smoke tests while Carl is out\n\n\nMarian will be at CERN next week\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nSyracuse (Derek): Help with startup time of Syracuse.  Eric's goal is to fill 30k cores in ~1hour.  Is that possible?  Will talk with factory ops.\n\n\nGlueX (Derek): From Richard Jones' talk at HOW, \nhttps://indico.cern.ch/event/759388/contributions/3352640/\n.  I got the 57 page notebook of problems he had.  Will read through them to see if there are any actionable items for Bosco/HTCondor/Blahp\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.27\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n14\n\n\n+14\n\n\nOpen\n\n\n\n\n\n\n7\n\n\n+7\n\n\nIn Progress\n\n\n\n\n\n\n16\n\n\n+16\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n0\n\n\n+0\n\n\nClosed\n\n\n\n\n\n\n37\n\n\n+37\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.27\n\n\nReady for Testing  \n\n\nGlobus Packages using GCT\n\n\nkoji 1.11.1-1.1\n\n\nCVMFS 2.6.0\n\n\nStashCache/XCache (13 tickets)\n\n\n\n\n\n\nReady for Release  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nIGTF 1.97\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.26\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-11\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-17\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-4\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n4\n\n\n+4\n\n\nClosed\n\n\n\n\n\n\n4\n\n\n-28\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.25\n\n\nReleased\n\n\nSingalarity 3.1.0\n\n\ncctools 7.0.9\n\n\nosg-pki-tools 3.1.0\n\n\nPegasus 4.9.1\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Reach out to users to find MyProxy testers\n\n\nAI (TimT): Assign UNL to test the new version of XCache\n\n\nAI (TimT): Determine the number of times we've promoted packages to testing to see if we need a new mailing list for the community testing announcements\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nPerfSonar collectors = DONE\n\n\nLots of GRACC questions at HOW, will likely take development\n\n\nMoving forward with new SciTokens setup at OSG-Connect.  Need to coordinate switchover.\n\n\nWhat would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska.\n\n\nStashCache paper accepted to PEARC, will likely disappear into a bunker to write.\n\n\nLots of good press about StashCache / Xcache at HOW.  Want to build off of that.\n\n\nInvestigating check_mk probe that will check the status of hosted-ce's.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "March 25, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#osg-technology-area-meeting-25-march-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Derek, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 25 March 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#announcements",
            "text": "HEPiX this week at UCSD  BrianL OOO 3/28 - 4/5 (ISGC Taiwan, vacation)  IRIS-HEP topical meeting about CDNs at 11:30am CDT",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#triage-duty",
            "text": "This week: TimT  Next week: Mat  4 (+0) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#jira",
            "text": "# of tickets  \u0394  State      170  +2  Open    28  -12  In Progress    16  +13  Ready for Testing    0  -0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#osg-software-team",
            "text": "3.4.27    AI (Mat): request promotion for XRootD pre-pre-release  AI (Mat): osg-build-1.14.2+ (SOFTWARE-3622)",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#discussion",
            "text": "AI (Mat): Needs to look into osg-build test failures before tagging/building osg-build  AI (TimT): Kick off condor pre-release smoke tests while Carl is out  Marian will be at CERN next week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#support-update",
            "text": "Syracuse (Derek): Help with startup time of Syracuse.  Eric's goal is to fill 30k cores in ~1hour.  Is that possible?  Will talk with factory ops.  GlueX (Derek): From Richard Jones' talk at HOW,  https://indico.cern.ch/event/759388/contributions/3352640/ .  I got the 57 page notebook of problems he had.  Will read through them to see if there are any actionable items for Bosco/HTCondor/Blahp",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#osg-release-team",
            "text": "3.4.27  \u0394  Status      14  +14  Open    7  +7  In Progress    16  +16  Ready for Testing    0  +0  Ready for Release    0  +0  Closed    37  +37  Total      OSG 3.4.27  Ready for Testing    Globus Packages using GCT  koji 1.11.1-1.1  CVMFS 2.6.0  StashCache/XCache (13 tickets)    Ready for Release    Nothing      Data    IGTF 1.97    Operations    Nothing    Contrib    Nothing        3.4.26  \u0394  Status      0  -11  Open    0  -17  In Progress    0  -4  Ready for Testing    0  +0  Ready for Release    4  +4  Closed    4  -28  Total      OSG 3.4.25  Released  Singalarity 3.1.0  cctools 7.0.9  osg-pki-tools 3.1.0  Pegasus 4.9.1",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#discussion_1",
            "text": "AI (TimT): Reach out to users to find MyProxy testers  AI (TimT): Assign UNL to test the new version of XCache  AI (TimT): Determine the number of times we've promoted packages to testing to see if we need a new mailing list for the community testing announcements",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#osg-investigations-team",
            "text": "PerfSonar collectors = DONE  Lots of GRACC questions at HOW, will likely take development  Moving forward with new SciTokens setup at OSG-Connect.  Need to coordinate switchover.  What would it take to run HTCondor-CE gratia probe on a slurm cluster?  Will start investigating with Nebraska.  StashCache paper accepted to PEARC, will likely disappear into a bunker to write.  Lots of good press about StashCache / Xcache at HOW.  Want to build off of that.  Investigating check_mk probe that will check the status of hosted-ce's.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190325/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190311/",
            "text": "OSG Technology Area Meeting, 11 March 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Edgar, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nHOW 2019 site admin training Thurs morning\n\n\nEdgar will be attending the Singularity user group meeting Tue/Wed\n\n\nEdgar won't be at the AHM\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Carl\n\n\nNext week: Edgar\n\n\n4 (-1) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n162\n\n\n+3\n\n\nOpen\n\n\n\n\n\n\n41\n\n\n+4\n\n\nIn Progress\n\n\n\n\n\n\n4\n\n\n-6\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-5\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.26\n\n\nAI (Carl, Mat): Tag and build new osg-build\n\n\nAI (Mat): Is XCache 1.0.2 ready?\n\n\nGlideinWMS 3.4.4 and XRootD 4.9.1 expected this week\n\n\n\n\n\n\nUpdate your koji configuration with \nosg-koji setup\n this week\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nYou can use the 'latest' branch from the osg-build GitHub repository if you'd like the latest released version of osg-build\n\n\nMat has tested stash-cache 1.0.2 but not the origin.\n    We decided that we should not hold the tag and build back for extensive origin testing since there are so many tickets.\n\n\nWe don't believe we'll have to rebuild the various XRootD plugins for 4.9.1\n\n\nCarl thinks he has a simple fix for Bockjoo's missing accounting records and will coordinate with Derek for applying it.\n    We discussed that we should test this on a few records first before running it over the entirety of the folder\n\n\nCarl contacted slurm-users about the supported Slurm versions but only got a sales pitch.\n    Derek will get us the version that UNL uses and we will likely use the version that we test in the nightlies as a baseline.\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nJLab (Edgar): Gratia probe was misconfigured so we haven't been getting records for a few months.\n    Gratia was failing immediately so there's a good chance that the history files are still there and that we can fix the configuration and get all of the missing records.\n\n\nStashCache (Edgar): the European StashCache is being overly utilized, users in Europe are being routed to NYC back to Amsterdam.\n    Edgar will coordinate with Geant to try and get this fixed.\n\n\nUFL (Carl, Derek): Missing January accounting records due to a Slurm update that broke our database queries.\n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.25\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-10\n\n\nOpen\n\n\n\n\n\n\n0\n\n\n-12\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-4\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n-5\n\n\nReady for Release\n\n\n\n\n\n\n6\n\n\n+5\n\n\nClosed\n\n\n\n\n\n\n6\n\n\n-26\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.25  \n\n\nReleased\n\n\ngsi-openssh\n\n\nxrootd-lcmaps 1.7.0 (EL6 and EL7)\n\n\nHTCondor 8.6.13-1.2\n\n\nKoji 1.11.1\n\n\nosg-tested-internal 3.4-7\n\n\nUpcoming  \n\n\nHTCondor 8.8.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.26\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n11\n\n\n+11\n\n\nOpen\n\n\n\n\n\n\n17\n\n\n+17\n\n\nIn Progress\n\n\n\n\n\n\n4\n\n\n+4\n\n\nReady for Testing\n\n\n\n\n\n\n0\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n0\n\n\n+0\n\n\nClosed\n\n\n\n\n\n\n32\n\n\n+32\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.25\n\n\nReady for Testing\n\n\nSingalarity 3.1.0\n\n\nGlobus Packages using GCT\n\n\ncctools 7.0.9\n\n\n\n\n\n\nReady for Release\n\n\nNothing\n\n\n\n\n\n\n\n\n\n\nData\n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nEdgar will test GlideinWMS when it arrives\n\n\nWill release Singularity, cctools, most likely Globus pacakges this week\n\n\nNeed to start testing XCache software\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nNew Perfsonar collectors.. almost done!  Waiting 24 hours for green light to switch over to production!\n\n\nCreating small script to create check_mk availability spreadsheet for OSG Ops.  Now in development.\n\n\nNew SciTokens setup at osg-connect.  Will be following up with the osg-connect ops and user support teams.  Will need to coordinate with both.  Created a project plan, but hit snag on the first step.  The new glideins don't work, everything else is on hold.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6",
            "title": "March 11, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#osg-technology-area-meeting-11-march-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Edgar, Mat, TimT",
            "title": "OSG Technology Area Meeting, 11 March 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#announcements",
            "text": "HOW 2019 site admin training Thurs morning  Edgar will be attending the Singularity user group meeting Tue/Wed  Edgar won't be at the AHM",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#triage-duty",
            "text": "This week: Carl  Next week: Edgar  4 (-1) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#jira",
            "text": "# of tickets  \u0394  State      162  +3  Open    41  +4  In Progress    4  -6  Ready for Testing    0  -5  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#osg-software-team",
            "text": "3.4.26  AI (Carl, Mat): Tag and build new osg-build  AI (Mat): Is XCache 1.0.2 ready?  GlideinWMS 3.4.4 and XRootD 4.9.1 expected this week    Update your koji configuration with  osg-koji setup  this week",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#discussion",
            "text": "You can use the 'latest' branch from the osg-build GitHub repository if you'd like the latest released version of osg-build  Mat has tested stash-cache 1.0.2 but not the origin.\n    We decided that we should not hold the tag and build back for extensive origin testing since there are so many tickets.  We don't believe we'll have to rebuild the various XRootD plugins for 4.9.1  Carl thinks he has a simple fix for Bockjoo's missing accounting records and will coordinate with Derek for applying it.\n    We discussed that we should test this on a few records first before running it over the entirety of the folder  Carl contacted slurm-users about the supported Slurm versions but only got a sales pitch.\n    Derek will get us the version that UNL uses and we will likely use the version that we test in the nightlies as a baseline.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#support-update",
            "text": "JLab (Edgar): Gratia probe was misconfigured so we haven't been getting records for a few months.\n    Gratia was failing immediately so there's a good chance that the history files are still there and that we can fix the configuration and get all of the missing records.  StashCache (Edgar): the European StashCache is being overly utilized, users in Europe are being routed to NYC back to Amsterdam.\n    Edgar will coordinate with Geant to try and get this fixed.  UFL (Carl, Derek): Missing January accounting records due to a Slurm update that broke our database queries.\n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#osg-release-team",
            "text": "3.4.25  \u0394  Status      0  -10  Open    0  -12  In Progress    0  -4  Ready for Testing    0  -5  Ready for Release    6  +5  Closed    6  -26  Total      OSG 3.4.25    Released  gsi-openssh  xrootd-lcmaps 1.7.0 (EL6 and EL7)  HTCondor 8.6.13-1.2  Koji 1.11.1  osg-tested-internal 3.4-7  Upcoming    HTCondor 8.8.1            3.4.26  \u0394  Status      11  +11  Open    17  +17  In Progress    4  +4  Ready for Testing    0  +0  Ready for Release    0  +0  Closed    32  +32  Total      OSG 3.4.25  Ready for Testing  Singalarity 3.1.0  Globus Packages using GCT  cctools 7.0.9    Ready for Release  Nothing      Data  Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#discussion_1",
            "text": "Edgar will test GlideinWMS when it arrives  Will release Singularity, cctools, most likely Globus pacakges this week  Need to start testing XCache software",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#osg-investigations-team",
            "text": "New Perfsonar collectors.. almost done!  Waiting 24 hours for green light to switch over to production!  Creating small script to create check_mk availability spreadsheet for OSG Ops.  Now in development.  New SciTokens setup at osg-connect.  Will be following up with the osg-connect ops and user support teams.  Will need to coordinate with both.  Created a project plan, but hit snag on the first step.  The new glideins don't work, everything else is on hold.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190311/#discussions",
            "text": "",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190304/",
            "text": "OSG Technology Area Meeting,  4 March 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n   \n\n\nAnnouncements\n\u00b6\n\n\nHOW 2019 site admin training Thurs morning  \n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: BrianL\n\n\nNext week: Carl\n\n\n5 (+0) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n159\n\n\n-89\n\n\nOpen\n\n\n\n\n\n\n37\n\n\n+1\n\n\nIn Progress\n\n\n\n\n\n\n10\n\n\n+6\n\n\nReady for Testing\n\n\n\n\n\n\n5\n\n\n+3\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.25  \n\n\nAdded sha1sums for osg-import-srpm. Are there any other osg-build changes?\n\n\nAI (Mat): follow-up with Andy regarding the XRootD 4.9.0 POSIX segfaults\n\n\nAI (Mat): Go through XCache 1.0 tickets and verify RFT status\n\n\n\n\n\n\nDoc Focus  \n\n\nNext doc focus Mar 7\n\n\nAI (BrianL): PR reviews\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nSupport Update\n\u00b6\n\n\n\n\nUFL (Carl, Derek): Missing January accounting records due to a Slurm update that broke our database queries.\n\n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.25\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n10\n\n\n-1\n\n\nOpen\n\n\n\n\n\n\n12\n\n\n+1\n\n\nIn Progress\n\n\n\n\n\n\n4\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n5\n\n\n+3\n\n\nReady for Release\n\n\n\n\n\n\n1\n\n\n+0\n\n\nClosed\n\n\n\n\n\n\n32\n\n\n+3\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.25  \n\n\nReady for Testing  \n\n\nXRootD 4.9.0\n\n\ngsi-openssh\n\n\nGlobus Packages\n\n\ncctools 7.0.9\n\n\n\n\n\n\nReady for Release  \n\n\nxrootd-lcmaps 1.7.0 (EL6 and EL7)\n\n\nHTCondor 8.6.13-1.2\n\n\nKoji 1.11.1\n\n\nosg-tested-internal 3.4-7\n\n\nUpcoming  \n\n\nHTCondor 8.8.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData - Today\n\n\nIGTF 1.96\n\n\nVO Package v86\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nHave Lincoln test gsi-openssh at GATech\n\n\nRelease what we have this week\n\n\nCheck with Dan Bradley (and Carl) about testing backup lz VOMS admin server\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nNew Perfsonar collectors.. sidelined.\n\n\nTicket support on topology on hold temporarily.\n\n\nCreating small script to create check_mk availability spreadsheet for OSG Ops.\n\n\nNew SciTokens setup at osg-connect.  Will be following up with the osg-connect ops and user support teams.  Will need to coordinate with both.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "March 4, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#osg-technology-area-meeting-4-march-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:",
            "title": "OSG Technology Area Meeting,  4 March 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#announcements",
            "text": "HOW 2019 site admin training Thurs morning",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#triage-duty",
            "text": "This week: BrianL  Next week: Carl  5 (+0) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#jira",
            "text": "# of tickets  \u0394  State      159  -89  Open    37  +1  In Progress    10  +6  Ready for Testing    5  +3  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#osg-software-team",
            "text": "3.4.25    Added sha1sums for osg-import-srpm. Are there any other osg-build changes?  AI (Mat): follow-up with Andy regarding the XRootD 4.9.0 POSIX segfaults  AI (Mat): Go through XCache 1.0 tickets and verify RFT status    Doc Focus    Next doc focus Mar 7  AI (BrianL): PR reviews",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#discussion",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#support-update",
            "text": "UFL (Carl, Derek): Missing January accounting records due to a Slurm update that broke our database queries. \n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#osg-release-team",
            "text": "3.4.25  \u0394  Status      10  -1  Open    12  +1  In Progress    4  +0  Ready for Testing    5  +3  Ready for Release    1  +0  Closed    32  +3  Total      OSG 3.4.25    Ready for Testing    XRootD 4.9.0  gsi-openssh  Globus Packages  cctools 7.0.9    Ready for Release    xrootd-lcmaps 1.7.0 (EL6 and EL7)  HTCondor 8.6.13-1.2  Koji 1.11.1  osg-tested-internal 3.4-7  Upcoming    HTCondor 8.8.1        Data - Today  IGTF 1.96  VO Package v86    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#discussion_1",
            "text": "Have Lincoln test gsi-openssh at GATech  Release what we have this week  Check with Dan Bradley (and Carl) about testing backup lz VOMS admin server",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#osg-investigations-team",
            "text": "New Perfsonar collectors.. sidelined.  Ticket support on topology on hold temporarily.  Creating small script to create check_mk availability spreadsheet for OSG Ops.  New SciTokens setup at osg-connect.  Will be following up with the osg-connect ops and user support teams.  Will need to coordinate with both.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190304/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190225/",
            "text": "OSG Technology Area Meeting, 25 February 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Edgar, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nHOW 2019 site admin training Thurs morning\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: BrianL\n\n\nNext week: BrianL (?)\n\n\n5 (-3) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n167\n\n\n+5\n\n\nOpen\n\n\n\n\n\n\n36\n\n\n-5\n\n\nIn Progress\n\n\n\n\n\n\n4\n\n\n-9\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nosghost downtime today\n\n\nEmail blast sent out to HTCondor-CE admins to update to >= 3.2.0 before April\n\n\n3.4.25  \n\n\nAI (Mat): globus package updates need to be completed by COB Thursday\n\n\nAI (Mat): Go through XCache 1.0 tickets and verify RFT status\n\n\nAI (Edgar): TPC tests need to be completed by COB Thursday\n\n\n\n\n\n\nDoc Focus  \n\n\nNext doc focus Mar 7\n\n\nAI (BrianL): PR reviews\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (Carl): Coordinate with Mat and send email about new osg-build version\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nBU (BrianL): Assisted with Globus/Rucio package installation\n\n\nLSU (BrianL, Edgar): Attended phone call to discussion package installation, potential addition of another cluster\n\n\nSyracuse (BrianL, Edgar): Multiple VOs have reported issues with their Squid cache.\n\n    We've contacted admins there to ask about the status of additional Squid hosts.\n\n\nUFL (Carl, Derek): Missing January accounting records due to a Slurm update that broke our database queries.\n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.24\n\n\n\u0394;\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n14\n\n\n+1\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.24  \n\n\nReady for Release\n\n\nosg-pki-tools - multi-word states\n\n\ngsi-openssh 7.4p1-2.3\n\n\nGlideinWMS 3.4.3 (failed?)\n\n\nxrootd-lcmaps 1.7.0\n\n\ncondor-cron, htcondor-ce - ALLOW\nREAD\n=*\n\n\nosg-test 2.3.1\n\n\nUpcoming  \n\n\nHDFS-FUSE for EL6\n\n\nSingularity 3.0.3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperations  \n\n\nosg-repo-scripts 1.3-1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.25\n\n\n\u0394;\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n11\n\n\n+11\n\n\nOpen\n\n\n\n\n\n\n11\n\n\n+11\n\n\nIn Progress\n\n\n\n\n\n\n4\n\n\n+4\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+2\n\n\nReady for Release\n\n\n\n\n\n\n1\n\n\n+1\n\n\nClosed\n\n\n\n\n\n\n29\n\n\n+29\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.25\n\n\nReady for Testing\n\n\nXRootD 4.9.0\n\n\ngsi-openssh\n\n\nGlideinWMS 3.4.3\n\n\nKoji 1.11.1\n\n\n\n\n\n\nReady for Release\n\n\nxrootd-lcmaps 1.7.0 (EL6 and EL7)\n\n\nUpcoming\n\n\nHTCondor 8.8.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData\n\n\nIGTF 1.96\n\n\n\n\n\n\nOperations\n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nDue to expiring OSG CA issued VO certificates, we expect to see many vo-client updates over the coming months.\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nNew Perfsonar collectors testing in parallel data pipeline.  1/2 Deployed in production.  This week will be the other 1/2.\n\n\nPEARC paper submitted!\n\n\nXRootD 4.9 released!\n\n\nFew minor changes to the ticket, then will re-review and deploy ticket creation to topology.opensciencegrid.org/ticket\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "February 25, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#osg-technology-area-meeting-25-february-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Edgar, Mat, TimT",
            "title": "OSG Technology Area Meeting, 25 February 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#announcements",
            "text": "HOW 2019 site admin training Thurs morning",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#triage-duty",
            "text": "This week: BrianL  Next week: BrianL (?)  5 (-3) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#jira",
            "text": "# of tickets  \u0394  State      167  +5  Open    36  -5  In Progress    4  -9  Ready for Testing    2  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#osg-software-team",
            "text": "osghost downtime today  Email blast sent out to HTCondor-CE admins to update to >= 3.2.0 before April  3.4.25    AI (Mat): globus package updates need to be completed by COB Thursday  AI (Mat): Go through XCache 1.0 tickets and verify RFT status  AI (Edgar): TPC tests need to be completed by COB Thursday    Doc Focus    Next doc focus Mar 7  AI (BrianL): PR reviews",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#discussion",
            "text": "AI (Carl): Coordinate with Mat and send email about new osg-build version",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#support-update",
            "text": "BU (BrianL): Assisted with Globus/Rucio package installation  LSU (BrianL, Edgar): Attended phone call to discussion package installation, potential addition of another cluster  Syracuse (BrianL, Edgar): Multiple VOs have reported issues with their Squid cache. \n    We've contacted admins there to ask about the status of additional Squid hosts.  UFL (Carl, Derek): Missing January accounting records due to a Slurm update that broke our database queries.\n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#osg-release-team",
            "text": "3.4.24  \u0394;  Status      14  +1  Total      OSG 3.4.24    Ready for Release  osg-pki-tools - multi-word states  gsi-openssh 7.4p1-2.3  GlideinWMS 3.4.3 (failed?)  xrootd-lcmaps 1.7.0  condor-cron, htcondor-ce - ALLOW READ =*  osg-test 2.3.1  Upcoming    HDFS-FUSE for EL6  Singularity 3.0.3        Operations    osg-repo-scripts 1.3-1        3.4.25  \u0394;  Status      11  +11  Open    11  +11  In Progress    4  +4  Ready for Testing    2  +2  Ready for Release    1  +1  Closed    29  +29  Total      OSG 3.4.25  Ready for Testing  XRootD 4.9.0  gsi-openssh  GlideinWMS 3.4.3  Koji 1.11.1    Ready for Release  xrootd-lcmaps 1.7.0 (EL6 and EL7)  Upcoming  HTCondor 8.8.1        Data  IGTF 1.96    Operations  Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#discussion_1",
            "text": "Due to expiring OSG CA issued VO certificates, we expect to see many vo-client updates over the coming months.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#osg-investigations-team",
            "text": "New Perfsonar collectors testing in parallel data pipeline.  1/2 Deployed in production.  This week will be the other 1/2.  PEARC paper submitted!  XRootD 4.9 released!  Few minor changes to the ticket, then will re-review and deploy ticket creation to topology.opensciencegrid.org/ticket",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190225/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190218/",
            "text": "OSG Technology Area Meeting, 18 February 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: BrianL\n\n\n8 (+0) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n162\n\n\n+5\n\n\nOpen\n\n\n\n\n\n\n41\n\n\n-2\n\n\nIn Progress\n\n\n\n\n\n\n13\n\n\n+11\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.24  \n\n\nAI (BrianL): Minor bug in the state option in osg-pki-tools (SOFTWARE-3591)\n\n\nAI (Carl/Mat): osg-build promotion to testing?\n\n\nAI (Edgar): TPC test status?\n\n\n\n\n\n\nAI (TimT): Contact CE site admins to update to HTCondor-CE >= 3.2.0\n\n\nAI (Brian, Carl, Mat): Fill out OSG service security spreadsheet by COB Thursday\n\n\nDoc Focus  \n\n\nNext doc focus either Mar 7 or 14\n\n\nAI (BrianL): PR reviews\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nSupport Update\n\u00b6\n\n\n\n\nUFL (Marian): multi-user XRootD plugin is not playing well with throttle plugin (\nhttps://github.com/xrootd/xrootd/issues/908\n)\n\n\nUFL (Derek, Carl): Missing January accounting records due to a Slurm update that broke our database queries.\n\n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).\n\n\nxrdfs (Marian): some inconsistencies between xrdfs and xrdcp. Contacted the XRootD team and they're investigating.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.24\n\n\n\u0394;\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-9\n\n\nOpen\n\n\n\n\n\n\n2\n\n\n-16\n\n\nIn Progress\n\n\n\n\n\n\n9\n\n\n+7\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n13\n\n\n-18\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.24  \n\n\nReady for Testing  \n\n\ngsi-openssh 7.4p1-2.3\n\n\nGlideinWMS 3.4.3 (failed?)\n\n\nxrootd-lcmaps 1.7.0\n\n\ncondor-cron, htcondor-ce - ALLOW_READ=*\n\n\nosg-test 2.3.1\n\n\n\n\n\n\nReady for Release  \n\n\nUpcoming  \n\n\nHDFS-FUSE for EL6\n\n\nSingularity 3.0.3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nosg-repo-scripts 1.3-1\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nNew Perfsonar collectors testing in parallel data pipeline.  1/2 Deployed in production.\n\n\nStill waiting on XRootD 4.9 release for XCache 1.0\n\n\nWriting PEARC paper for StashCache, will be submitted on Wed.\n\n\nDeployed testing ticket creation to topology-itb.opensciencegrid.org/ticket\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nWe need to communicate with Freshdesk agents that CCs are visible when responding to tickets.",
            "title": "February 18, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#osg-technology-area-meeting-18-february-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 18 February 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#announcements",
            "text": "",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#triage-duty",
            "text": "This week: Mat  Next week: BrianL  8 (+0) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#jira",
            "text": "# of tickets  \u0394  State      162  +5  Open    41  -2  In Progress    13  +11  Ready for Testing    2  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#osg-software-team",
            "text": "3.4.24    AI (BrianL): Minor bug in the state option in osg-pki-tools (SOFTWARE-3591)  AI (Carl/Mat): osg-build promotion to testing?  AI (Edgar): TPC test status?    AI (TimT): Contact CE site admins to update to HTCondor-CE >= 3.2.0  AI (Brian, Carl, Mat): Fill out OSG service security spreadsheet by COB Thursday  Doc Focus    Next doc focus either Mar 7 or 14  AI (BrianL): PR reviews",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#discussion",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#support-update",
            "text": "UFL (Marian): multi-user XRootD plugin is not playing well with throttle plugin ( https://github.com/xrootd/xrootd/issues/908 )  UFL (Derek, Carl): Missing January accounting records due to a Slurm update that broke our database queries. \n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).  xrdfs (Marian): some inconsistencies between xrdfs and xrdcp. Contacted the XRootD team and they're investigating.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#osg-release-team",
            "text": "3.4.24  \u0394;  Status      0  -9  Open    2  -16  In Progress    9  +7  Ready for Testing    2  +0  Ready for Release    13  -18  Total      OSG 3.4.24    Ready for Testing    gsi-openssh 7.4p1-2.3  GlideinWMS 3.4.3 (failed?)  xrootd-lcmaps 1.7.0  condor-cron, htcondor-ce - ALLOW_READ=*  osg-test 2.3.1    Ready for Release    Upcoming    HDFS-FUSE for EL6  Singularity 3.0.3        Data    Nothing    Operations    osg-repo-scripts 1.3-1    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#osg-investigations-team",
            "text": "New Perfsonar collectors testing in parallel data pipeline.  1/2 Deployed in production.  Still waiting on XRootD 4.9 release for XCache 1.0  Writing PEARC paper for StashCache, will be submitted on Wed.  Deployed testing ticket creation to topology-itb.opensciencegrid.org/ticket",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190218/#discussions",
            "text": "We need to communicate with Freshdesk agents that CCs are visible when responding to tickets.",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190211/",
            "text": "OSG Technology Area Meeting, 11 February 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Edgar, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Edgar\n\n\nNext week: Mat\n\n\n8 (+1) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n157\n\n\n+7\n\n\nOpen\n\n\n\n\n\n\n43\n\n\n+5\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.24  \n\n\nXRootD 4.9.0 RC5 built, RC6 expected soon\n\n\nAI (BrianL): HTCondor-CE and condor-cron builds to support HTCondor 8.9.0\n\n\nAI (Edgar): TPC test setup is complete, just need to write the TPC test\n\n\n\n\n\n\nDoc Focus  \n\n\nNext doc focus this week 2/14\n\n\nAI (BrianL): PR reviews\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nAI (BrianL) - Follow-up with Marco about GWMS w.r.t. condor 8.9.0 security config changes\n\n\nSupport Update\n\u00b6\n\n\n\n\nAGLT2 (BrianL): high load on some worker nodes (\nls /tmp hangs\n) with some ATLAS jobs using 100% of swap. Spent last week sorting out login issues.\n\n\nAMNH (BrianL): Successfully set up job submission to the AMNH Slurm cluster.\n    There's a BLAHP/Slurm issue that Suchandra had workaround hacks for that we'll need to investigate.\n\n\nLIGO (Mat): GSI-OpenSSH hanging issue, gave them some debugging instructions.\n\n\nTopology (Carl): Copy-paste error of downtime created some issues for our consumers. We will be adding a validation check for CreatedTime.\n\n\nUFL (Derek): Missing January accounting records due to a Slurm update that broke our database queries.\n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.24\n\n\n\u0394;\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n9\n\n\n+0\n\n\nOpen\n\n\n\n\n\n\n18\n\n\n+2\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n31\n\n\n+3\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.24  \n\n\nReady for Testing  \n\n\ngsi-openssh 7.4p1-2.3\n\n\nGlideinWMS 3.4.3\n\n\n\n\n\n\nReady for Release  \n\n\nUpcoming  \n\n\nHDFS-FUSE for EL6\n\n\nSingularity 3.0.3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nEdgar is working with Jaime to sort out \ncondor_ssh_to_job\n with GlideinWMS + Singularity\n\n\nNew Perfsonar collectors testing in parallel data pipeline.\n\n\nStill waiting on XRootD 4.9 release for XCache 1.0\n\n\nWriting PEARC paper for StashCache.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "February 11, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#osg-technology-area-meeting-11-february-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Edgar, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 11 February 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#announcements",
            "text": "",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#triage-duty",
            "text": "This week: Edgar  Next week: Mat  8 (+1) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#jira",
            "text": "# of tickets  \u0394  State      157  +7  Open    43  +5  In Progress    2  +0  Ready for Testing    2  +1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#osg-software-team",
            "text": "3.4.24    XRootD 4.9.0 RC5 built, RC6 expected soon  AI (BrianL): HTCondor-CE and condor-cron builds to support HTCondor 8.9.0  AI (Edgar): TPC test setup is complete, just need to write the TPC test    Doc Focus    Next doc focus this week 2/14  AI (BrianL): PR reviews",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#discussion",
            "text": "AI (BrianL) - Follow-up with Marco about GWMS w.r.t. condor 8.9.0 security config changes",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#support-update",
            "text": "AGLT2 (BrianL): high load on some worker nodes ( ls /tmp hangs ) with some ATLAS jobs using 100% of swap. Spent last week sorting out login issues.  AMNH (BrianL): Successfully set up job submission to the AMNH Slurm cluster.\n    There's a BLAHP/Slurm issue that Suchandra had workaround hacks for that we'll need to investigate.  LIGO (Mat): GSI-OpenSSH hanging issue, gave them some debugging instructions.  Topology (Carl): Copy-paste error of downtime created some issues for our consumers. We will be adding a validation check for CreatedTime.  UFL (Derek): Missing January accounting records due to a Slurm update that broke our database queries.\n    Bockjoo has a workaround that has temporarily solved this issue but we'd like to solve this more sustainably (SOFTWARE-1588).",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#osg-release-team",
            "text": "3.4.24  \u0394;  Status      9  +0  Open    18  +2  In Progress    2  +0  Ready for Testing    2  +1  Ready for Release    31  +3  Total      OSG 3.4.24    Ready for Testing    gsi-openssh 7.4p1-2.3  GlideinWMS 3.4.3    Ready for Release    Upcoming    HDFS-FUSE for EL6  Singularity 3.0.3        Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#osg-investigations-team",
            "text": "Edgar is working with Jaime to sort out  condor_ssh_to_job  with GlideinWMS + Singularity  New Perfsonar collectors testing in parallel data pipeline.  Still waiting on XRootD 4.9 release for XCache 1.0  Writing PEARC paper for StashCache.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190211/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190204/",
            "text": "OSG Technology Area Meeting,  4 February 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Derek, Edgar, Marian, Marco Mambelli, TimT\n\n\nAnnouncements\n\u00b6\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Carl\n\n\nNext week: Edgar\n\n\n7 (+1) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n150\n\n\n+4\n\n\nOpen\n\n\n\n\n\n\n38\n\n\n+3\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n-2\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.24  \n\n\nXRootD 4.9.0 RC4 built and needs to be promoted to testing\n\n\nXCache 1.0.1 tagged and built into development\n\n\nAI (Mat): Update gsi-openssh version\n\n\nAI (Edgar): TPC test setup is complete, just need to write the TPC test\n\n\n\n\n\n\nDoc Focus  \n\n\nAI (BrianL): PR reviews\n\n\nAI (Mat): Stash registration + cache installation updates\n\n\nExpect a doodle poll for this month's doc focus\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nSupport Update\n\u00b6\n\n\n\n\nAGLT2 (BrianL): high load on some worker nodes (\nls /tmp hangs\n) with some ATLAS jobs using 100% of swap. Happening less frequently now\n\n\nClemson and UERJ (Mat, BrianL): Uncovered an issue in our HTCondor-CE installation doc (separating the job queue log from SPOOL doesn't work).\n    Reverted that documentation for now and we're discussing details with the HTCondor team.\n\n\nGlideinWMS frontends (Edgar): Can't condor_ssh_to_job in OSG jobs, discussing with the HTCondor team.\n    This may be due to singularity and/or shared port configuration.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.24\n\n\n\u0394;\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n9\n\n\n+2\n\n\nOpen\n\n\n\n\n\n\n16\n\n\n+1\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n-2\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n28\n\n\n+1\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.24  \n\n\nReady for Testing  \n\n\nxrootd-lcmaps 1.6.0\n\n\nUpcoming  \n\n\nSingularity 3.0.3\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nUpcoming  \n\n\nHDFS-FUSE for EL6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nNew Perfsonar collectors testing in parallel data pipeline.\n\n\nStill waiting on XRootD 4.9 release for XCache 1.0\n\n\nDerek broke the StashCache monitoring when deployed the new, rewritten, XCache monitors on Friday.  Fixed this morning.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "February 4, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#osg-technology-area-meeting-4-february-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Derek, Edgar, Marian, Marco Mambelli, TimT",
            "title": "OSG Technology Area Meeting,  4 February 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#announcements",
            "text": "",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#triage-duty",
            "text": "This week: Carl  Next week: Edgar  7 (+1) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#jira",
            "text": "# of tickets  \u0394  State      150  +4  Open    38  +3  In Progress    2  -2  Ready for Testing    1  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#osg-software-team",
            "text": "3.4.24    XRootD 4.9.0 RC4 built and needs to be promoted to testing  XCache 1.0.1 tagged and built into development  AI (Mat): Update gsi-openssh version  AI (Edgar): TPC test setup is complete, just need to write the TPC test    Doc Focus    AI (BrianL): PR reviews  AI (Mat): Stash registration + cache installation updates  Expect a doodle poll for this month's doc focus",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#discussion",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#support-update",
            "text": "AGLT2 (BrianL): high load on some worker nodes ( ls /tmp hangs ) with some ATLAS jobs using 100% of swap. Happening less frequently now  Clemson and UERJ (Mat, BrianL): Uncovered an issue in our HTCondor-CE installation doc (separating the job queue log from SPOOL doesn't work).\n    Reverted that documentation for now and we're discussing details with the HTCondor team.  GlideinWMS frontends (Edgar): Can't condor_ssh_to_job in OSG jobs, discussing with the HTCondor team.\n    This may be due to singularity and/or shared port configuration.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#osg-release-team",
            "text": "3.4.24  \u0394;  Status      9  +2  Open    16  +1  In Progress    2  -2  Ready for Testing    1  +0  Ready for Release    28  +1  Total      OSG 3.4.24    Ready for Testing    xrootd-lcmaps 1.6.0  Upcoming    Singularity 3.0.3      Ready for Release    Upcoming    HDFS-FUSE for EL6        Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#osg-investigations-team",
            "text": "New Perfsonar collectors testing in parallel data pipeline.  Still waiting on XRootD 4.9 release for XCache 1.0  Derek broke the StashCache monitoring when deployed the new, rewritten, XCache monitors on Friday.  Fixed this morning.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190204/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190128/",
            "text": "OSG Technology Area Meeting, 28 January 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Edgar, Marco Mambelli, Mat, TimT  \n\n\nAnnouncements\n\u00b6\n\n\nOperations F2F meeting to Tues-Thurs (\nhttps://indico.fnal.gov/event/19580/\n)  \n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: TimT\n\n\nNext week: Carl\n\n\n6 (+1) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n146\n\n\n-6\n\n\nOpen\n\n\n\n\n\n\n35\n\n\n+5\n\n\nIn Progress\n\n\n\n\n\n\n4\n\n\n+0\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n-4\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.24  \n\n\nXRootD 4.9.0 RC4 soon\n\n\nAI (Mat): What's left for XCache 1.0.1?\n\n\nAI (Mat): Update gsi-openssh version\n\n\n\n\n\n\nXCache container due at the end of the month\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nHold off on tagging XCache 1.0.1 since container work is still ongoing and finding issues\n\n\nAI (BrianL): follow-up with Marco regarding signal trapping in the blahp\n\n\nStash Cache and Origin registrations need to authZ updates before the release of XCache 1.0\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nAGLT2 (BrianL): high load on some worker nodes (\nls /tmp hangs\n) with some ATLAS jobs using 100% of swap\n\n\nFNAL (BrianL): Issues with the HTCondor accounting fix, Farrukh is in direct contact with the HTCondor team\n\n\nGeorgia Tech (Edgar): Initial cache registration is complete\n\n\nIce Cube (Edgar): Edgar set up a public squid for Ice Cube so that UW-Madison's CMS T2 can retire their public squids\n\n\nPurdue (Marco): Glideins ignoring SIGTERM because the \npbs_script.sh\n wrapper script created by the BLAHP is trapping signals and not forwarding them\n\n\nUERJ (Mat): Job router is ignoring jobs in the CE queue, discussing the issue with the HTCondor team\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.24\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n7\n\n\n+7\n\n\nOpen\n\n\n\n\n\n\n15\n\n\n+15\n\n\nIn Progress\n\n\n\n\n\n\n4\n\n\n+4\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+1\n\n\nReady for Release\n\n\n\n\n\n\n27\n\n\n+27\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.24\n\n\nReady for Testing\n\n\nxrootd-lcmaps 1.6.0\n\n\nUpcoming\n\n\nSingularity 3.0.3\n\n\n\n\n\n\n\n\n\n\nReady for Release  \n\n\nUpcoming  \n\n\nHDFS-FUSE for EL6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData  \n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Ping Marian to test xrootd-lcmaps\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\nEdgar is working with a student to do load tests of authorized reads of LIGO data from a cache.\nThey've noticed some issues when there are thousands of clients trying to read the data and will investigate it further this week.\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "January 28, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#osg-technology-area-meeting-28-january-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Edgar, Marco Mambelli, Mat, TimT",
            "title": "OSG Technology Area Meeting, 28 January 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#announcements",
            "text": "Operations F2F meeting to Tues-Thurs ( https://indico.fnal.gov/event/19580/ )",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#triage-duty",
            "text": "This week: TimT  Next week: Carl  6 (+1) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#jira",
            "text": "# of tickets  \u0394  State      146  -6  Open    35  +5  In Progress    4  +0  Ready for Testing    1  -4  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#osg-software-team",
            "text": "3.4.24    XRootD 4.9.0 RC4 soon  AI (Mat): What's left for XCache 1.0.1?  AI (Mat): Update gsi-openssh version    XCache container due at the end of the month",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#discussion",
            "text": "Hold off on tagging XCache 1.0.1 since container work is still ongoing and finding issues  AI (BrianL): follow-up with Marco regarding signal trapping in the blahp  Stash Cache and Origin registrations need to authZ updates before the release of XCache 1.0",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#support-update",
            "text": "AGLT2 (BrianL): high load on some worker nodes ( ls /tmp hangs ) with some ATLAS jobs using 100% of swap  FNAL (BrianL): Issues with the HTCondor accounting fix, Farrukh is in direct contact with the HTCondor team  Georgia Tech (Edgar): Initial cache registration is complete  Ice Cube (Edgar): Edgar set up a public squid for Ice Cube so that UW-Madison's CMS T2 can retire their public squids  Purdue (Marco): Glideins ignoring SIGTERM because the  pbs_script.sh  wrapper script created by the BLAHP is trapping signals and not forwarding them  UERJ (Mat): Job router is ignoring jobs in the CE queue, discussing the issue with the HTCondor team",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#osg-release-team",
            "text": "3.4.24  \u0394  Status      7  +7  Open    15  +15  In Progress    4  +4  Ready for Testing    1  +1  Ready for Release    27  +27  Total      OSG 3.4.24  Ready for Testing  xrootd-lcmaps 1.6.0  Upcoming  Singularity 3.0.3      Ready for Release    Upcoming    HDFS-FUSE for EL6        Data    Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#discussion_1",
            "text": "AI (TimT): Ping Marian to test xrootd-lcmaps",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#osg-investigations-team",
            "text": "Edgar is working with a student to do load tests of authorized reads of LIGO data from a cache.\nThey've noticed some issues when there are thousands of clients trying to read the data and will investigate it further this week.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190128/#discussions",
            "text": "None this week",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190122/",
            "text": "OSG Technology Area Meeting, 22 January 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianL, Carl, Derek, Edgar, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\n\n\nOSG All Hands registration open (https://opensciencegrid.org/all-hands/2019/)\n\n\nOperations F2F meeting to be held next Tues-Thurs (https://indico.fnal.gov/event/19580/)\n\n\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Carl\n\n\nNext week: TimT (?)\n\n\n5 (+0) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n152\n\n\n+2\n\n\nOpen\n\n\n\n\n\n\n30\n\n\n-1\n\n\nIn Progress\n\n\n\n\n\n\n4\n\n\n+3\n\n\nReady for Testing\n\n\n\n\n\n\n5\n\n\n+3\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.24  \n\n\nXRootD 4.9.0 RC4 soon?\n\n\nAI (BrianB, Derek, Marian, Mat): Various StashCache 1.0 tickets\n\n\nAI (Mat): Update gsi-openssh version\n\n\n\n\n\n\nXCache container due at the end of the month\n\n\nNext doc focus this Thursday, 2018-01-24\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nSupport Update\n\u00b6\n\n\n\n\nAGLT2 (BrianL): high load on some worker nodes (=ls /tmp hangs=) with some ATLAS jobs using 100% of swap\n\n\nColorado (BrianL): Tanya's group is using the hostname for blackhole detection, and they will investigate why the experiment itself is testing for the hostname.\n\n\nFNAL (BrianL): Accounting group issues are being resolved in the job router. The fix will make it into 8.6.13-1.2 and 8.8.1\n\n\nGeorgia Tech (Edgar): They got an IGTF InCommon certificate and their cache registration needs to be updated to support XCache 1.0\n\n\nInternet2 (Edgar): Bug in CVMFS fault-tolernace that is being addressed upstream\n\n\nNotre Dame (Edgar): issue with accessing Boone and other FNAL experiments from Stash Cache. Turned out to be an issue with two old squids at the UW CMS T2 that were open to the public and that IceCube depended on these squids so they can't be turned down. IceCube and Edgar will work on solutions so that they don't rely on the UW squids any longer.\n\n\nNERSC (Mat): Someone wanted to recompile OSG Software for SUSE, Mat pointed them at the tarballs and recommended the Docker images\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.23\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-9\n\n\nOpen\n\n\n\n\n\n\n1\n\n\n-15\n\n\nIn Progress\n\n\n\n\n\n\n0\n\n\n-1\n\n\nReady for Testing\n\n\n\n\n\n\n6\n\n\n+5\n\n\nReady for Release\n\n\n\n\n\n\n7\n\n\n-20\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.23 - Tomorrow (Wednesday)\n\n\nReady for Release  \n\n\ngratia-probes\n\n\nInterpret CPU expression for Hosted CEs\n\n\nSet Processors field properly for Slurm\n\n\nTests: validate processors field\n\n\n\n\n\n\nUpcoming\n\n\nHTCondor 8.8.0\n\n\nSingularity 3.0.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData\n\n\nNothing\n\n\n\n\n\n\nOperations  \n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (TimT): Ping Marian to test xrootd-lcmaps\n\n\nAI (TimT): Request testing of HDFS on EL6 from Purdue/Notre Dame\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nOSG Ops meeting next week, investigations is deeply involved in ops.\n\n\nLots of changes to the perfsonar infrastructure software.  Should be in \"testing mode\" this week.\n\n\nLots of performance tests by the experiments that may lead to xrootd bug reports which we will be facilitating.\n\n\n\n\nGRACC updates for hosted CE gratia probe fixes.  Will need to do some data analaytics.\n\n\n\n\n\n\nNeed an update - Re-organize caches behind redirectors to split load with I2 caches. Nebraska and KC cache first. Need to register the redirector with the cache discovery methods.\n\n\n\n\nNeed an update - Perfsonar mesh for the StashCache nodes, or at least nearby nodes.\n\n\n\n\nDone last week:  \n\n\n\n\nSome more SciTokens\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nAI (Edgar): Coordinate with BrianL and Mat for k8s-ization of StashCache origin and hosted CEs",
            "title": "January 22, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#osg-technology-area-meeting-22-january-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianL, Carl, Derek, Edgar, Mat, TimT",
            "title": "OSG Technology Area Meeting, 22 January 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#announcements",
            "text": "OSG All Hands registration open (https://opensciencegrid.org/all-hands/2019/)  Operations F2F meeting to be held next Tues-Thurs (https://indico.fnal.gov/event/19580/)",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#triage-duty",
            "text": "This week: Carl  Next week: TimT (?)  5 (+0) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#jira",
            "text": "# of tickets  \u0394  State      152  +2  Open    30  -1  In Progress    4  +3  Ready for Testing    5  +3  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#osg-software-team",
            "text": "3.4.24    XRootD 4.9.0 RC4 soon?  AI (BrianB, Derek, Marian, Mat): Various StashCache 1.0 tickets  AI (Mat): Update gsi-openssh version    XCache container due at the end of the month  Next doc focus this Thursday, 2018-01-24",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#discussion",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#support-update",
            "text": "AGLT2 (BrianL): high load on some worker nodes (=ls /tmp hangs=) with some ATLAS jobs using 100% of swap  Colorado (BrianL): Tanya's group is using the hostname for blackhole detection, and they will investigate why the experiment itself is testing for the hostname.  FNAL (BrianL): Accounting group issues are being resolved in the job router. The fix will make it into 8.6.13-1.2 and 8.8.1  Georgia Tech (Edgar): They got an IGTF InCommon certificate and their cache registration needs to be updated to support XCache 1.0  Internet2 (Edgar): Bug in CVMFS fault-tolernace that is being addressed upstream  Notre Dame (Edgar): issue with accessing Boone and other FNAL experiments from Stash Cache. Turned out to be an issue with two old squids at the UW CMS T2 that were open to the public and that IceCube depended on these squids so they can't be turned down. IceCube and Edgar will work on solutions so that they don't rely on the UW squids any longer.  NERSC (Mat): Someone wanted to recompile OSG Software for SUSE, Mat pointed them at the tarballs and recommended the Docker images",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#osg-release-team",
            "text": "3.4.23  \u0394  Status      0  -9  Open    1  -15  In Progress    0  -1  Ready for Testing    6  +5  Ready for Release    7  -20  Total      OSG 3.4.23 - Tomorrow (Wednesday)  Ready for Release    gratia-probes  Interpret CPU expression for Hosted CEs  Set Processors field properly for Slurm  Tests: validate processors field    Upcoming  HTCondor 8.8.0  Singularity 3.0.2        Data  Nothing    Operations    Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#discussion_1",
            "text": "AI (TimT): Ping Marian to test xrootd-lcmaps  AI (TimT): Request testing of HDFS on EL6 from Purdue/Notre Dame",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#osg-investigations-team",
            "text": "OSG Ops meeting next week, investigations is deeply involved in ops.  Lots of changes to the perfsonar infrastructure software.  Should be in \"testing mode\" this week.  Lots of performance tests by the experiments that may lead to xrootd bug reports which we will be facilitating.   GRACC updates for hosted CE gratia probe fixes.  Will need to do some data analaytics.    Need an update - Re-organize caches behind redirectors to split load with I2 caches. Nebraska and KC cache first. Need to register the redirector with the cache discovery methods.   Need an update - Perfsonar mesh for the StashCache nodes, or at least nearby nodes.   Done last week:     Some more SciTokens",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190122/#discussions",
            "text": "AI (Edgar): Coordinate with BrianL and Mat for k8s-ization of StashCache origin and hosted CEs",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190114/",
            "text": "OSG Technology Area Meeting, 14 January 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianB, BrianL, Derek, Edgar, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nNext meeting on Tues Jan 22, 2018 due to MLK Jr day  \n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Mat\n\n\nNext week: Carl\n\n\n5 (-1) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n150\n\n\n+2\n\n\nOpen\n\n\n\n\n\n\n31\n\n\n+5\n\n\nIn Progress\n\n\n\n\n\n\n1\n\n\n-1\n\n\nReady for Testing\n\n\n\n\n\n\n2\n\n\n-1\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\n3.4.23  \n\n\nAI (Carl): Release gratia-probe 1.18.28+\n\n\nAI (BrianB, Derek, Marian, Mat): Various StashCache 1.0 tickets\n\n\nAI (Mat): Update gsi-openssh version\n\n\nAI (BrianB): Review BrianL's xrootd-lcmaps pull request\n\n\n\n\n\n\nXCache container due at the end of the month\n\n\nNext doc focus 2018-01-24\n\n\nPotential student hire at UW-Madison\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nA default XCache image will serve as the base for StashCache and ATLAS XCache\n\n\nOrganize XCache Dockerfiles in a single repository either under different directories or branches\n\n\n\n\nSupport Update\n\u00b6\n\n\n\n\nAGLT2 (BrianL): high load on some worker nodes (\nls /tmp hangs\n) with some ATLAS jobs using 100% of swap\n\n\nColorado (BrianL): Some FIFE jobs are failing to fetch the worker node hostname causing job failure. As a result, FNAL is blacklisting Colorado.\n\n\nFNAL (BrianL): Accounting group issues when submitting jobs through a CE. The same user can show up under the CE UID domain or the local batch system UID domain\n\n\nGeorgia Tech (Derek, Edgar): They need some help registering a Stash cache and updating their registration to support XCache 1.0. Edgar is working with them to get an IGTF InCommon certificate.\n\n\n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.23\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n9\n\n\n-3\n\n\nOpen\n\n\n\n\n\n\n16\n\n\n+7\n\n\nIn Progress\n\n\n\n\n\n\n1\n\n\n-1\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n27\n\n\n+3\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.23 - Perhaps this week\n\n\nReady for Release  \n\n\nHTCondor 8.8.0\n\n\n\n\n\n\n\n\n\n\nData - today\n\n\nIGTF 1.95\n\n\n\n\n\n\nOperations\n\n\nNothing\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (Carl): Manually test HDFS 2.6 on EL6 packages, especially upgrades from EL6.\n\n\nAI (BrianL, TimT): Write HDFS release notes to indicate that this update is only intended to support mounting HDFS via FUSE with EL6 clients.\n    It is not intended for updating name nodes, data nodes, XRootD, or GridFTP hosts. Instead we recommend updating to EL7.\n\n\n\n\nOSG Investigations Team\n\u00b6\n\n\n\n\nRe-organize caches behind redirectors to split load with I2 caches. Nebraska and KC cache first. Need to register the redirector with the cache discovery methods.\n\n\nPerfsonar mesh for the StashCache nodes, or at least nearby nodes.\n\n\nRe-organize the PerfSonar Collectors\n\n\n\n\nDone last week:  \n\n\n\n\nLots of SciTokens effort that will be integrated into the campus and user support teams for Stash Writeback support.\n\n\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nAI (Edgar): Coordinate with BrianL and Mat for k8s-ization of StashCache origin and hosted CEs",
            "title": "January 14, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#osg-technology-area-meeting-14-january-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianB, BrianL, Derek, Edgar, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting, 14 January 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#announcements",
            "text": "Next meeting on Tues Jan 22, 2018 due to MLK Jr day",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#triage-duty",
            "text": "This week: Mat  Next week: Carl  5 (-1) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#jira",
            "text": "# of tickets  \u0394  State      150  +2  Open    31  +5  In Progress    1  -1  Ready for Testing    2  -1  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#osg-software-team",
            "text": "3.4.23    AI (Carl): Release gratia-probe 1.18.28+  AI (BrianB, Derek, Marian, Mat): Various StashCache 1.0 tickets  AI (Mat): Update gsi-openssh version  AI (BrianB): Review BrianL's xrootd-lcmaps pull request    XCache container due at the end of the month  Next doc focus 2018-01-24  Potential student hire at UW-Madison",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#discussion",
            "text": "A default XCache image will serve as the base for StashCache and ATLAS XCache  Organize XCache Dockerfiles in a single repository either under different directories or branches",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#support-update",
            "text": "AGLT2 (BrianL): high load on some worker nodes ( ls /tmp hangs ) with some ATLAS jobs using 100% of swap  Colorado (BrianL): Some FIFE jobs are failing to fetch the worker node hostname causing job failure. As a result, FNAL is blacklisting Colorado.  FNAL (BrianL): Accounting group issues when submitting jobs through a CE. The same user can show up under the CE UID domain or the local batch system UID domain  Georgia Tech (Derek, Edgar): They need some help registering a Stash cache and updating their registration to support XCache 1.0. Edgar is working with them to get an IGTF InCommon certificate.",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#osg-release-team",
            "text": "3.4.23  \u0394  Status      9  -3  Open    16  +7  In Progress    1  -1  Ready for Testing    1  +0  Ready for Release    27  +3  Total      OSG 3.4.23 - Perhaps this week  Ready for Release    HTCondor 8.8.0      Data - today  IGTF 1.95    Operations  Nothing    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#discussion_1",
            "text": "AI (Carl): Manually test HDFS 2.6 on EL6 packages, especially upgrades from EL6.  AI (BrianL, TimT): Write HDFS release notes to indicate that this update is only intended to support mounting HDFS via FUSE with EL6 clients.\n    It is not intended for updating name nodes, data nodes, XRootD, or GridFTP hosts. Instead we recommend updating to EL7.",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#osg-investigations-team",
            "text": "Re-organize caches behind redirectors to split load with I2 caches. Nebraska and KC cache first. Need to register the redirector with the cache discovery methods.  Perfsonar mesh for the StashCache nodes, or at least nearby nodes.  Re-organize the PerfSonar Collectors   Done last week:     Lots of SciTokens effort that will be integrated into the campus and user support teams for Stash Writeback support.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190114/#discussions",
            "text": "AI (Edgar): Coordinate with BrianL and Mat for k8s-ization of StashCache origin and hosted CEs",
            "title": "Discussions"
        },
        {
            "location": "/meetings/2019/TechArea20190107/",
            "text": "OSG Technology Area Meeting,  7 January 2019\n\u00b6\n\n\nCoordinates:\n Conference: 719-284-5267, PIN: 57363; \nhttps://www.uberconference.com/osgblin\n\n\nAttending:\n BrianB, BrianL, Carl, Derek, Edgar, Marco, Marian, Mat, TimT\n\n\nAnnouncements\n\u00b6\n\n\nTriage Duty\n\u00b6\n\n\n\n\nThis week: Edgar\n\n\nNext week: Mat\n\n\n6 (+1) open tickets\n\n\n\n\nJIRA\n\u00b6\n\n\n\n\n\n\n\n\n# of tickets\n\n\n\u0394\n\n\nState\n\n\n\n\n\n\n\n\n\n\n148\n\n\n-4\n\n\nOpen\n\n\n\n\n\n\n26\n\n\n+5\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n+1\n\n\nReady for Testing\n\n\n\n\n\n\n3\n\n\n+0\n\n\nReady for Release\n\n\n\n\n\n\n\n\nOSG Software Team\n\u00b6\n\n\n\n\nXCache container due at the end of the month\n\n\nTopology auto-merge: what's left?\n\n\n3.4.23  \n\n\nAI (BrianB, Derek, Marian, Mat): Various StashCache 1.0 tickets\n\n\nAI (Mat): Update gsi-openssh version\n\n\nAI (BrianB): Review BrianL's xrootd-lcmaps pull request\n\n\n\n\n\n\nNext doc focus 2018-01-24\n\n\nPotential student hire at UW-Madison\n\n\n\n\nDiscussion\n\u00b6\n\n\n\n\nAI (BrianL, Mat): Coordinate and divvy XCache container work\n\n\nAI (Carl) Auto-merge PR to be submitted midweek\n\n\nGlideinWMS changed the schedd port from 9615 to 9618 in 3.4.1; we need to find the number of submit hosts still listening on 9615, notify them about the change and update the documentation\n\n\nUNL has been running XRootD-4.9 RC3 since Dec 21st\n\n\n\n\nSupport Update\n\u00b6\n\n\nNone this week  \n\n\nOSG Release Team\n\u00b6\n\n\n\n\n\n\n\n\n3.4.23\n\n\n\u0394\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\n12\n\n\n+5\n\n\nOpen\n\n\n\n\n\n\n9\n\n\n+4\n\n\nIn Progress\n\n\n\n\n\n\n2\n\n\n-7\n\n\nReady for Testing\n\n\n\n\n\n\n1\n\n\n-1\n\n\nReady for Release\n\n\n\n\n\n\n24\n\n\n+1\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\nOSG 3.4.23 - Thursday or Wednesday Release\n\n\nTesting  \n\n\nHTCondor 8.8.0\n\n\n\n\n\n\nReady for Release  \n\n\nHDFS-FUSE for EL6\n\n\n\n\n\n\n\n\n\n\nData - this week\n\n\nPerhaps IGTF 1.95\n\n\n\n\n\n\nOperations - Tuesday Release\n\n\nrepo-update-cadist updates\n\n\noasis-goc\n\n\n\n\n\n\nContrib  \n\n\nNothing\n\n\n\n\n\n\n\n\nDiscussion\n\u00b6\n\n\nNone this week  \n\n\nOSG Investigations Team\n\u00b6\n\n\nThis week is mostly catching up with the changes made over the break.\n\n\n\n\nXRootD monitoring collector: Large refactor\n\n\nAlso making changes for WLCG compatibility.\n\n\n\n\n\n\nStashCache Origin configs generated from Topology.\n\n\nRe-organize caches behind redirectors to split load with I2 caches. Nebraska and KC cache first. Need to register the redirector with the cache discovery methods.\n\n\nPerfsonar mesh for the StashCache nodes, or at least nearby nodes.\n\n\n\n\nFinishing XCache is the focus for the next few weeks.\n\n\nOngoing\n\u00b6\n\n\n\n\nGRACC Project\n\n\nStashCache Project\n\n\n\n\nDiscussions\n\u00b6\n\n\nNone this week",
            "title": "January 7, 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#osg-technology-area-meeting-7-january-2019",
            "text": "Coordinates:  Conference: 719-284-5267, PIN: 57363;  https://www.uberconference.com/osgblin  Attending:  BrianB, BrianL, Carl, Derek, Edgar, Marco, Marian, Mat, TimT",
            "title": "OSG Technology Area Meeting,  7 January 2019"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#announcements",
            "text": "",
            "title": "Announcements"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#triage-duty",
            "text": "This week: Edgar  Next week: Mat  6 (+1) open tickets",
            "title": "Triage Duty"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#jira",
            "text": "# of tickets  \u0394  State      148  -4  Open    26  +5  In Progress    2  +1  Ready for Testing    3  +0  Ready for Release",
            "title": "JIRA"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#osg-software-team",
            "text": "XCache container due at the end of the month  Topology auto-merge: what's left?  3.4.23    AI (BrianB, Derek, Marian, Mat): Various StashCache 1.0 tickets  AI (Mat): Update gsi-openssh version  AI (BrianB): Review BrianL's xrootd-lcmaps pull request    Next doc focus 2018-01-24  Potential student hire at UW-Madison",
            "title": "OSG Software Team"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#discussion",
            "text": "AI (BrianL, Mat): Coordinate and divvy XCache container work  AI (Carl) Auto-merge PR to be submitted midweek  GlideinWMS changed the schedd port from 9615 to 9618 in 3.4.1; we need to find the number of submit hosts still listening on 9615, notify them about the change and update the documentation  UNL has been running XRootD-4.9 RC3 since Dec 21st",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#support-update",
            "text": "None this week",
            "title": "Support Update"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#osg-release-team",
            "text": "3.4.23  \u0394  Status      12  +5  Open    9  +4  In Progress    2  -7  Ready for Testing    1  -1  Ready for Release    24  +1  Total      OSG 3.4.23 - Thursday or Wednesday Release  Testing    HTCondor 8.8.0    Ready for Release    HDFS-FUSE for EL6      Data - this week  Perhaps IGTF 1.95    Operations - Tuesday Release  repo-update-cadist updates  oasis-goc    Contrib    Nothing",
            "title": "OSG Release Team"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#discussion_1",
            "text": "None this week",
            "title": "Discussion"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#osg-investigations-team",
            "text": "This week is mostly catching up with the changes made over the break.   XRootD monitoring collector: Large refactor  Also making changes for WLCG compatibility.    StashCache Origin configs generated from Topology.  Re-organize caches behind redirectors to split load with I2 caches. Nebraska and KC cache first. Need to register the redirector with the cache discovery methods.  Perfsonar mesh for the StashCache nodes, or at least nearby nodes.   Finishing XCache is the focus for the next few weeks.",
            "title": "OSG Investigations Team"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#ongoing",
            "text": "GRACC Project  StashCache Project",
            "title": "Ongoing"
        },
        {
            "location": "/meetings/2019/TechArea20190107/#discussions",
            "text": "None this week",
            "title": "Discussions"
        }
    ]
}